<?xml version="1.0" encoding="UTF-8"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>InfoQ 推荐</title><link>https://www.infoq.cn</link><atom:link href="http://10.0.0.5:1200/infoq/recommend" rel="self" type="application/rss+xml"></atom:link><description>InfoQ 推荐 - Powered by RSSHub</description><generator>RSSHub</generator><webMaster>contact@rsshub.app (RSSHub)</webMaster><language>en</language><lastBuildDate>Wed, 11 Feb 2026 19:05:53 GMT</lastBuildDate><ttl>5</ttl><item><title>ChatGPT的第一块广告位，被谁买走了？OpenAI：别骂，我们这次所有底线都招了</title><description>&lt;p&gt;整理 | 华卫&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;ChatGPT 无广告体验的日子要结束了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;经过数周的预热，刚刚，OpenAI宣布，将正式开始在其AI平台测试广告，ChatGPT用户可能很快就会在对话中看到广告。这些广告会以标注“赞助”的链接形式出现在ChatGPT回答底部，但OpenAI表示，广告不会影响ChatGPT给出的回答内容，在视觉上也会区分开来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前，广告仅对免费版ChatGPT用户以及每月8美元的低价订阅服务Go套餐用户展示，Plus、Pro、商业版、企业版和教育版用户不会看到任何广告。也就是说，想要避开广告的用户至少需要每月支付20美元订阅Plus套餐。OpenAI提到，免费版用户要想退出广告，但代价是每日免费对话次数减少；Go套餐用户无法选择退出广告。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://uploader.shimo.im/f/2bKQWp6d3KB8gasG.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3NzA4MDQzMzUsImZpbGVHVUlEIjoiS2xrS3ZteFl6cENnbVhxZCIsImlhdCI6MTc3MDgwNDAzNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwicGFhIjoiYWxsOmFsbDoiLCJ1c2VySWQiOjUxNzIzNzI1fQ.p13l2Z-_MU334JoSfqO9fDApNfEl33BiVbOB7URaies&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一位接近OpenAI的消息人士表示，OpenAI预计从长远来看，广告收入占比将低于其总收入的一半。目前，该公司还通过其聊天机器人集成的购物功能，从用户购买的商品中抽取分成。另据外媒报道，OpenAI首席执行官Sam Altman告诉员工，ChatGPT“月增长率已恢复到10%以上”，将于本周部署“更新后的聊天模型”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;ChatGPT 广告规则全曝光&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此次广告功能推出前，Anthropic在一则广告中暗讽了ChatGPT的广告模式。例如在其中一则广告里，一名年轻男子向人工智能求助练出六块腹肌，化身私人教练的 AI 先是为他提供指导，随后却开始推销一款虚构的增高鞋垫。之后，Anthropic修改了广告标语，改为：“广告自有其时间与场合，但你和AI的对话不该是其中之一。”而这很快引发了 Altman的不满，他称其“明显不诚实”，是在用“欺骗性广告去批评那些并不存在、理论上的欺骗性广告”，与他们实际的广告模式不符。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;就在OpenAI最新一期的播客里，OpenAI 的广告负责人之一 Asad Awan 详细介绍了其AI产品中的广告制定决策。“一方面走‘清高路线’，不做广告，但同时限制使用额度、用能力较弱的模型；另一方面，拥抱广告模式。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这场对话中，不少外界关注的核心问题都摆到了台面上，且给出了清晰的回答。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;从用户角度看，为什么要做广告？为什么是现在？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“这回到了我们的使命，让 AGI 惠及全人类。”Awan解释道，当一款消费级产品有超过 8 亿用户时，如何把最好的产品带给每个人？广告是经过验证的成熟模式，对于一家希望把最好的 AI 带给全人类的公司来说，这是很自然的选择。提供最好的模型、更高的使用限额，让广告对用户和企业都真正有用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他表示，大家担心广告可能带来负面影响，所以OpenAI 更看重广告的原则：为平台设立极高的标准，让广告真正有用。其确立了几条核心原则：&lt;/p&gt;&lt;p&gt;第一，模型回答与广告完全独立，无论视觉上还是模型训练、系统逻辑上，确保回答始终可信，整个产品都建立在信任之上。第二，对话是隐私的。敏感对话绝不会出现广告，对话内容绝不会共享给广告主。我们会在内部匹配合适的广告，但广告主看不到用户对话。第三，透明与可控。用户能清楚理解数据如何使用，并且可以自主控制。第四，激励机制以用户价值为中心。我们不追求用户在平台上的停留时长，一个真正有用的广告就足够了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“简单来说就是，用广告普及 AI，同时严防各种负面问题，从一开始就明确原则，持续测试、改进。”Awan说道。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;广告的出现频率是怎样的？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“最高原则是：有没有有用的广告可以展示。”Awan称，核心原则是：是否有用、有帮助、对用户的操作有补充，能不能展示优质商品，内容质量要高、广告质量要高、相关性要高。“如果没有，我们宁可一条都不展示。实际上在测试阶段，你会看到广告非常少，因为我们态度很保守，也在学习该在什么位置插入。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据介绍，模型看不到广告，也有防护措施。“狂轰滥炸广告对用户、对商家都没好处。我们不想让广告主乱花钱买曝光，也不想让用户看一堆广告，我们只想展示那条正确的广告。作为顶尖 AI 公司，这正是我们能做好的事。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;当公司有专门的广告收入部门时，还会把模型和广告之间这堵墙砌死吗？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“只要目标和激励机制是成为最值得信任的 AI，我们就不会走偏。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Awan强调，“我们的核心业务是信任。对 C 端用户，是提供可信的优质回答；对企业客户，信任更是一切，你把最重要的数据交给我们，我们必须守住。如果我们真的想成为你最贴身的智能助手，就必须让你放心分享最重要的信息，并且知道它会被妥善对待。我们的商业模式就是 信任，这和很多只做一次性查询、内容推荐的产品完全不同。对我们而言，信任不是可选项，而是必需品。我们希望被用户记住的，就是‘可信’。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;如何回应拿广告这件事开玩笑的竞争对手？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“不同公司使命不同。”Awan表示，OpenAI的业务场景更多元：企业业务、订阅业务、海量免费用户业务。企业版没有广告，订阅版没有广告，广告是为了支撑免费用户业务。“如果你的使命不是普惠 AI，那不做广告很合理；但我们的使命就是在各类场景里落地，让所有人用上最好的 AI。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他强调，如果只服务付费用户，当然可以说 “我们不用做广告”。但OpenAI的愿景不是抽象的，而是非常实在：AI 如何真正帮助普通人。“如果走精英路线，只有付得起钱的人才能用 AI，那从价值观上我们就不认同。我们的立场非常明确：每个人都应该用上最好的 AI。而且我们不是一家纯广告公司，纯广告公司的激励机制和我们完全不同。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;十年后的广告会变成什么样？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;据Awan透露，下一步会是更真实的对话式广告，能真正了解产品是什么。再往后，AI 可以在后台自动聚合最优折扣、最划算的商品、最合适的版本。一边是用户主动搜索，一边是商家希望被合适的人发现，两边匹配起来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“未来会更加智能体化。我们先从现有形式开始，把体验做好，让它更相关、可控、可理解、可信。随着主产品和系统进化，广告形态也会一起进化。”Awan表示。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;第一批投放广告的公司露面了&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;ChatGPT 推出广告之际，正值人工智能行业竞争压力不断加剧，且外界对大型 AI 平台的可持续盈利模式抱有更高期待。OpenAI表示，“ChatGPT 被数亿人用于学习、工作和日常决策。为了确保免费版和 Go 版的快速稳定运行，我们需要投入大量基础设施和持续资金。广告收入有助于资助这些工作，从而通过更高质量的免费和低成本选项，让更多人能够使用人工智能，并使我们能够不断提升所提供的智能和功能。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;同时，该公司称，广告商只会获得汇总的广告浏览量和点击量数据，不会获取用户的ChatGPT对话个性化数据或内容。免费版和Go版用户都可以对广告反馈、关闭广告个性化设置、关闭基于历史对话的广告推荐，从而限制赞助内容的推送方式并删除广告相关数据。此外，OpenAI现在并非对所有用户和对话都会投放广告，比如18 岁以下用户以及涉及健康、心理健康、政治等特定敏感话题的对话场景。即便免费版与 Go 版的成年用户，也未必会立即看到广告，因为该功能仍处于测试阶段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://uploader.shimo.im/f/vAnwSrozg2s8yFXP.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJleHAiOjE3NzA4MDQzMzUsImZpbGVHVUlEIjoiS2xrS3ZteFl6cENnbVhxZCIsImlhdCI6MTc3MDgwNDAzNSwiaXNzIjoidXBsb2FkZXJfYWNjZXNzX3Jlc291cmNlIiwicGFhIjoiYWxsOmFsbDoiLCJ1c2VySWQiOjUxNzIzNzI1fQ.p13l2Z-_MU334JoSfqO9fDApNfEl33BiVbOB7URaies&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;尽管此举在ChatGPT用户和行业观察人士中引发了褒贬不一的反应，但 OpenAI 坚称，投放广告是为了补贴免费及低价服务的使用成本。该公司强调，“此次测试的重点是学习。我们会密切关注反馈，以确保广告在推广之前能够实用且自然地融入ChatGPT体验。”早期用户的反馈将有助于改进广告，并可能在未来扩大广告投放范围。OpenAI 表示，将利用此次试点项目的洞察，更好地平衡盈利与用户体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当前，已有多家公司也透露了他们将如何投放 ChatGPT 广告。Adobe表示，将率先投放 Acrobat Studio 和 Firefly 相关广告作为初期试点。已经与 ChatGPT 完成集成的Target，则会在用户提出诸如“有哪些台面式厨电能让日常做饭更方便？”这类问题时展示广告。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而随着测试的推进，OpenAI 的做法很可能会影响其他人工智能公司对盈利模式的思考，以及广告在对话式 AI 工具中的角色。不过，开发 Claude AI 助手的 Anthropic 已 “承诺” 永远不会加入广告，甚至还在投放了的一系列超级碗广告里宣传这一决定。据报道， OpenAI 的竞争对手谷歌也曾暗示，其 Gemini AI 平台可能会在 2026 年投放广告，不过谷歌 DeepMind 首席执行官 Demis Hassabis 在 1 月底表示，Gemini “没有计划”投放广告。目前，谷歌已在搜索结果旁边的 AI 概览中投放广告。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在未来某一天，或许所有免费的AI应用和服务都会出现广告，但至少目前，ChatGPT是唯一一家率先推出广告的大型应用和服务商。微软Copilot之前的版本（当时名为Bing Chat）也曾出现过广告，但目前的版本似乎已经取消了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://openai.com/index/testing-ads-in-chatgpt/&quot;&gt;https://openai.com/index/testing-ads-in-chatgpt/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.cnbc.com/2026/02/09/sam-altman-touts-chatgpt-growth-as-openai-nears-100-billion-funding.html&quot;&gt;https://www.cnbc.com/2026/02/09/sam-altman-touts-chatgpt-growth-as-openai-nears-100-billion-funding.html&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=2agJo3Jf_O4&quot;&gt;https://www.youtube.com/watch?v=2agJo3Jf_O4&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/Y6SK6Mu5t4gmCk5mhxvk</link><guid isPermaLink="false">https://www.infoq.cn/article/Y6SK6Mu5t4gmCk5mhxvk</guid><pubDate>Wed, 11 Feb 2026 10:01:56 GMT</pubDate><author>华卫</author><category>AI&amp;大模型</category></item><item><title>传字节今年要造10万颗推理芯片，1600 亿预算砸向AI！</title><description>&lt;p&gt;整理 | 华卫&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;近日，据两位知情人士透露，字节跳动正研发AI芯片，并与三星电子洽谈代工生产事宜。知情人士称，字节跳动目标是在3 月底前获得芯片样片。其中一位消息源及另一位相关人士表示，该芯片专为AI 推理任务设计，公司计划今年至少生产10 万颗，并有望逐步将产能提升至35 万颗。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一位消息源指出，与三星的谈判还包括获取存储芯片供应。在全球 AI 基础设施建设热潮下，存储芯片供应极度紧缺，这也让这笔合作更具吸引力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;字节跳动发言人在一份声明中表示，有关其自研芯片项目的信息不准确，但未做进一步说明。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;若推进顺利，此举将成为字节跳动的一个里程碑。该公司长期以来一直希望研发芯片以支撑自身 AI 业务，其芯片相关布局最早可追溯至 2022 年，当时便已开始大规模招聘芯片领域人才。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该芯片项目代号为 SeedChip，是字节跳动全面加码 AI 研发的一部分。 从芯片到大语言模型，公司押注这项技术将彻底改造其涵盖短视频、电商、企业云服务的业务版图。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;字节跳动于 2023 年成立 Seed 部门，专注研发 AI 大模型并推动其落地应用。据一位消息人士透露，字节跳动今年计划在 AI 相关采购上投入 超过 1600 亿元人民币（约 220 亿美元），其中超过一半用于采购英伟达芯片（包括 H200）以及推进自研芯片。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据第四位知情会议内容的人士称，字节跳动高管赵祺在 1 月的全员大会上向员工表示，公司的 AI 投入将惠及所有业务部门。赵祺目前负责字节跳动的豆包聊天机器人及其海外版本 Dola。他坦言，公司的 AI 大模型仍落后于 OpenAI 等全球领先者，但承诺今年将继续大力支持 AI 研发。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.reuters.com/world/asia-pacific/bytedance-developing-ai-chip-manufacturing-talks-with-samsung-sources-say-2026-02-11/&quot;&gt;https://www.reuters.com/world/asia-pacific/bytedance-developing-ai-chip-manufacturing-talks-with-samsung-sources-say-2026-02-11/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/AradpbWZZoiWVmehvBLB</link><guid isPermaLink="false">https://www.infoq.cn/article/AradpbWZZoiWVmehvBLB</guid><pubDate>Wed, 11 Feb 2026 09:40:36 GMT</pubDate><author>华卫</author><category>芯片&amp;算力</category></item><item><title>从多模态走向全模态！蚂蚁开源 Ming-Flash-Omni 2.0，对标Gemini 2.5 Pro</title><description>&lt;p&gt;2 月 11 日，蚂蚁集团开源发布全模态大模型 Ming-Flash-Omni 2.0。在多项公开基准测试中，该模型在视觉语言理解、语音可控生成、图像生成与编辑等关键能力表现突出，部分指标超越Gemini 2.5 Pro。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;模型地址：https://github.com/inclusionAI/Ming&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;据介绍，Ming-Flash-Omni 2.0 是业界首个全场景音频统一生成模型，可在同一条音轨中同时生成语音、环境音效与音乐。用户只需用自然语言下指令，即可对音色、语速、语调、音量、情绪与方言等进行精细控制。模型在推理阶段实现了&amp;nbsp;3.1Hz 的极低推理帧率，实现了分钟级长音频的实时高保真生成，在推理效率与成本控制上走在前列。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c6/c6ced55efdf5e6d69a184c6e8ce4b68a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（图说：Ming-Flash-Omni-2.0&amp;nbsp;在视觉语言理解、语音可控生成、图像生成与编辑等核心领域实测表现均已达到开源领先水准）&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;全模态和多模态有啥不一样？&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在大模型快速演进的背景下，“多模态”和“全模态”这两个概念正在频繁出现在技术发布和行业讨论中。表面看，它们都指向“模型能处理多种类型的数据”，但在底层实现路径和能力边界上，两者存在本质差异。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从能力表象来看，多模态与全模态高度相似。无论是多模态大模型还是全模态大模型，用户侧的直观体验都是：模型可以同时接收文本、图片、视频，甚至音频等不同模态的输入，并给出统一的输出结果。这也是许多非技术用户容易将两者混为一谈的原因。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;真正的分水岭，出现在模型内部的实现方式。目前主流的“多模态大模型”，本质上是一种“模型拼装”思路：针对不同模态的数据，系统会分别调用对应的专用模型进行处理——例如，文本由语言模型理解，图像由视觉模型解析，音频交给语音模型识别。随后，再通过一个融合模块，将来自不同模型的结果进行整合，生成最终输出。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种架构的优势在于工程实现相对成熟、可控，也便于在已有单模态模型基础上快速扩展能力。但其局限同样明显：不同模态之间更多是“后验融合”，信息在中间环节已经被压缩或结构化，跨模态的深层语义关联难以充分建模。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;相比之下，“全模态大模型”走的是一条更底层的路线。所谓全模态，并不是简单地“支持更多输入类型”，而是指模型在设计之初，就将多种模态视为统一的信息空间，在同一个模型参数体系中进行联合建模。文本、图像、音频、视频不再对应独立的子模型，而是通过统一的表示方式进入同一套网络中学习、推理和生成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这意味着，全模态大模型具备原生的跨模态理解与生成能力：不同模态之间的关联不是在输出阶段“拼接”出来的，而是在模型内部的表示层和推理过程中自然形成的。从理论上看，这种架构更接近人类对世界的感知方式，也更有潜力支持复杂的跨模态推理任务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在当下，大多数落地应用仍然基于多模态架构。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;业内普遍认为，多模态大模型最终会走向更统一的架构，让不同模态与任务实现更深层协同。但现实是，“全模态”模型往往很难同时做到通用与专精：在特定单项能力上，开源模型往往不及专用模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;蚂蚁集团在全模态方向已持续投入多年，Ming-Omni系列正是在这一背景下持续演进：早期版本构建统一多模态能力底座，中期版本验证规模增长带来的能力提升，而最新2.0版本通过更大规模数据与系统性训练优化，将全模态理解与生成能力推至开源领先水平，并在部分领域超越顶级专用模型。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此次将Ming-Flash-Omni 2.0 开源，意味着其核心能力以“可复用底座”的形式对外释放，为端到端多模态应用开发提供统一能力入口。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ming-Flash-Omni 2.0 基于 Ling-2.0 架构（MoE，100B-A6B）训练，围绕“看得更准、听得更细、生成更稳”三大目标全面优化。视觉方面，融合亿级细粒度数据与难例训练策略，显著提升对近缘动植物、工艺细节和稀有文物等复杂对象的识别能力；音频方面，实现语音、音效、音乐同轨生成，支持自然语言精细控制音色、语速、情绪等参数，并具备零样本音色克隆与定制能力；图像方面，增强复杂编辑的稳定性，支持光影调整、场景替换、人物姿态优化及一键修图等功能，在动态场景中仍保持画面连贯与细节真实。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;百灵模型负责人周俊表示，全模态技术的关键在于通过统一架构实现多模态能力的深度融合与高效调用。开源后，开发者可基于同一套框架复用视觉、语音与生成能力，显著降低多模型串联的复杂度与成本。未来，团队将持续优化视频时序理解、复杂图像编辑与长音频生成实时性，完善工具链与评测体系，推动全模态技术在实际业务中规模化落地。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description><link>https://www.infoq.cn/article/d9TEFiU7kq8EKCIodTmI</link><guid isPermaLink="false">https://www.infoq.cn/article/d9TEFiU7kq8EKCIodTmI</guid><pubDate>Wed, 11 Feb 2026 09:31:43 GMT</pubDate><author>李冬梅</author><category>生成式 AI</category></item><item><title>Snowflake 语义视图自动驾驶：分钟级 AI 驱动的语义建模 ｜ 技术趋势</title><description>&lt;p&gt;2026 年，智能体将在企业级应用中取得哪些实质性突破？&lt;a href=&quot;https://www.infoq.cn/minibook/keTZm4fpOmFEzmx77Zpq&quot;&gt;点击下载&lt;/a&gt;&quot;《2026 年 AI 与数据发展预测》白皮书，获悉专家一手前瞻，抢先拥抱新的工作方式！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具备治理性、可信语义的数据层已成为AI就绪数据的基础能力。近日，Snowflake正式宣布语义视图自动驾驶（Semantic View Autopilot，SVA） 全面上市。该系统能够基于现有查询与商业智能资产，自动生成语义视图。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;问题在于定义缺失，而非大语言模型能力&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2025年，开发 AI 智能体的团队发现，即便最先进的模型也难以应对不一致的业务逻辑。真正的障碍并非 AI 能力，而是数据定义的缺失。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;VTS 工程高级副总裁 Prashanth Sanagavarapu 指出：“构建并维护统一的语义层需要大量人工投入，以避免数据指标冲突。” 为此，我们推出语义视图自动驾驶方案，旨在自动化构建这一具备治理能力且可信的语义层。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“语义视图自动驾驶技术为我们的 AI 系统提供了统一且受控的业务指标理解框架……使我们能够提供可靠的个性化服务及AI驱动的交互体验，赢得客户的长期信任。”Simon AI 首席技术官 Matt Walker 表示。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Snowflake 自动化语义视图创建&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;语义视图不仅提供数据结构信息，更能阐释数据的业务含义与设计意图。它能够指导大语言模型（LLM）将原始数据转化为业务概念，但传统的创建过程往往耗时费力且高度依赖人工操作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对数据团队而言，确保业务逻辑的一致性至关重要。然而，人工创建语义视图负担沉重，例如，产品团队定义“月度经常性收入”时，可能未意识到财务部门会排除一次性设置费用。这类隐藏规则通常仅在部署后、数据对不齐时才会暴露。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Snowflake语义视图自动化功能（SVA）通过自动创建和管理语义视图来弥合这一鸿沟。该功能无需工程师从零开始编写定义，而是基于查询历史与可信商业智能资产，主动推荐从中学到的候选指标与筛选条件，使团队能够在数分钟内完成审核、认证与部署，而非耗费数周时间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;运作机制：基于共识模式的学习&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SVA 的核心原理在于：您的语义定义已蕴藏于查询历史、数据使用情况及仪表板之中。这使语义建模从编码工作转变为治理优化——团队只需专注于审阅 SVA 自动发现的业务逻辑。这些经治理的定义将为 Snowflake Cortex Analyst、Cortex Agents及Snowflake Intelligence 提供支持，以获取更精准可信的结果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;SVA 通过分析以下三类关键信号实现这一过程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;模式识别与共识驱动提取&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SVA 采用聚类算法分析查询模式与自然语言问题，以识别共识性业务逻辑。当存在冲突定义时（例如不同的“活跃用户”筛选条件），SVA 会将最高频出现的模式作为推荐方案提出。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如：若 200 余次查询均将“活跃用户”计算规则定义为“用户参与度分数&amp;gt; 50 且 最后登录天数&amp;lt; 30”，则即使用户近期运行了不同条件的查询，SVA 仍会优先推荐此共识逻辑作为标准提案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;多源高置信信号学习&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最高置信源通常来自现有商业智能（BI）仪表板，其中沉淀了多年的业务逻辑。Tableau 是 SVA 支持的首个 BI 工具，未来将通过我们 20 余家 OSI 合作伙伴接入更多平台。SVA 可在数分钟内将静态仪表板转化为对话式人工智能应用（详见实践操作指南）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;团队亦可直接上传可信 SQL 查询语句。SVA 将自动提取数据关系与业务指标，并将其存储为经过验证的查询模型供后续使用。得益于全程在 Snowflake 内部运行，SVA 能够直接分析真实业务数据。通过列基数分析可推断关系类型，进而智能生成优化建议，例如为提升精度推荐部署 Cortex Search 服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;基于持续演化的使用模式进行迭代更新&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SVA 通过监控用户查询模式，持续优化语义视图的时效性。例如当企业新增“专业版”订阅层级时，SVA 将自动识别包含 subscription_tier = &#39;pro&#39; 的新查询模式，并主动建议将其纳入语义视图体系，确保业务规则演进过程中智能应答始终保持一致性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从传统商业智能向 AI 智能体的转型，需要建立在数据使用实践而非 LLM 预设的语义基础之上。Semantic View Autopilot 通过真实使用场景驱动语义建模，为您提供当前最快捷的、具备治理能力的上下文感知AI实现路径，现已全面覆盖 Snowflake 所有支持 Cortex Analyst 服务的区域。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;即刻开启智能语义视图之旅。欢迎在您的 Snowflake 账户中体验 &lt;a href=&quot;https://docs.snowflake.com/en/user-guide/views-semantic/autopilot&quot;&gt;SVA&lt;/a&gt;&quot;，并获取为 Cortex Analyst 构建语义视图的&lt;a href=&quot;https://www.snowflake.com/en/developers/guides/best-practices-semantic-views-cortex-analyst/&quot;&gt;最佳实践&lt;/a&gt;&quot;指南。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文地址：&lt;a href=&quot;https://www.snowflake.com/en/blog/semantic-view-autopilot/&quot;&gt;https://www.snowflake.com/en/blog/semantic-view-autopilot/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/36/3625913187f520bdbc21798ff22d17aa.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;点击链接立即报名注册：&lt;a href=&quot;https://www.snowflake.com/events/ascent-snowflake-platform-training-china-cn/&quot;&gt;Ascent - Snowflake Platform Training - China&lt;/a&gt;&quot;，更多 Snowflake 精彩活动请关注&lt;a href=&quot;https://www.infoq.cn/space/snowflake&quot;&gt;专区&lt;/a&gt;&quot;。&lt;/p&gt;</description><link>https://www.infoq.cn/article/4gjxPMiGtEfB946j2U27</link><guid isPermaLink="false">https://www.infoq.cn/article/4gjxPMiGtEfB946j2U27</guid><pubDate>Wed, 11 Feb 2026 09:25:22 GMT</pubDate><author>Abhinav Vadrevu</author><category>Snowflake</category><category>大数据</category><category>AI&amp;大模型</category></item><item><title>OpenAI 与 Anthropic双雄打擂台！专家：2026 年 Agent 将在产业里遍地开花</title><description>&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;人工智能正处于阶梯式发展的平台期，当前研究路径的收益正在收敛，下一次跃迁需要全新的范式突破。与此同时，产业应用正在加速成熟，2026年有望成为Agent大规模落地的关键之年。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;上周，OpenAI 与 Anthropic 几乎在同一时间抛出了各自最新的模型更新——OpenAI Codex 5.3 与 Claude 4.6。没有发布会轰鸣，也没有颠覆式叙事，但在开发者社区和产业侧，这两次更新仍被迅速解读为一个清晰信号：大模型能力正在逼近一个阶段性的上限，而行业正在集体寻找新的突破口。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果用一个词来形容2025年的人工智能行业，那就是“临界”。一方面，大模型的通用能力已达到较高水平，在语言理解、推理、代码生成等维度上正在逼近甚至超过人类专家水准；另一方面，沿着既有路径继续堆叠规模与算力，边际收益正在迅速收敛。技术并未停滞，但“下一次质变从何而来”，正在成为整个行业共同面对的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下一代范式突破的方向是什么？中美竞争的真正差距在哪里？Agent如何从概念走向真正的产业落地？这些追问贯穿整个行业，而在2026年，它们变得无法回避。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;近期，带着这些问题我们与中关村人工智能研究院副院长&amp;amp; 北京中关村学院副教授（以下简称“中关村两院”）郑书新进行了一次深度访谈。郑书新认为，人工智能正处于阶梯式跃迁的平台期，下一次跃迁需要全新的范式突破。他同时指出，当前中美竞争的核心差距不在技术路线，而在高质量数据和算力资源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在产业侧，郑书新认为技术突破与产业普及之间始终存在时间差，这是历史常态而非失败。就像蒸汽机的发明并不会立刻带来工业革命的大规模落地，AI能力要转化为大规模应用，同样依赖配套系统与产品形态的逐步成熟。在他看来，2026年将是Agent在真实场景中集中落地的一年，而Coding Agent等新范式也正在重塑传统软件开发的基本逻辑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以下为访谈实录，经由InfoQ编辑及整理：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;开场：个人介绍与研究背景&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;InfoQ：您在AI领域深耕多年，能否和我们分享一下您的研究历程和主要工作？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：我从十多年前开始接触人工智能，一直深耕大模型领域。早期专注于大规模分布式优化，搭建了当时微软最大的异步分布式训练系统。此后转向大语言模型研究，提出了Pre-LN等训练优化与架构改进方法，将模型训练效率提升了约一个数量级。这些成果后来被主流大模型广泛采用（如OpenAI开源模型gpt-oss 等）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在通用模型与方法研究阶段，我提出的Graphormer架构，现在是图（Graph）学习领域的主流基座模型之一。近期，我致力于将大模型与生成式AI技术引入科学发现领域，提出的分子平衡分布预测框架突破了传统生物分子模拟的瓶颈，将分子动力学模拟效率提升数十万倍，相关成果发表于《Science》封面及《Nature Machine Intelligence》等顶级期刊。&lt;/p&gt;&lt;p&gt;2024年底，我加入中关村两院，现任学院副教授、研究院副院长，在AI基础学部负责大模型方向的研究与战略布局。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：您刚才提到目前在中关村两院AI基础学部负责大模型方向的研究。中关村两院肩负着北京乃至国家AI创新生态建设的使命，能否介绍一下两院的核心定位？AI基础学部在其中扮演怎样的角色？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：北京中关村学院与中关村人工智能研究院是一体两面，融合发展，是教育科技人才一体化的新尝试，是新型研发机构的二次方。北京中关村学院肩负着培养人工智能领军人才的重要使命，是国家教育、科技、人才一体化改革的&quot;试验田&quot;。中关村人工智能研究院与中关村学院共同开展面向未来、具有产业价值、颠覆性的人工智能技术研发及成果产业化落地。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;AI基础学部在这个框架下承担具体的技术攻关和方向布局，我们的战略目标是补全AGI下半场的关键拼图，在产业上输出能真正重塑行业逻辑的核心变量，在人才上培养兼具工程能力与科学直觉的领军人才。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;AI整体发展Overview&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;InfoQ：站在2026年初这个时间节点，您认为当前中国 AI发展最需要解决的关键问题是什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;AI发展正处在阶梯式跃迁的平台期，沿着现有技术路径的边际收益在递减，需要找到下一代突破方向。同时， AI本身也有两个特征：它是根植于产业的技术；并且，这场博弈有明确的时间窗口，很有可能在3-5年内见分晓。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基于这些判断，我认为当前有两个核心问题需要关注。第一是战略层面：这场范式竞争的背后是中美科技博弈，我们如何争取先手、发展自主生态。第二是应用层面：AI如何真正拉动GDP，实现高质量发展。现在AI的行业渗透率已经很高，但对GDP的实际贡献还很有限。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;AI技术发展现状&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;InfoQ：您刚才提到技术上的关键问题是中美技术博弈中争取先手。能否展开谈谈，您如何看待当前AI技术的发展阶段？下一代技术突破的方向会是什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;人工智能的发展遵循&quot;阶梯式跃迁&quot;的规律。最近一次重大跃迁是GPT带来的规模定律。但现在，智能性提升进入平台期，沿着现有技术路径的收益在递减，近期已经有多个迹象有所印证。其一，预训练范式遇到瓶颈。规模定律的红利趋近耗竭，可用于模型训练的互联网高质量数据见顶，继续扩大模型规模的边际收益显著下降。其二，后训练范式同样存在局限。当前业界普遍转向精细化的奖励函数设计，奖励函数的设计复杂度已经堪比当年的特征工程，本质上是在既定框架内反复调优。Meta近期发布的研究也表明，后训练的增量空间可能比预期更有限。如果“Less Structure, More Intelligence”成立，那么现有策略能否一路带领我们通向AGI，坦率说是存疑的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那么，下一代突破的方向是什么？可能是针对本代AI范式的缺点进行改进、寻找突破口，例如突破记忆与持续学习的瓶颈、打通经验学习（Learning from Experience）和自我博弈（Self-Play）的路径、提高长上下文支持能力、探索动态数据的新训练方法等。但也有可能需要探索全新的技术范式，例如受神经科学启发的软硬件结合架构、新的数据来源、离散Diffusion等新的建模方式、以及新的智能性理论与奖励函数设计等。然而，下一代探索是高风险、长周期的，对商业公司而言往往优先级较低，毕竟它们需要兼顾短期业绩和股东回报；而多数高校虽有学术自由度，但在算力和工程资源上存在现实约束。正因如此，中关村两院希望在这个时点带发挥独特作用，做难而正确的事情，沿现有路线突破和全新范式探索两个方向布局。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：2025年Agent很火，有人把Agent理解为大模型的应用层封装，有人把它理解为落地的应用形式。您如何看待当前AI Agent的发展现状？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;大家普遍把Agent理解为技术上的研究领域，或是一种落地的应用形式。但在我看来，Agent 就是基座模型，是当前业界押注智能性提升的主要技术路线。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么这么说？预训练Scaling Law边际效益递减的根本原因在于互联网高质量数据已接近上限。现在的核心解法之一就是找新的数据来源——合成数据，它的本质是搜索，在超高维的语言空间中使用预训练好的大模型去发现新的有价值数据，依托这些合成数据来进一步提升模型的性能。以o1为代表的推理模型，就是通过搜索和强化学习在语言空间中生成高质量的思维链数据；而Agent进一步扩展了搜索空间的边界，与环境交互并调用工具，发现全新的高价值数据，可能存在新的Scaling Law。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：在2026年，您认为AI Agent领域最值得期待的技术突破点是什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：类似整个AI 领域的进展方向，我期待的一是改进现有范式的短板，二是新的训练范式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在现有范式的改进上，有几个方向值得关注。首先是运行时学习（Runtime Learning），让智能体能够在运行过程中持续学习和改进，而不只是依赖预训练阶段的能力。其次是记忆机制，Agent需要在长周期任务中保持上下文连贯，有效地存储和调用历史信息。此外，幻觉与可靠性、下一代评测方法、智能体系统的整体可用性与智能性等也是关键课题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在新范式的探索上，自我迭代的训练方式，以及内在动机（Intrinsic Motivation）驱动的奖励机制，都可能为Agent带来阶跃式的突破。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这些也是中关村两院大模型领域的重点布局方向。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：相比国外，您认为国内在AI研究方面最大的优势和短板分别是什么？在全球AI竞争中，我们最需要补上的“关键一课”是什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;中国拥有庞大的人才基数和深厚的数理传统，大量工程师具备扎实的数学功底和出色的工程落地能力。与此同时，中国的产业门类齐全、应用场景丰富、市场规模庞大，这种独特的生态为AI落地提供了天然的试验田，也孕育了极强的产品化能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;再说短板，目前核心有两点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一点是数据。目前中美技术路线上已经趋于透明，国内头部大厂和美国最大的差距就是数据，这是大模型智能性提升的主要来源。美国正在系统性地采集长程、复杂、高难度的专业级数据，这类数据的特点是推理链条长、多轮交互、涉及多种工具调用，单条价值可达上千美金。这也是OpenAI等公司研发的重点，目前已经有专门的公司在帮大厂收集编程、金融、法律、咨询等领域的专家级知识和数据，可以预见2026年在这些专业领域会有显著突破。我们在这方面还比较欠缺。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二点是算力。我认为算力是智能性提升的第一性原理——科学的进步依赖多样性的探索，而多样性的探索依赖充足的算力。但目前我们在这方面面临不少挑战：一是芯片本身的性能受限，二是大规模组网能力有待提升。据传美国xAI已经有80万张H100级别的集群，而国内头部的&quot;六小龙&quot;基本还在5万张上下。在这种情况下，对我们的要求就更高了——需要特别巧妙精细的设计，省着用，才能做出东西；但美国目前可以进行大规模、多方向的并行探索。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;AI产业现状&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;InfoQ：您之前提到，产业上目前的问题是行业渗透率高，但对GDP的实际拉动效益还很有限。从整个AI领域来看，您认为产业真正的爆发拐点会在什么时候到来？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;现在确实面临技术跑在前面的情况，即模型能力已经在很多领域达到“博士级别”智能，但在产业端体感还比较弱，对GDP拉动有限。不过这是正常的，因为技术研发和产业落地之间存在时间差。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;打个比方，蒸汽机的出现是一场动力革命——它重新定义了制造业、交通、能源等几乎所有行业。但从瓦特改良蒸汽机到工业革命全面铺开，中间隔了几十年，因为需要铁路、工厂、煤炭供应链等一整套配套系统逐步成型。AI也正处在类似的阶段：核心的&quot;动力源&quot;已经出现，但要真正重塑产业，还需要数据基础设施、工程化工具链、行业know-how的深度融合。不同的是，这一轮的节奏会快得多，可能几年而不是几十年。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;事实上，这个进程已经在加速。2025年Agent的突破是一个缩影——更广泛地看，AI已经在各行各业开始渗透，很多场景不需要&quot;博士级&quot;智能，关键是被打磨成真正可用的产品。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我的判断是，2026年会是AI产业落地的关键一年。一方面，Agent、Coding Agent 等产品形态会让更多用户在工作和生活中真正用上AI；另一方面，垂直行业的AI应用也在快速成熟，一级市场已经有大量公司在做得不错的公司。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尤其值得关注的是白领和知识工作者群体。当前模型在多学科领域已经接近博士级智能，法律、金融、咨询、研究等领域有望率先释放生产力红利，AI对GDP的拉动很可能从这里开始。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：Coding Agent是当前讨论的热门方向，您怎么看？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;Coding Agent正在颠覆传统软件开发的范式。过去的逻辑是一个团队精心打磨3个产品，最后可能有1个成功；现在借助Coding Agent，个体就能快速开发100个产品，成功的概率和路径都被彻底改变了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我自己每天都在用Codex这些工具，经常多个任务并行。此刻我的电脑上就同时跑着4个Codex Agent，帮我完成各种任务。很多以前停留在想法阶段的项目，现在都能快速变成可运行的产品。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更让我兴奋的是，这种能力可以快速复制给零基础的人。我在北京中关村学院开了门AI Agent编程课程，宗旨都是“零帧起手手写代码”。大约半个月前，斯坦福也开出一门类似课程，理念是“全程不写一行代码”，和我不谋而合。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;课程只有四个半天，学生来自物理、材料、金融等各专业，很多人零编程基础。但结课时，所有小组都拿出了可运行的Demo：有人把Deep Research做成了“带事实核查的Deep Research”；有人把语音对话GPT改造成&quot;带快慢双系统的版本&quot;——快系统负责即时回应，慢系统在后台深度推理，最后融合呈现。零基础、跨背景，四个半天就能独立做出产品，这在以前是不可想象的，也是Coding Agent带来的价值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：在您看来，有哪些公司或产品在Agent领域做得比较出色？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;现在这个领域非常活跃，Agent的发展正在从“对话”向“办事”演进。如果说去年大家还在讨论概念，今年我们已经看到了很多能真正提高生产力的落地案例。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比如当下非常热门的几个产品，它们的共性在于：深度接管系统与文件，自主规划、异步执行、完成任务。如开源的Clawdbot被称为“AI Jarvis”；Anthropic的Claude Cowork实现了从“对话助手”到“数字同事”的跨越。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Coding Agent是目前落地最快的方向之一。海外的Cursor、Claude Code已成为开发者标配；国内方面，Kimi K2.5作为Agentic模型表现亮眼，基座模型中GLM-4.7领先，DeepSeek-V3.2、Qwen3、MiniMax-M2.1也都不错。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：您刚才提到了一些Agent应用产品，也提到了一些基座模型厂商。这其实涉及到行业里一个持续讨论的话题：通用大模型是否只是大厂之间的游戏？之前有嘉宾认为，通用大模型需要耗费大量人力物力财力，应该留给大厂去做，其他厂商可以在垂域模型中寻找生存空间。对此您怎么看？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;如果讨论的是大语言模型，我倾向于认为所谓的“生存空间”其实更多是“讲故事的空间”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通用大模型的发展已经非常成熟，以最近发布的模型为例，像Gemini 3和GPT-5.2 Deep Think版本都非常强大。目前来看，很难找到能在某个领域超越这两个模型的垂域模型。以法律和教育问题为例，我更倾向于直接使用GPT-5.2或Gemini 3，而不是专门的法律或教育模型。虽然这些通用模型的成本较高，但其性能已经非常出色。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果我要针对某个垂域开发应用，我会直接基于GPT-5.2进行开发，做好用户界面、数据库和基本范式，而不是自己去研发垂域模型。这种观点可能比较极端，但这是基于目前技术现状的判断——垂域模型的生存空间很有限。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：但垂域模型厂商会说他们的成本更低，这是否是一个优势？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;我觉得这种说法有些本末倒置。首先，模型需要能够真正解决问题，才能谈成本优化。现在很多具身智能公司还在纠结成本问题，但它们可能都还没有找准真正能产生价值的应用场景。这种&quot;成本倒置&quot;的思路是不合理的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;科研方向与人才培养&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;InfoQ：刚才我们聊了很多技术方向和产业趋势，您也提到了不少前沿探索的可能性。能否具体谈谈您目前的科研方向与布局？您最看好哪个方向，为什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：我在学院负责大模型方向的研究，团队并行推进的方向很多，最近的一项工作是让智能体“预测未来”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;各行各业本质上都绕不开同一道关：通过预测未来辅助科学决策。这听起来宏大，不同领域、不同机构，都在用各自的方式探索这个方向。比如政府出台政策前需要预判市场与社会反馈；企业制定战略前需要预估行业走势；金融机构甚至用系统去预测美国大选结果、下一场球赛谁输谁赢。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这项工作的核心在于将“信息采集—逻辑推演—仿真模拟”三个环节形成闭环：首先通过智能体全自动打捞全网多模态开源情报，消除信息差；然后借助大模型的复杂推理能力进行因果建模和趋势判断；最后在虚拟环境中让成千上万个智能体反复演练，输出不同时间尺度下的演化曲线与风险概率。我们已参加多项国际预测评测，最好成绩全球第二，最新模型正在冲刺第一。把这三个环节打通，预测未来就不再是玄学，而成为可工程化的科学决策平台。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：您之前介绍中关村两院和AI基础学部时，特别强调了人才培养这个维度。在AI攻坚克难的过程中，我们需要大量技术人才。您如何判断一个年轻人是否具备成为优秀科学家的潜力？在您看来，中国未来的AI人才应该具备哪三类核心能力？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;我去判断一个人是否有潜力时，会看重三个特质：首先是问题意识，他能不能自己发现问题、定义问题，而不只是等别人给题目；其次是挫折反应，科研99%的时间是失败，关键看如何应对失败；最后是跨界好奇心，他会不会主动去了解自己领域之外的东西，很多突破来自领域交叉。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;优秀人才还应该具备三类核心能力：一是数学和物理的第一性原理思维，这是AI时代下更重要的底层能力；二是系统工程能力，能把一个想法从论文变成可运行的系统；三是科学品味，知道什么问题值得做，这个最难教，但也最重要。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：随着AI的普及，我们观察到一个现象：无论是企事业单位、高校还是中小学，大家都在学习AI和编程，但也越来越依赖现成工具——从调用API、套模板，到直接使用AutoML、Copilot等——而对数学基础、算法原理的关注反而不足。微软CEO萨提亚·纳德拉也曾提到，AI很重要，但要避免过度依赖。您如何看待这种&quot;工具熟练度高，但科学基础薄弱&quot;的趋势？会担心未来的研究者变成&quot;只会调包、不会创新&quot;吗？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;我的观点可能稍有不同，我想用一段技术演进的历史来解释这个问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最早的程序员需要用“0和1”直接跟计算机对话，甚至在纸带上打孔输入程序。后来有了汇编语言，可以用简单的英文指令代替那些0和1。再后来出现了Python，写代码几乎像写英语句子。你会发现，每一次演进都在做同一件事：把繁琐的底层操作打包藏起来，让人不用操心&quot;怎么做&quot;，而是专注于“做什么”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个过程中，每一次进步都伴随着类似您提到的担忧：新一代程序员不懂底层原理了怎么办？但事实是，正是因为不用再纠结底层细节，程序员们才能腾出精力去解决更复杂、更有价值的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;今天的AI工具也是一样。它让研究者可以跳过很多繁琐的技术步骤，把精力放在真正重要的问题上——比如提出新假设、设计新实验、发现新规律。这些才是创新的本质，而不是亲手写每一行代码。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以我的建议反而是：大胆拥抱最先进的工具，但要清楚自己真正想解决的问题是什么。工具是手段，问题才是目的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;InfoQ：如果让您预测2030年最具影响力的AI科学突破，您会押注在哪三件事上？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;郑书新：&amp;nbsp;我会押注在这三个方向上：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一，AI智能性超过人类，ASI（超级人工智能）实现。&lt;/p&gt;&lt;p&gt;第二，AI在科学研究中能够自主完成发现和突破，比如找到治愈癌症的路径，或者解决数学领域悬而未决的开放问题。&lt;/p&gt;&lt;p&gt;第三，AI走进物理世界，对实体产业形成实质性推动。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;采访嘉宾：&lt;/p&gt;&lt;p&gt;郑书新，中关村人工智能研究院副院长&amp;amp; 北京中关村学院副教授&lt;/p&gt;</description><link>https://www.infoq.cn/article/iHkvlLuTCWNJv27eJ1XY</link><guid isPermaLink="false">https://www.infoq.cn/article/iHkvlLuTCWNJv27eJ1XY</guid><pubDate>Wed, 11 Feb 2026 09:00:00 GMT</pubDate><author>李冬梅</author><category>AI 工程化</category></item><item><title>如何利用 Snowflake 将 AI 创新转化为可靠、生产就绪的应用 ｜ 技术趋势</title><description>&lt;p&gt;2026 年，智能体将在企业级应用中取得哪些实质性突破？&lt;a href=&quot;https://www.infoq.cn/minibook/keTZm4fpOmFEzmx77Zpq&quot;&gt;点击下载&lt;/a&gt;&quot;《2026 年 AI 与数据发展预测》白皮书，获悉专家一手前瞻，抢先拥抱新的工作方式！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;人工智能创新正在持续重塑各行业与企业级的应用场景与用户体验。各公司日益聚焦于为终端用户创造可量化的实际价值。要实现这些价值，就需要可扩展、安全可靠且与企业数据深度整合的人工智能技术。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 Snowflake，我们致力于帮助客户将人工智能与机器学习的宏伟蓝图转化为现实影响。这意味着我们将开发工具置于核心位置，使开发者能够更轻松地构建可靠的智能体，加速人工智能/机器学习工作流的上线部署，并在规模化扩展时从容管控相关负载。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们最新的产品创新赋予客户基于 Snowflake 平台构建可靠、企业级应用的能力。这将带来更高效的执行、更简化的运维流程，以及企业可放心投入生产环境的人工智能工具。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Snowflake Intelligence 作为即开即用的企业级智能体&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Snowflake Intelligence 整合了一系列功能模块，旨在帮助企业用户快速、安全、自主地实现人工智能价值。本次更新聚焦三大核心需求：&lt;/p&gt;&lt;p&gt;&amp;nbsp;支持用户将有价值的对话输出保存为成果资产，并可将这些资产共享给其他利益相关方以支持商业决策（即将推出）；通过安全的原生移动端访问，满足业务人员随时随地使用需求（即将推出）；客户现可将业务人员纳入Snowflake Intelligence使用范畴，同时限制其对SQL及数据工具的访问权限。所有现有安全策略持续生效，管理员仅需通过单一用户属性即可启用该功能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Snowflake Intelligence 致力于在工作发生的任何场景下提供可信洞察。其自然语言交互界面支持每位员工在Snowflake安全可控的平台内直接提出问题、挖掘数据表象背后的成因，并及时采取数据驱动的行动。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些功能共同构筑了 Snowflake Intelligence 作为可信赖企业智能体的核心能力，在用户需要的时空节点交付关键洞察，为全组织范围内的时效性数据驱动决策提供支撑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Artifacts：将对话转化为商业成果&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Artifacts（即将开启公开预览）代表着 Snowflake Intelligence 在赋能商业用户方式上的根本性转变。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Artifacts 可将 Snowflake Intelligence 中的对话转化为可保存、可共享的输出成果，例如图表与表格，并完整保留可视化呈现、底层 SQL 及上下文元数据。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Artifacts 是 Snowflake Intelligence 中实现企业知识捕获、共享与执行的核心单元。用户可通过保存 Artifacts 避免重复分析工作，安全地向团队成员共享实时引用，并在上下文中探索后续问题。Artifacts 支持用户回溯已构建的内容，与他人共享，并基于可信的企业数据直接展开协作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更广泛而言，Artifacts 是 Snowflake Intelligence 向终端用户交付商业洞察能力的基础架构。通过Artifacts，Snowflake Intelligence 不再仅限于临时查询或后续追问，而是成为驱动业务发展的起点。借助Artifacts，我们正将 Snowflake Intelligence 打造为全组织统一、可靠决策的核心枢纽。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Snowflake Intelligence 即将登陆移动端&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Snowflake Intelligence 将以 iOS 移动应用程序的形式（即将进入公开预览阶段）推出，提供更优的原生移动体验。移动端访问确保企业领导者和业务用户能够全天候连接企业知识库，无论是查看核心指标、追踪趋势变化，还是在决策过程中实时跟进关键问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为提供安全易用的体验，Snowflake Intelligence 移动应用将支持基于 FaceID 的会话续期功能（即将进入公开预览阶段）。用户可通过 FaceID 进行身份验证，令牌将在后台自动刷新。刷新令牌始终保持受保护状态，绑定设备并定期轮换，在实现企业级安全管控的同时，提供流畅的消费级移动体验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;扩展访问权限：支持受限登录与 Snowflake Intelligence 专属用户&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Snowflake Intelligence 现支持用户直接登录，使业务用户无需了解 Snowflake 或操作 Snowsight 即可登录平台并开始提出问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于需要更严格管控的企业，Snowflake Intelligence 专属用户功能允许业务用户仅访问 Snowflake Intelligence，无法使用 Snowsight、SQL 接口或其他数据工具。这一设计让业务用户专注于专为其打造的交互界面，同时帮助企业统一管控使用范围、控制成本，并自动实施所有现有安全策略。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Snowflake Intelligence 还支持身份提供程序重定向功能。通过配置的身份提供程序（如 Okta 或 Entra ID）进行认证的用户，可获得简化的 Snowflake Intelligence 登录体验。这些功能相结合，使得在保障集中化治理控制的同时，能够轻松扩展企业内部的访问范围。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;轻松构建、部署与迭代智能体体验&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;智能体现已成为企业工作流的核心。企业需要一个可靠、可信的体系架构，以在受管控且能跨团队、跨应用扩展的环境中，提供稳定精准的智能体验。我们很高兴宣布 Snowflake 平台上的重要创新，这些创新将帮助客户自信地构建并扩展生产级智能体。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现已全面推出的 Cortex Code，通过赋能各类构建者——从资深工程师到非技术团队——利用自然语言交互构建并优化智能体，全面支持这一进程。它帮助团队轻松生成合成数据，创建与调试语义视图，并快速构建和调试智能体行为，从而加速在 Snowflake AI 数据云上的生产部署。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;即将全面推出的语义视图自动巡航功能，可助力团队自动化创建并部署生产就绪的语义视图。通过学习查询历史，语义视图自动巡航简化了建模工作流，帮助组织更快接入新用例，同时在跨团队间提供一致的洞察分析。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为推进智能体在组织内的广泛应用，Cortex Agent Sharing（即将正式发布）可帮助用户轻松发现、复用并规模化部署由内部团队或合作伙伴构建的智能体。该功能使企业能够统一智能体能力标准，避免重复开发，并将经过验证的智能体快速拓展至各团队，无需为不同用例重复构建。团队可通过 Snowflake Marketplace 获取各类方案，并利用合作伙伴构建的智能体加速实现业务价值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通过 Agent Evaluations（即将正式发布），客户能够深入洞察智能体的推理过程、工具选择与响应生成机制，从而优化智能体行为，并在其演进过程中持续提升准确性。这种透明度有助于团队通过便捷的准确性验证与逻辑一致性检查，建立对智能体质量的信心，确保其满足生产环境要求。通过完整呈现智能体的“思考过程”，Agent Evaluations 减少了调试过程中的猜测性工作，使团队能够快速定位并修复错误或性能瓶颈。最终，通过对答案、逻辑及工具使用进行验证，企业可放心地将智能体从早期实验阶段推进为团队信赖的、可用于生产环境的成熟系统。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;面向企业数据访问的模型上下文协议（Model Context Protocol）支持&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Snowflake Intelligence 现已支持模型上下文协议（MCP），以简化与第三方工具及服务的集成。我们于 2025 年 10 月推出了由 Snowflake 托管的&lt;a href=&quot;https://www.snowflake.com/en/blog/managed-mcp-servers-secure-data-agents/&quot;&gt; MCP &lt;/a&gt;&quot;server，并在此基础上进一步推出 Snowflake MCP 客户端（即将全面上市），帮助客户以更便捷、可靠的方式连接外部数据源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通过 Snowflake MCP 客户端，账户管理员可以注册预置或自定义的 MCP 服务器（例如 Atlassian、Salesforce 或 Workday），并将其直接集成至 Cortex 智能体中。开发人员可在智能体编排过程中使用 MCP 服务器，实现无缝的工具发现与调用。Snowflake 统一管理包括令牌处理在内的认证流程，并提供可观测性支持，确保集成过程安全可控。在本次发布中，Snowflake 支持在智能体调用期间完整的 MCP 工具发现功能，同时提供监控与令牌管理能力，使客户能够安全地跨系统访问并处理企业数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;面向企业级智能体的高性能与低延迟&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在生产环境中，一致性及准确性对用户体验与应用推广至关重要。Snowflake 持续投入智能体技术栈的全面优化，致力于提供响应更迅速、结果更精准且具备规模化可预测性的AI驱动体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Snowflake 即将推出持续学习型智能体记忆库（公共预览版），这是企业级智能体在质量层面的重大升级。该功能使智能体能够持续从跨用户的高质量历史响应中学习，从而提升回答一致性并增强可信度。同时，智能体可长期记忆个体用户的偏好与事实信息，为用户提供更加个性化的 Snowflake Intelligence 体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通过将文本转 SQL 功能深度集成至智能体编排流程，Snowflake 进一步提升了分析工作流的准确性与响应速度。用户得以更高效地访问数据，在查看 SQL 执行过程的同时透视 LLM 决策逻辑，并针对多样化工作负载灵活优化智能体行为模式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;支持智能体版本管理与成本追踪的治理机制&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着人工智能应用不断发展，企业需要具备相应的治理能力以实现规模化扩展。Snowflake 通过智能体版本管理与集成化运行监控功能，为企业提供此类治理支持。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;智能体版本管理功能（即将开放公开预览）为 Snowflake Cortex 智能体提供 CI/CD 支持，使客户能够安全地构建、部署和迭代智能体工作负载。开发人员可创建版本快照，通过 Git 管理变更，并安全地推进或回滚部署。此外，客户即将通过使用量视图（即将正式发布）追踪 Snowflake Intelligence 与智能体的使用情况，从而获得更完善的运行状态洞察。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;除可视化监控外，Snowflake 还支持团队主动管控 AI 成本。已正式发布的 AI_COUNT_TOKENS 函数可在执行前预估使用量，而即将发布的 AI 函数增量计量视图（即将正式发布）将为运行中的查询提供使用量与成本数据，帮助团队在执行期间实施限额管控并触发相应操作。这些功能使企业能够在维持可预测开支与运行管控的同时，实现生产环境中 AI 应用的规模化扩展。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通过版本管理与成本追踪相结合，团队能够在保持清晰洞察的前提下快速发展，以负责任的方式构建高性能规模化应用程序。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;通过智能体工作流加速多模态机器学习模型的在线部署&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在人工智能领域，传统机器学习仍然占据重要地位。我们欣然宣布，Snowflake ML 在智能体、多模态及实时工作流方面推出了全新功能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们持续投入现代化开发体验，致力于提升生产效率。新一代 Snowflake Notebooks（现已正式发布）现已成为 Snowflake Workspaces 的核心组成部分，运行于基于 Snowflake 容器运行时构建的 Jupyter 环境中。Snowflake Notebooks 使开发者能够将已有的基于 Jupyter 的笔记本、脚本及模型训练流程无缝引入 Snowflake 统一平台，实现先进的模型开发工作流。通过与 Snowsight 中的 Cortex Code 功能（即将正式发布）深度集成，Snowflake Notebooks 进一步提升了开发与迭代的效能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;数据科学家在开发和调试机器学习工作流时，常常面临周期冗长的问题，导致运维瓶颈以及实际投产的模型数量有限。如今，Snowflake 将 Cortex Code 集成至 Snowflake Notebooks 的机器学习工作流中，引入智能体人工智能，使其能够基于简单的自然语言提示自主迭代、优化并生成完整可执行的机器学习流水线。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;针对实时机器学习模型，Snowflake ML 现已正式发布&lt;a href=&quot;https://docs.snowflake.com/en/developer-guide/snowflake-ml/feature-store/create-and-serve-online-features-python&quot;&gt;在线特征存储&lt;/a&gt;&quot;与&lt;a href=&quot;https://docs.snowflake.com/en/developer-guide/snowflake-ml/inference/real-time-inference-rest-api&quot;&gt;在线模型服务&lt;/a&gt;&quot;功能，使模型部署更加便捷。开发者现可将特征服务延迟控制在 30 毫秒内，模型服务延迟控制在 100 毫秒内，有力支持个性化推荐、欺诈检测等低延迟在线场景，且无需额外基础设施或复杂配置。此外，基于 Hugging Face 等主流多模态模型中心进行大规模推理的功能，目前已进入公开预览阶段。结合图像、视频等非结构化数据进行推理，可在 Snowflake 平台上直接实现物体检测、视觉问答和自动语音识别等多种人工智能应用，无需构建复杂流程或迁移数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;AI 发展的未来&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;今日发布的多项成果，共同奠定了 Cortex Agents 作为企业级AI统一基础的地位。Semantic View Autopilot 助力开发者提升 Cortex Agents 的准确性，并加速推进高级用例的落地。最新的 &lt;a href=&quot;https://www.snowflake.com/en/blog/production-ml-workflows/&quot;&gt;Snowflake ML&lt;/a&gt;&quot; 升级，使开发者能够构建可供 Cortex Agents 直接调用的模型，从而为用户提供基于机器学习的预测与建议。在生产环境中，我们推出的 Evaluations for Cortex Agents 确保智能体输出结果既可信赖，又便于监控。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;借助 Snowflake 平台，企业能够将 AI 智能体与应用从实验阶段推进至生产部署，并获得团队信赖、由运维人员统一管理，最终直接赋能业务成效。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;行动倡议：&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1.&amp;nbsp;立即开始在 &lt;a href=&quot;https://www.snowflake.com/en/product/snowflake-intelligence/&quot;&gt;Snowflake Intelligence&lt;/a&gt;&quot; 中创建、保存并共享各类资产，以促进协同并推动业务行动。&lt;/p&gt;&lt;p&gt;2.&amp;nbsp;探索与 &lt;a href=&quot;https://www.snowflake.com/en/news/press-releases/snowflake-unveils-cortex-code-an-ai-coding-agent-that-drastically-increases-productivity-by-understanding-your-enterprise-data-context/&quot;&gt;Cortex Code&lt;/a&gt;&quot; 相关的发布内容。&lt;/p&gt;&lt;p&gt;3.&amp;nbsp;通过此篇&lt;a href=&quot;https://www.snowflake.com/en/blog/production-ml-workflows/&quot;&gt;博客&lt;/a&gt;&quot;，进一步了解机器学习领域的最新动态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文地址：&lt;a href=&quot;https://www.snowflake.com/en/blog/building-reliable-applications/&quot;&gt;https://www.snowflake.com/en/blog/building-reliable-applications/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/36/3625913187f520bdbc21798ff22d17aa.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;点击链接立即报名注册：&lt;a href=&quot;https://www.snowflake.com/events/ascent-snowflake-platform-training-china-cn/&quot;&gt;Ascent - Snowflake Platform Training - China&lt;/a&gt;&quot;，更多 Snowflake 精彩活动请关注&lt;a href=&quot;https://www.infoq.cn/space/snowflake&quot;&gt;专区&lt;/a&gt;&quot;。&lt;/p&gt;</description><link>https://www.infoq.cn/article/HQCgKB6UVJvDTePdIdoU</link><guid isPermaLink="false">https://www.infoq.cn/article/HQCgKB6UVJvDTePdIdoU</guid><pubDate>Wed, 11 Feb 2026 08:32:13 GMT</pubDate><author>Arun Agarwal</author><category>Snowflake</category><category>大数据</category><category>AI&amp;大模型</category></item><item><title>离开半年，48 岁前 GitHub CEO 携开源 AI 开发者平台和老东家打擂</title><description>&lt;p&gt;在很长一段时间里，Thomas Dohmke 都被视为“最不像 CEO 的 CEO”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他会在深夜亲自回复 GitHub Issues，会在发布会上公开演示自己写代码的过程，也会在 Copilot 最早的内测阶段，反复强调一句话：“如果这个东西不能改变开发者每天的工作方式，那它就不值得存在。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但去年 8 月，这位 GitHub 首席执行官正式离职。外界一度猜测，他是否会加入另一家大厂，或转向 AI 创业投资。但几个月后，他给出的答案更直接——重新创业。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;今年48岁的 Thomas Dohmke 创办了一家名为 Entire 的新公司，这是一个面向“智能编码时代”的开源开发者平台。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他在x上宣布了这一消息。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/25/256cac6b650826d68c54daf800c89f1d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Grab 首席产品官 Philipp Kandal在x上发帖表示祝贺。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/08/08fdab18156a75f989f5442f40a04ba1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Entire 是谁？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;那么，这个 Entire 到底是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据 Dohmke 介绍，Entire 是一个平台，但它未必会与 GitHub 展开竞争。Dohmke 表示，其理念是在技术栈的更高层构建一个平台，让开发者能够管理智能体的推理过程并与之协作。代码仓库仍将是其中的核心。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d4/d42e49833f9dd976315947b71e172543.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Entire 正在构建的是一个三层平台，其基础是一个从零开始构建的全新 Git 兼容数据库，中间是一个语义推理层，最上面是一个用户界面。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;团队认为，由于这些新存储库中存储的信息有所不同，因此需要一个新的数据库层——具体来说，智能体在使用这些工具时能够提供比人类更多的上下文信息。这个新数据库将允许人类和智能体不仅可以查询代码，还可以查询代码背后的逻辑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;由于代理使用此数据库及其 API 端点的频率可能远远高于人类使用 Git 存储库的频率，因此团队还需要考虑性能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dohmke 还表示，与传统的集中式Git仓库不同，这种新型数据库可以构建成一个全球分布式的节点网络。对于需要（或希望）确保数据主权的用户来说，这是一个重要的卖点。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;虽然用户界面仍在开发中，但 Entire 已经构建了部分功能，用于可视化存储在Git中的检查点。不过，目前团队主要专注于命令行体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;至于为什么要开发这样一个平台，Dohmke给出了他的解释。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dohmke强调，当前开发者/客服工作流程中存在的一个问题是我们现在经常听到的：代码交付的瓶颈不在于编写代码，而在于审查客服编写的代码。这已经导致开发者精疲力竭。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;比如，爱尔兰软件工程师、谷歌Gemini 开发者（同时也在参与Chrome的开发） Addy Osmani 就曾公开表达了对 Vibe Coding 不信任。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“我们在谷歌也使用Vibe 编码——我发现它非常适合原型设计和最小可行产品（MVP），对学习也很有帮助……”Osmani 在11月初的一个播客节目中说道。“但总的来说，Vibe 编码更注重速度和探索，而不是正确性和可维护性。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/3c/3cb679cd4e55564b299da15829e314e1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Dohmke 认为，未来将会出现更多的Agent。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“如果你在整个软件生命周期中都遵循这个流程，那么编写代码之后的下一步就是代码审查——无论是你自己的代码，还是通过拉取请求审查团队成员的代码，”Dohmke说道。“但是拉取请求也存在同样的问题（在理解代码方面）。它会显示一些我从未编写过的文件的更改。而像Copilot这样的代码审查工具会给我提供关于其代码的反馈，这在我对代码还有一些基本理解的情况下非常有用，但如果我不真正理解这些代码的作用，那么这些反馈就变得毫无意义或多余了。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当代码较多而上下文较少时，解决方案可能是使用代理和确定性工具来测试代码，并确保其合规性和安全性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他解释说：“这正逐渐成为瓶颈，所以你必须从流程中剔除这一步骤。我认为这是业内最大的挑战之一，因为在我们应对日益增多的网络攻击的同时，许多组织已经引入了零信任流程，这意味着任何部署都必须经过人工审核。因此，我认为，在我们看来，许多创新将在这一领域涌现，而我们希望成为其中的一份子。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;首发新品&amp;nbsp;Checkpoints，并开源&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Checkpoints 是 Entire 公司发布的首款产品。这款全新开源工具集成了 Claude Code 和 Google 的 Gemini CLI（即将支持 Open Codex），能够自动提取并记录智能体的推理、意图和结果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在当前的 Agent 开发流程中，一个长期被忽视的问题正在变得愈发突出：会话是短暂的，而决策是不可逆的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;大多数情况下，智能体的提示词停留在终端里，推理过程被塞进上下文窗口。一旦会话结束，这些信息便随之消失。代码最终被提交进 Git，但 Git 只记录了“改了什么”，却无法回答“为什么这么改”。当智能体在一次会话中生成成百上千行代码时，这种上下文的缺失会迅速放大：早期的约束条件、设计取舍、被否定的方案，都无法被追溯。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;结果是，智能体之间几乎无法真正协作。它们会在不同会话中重复推理、重复试错，重新消耗token，甚至推翻数小时、数天前已经做出的决定。随着代码库规模扩大，这种“失忆式开发”正在成为效率和一致性的隐性成本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了解决这一问题，一种名为 Checkpoints 的新机制被提出。它试图把原本易逝的智能体上下文，变成可持久、可追溯的工程资产。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Checkpoints 的核心思路是：将智能体的完整会话上下文，作为 Git 中的一等版本数据保存下来。当由智能体生成的代码被提交时，系统不仅记录代码本身，还会同步捕获这次会话中的关键信息，包括提示词、日志、访问过的文件、工具调用情况以及令牌消耗等。这些信息与代码提交一一绑定，构成一条“为什么这样写”的语义轨迹。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从使用方式上看，Checkpoints 以一个“Git 感知”的命令行工具运行。每一次由智能体触发的提交，都会生成一个结构化的检查点对象，并与对应的提交 SHA 关联。代码仓库的内容本身并不发生改变，新增的是一层上下文元数据。当开发者将代码推送到远程仓库时，这些检查点会被同步写入一个独立的、只追加的分支，形成完整的审计日志。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这意味着，开发者不再只能回溯代码差异本身，还可以追溯到产生这些差异的推理过程和决策背景。在多人、多智能体协作的场景下，代码库的演进第一次具备了“记忆能力”，而不再只是结果的堆叠。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“中间层的作用在于向人类和Agent提供所有促成软件产品诞生的信息，” Dohmke 解释说。“而如今，在GitHub代码库中，包含了所有代码，有时还有文档和依赖项，但基本上缺少了所有关于如何实现这些代码的信息。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这是因为这些系统是为人类开发者设计的，虽然开发者在完成代码编写后可能会编写测试用例和文档，但记录他们具体的推理步骤却从未被纳入流程。而在传统的、非智能体的工作流程中，大量的机构知识从未被记录下来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“这是我们更大愿景的第一步，即在软件项目的生命周期中提供语义推理层，这样你就可以在未来的任何时间点，以人类或智能体的身份，追踪决策的制定原因，”Dohmke 解释道。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通过保存所有这些数据，Checkpoints 将允许开发人员查看代理是如何生成代码的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，有x用户在x上询问数据会如何处理？是否会被用于其他地方。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dohmke 表示：“Entire 会将上下文和Checkpoints存储在用户的 GitHub 代码库中。只要用户登陆上来，Entire 会将其同步到 Supabase 数据库，仅用于显示目的。从长远来看，我们希望构建一个语义层，以便人类开发者和智能体能够并行地进行推理、协作和构建。我们不会将您的数据用于除向您和您的团队提供平台功能之外的任何其他用途。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/8f/8fe72ef1e0359147e9f550de7bc5ad27.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;一位“工程师型 CEO”的来时路&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Thomas Dohmke 并不是传统意义上“职业经理人”出身。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在加入 GitHub 之前，他是一名工程师、创业者，也是 GitHub 的长期重度用户。2018 年 GitHub 被微软收购后，他进入微软体系，随后在 2021 年接任 CEO，成为 GitHub 历史上第一位真正意义上的“工程师型掌舵人”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在他任内，GitHub 完成了一次关键转向：从“代码托管平台”，变成“以 Copilot 为核心的 AI 开发平台”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Copilot 的推出，并非单点功能升级，而是一次底层范式变化。GitHub 不再只服务“人如何协作写代码”，而是开始服务“人如何与 AI 一起写代码”。这一判断，后来被证明是整个行业的分水岭。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;也正因为如此，当 Dohmke 在 2025 年宣布离职时，他特意强调：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;这是一次完全友好的离开，不是对 GitHub 或微软路线的否定。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据他在接受 The New Stack 采访时回忆，自己在 6 月与微软 CEO 萨提亚·纳德拉进行过一次长谈。他向纳德拉坦陈了自己的想法：想回到“从零开始造东西”的状态。纳德拉的回应是，希望他“把 CEO 的工作好好做完”，同时也欢迎他继续留在微软生态中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这也解释了一个细节：微软风投部门 M12，成为 Entire 的投资方之一。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/38/389d436b05484d1818c46c4cfffc844e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;有了GitHub技术领导者这样的职业经历做背书，Dohmke 在资本市场备受青睐。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Entire 的首轮融资规模达 6000 万美元，由 Felicis 领投，Madrona、Basis Set 以及微软 M12 共同参与，公司估值达 3 亿美元。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;事实上，6000 万美元的融资在开发者工具领域并不常见。更重要的是，这是一个产品仍处于早期阶段的平台。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在投资人看来，这并不是一次“押产品”，而是一次押人 + 押判断。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dohmke 给出的核心判断是：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;GitHub 所代表的那一代开发者平台，诞生于“人写代码”的时代，而不是“Agent写代码”的时代。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e9/e9d6afa029f9291b02c2e7e84ed650df.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Felicis 创始人Aydin Senkut则押注的是Dohmke 丰富的行业经验，他在x上发文称：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我第一次见到 &lt;a href=&quot;https://x.com/ashtom&quot;&gt;@ashtom&lt;/a&gt;&quot; 他的远见卓识令我叹服。他对现代开发流程有着深刻的理解。作为 GitHub 的 CEO，他带领公司完成了人工智能的转型，并将平台规模扩展到全球超过 1.5 亿开发者。但他同时也清晰地预见到，如今整个行业都需要彻底革新。他的信念和洞察力令我深受鼓舞。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f8/f8d7d538bc3952e4d699c4c6b9c37b66.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着本轮融资的完成，Entire计划将其员工人数从目前的15人增加到约30人，并尽快搭建其平台。但正如Dohmke强调的那样，如今重要的不仅仅是员工。Entire团队甚至在其新闻稿中也提到，他们计划将团队规模扩大到“数百名客服人员”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“我认为到了2026年，任何领导者都需要重新审视员工人数，不再仅仅关注薪资、福利、差旅和开支，还要关注代币价值。我和一些工程师交流过，包括我自己团队的工程师，以及湾区的工程师，他们都在谈论每月价值数千美元的代币，”多姆克说道。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;至于商业模式，Dohmke 告诉我们，团队计划遵循成熟的开源模式，即以宽松的许可协议提供平台的大部分功能，然后提供具有附加功能的托管服务来实现盈利。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;网友：能用，但没必要硬吹&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 Thomas Dohmke 宣布创办 Entire、并完成 6000 万美元种子轮融资之后，Hacker News 很快成为这条消息的“情绪放大器”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有Hacker News用户称，这并不意外。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一位长期定义开发者工作流的关键人物，带着“为智能体时代重构软件工程”的宏大叙事重新创业，再加上一笔在开发者工具领域堪称夸张的种子轮融资，本身就足以触发 Hacker News 最典型的那种讨论：技术是否真的新？价值是否被高估？以及——这到底是在投产品，还是在投人？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从整体来看，HN 上的讨论并未形成简单的“看好 / 唱衰”对立，而是呈现出几条高度一致、反复交织的主线。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第一条主线，大家更多的是在讨论“Entire到底是不是一个新原语？”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;支持者与反对者的分歧，首先集中在 Entire 的首个产品 Checkpoints 本身。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/1e/1e2f474191775ab0427f59e7f92160c9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在支持一方看来，Checkpoints 并不是一个“方便功能”，而是一种新的软件工程原语。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有开发者指出，Checkpoints 的关键不在于“保存 AI 生成的代码”，而在于它将代理的完整上下文——包括会话记录、提示、访问过的文件、工具调用和 token 使用情况——作为一级版本化数据，与代码提交一并捕获并长期保存。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这一视角下，Checkpoints 并不是在解决“怎么写代码”，而是在解决一个更根本的问题：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;当代码主要由代理生成时，软件工程应该如何记录“思考过程”？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种观点认为，如果开发者无法回溯代理为什么在某个时间点做出某种选择，那么代码审查、安全验证乃至长期维护都会变得越来越脆弱。从这个意义上说，把推理过程纳入版本控制体系，本身就是一次范式转移。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但反对者几乎立刻给出了另一种解读。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在他们看来，这种能力并不新，甚至实现成本极低：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;“你完全可以把 AI 生成的上下文当成文本，用 git add 提交。”&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这类评论中，Checkpoints 被描述为一个“被概念包装过的简单想法”：不是不能用，而是远不足以支撑一个被资本高度追捧的平台叙事。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另外一个比较集中被讨论的话题是，6000 万美元，究竟买的是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果说产品价值仍有争论，那么融资规模几乎是 Hacker News 上争议最集中的部分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;多位用户直言，他们并不否认“记录开发决策”这件事的意义，但完全无法理解：为什么这值得 6000 万美元的种子轮？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有人直接点破，这笔融资隐含的估值，很可能已经超过 6 亿美元。在他们看来，这并不是“新的经济学”，而是风险投资在为自身账面价值服务——通过对早期项目给出极高定价，抬升整个基金组合的名义估值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/7b/7b5f1d6900b3a69822bf1764b77eceda.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更激进的评论甚至认为，这种行为本身就应该被监管。但也有另一种更冷静、也更现实的声音指出：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;钱并不是在寻找“完美产品”，而是在寻找“可能的落点”。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://techcrunch.com/2026/02/10/former-github-ceo-raises-record-60m-dev-tool-seed-round-at-300m-valuation/?utm_source=dlvr.it&amp;amp;utm_medium=twitter&quot;&gt;https://techcrunch.com/2026/02/10/former-github-ceo-raises-record-60m-dev-tool-seed-round-at-300m-valuation/?utm_source=dlvr.it&amp;amp;utm_medium=twitter&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://thenewstack.io/thomas-dohmke-interview-entire/&quot;&gt;https://thenewstack.io/thomas-dohmke-interview-entire/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=NrQkdDVupQE&quot;&gt;https://www.youtube.com/watch?v=NrQkdDVupQE&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/fcjA0034GUQVp20cjHZU</link><guid isPermaLink="false">https://www.infoq.cn/article/fcjA0034GUQVp20cjHZU</guid><pubDate>Wed, 11 Feb 2026 08:16:45 GMT</pubDate><author>李冬梅</author><category>生成式 AI</category></item><item><title>网易有道发布中国版“OpenClaw”，推出全场景个人助理Agent“LobsterAI”</title><description>&lt;p&gt;随着AI从“能聊天”迈向“能办事”的Agent阶段，个人AI Agent已成为科技圈公认的下一波浪潮。2月11日，网易有道正式推出桌面级Agent“LobsterAI”（中文名：有道龙虾）。这是一个定位为“7×24 小时帮你干活的全场景个人助理Agent”，目前已在官网开放内测申请。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2b/2bfbe9878668dc1d15c000b8fcd3c8da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;图源：LobsterAI 官网&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，LobsterAI在产品形态上展现了独特的融合创新思路：它不仅具备海外爆火的“OpenClaw”那样自主跨应用执行复杂任务的能力，更融合了类似“Claude Cowork”的GUI（图形化交互）界面，旨在打造一款让用户能轻松驾驭、更安全、更易配置的中国版自主智能体。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e2/e2b11ad15dc6a935aff9dd607be834c7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;LobsterAI 界面图，图源：网易有道&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此前，海外开源项目“OpenClaw”因展示出惊人的“自主操控能力”而引爆技术圈，证明了Agent产品的能力边界；而另一款产品“Claude Cowork”，则利用具备强编程能力的模型，通过编程来完成各类任务，不仅取得了很好的效果，也为行业打开了更广阔的想象空间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“LobsterAI也希望打造一款拥有高自由度，且具有长时记忆、定时任务等功能的产品，来拓宽和探索Agent在工作与学习场景下的应用潜能。”LobsterAI相关负责人介绍。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与传统对话式AI不同，LobsterAI具备真正的“干活能力”——它摒弃了复杂的命令行操作，采用了类似Claude Cowork的直观GUI界面；无论是资讯获取、日程管理、还是深度数据分析，用户只需与其对话，LobsterAI便能在获得授权后，自动在本地计算机中通过程序化方式执行复杂流程，并交付结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从官方释出的信息来看，目前在设备支持上，LobsterAI已打通移动端与PC端的连接，用户可通过手机端在钉钉、飞书等软件中进行远程交互；哪怕你不在电脑前，也能指挥家里的LobsterAI帮你处理紧急工作，真正实现“数字分身”随时待命。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/6d/6df8b8804fc336c898105a9805d06fa5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;LobsterAI 支持手机端钉钉远程交互，图源：网易有道&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在使用过程中，LobsterAI还支持定时任务机制，例如设定每天清晨自动搜集行业新闻、整理邮件摘要，当你开始工作时，所需资料已准备就绪。同时，LobsterAI还具备长上下文记忆能力，能够在多次协作中逐步理解用户偏好，形成更高效、连贯的个性化体验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而针对用户关心的Agent自动操作风险，LobsterAI也采用了严格的“本地优先”策略。系统默认在沙盒环境（Sandbox）下的指定文件夹内运行，防止误操作破坏系统文件；同时支持数据本地化处理，杜绝云端泄露风险。在模型支持上，LobsterAI既预置了主流大模型API，也支持通过Ollama等框架调用DeepSeek&amp;nbsp;等本地开源模型，用户可根据任务对隐私和性能的需求灵活切换。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;业内观察人士指出，LobsterAI的上线，是有道多年积累的AI底层能力与应用洞察的一次集中爆发。它巧妙地结合了OpenClaw的技术深度与消费级产品的易用性，为国内Agent赛道提供了可落地的范本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;产品内测申请入口：&lt;a href=&quot;https://lobsterai.youdao.com/&quot;&gt;lobsterai.youdao.com&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/fuib2PTStVR1lfgjZUMc</link><guid isPermaLink="false">https://www.infoq.cn/article/fuib2PTStVR1lfgjZUMc</guid><pubDate>Wed, 11 Feb 2026 08:15:10 GMT</pubDate><author>网易有道技术团队</author><category>企业动态</category><category>AI&amp;大模型</category></item><item><title>谷歌推动模型上下文协议支持gRPC</title><description>&lt;p&gt;谷歌云&lt;a href=&quot;https://cloud.google.com/blog/products/networking/grpc-as-a-native-transport-for-mcp&quot;&gt;宣布&lt;/a&gt;&quot;将为模型上下文协议（Model Context Protocol，MCP）贡献一个gRPC传输包，填补那些在微服务中全面标准化使用gRPC的企业所面临的关键空白。MCP是&lt;a href=&quot;https://www.anthropic.com/news/model-context-protocol&quot;&gt;Anthropic推出的协议&lt;/a&gt;&quot;，用于实现AI智能体与外部工具和数据的集成，目前在企业环境中获得了广泛关注。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前，MCP默认使用&lt;a href=&quot;https://www.jsonrpc.org/historical/json-rpc-over-http.html&quot;&gt;基于HTTP的JSON-RPC&lt;/a&gt;&quot;作为传输层。这在处理自然语言负载时表现良好，但对于已全面采用gRPC的开发者而言，却带来了极大的不便。其他可选方案包括，重写服务以适配MCP的JSON传输、搭建转码代理，或并行维护两套独立实现，但是这些方案均不理想。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Spotify已经亲身体验过这种痛苦。该公司的高级员工工程师兼开发者体验技术负责人Stefan Särne在谷歌的&lt;a href=&quot;https://cloud.google.com/blog/products/networking/grpc-as-a-native-transport-for-mcp&quot;&gt;博客文章&lt;/a&gt;&quot;中表示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;由于gRPC是我们后端的标准协议，我们已在内部为基于gRPC的MCP提供了实验性支持，并且我们已经看到了其优势：对开发者而言非常易用且熟悉，同时通过利用结构化和静态类型的API，减少了构建MCP服务器所需的工作量。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一举措也得到了社区的支持。至少从2025年4月起，开发者就开始呼吁，在&lt;a href=&quot;https://github.com/modelcontextprotocol/modelcontextprotocol/discussions/1144&quot;&gt;GitHub的一次讨论（#1144）&lt;/a&gt;&quot;中，从业者们主张MCP从一开始就应该围绕gRPC构建，部分开发者在此期间已推出了自己基于gRPC的MCP服务器。2025年7月的一个&lt;a href=&quot;https://github.com/modelcontextprotocol/modelcontextprotocol/issues/966&quot;&gt;GitHub 问题（#966）&lt;/a&gt;&quot;获得了43个赞，开发者们指出，基于HTTP的JSON传输存在JSON序列化带来的高开销、资源监听时低效的长轮询，以及API契约缺乏类型安全性等问题。MCP维护者此后已经同意在SDK中支持可插拔得传输层，而谷歌计划自行贡献并分发gRPC传输包。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通过在底层使用&lt;a href=&quot;https://protobuf.dev/&quot;&gt;Protocol Buffers&lt;/a&gt;&quot;替换JSON，可以显著降低网络带宽和CPU开销。对于已部署gRPC基础设施的企业而言，这意味着AI智能体可以直接与现有服务通信，无需额外添加转换层。Protocol Buffers的结构化、类型化契约也与大多数后端服务的定义方式更为契合。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但是，该提案并未完全解决一个现实的矛盾。在&lt;a href=&quot;https://www.aifire.co/p/mcp-vs-grpc-the-future-of-ai-native-agent-connectivity&quot;&gt;Medium上&lt;/a&gt;&quot;，有一篇对比MCP与gRPC的分析文章指出：“gRPC的服务反射提供了结构信息（方法名、参数），但缺乏LLM所需的语义化、自然语言描述（也就是‘何时’和‘为何’）。”MCP 从设计之初就是为了向AI智能体提供这类上下文，即工具描述、资源说明、提示词指导，而gRPC本身并不具备这一能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;因此，更大的架构问题依然存在：MCP是应该适配gRPC这类现有的RPC系统，还是这些系统需要学习MCP的语言？从业者们对此意见不一。一些人认为，强制将运行良好的gRPC服务重写为JSON-RPC是完全不必要的麻烦。另一些人则认为，不能简单地将gRPC强加于一个以AI为中心的协议之上，而不添加LLM实际运行所需的语义层。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于将AI智能体投入生产环境的开发者而言，实际优势显而易见。那些已深度使用gRPC的企业（包括谷歌自身），它们“在全球范围内依赖gRPC来启用服务和提供API”，现在均可以直接采用MCP，而无需破坏现有的服务契约了。谷歌还为其自有服务推出了具有全球一致性端点的全托管远程MCP服务器，结合gRPC支持，使谷歌云能够直接面向那些已投资gRPC、希望添加AI智能体能力的企业。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;gRPC传输层仍在开发中。谷歌正通过Python SDK中一个关于可插拔传输接口的活跃&lt;a href=&quot;https://github.com/modelcontextprotocol/python-sdk/pull/1591&quot;&gt;pull request&lt;/a&gt;&quot;，与MCP社区合作推进。如果开发者关注该领域的话，MCP的GitHub仓库和&lt;a href=&quot;https://modelcontextprotocol.io/community/communication&quot;&gt;贡献者频道&lt;/a&gt;&quot;是了解最新进展的主要渠道。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/02/google-grpc-mcp-transport/&quot;&gt;&amp;nbsp;Google Pushes for gRPC Support in Model Context Protocol&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/IvpIeymHIWETqu4X7qo7</link><guid isPermaLink="false">https://www.infoq.cn/article/IvpIeymHIWETqu4X7qo7</guid><pubDate>Wed, 11 Feb 2026 08:00:00 GMT</pubDate><author>作者：Steef-Jan Wiggers</author><category>Google</category><category>AI&amp;大模型</category></item><item><title>Datadog 在其 LLM 可观测性工具中集成 Google ADK</title><description>&lt;p&gt;Datadog 近期&lt;a href=&quot;https://cloud.google.com/blog/products/management-tools/datadog-integrates-agent-development-kit-or-adk/&quot;&gt;宣布&lt;/a&gt;&quot;，其 LLM 可观测性平台已为使用 &lt;a href=&quot;https://google.github.io/adk-docs/&quot;&gt;Google Agent Development Kit (ADK)&lt;/a&gt;&quot; 构建的应用程序提供自动埋点功能，帮助用户更深入地洞察 AI 驱动型智能体系统的行为、性能、成本及安全性。该集成在 &lt;a href=&quot;https://cloud.google.com/blog/products/management-tools/datadog-integrates-agent-development-kit-or-adk/&quot;&gt;Google Cloud 博客&lt;/a&gt;&quot;上进行了重点介绍，旨在让开发者和 SRE 团队无需繁琐的手动配置或自定义埋点即可轻松监控和排查复杂的多步骤 AI 智能体工作流。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着企业越来越多地采用 ADK 等框架构建自主 AI 智能体，这些系统的非确定性特质使得预测输出、诊断故障和控制成本变得困难。Datadog 的新集成将 ADK 应用的信号接入其可观测性系统，使团队能够可视化智能体决策路径、追踪工具调用、测量令牌使用量和延迟，并标记出可能导致性能下降或 API 成本激增的意外循环和错误路由步骤。Datadog 通过将这些遥测数据与其他系统指标关联，帮助团队提升智能体的可靠性和运营信心。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该集成还填补了智能体部署中的一个空白：虽然 ADK 为跨场景构建 AI 智能体提供了灵活的框架，但其本身缺乏针对生产环境的监控和治理工具。Datadog 的埋点功能通过自动追踪每个智能体的操作并将其呈现在统一的时间线上，填补了这一空白，使团队能够轻松定位工具选择错误或低效重试循环等问题，从而避免因这些问题导致延迟增加或令牌开销上升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.datadoghq.com/product/llm-observability/&quot;&gt;Datadog 的 LLM 可观测性&lt;/a&gt;&quot;平台现在支持查看每个工具和工作流分支的令牌消耗及延迟情况，帮助识别智能体的异常行为和成本超支风险。这在企业环境中尤为重要，因为复杂的智能体编排往往涉及多模型、多工作流及外部系统集成，而传统应用性能监控难以应对以 AI 为核心的业务逻辑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过这一集成，Datadog 将其可观测性平台（已覆盖基础设施、安全和分布式系统）拓展至新兴的智能体 AI 应用领域，弥合了 AI 实验与稳定生产部署之间的鸿沟。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其他可观测性厂商也在开发类似的集成功能，帮助企业更好地理解和使用 LLM：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://newrelic.com/&quot;&gt;New Relic&lt;/a&gt;&quot; 提供全栈可观测性和 APM，具备强大的分布式追踪和性能洞察能力，正通过扩展遥测关联和 AI 感知监控功能向 AI 可观测性演进。虽然它尚未拥有与 Datadog ADK 集成相同水平的专用 LLM 工具，但它为应用和基础设施提供了坚实的端到端可见性，帮助团队理解 AI 和智能体工作负载如何与系统的其他部分交互。New Relic 采用基于数据摄取量而非主机数量的定价模式，对关注成本的团队而言更具可预测性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Splunk 的可观测性产品（包括 &lt;a href=&quot;https://www.splunk.com/en_us/products/observability-cloud.html&quot;&gt;Splunk Observability Cloud&lt;/a&gt;&quot;）擅长高容量日志摄取和查询，在跨各类数据集的详细取证分析方面表现突出。然而，与 Datadog 深度集成的智能体可观测性特性相比，开箱即用地关联 AI 特定信号（如令牌消耗或模型决策路径）可能需要更多配置工作。Splunk 在处理大规模非结构化遥测和以安全为中心的监控方面表现依然强劲，但在没有自定义埋点或插件的情况下，其内置的 AI/智能体工作流功能可能相对滞后。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;围绕 AI 和智能体可观测性的新兴需求正推动各厂商持续升级其工具，聚焦运行时追踪、序列与路径可视化，以及 AI 工作负载的成本和延迟洞察，但各厂商均基于自身核心优势采取了差异化策略。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/02/datadog-google-llm-observability/&quot;&gt;https://www.infoq.com/news/2026/02/datadog-google-llm-observability/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/ybR4DQTz6udDxBmKZpOi</link><guid isPermaLink="false">https://www.infoq.cn/article/ybR4DQTz6udDxBmKZpOi</guid><pubDate>Wed, 11 Feb 2026 07:00:00 GMT</pubDate><author>作者：Craig Risi</author><category>AI&amp;大模型</category></item><item><title>微软发布OData .NET（ODL）9.0.0预览版3：安全性、现代化API及规范遵从性</title><description>&lt;p&gt;微软&lt;a href=&quot;https://devblogs.microsoft.com/odata/announcing-odata-net-odl-9-preview-3-release/&quot;&gt;发布&lt;/a&gt;&quot;了OData .NET（ODL）9.0.0预览版3（这是OData .NET客户端和核心库的最新预览版本），延续了该库的现代化进程。这个预览版聚焦于更安全的默认行为、运行时API清理以及OData规范遵从性提升。OData .NET团队正朝着9.x的稳定版本努力推进。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;OData .NET核心库（如Microsoft.OData.Core）当前的稳定版本仍然是NuGet上的&lt;a href=&quot;https://github.com/OData/odata.net/releases/tag/8.4.3&quot;&gt;8.4.x系列版本&lt;/a&gt;&quot;，其中，8.4.3是该系列的最新稳定版本。该稳定分支支持OData v4/v4.01，并且广泛应用于生产环境，而&lt;a href=&quot;https://github.com/OData/odata.net/releases/tag/9.0.0-preview.3&quot;&gt;9.x版本仍在预览当中&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;预览版3延续了9.x早期预览版的约定，但根据开发者的反馈以及OData规范进行了以下几个方面的增强：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;动作查询执行现在使用SingleOrDefault()语义处理可空引用，在保留对非空值的严格检查的同时，减少了由常见的空响应所引发的意料之外的异常。移除了与ISerializable相关的旧序列化构造函数，消除了现代SDK上的构建警告。放弃了旧的CsdlTarget概念，并弃用了过时的返回类型访问器，转而支持更新的EDM接口。与IEdmOperation接口返回类型属性（ReturnType）相关的过时API也已被新的IEdmOperationReturn抽象完全替换。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些变化反映了这样一种发展方向：与.NET 8/9/10运行时保持兼容、内存占用更低的分配模式（如添加ReadOnlySpan&lt;char&gt;查找重载）以及对平台内置API的依赖。&lt;/char&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;预览版3的一个关键行为变化是强制对非类型化值进行结构化类型反序列化（不再有ReadUntypedAsString切换），使运行时行为更接近&lt;a href=&quot;https://www.odata.org/documentation/&quot;&gt;官方的OData JSON格式&lt;/a&gt;&quot;。此外，未指定类型的数值现在默认推断为特定的CLR数值类型，并提供兼容性标志以支持旧版结果（即解析为decimal的数值）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从稳定的8.x系列版本升级到9.x预览版的NuGet包应被视为破坏性变更：开发者需要检查可空返回值处理、预期的非类型化JSON shapes以及对已移除的旧API的依赖。由于9.x版本仍处于预览阶段，不建议在没有仔细测试的情况下用于生产环境。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;OData生态系统继续向前发展。举例来说，ASP.NET Core OData包独自进入了自己的9.x+系列（包括像&lt;a href=&quot;https://www.nuget.org/packages/Microsoft.AspNetCore.OData/9.4.1&quot;&gt;Microsoft.AspNetCore.OData 9.4.x&lt;/a&gt;&quot;这样的稳定版本），这表明服务端和客户端OData技术栈的相关工作正在并行推进。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有兴趣提供反馈或跟踪稳定化计划的开发者，可以关注&lt;a href=&quot;https://www.infoq.com/news/2026/01/odata-net-preview-9/odata.net&quot;&gt;OData/odata.net GitHub存储库&lt;/a&gt;&quot;和&lt;a href=&quot;https://devblogs.microsoft.com/odata/&quot;&gt;OData官方博客&lt;/a&gt;&quot;，获取预览公告、迁移指南和9.0最终稳定版的路线图动态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/odata-net-preview-9/&quot;&gt;https://www.infoq.com/news/2026/01/odata-net-preview-9/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/f0ev3d8fZtw2DaIdp85S</link><guid isPermaLink="false">https://www.infoq.cn/article/f0ev3d8fZtw2DaIdp85S</guid><pubDate>Wed, 11 Feb 2026 02:36:54 GMT</pubDate><author>作者：Edin Kapić</author><category>微软</category><category>后端</category></item><item><title>OpenEverest：开源数据库自动化平台</title><description>&lt;p&gt;近日，Percona宣布推出&lt;a href=&quot;https://openeverest.io/&quot;&gt;OpenEverest&lt;/a&gt;&quot;，这是一个支持多种数据库技术的开源平台，用于自动化数据库配置和管理。该平台最初发布时名为Percona Everest，可以托管在任何Kubernetes基础设施上，既可以是云端也可以是本地。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该项目的主要目标是避免供应商锁定，同时提供自动化的私有DBaaS。它基于Kubernetes operator构建，旨在避免依赖单一云供应商技术的复杂部署。OpenEverest是模块化的，允许开发人员和数据库管理员组合不同的数据库、存储系统和部署方法以满足特定的需求。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/aa/aac5d2f8395d99b4d773040c671752c7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;作为一个插件系统，其核心功能支持GKE Autopilot和Pod调度策略等特性。OpenEverest维护者、Solarica创始人&lt;a href=&quot;https://www.linkedin.com/in/sergeypronin/&quot;&gt;Sergey Pronin&lt;/a&gt;&quot;&lt;a href=&quot;https://openeverest.io/blog/welcome-to-everest/&quot;&gt;解释&lt;/a&gt;&quot;说：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;目前，我们专注于数据库管理，但我们真正的愿景远不止于此。我们正在构建一个模块化的基础架构，让你可以无缝地集成更多的数据引擎，连接整个运维体系，从而应对更广泛的数据基础设施挑战。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该项目通过其Web UI和&lt;a href=&quot;https://openeverest.io/docs/api/1.10.0/&quot;&gt;REST API&lt;/a&gt;&quot;简化了软件更新、监控、存储扩展和外部访问配置等运维任务。自定义资源DatabaseCluster、DatabaseClusterBackup和DatabaseClusterRestore定义了OpenEverest如何在Kubernetes中声明式地配置数据库集群以及管理它们的备份和恢复，使这些操作可以作为版本化的原生Kubernetes对象进行处理，并隐藏了特定于数据库运营商的大部分差异。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当Percona推出该项目的测试版时，社区反响褒贬不一。在Hacker News上，这引发了一场关于在Kubernetes上运行数据库集群是否是个好主意的&lt;a href=&quot;https://news.ycombinator.com/item?id=41411122&quot;&gt;辩论&lt;/a&gt;&quot;：一些人对使用Kubernetes运行数据工作负载持怀疑态度，其他人则强调托管备份、集群、扩展、升级、优化的好处，其中有位用户指出，“Kubernetes不适合运行数据库”是一个非常过时的看法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前，该项目支持通过各数据库引擎专属的&lt;a href=&quot;https://www.percona.com/software/percona-operators&quot;&gt;Percona operator&lt;/a&gt;&quot;部署和管理MySQL、PostgreSQL及MongoDB数据库集群。其功能涵盖数据库配置与扩展、备份及灾难恢复、基于角色的访问控制，以及在Kubernetes环境中灵活地分配资源。最新版本&lt;a href=&quot;https://newreleases.io/project/github/openeverest/openeverest/release/v1.11.0&quot;&gt;OpenEverest v1.11.0&lt;/a&gt;&quot;新增对PostgreSQL 18.1的支持，并通过NodePort支持实现了更灵活的网络配置。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/openeverest/roadmap&quot;&gt;正在进行当中的工作&lt;/a&gt;&quot;包括支持ClickHouse、Vitess、DocumentDB、Valkey等工具以及集成Prometheus和其他可观察性平台。根据&lt;a href=&quot;https://vision.openeverest.io/&quot;&gt;项目愿景页面的介绍&lt;/a&gt;&quot;，其长期目标是为构建和运营数据平台提供一个灵活的开源选项，并充分利用Kubernetes的普及性：“根据Kubernetes的调查数据，已经有50%的组织在生产环境的Kubernetes上运行数据工作负载。”Pronin&lt;a href=&quot;https://openeverest.io/blog/welcome-to-everest/&quot;&gt;阐述&lt;/a&gt;&quot;了从单供应商解决方案向开源转型的过程：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;该项目正在转变为OpenEverest——一个采用开放治理模式、拥有蓬勃发展的多供应商社区的独立开源项目。（……）OpenEverest将通过社区驱动的开放治理模式运作，摆脱单一供应商的控制。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该团队计划将该项目捐赠给CNCF，以保证其长期的独立性，并继续指导其孵化过程。OpenEverest并非在Kubernetes上管理数据库集群的唯一选择。KubeBlocks是一款开源operator（遵循AGPL-3.0许可），设计用于通过统一的API管理多种数据库类型，它目前支持35种数据库引擎，远超OpenEverest；而作为数据库管理平台，KubeDB虽然支持多种数据库，但已不再完全开源。此外，StackGres等特定于数据库的operator则专注于为单一主流开源数据库引擎提供深度功能集。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenEverest遵循Apache License 2.0许可。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/openeverest-kubernetes-databases/&quot;&gt;https://www.infoq.com/news/2026/01/openeverest-kubernetes-databases/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/QIisU8EsIh2itQlUSFj9</link><guid isPermaLink="false">https://www.infoq.cn/article/QIisU8EsIh2itQlUSFj9</guid><pubDate>Wed, 11 Feb 2026 02:34:03 GMT</pubDate><author>作者：Renato Losio</author><category>大数据</category><category>开源</category></item><item><title>预防数据泄露：在GCP上实施VPC服务控制的实践</title><description>&lt;p&gt;&lt;/p&gt;&lt;h2&gt;云环境中数据窃取方面的挑战&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;云计算革命彻底改变了应用程序的开发与部署方式。然而，传统的网络安全模式（即“&lt;a href=&quot;https://www.cloudflare.com/learning/access-management/castle-and-moat-network-security/&quot;&gt;城堡与护城河&lt;/a&gt;&quot;”方式）在云原生架构中就显得力不从心了。在云环境中，资源是分布式的、短暂的，并且可以从任何地方进行访问。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于迁移到公有云的企业来说，通过内部威胁、凭据盗取和服务配置错误所导致的数据窃取已成为一个重要的问题。行业报告显示，涉及云配置错误的数据泄露事件，每次给组织造成的平均损失为445万美元。在金融服务、医疗保健和受监管的行业，客户数据保护不仅仅是安全问题，更是合规性和法律的强制要求。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;虽然本文主要关注Google Cloud Platform的VPC Service Controls (VPC-SC)，但其原则、挑战和最佳实践广泛适用于各大云服务商。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;AWS通过VPC Endpoints和Service Control Policies提供了类似的功能，而Azure则提供了Service Endpoints和Private Link。虽然实现细节不同，但防止数据窃取的战略方法（全面发现、分阶段推出、组织协调和分层安全）是超越任何特定平台而共通的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在Google Cloud Platform中，&lt;a href=&quot;https://docs.cloud.google.com/vpc-service-controls/docs/overview&quot;&gt;VPC-SC&lt;/a&gt;&quot;在敏感云资源周围创建安全边界，防止未经授权的数据窃取，同时保持云的敏捷性和可扩展性。然而，在企业规模上实施VPC-SC（跨越数百个项目、多个区域和多样化的应用程序）需要战略级的规划、组织协调，并且要对安全需求和操作限制有着深刻的理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;本文分享了在大型金融科技组织的Google Cloud Platform (GCP)环境中实施VPC-SC的经验教训，以保护支付处理工作负载、客户数据分析和多区域部署。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;本文不会提供分步骤的配置指南，而是分享战略决策、组织挑战和来之不易的经验教训，这些因素决定了安全实施是否能够成功。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;深入理解VPC Service Controls：超越基础的周边安全性&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;VPC Service Controls会在GCP服务周围创建安全边界，强制执行基于资源位置、身份和网络来源的上下文感知访问策略。与在网络层操作的VPC防火墙不同，VPC-SC在服务API层进行操作，无论网络路径如何，都能控制对Google Cloud Storage、BigQuery、Vertex AI和Compute Engine的访问。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;它的三大核心构建块包括：&lt;/p&gt;&lt;p&gt;服务边界 (Service Perimeters)：在受保护的GCP项目和资源周围定义逻辑边界。边界内的资源可以自由通信，来自外部的访问则需要通过访问级别或入站/出站策略进行明确授权。访问级别 (Access Levels)：基于IP地址、设备状态、用户身份或地理位置定义访问边界内资源的条件，从而能够超越简单的允许/拒绝规则，实现上下文感知的安全性。入站和出站策略 (Ingress and Egress Policies)：指定哪些身份可以访问边界内的资源，以及边界内可以访问哪些外部资源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有一个常见的误解，那就是VPC-SC并不会取代网络安全，而是它的补充。实际上，如果VPC-SC配置得当，即使攻击者攻陷了VPC网络内的虚拟机，也无法将数据窃取到外部云存储桶中，无论网络连接情况如何，API调用都会被阻止。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一个关键区别是，VPC-SC保护的是受支持的GCP服务，而不是任意的网络流量。Google Cloud Storage、BigQuery、Compute Engine、Vertex AI、BigTable、GKE等都能得到保护，但VPC-SC并不控制虚拟机的出站互联网流量，也不检查应用程序协议。与虚拟防火墙和Cloud Armor的集成对于全面安全性仍然至关重要。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;架构图&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e9/e9fa02aacd83fc80372700b8dac5d7ea.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;设计VPC-SC架构：重要的战略决策&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;规划期间所做的关键设计决策决定了实施的成功或失败。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;从数据分类开始&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;并不是所有的数据都需要相同的保护。根据敏感性对数据进行分类，例如需要符合PCI-DSS的支付卡数据、受GDPR（General Data Protection Regulation）或CCPA（California Consumer Privacy Act）约束的个人身份信息 (personally identifiable information，PII)、机密业务数据和非敏感运营数据。这种分类会驱动边界的规划。高敏感的数据需要严格控制边界，允许的例外情况最少，而较低敏感的数据则允许更宽松的策略。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;建议分为三个边界层级：高安全性，用于支付处理，无出站策略；中安全性，用于客户分析，对出站访问受控的服务进行限制； 低安全性，用于开发/测试，策略较为宽松。这种方法在安全严谨性和运营灵活性之间取得了平衡。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;彻底映射依赖关系&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;依赖关系映射不完整是VPC-SC实施失败的头号原因。现代云应用程序依赖于共享服务、跨项目通信、CI/CD流水线、监控工具和第三方集成。在执行之前，必须记录每一个依赖关系。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们建议使用Cloud Asset Inventory进行资源发现，并分析Cloud Logging以获取服务到服务之间的通信模式。同时，采访应用程序团队以了解日志中看不到的外部依赖关系。对于大型组织，建议为发现阶段预留四到六周的时间，过于匆忙容易引发生产事故。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;服务账户是隐藏的依赖噩梦：在多个项目中共享的某个服务账户会引发意想不到的跨边界依赖关系。在为我所在的组织实施VPC-SC期间，我发现了散布在遗留系统、批处理作业和第三方集成中的数十个未记录的服务账户。其中许多可以追溯到多年以前，而维护它们的团队早已离职。每次发现都需要进行仔细评估，以确定该账号的使用是代表合法的业务需求，还是需要补救的安全漏洞。这一经验强化了服务账户发现必须与资源发现需要一样严格的观点，忽略某几个身份标识可能会破坏你的整个边界策略。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;边界拓扑：一个大边界还是多个小边界？&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;应该创建一个大的边界，还是按应用程序、业务部门或数据分类组织的多个较小的边界呢？答案取决于具体的组织结构和安全要求。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;多个边界会提供更强的隔离性，某个边界的违规不会危及其他边界。然而，它们增加了复杂性，因为跨边界通信需要显式策略或边界桥接。我发现混合方法效果最好：按安全层级（高/中/低）组织的广泛边界，以及用于共享服务（如集中日志记录、监控和CI/CD）或多个边界之间入站/出站策略的边界桥接。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于多区域部署，要避免为每个区域创建单独的边界。区域边界会带来不必要的复杂性，而不会增加额外的安全价值。VPC-SC策略是全局应用的。建议将所有区域资源包含在单个逻辑边界内，并在需要时使用IAM策略或访问级别进行特定于区域的访问控制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;实施：从设计到生产的三个阶段&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;第一阶段：发现与基线（四到六周）&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;发现工作不仅仅涉及技术资产盘点，还需要理解团队的工作方式、应用程序的通信模式以及安全漏洞的位置。为此，我组建了一个跨职能的工作组，成员包括安全工程师、基础设施团队、应用程序开发人员和业务利益相关者，我们每周开会，以审查发现结果、解决依赖性问题，并就边界范围达成共识。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;技术发现会利用多个来源：Google的Cloud Asset Inventory用于资源发现，Cloud Logging用于API模式，并且要采用团队访谈的方式来获取GCP日志无法捕获的上下文。我创建了可视化工具来映射服务的依赖关系，使得识别应该在边界内分组的资源集群变得更容易。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;第二阶段：演练模式实施（至少六到八周）&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;VPC-SC的演练模式（Dry-run Mode）使安全实施成为可能。在演练模式下，会评估边界策略，违规行为会被记录，但API调用不会被阻止。这种方法允许我们在生产环境中测试边界配置，而不会产生服务中断的风险。我的建议是，将初始的边界配置以演练模式部署至少30天。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;每日分析违规日志，按服务、方法和主体对违规行为进行分组，以识别模式。特定服务账户产生的大量违规可能表明存在未被发现的合法用例，或者需要限制权限过高的凭证。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;区分违规的性质：并非所有违规都是同等重要的。例如，被VPC-SC阻止的BigQuery读取操作可能会破坏关键的分析仪表板；而服务向外部存储桶写入数据的行为，可能正是我们要防止的数据窃取。建立违规分类（比如，需要调整策略的合法用例、可接受的已记录风险、需要补救的安全漏洞），并通过这个框架处理每一个违规行为。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;建立自动化仪表盘，显示违规趋势。违规数量的下降表明针对合法用例的政策调整取得了成功，而稳定或增加的违规行为则表明持续有依赖关系被发现，或者团队正在寻找绕过（尚未强制执行）控制措施的解决方法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;第三阶段：强制执行与运维管理&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;强制执行的决策应该以数据为驱动：违规行为应该被分类和批准，测试并记录回滚程序，并获得受影响团队的利益相关者签字。强制执行是逐步进行的：首先是开发环境，然后是预发布环境，最后是生产环境。每个环境强制执行两周，然后再进入下一个环境，以确保意外问题会首先在风险较低的环境中出现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;强制执行后，应该建立明确的例外请求流程：开发人员会遇到被边界策略阻止的合法场景。例外流程必须在安全性（不能授予破坏控制措施的全面例外权限）与敏捷（避免创建官僚式的冗长申请机制）之间取得平衡。在我的项目中，我创建了分层的例外机制：临时（72小时，由安全团队批准）、永久（需要安全架构审查）和书面申请。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;现实世界中的挑战与解决方案&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;BigQuery分析中断事件&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在强制执行数据分析边界三周后，我们的商业智能仪表板停止了更新。调查发现，边界外的服务账户正在访问BigQuery数据集。这个依赖关系在演练测试中被遗漏了，因为相关的批处理作业每月才运行一次。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们的紧急修复是创建一个临时的出站策略，允许特定的BigQuery进行操作，而长期解决方案则涉及重构批处理作业以使用边界内的服务账户，并更新依赖关系的文档。这一样例再次向我们重申，演练周期必须跨越完整的业务周期，并且自动化的依赖关系发现应该补充而不是替代人类的知识。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;平衡安全性与开发人员的生产力&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最大的挑战并非技术层面，而是在组织层面。起初，开发人员将VPC-SC视为阻碍工作且无明显收益的障碍。一些人甚至试图通过在服务前使用&lt;a href=&quot;https://docs.cloud.google.com/vpc/docs/private-service-connect&quot;&gt;Private Service Connect (PSC)&amp;nbsp;&lt;/a&gt;&quot;来绕过边界。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;解决方案需要改变我对安全性的沟通方式。我不再将VPC-SC呈现为一种限制，而是将其框架化为一种工具，保护他们的应用程序免受数据泄露，保护公司免受监管处罚，并保护他们的团队免受与安全事件相关联的风险。我的团队在自助工具上投入了大量资源，建立了一个网络门户，开发人员可以在其中检查服务账户访问权限、请求具有明确承诺的例外，并查看政策违规的解释和建议的补救措施。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当开发人员看到安全团队迅速响应合法需求，同时在不必要的例外方面保持坚定的边界时，他们的情绪也从抵制转变为接受。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;传统应用重构&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对本地环境设计的遗留应用程序通常会假定对存储和数据库都能够无限制地进行访问。一个从本地迁移过来的支付处理应用程序，几乎没有做任何更改，就试图将日志写入另一个GCP组织中的云存储桶，这在本地环境中是合理的模式，但在云安全边界中却是违规的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们并没有为这个应用程序创建一个例外来允许跨组织的数据传输，而是与应用程序团队合作重构了日志记录。现在，日志写入边界内的一个桶中，并且一个授权的导出过程将经过清理的日志移动到另一个组织中的桶中进行合规归档。这种重构花了六周时间，但提高了安全态势并减少了运营复杂性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当VPC-SC阻止操作时，首先问一下自己，“这应该是被允许吗？”而不是问，“我们该如何允许它？”有时候被阻止的操作代表了需要补救的技术债务，而不是需要适应的现状。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;将VPC-SC融入更广泛的云安全架构中&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;采用VPC Service Controls是全面云安全架构的一部分，而非独立的解决方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;分层的防御模型&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;将云安全视为一个同心层，需要在不同的层次提供保护。VPC-SC在服务API层运行，控制对GCP服务的访问。虚拟防火墙（例如Palo Alto Networks VM-Series）在网络层运行，控制IP流量并检查应用程序协议。Cloud Armor在应用程序层提供分布式拒绝服务（DDoS）保护和Web应用程序防火墙（WAF）功能。身份和访问管理（IAM）在资源级别控制基于身份的访问。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;每个层次都会捕捉不同的威胁向量。攻击者攻陷虚拟机后，即使他们已经绕过了网络级防火墙规则，可能也会被VPC-SC阻止通过云存储API进行数据窃取。DDoS攻击可能会在压垮虚拟防火墙之前被Cloud Armor缓解。即使攻击者已经进入了VPC网络和边界内，被盗凭据可能会被IAM的上下文感知访问策略检测到。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;VPC-SC为敏感资源定义了广泛的安全边界，虚拟防火墙提供了细粒度的网络流量控制和协议检查，Cloud Armor保护面向互联网的应用程序，而IAM在边界内强制执行最小权限访问。单一的控制措施是不够的，安全性来自它们的相互作用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;监控与事件响应&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;VPC-SC会为每次策略评估生成审计日志，从而为安全监控创建了丰富的数据。这些日志可以流式传输到Splunk等安全信息和事件管理（Security Information and Event Management，SIEM）平台进行分析和警报，或者使用原生GCP日志进行分析。关键的监控场景包括：&lt;/p&gt;&lt;p&gt;策略违规异常激增表明可能存在攻击或配置错误。同一主体重复违规可能表明存在合法的访问问题或侦察行为。出站违规访问敏感数据或外部存储桶可能表明正在尝试进行数据窃取。VPC-SC配置的变更应该仅通过批准的基础设施即代码流程进行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;针对VPC-SC检测到的数据窃取尝试的事件响应剧本包括：立即调查源主体和目的地，如果确认攻击则暂时收紧边界政策，进行Cloud Logging的取证分析以确定访问的数据，进行事后审查以确定事件是由安全漏洞还是成功攻击引起的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;衡量是否成功：指标与KPI&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;量化VPC-SC的影响需要定义业务、安全和运营指标。我们项目中的测量指标包括：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;安全指标&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前六个月内阻止了847次尝试进行数据窃取。通过逻辑隔离，PCI-DSS审计范围减少了40%。数据访问异常检测时间减少了45%。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;运维指标&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在稳定后，部署时间增加不到5%。标准例外的平均处理时间为四小时。通过自动化，策略管理时间减少了60%。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;业务指标&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;预计每年因为避免数据泄露减少了450万美元的损失每年合规成本节约20万美元实施成本为80万美元（12名工程师耗时6个月）在18个月内实现了正投资回报率（ROI）&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;最佳实践与经验教训&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;服务发现永无止境，即便采用穷举式的发现方法，也要预期会有意料之外的依赖关系。将服务发现过程视为持续进行的行为，维护依赖关系待办事项列表，安排季度审查，并要求对所有新部署进行依赖关系文档编制。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;演练时长至关重要，30天的演练测试是最低要求，而不是目标。对于具有每月批处理作业、季度报告周期或季节性流量模式的应用程序，要延长演练时间以捕获完整的业务周期。一周的强制执行延迟与生产中断的成本相比是微不足道的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;例外流程决定了成败，你的例外流程决定了VPC-SC是增强还是阻碍。明确的时间承诺、透明的批准标准和自助式请求提交，能够使开发人员将安全视为合作伙伴而非障碍。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;全面自动化，手工化的策略管理难以为继。对于所有的VPC-SC配置均应使用基础设施即代码（例如Terraform），或者构建一个自助工具，可以使用Cloud Functions添加策略。在生产部署之前实施自动化验证测试策略更改。自动化的预部署验证可以在生产之前捕获策略冲突。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;沟通能够消除阻力，技术卓越并不意味着能够被采用。我在沟通和利益相关者管理方面花的时间和技术实施一样多。制定定期的办公时间解释为什么VPC-SC能够保护每个人，带有示例和故障排除指南的清晰文档，对被VPC-SC阻止的开发人员积极进行响应，将组织文化从抵制转变为支持。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;未来改进的方向&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;VPC Service Controls代表了当前GCP数据窃取预防的最佳实践，但威胁和技术仍在不断发展。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;将VPC-SC与零信任原则对齐，明确验证的合规性，使用最小权限进行访问，并假定存在漏洞。未来的演进应该加强基于实时风险评分的动态访问级别，与身份威胁检测进行集成，在检测到可疑行为时及时撤销访问，以及基于威胁情报自动进行边界策略调整。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当前的IaC方式将安全策略视为静态配置。下一代的方法会将策略视为可测试、版本化的代码，并进行自动验证和部署。我们正在朝着策略测试、针对模拟攻击场景验证边界有效性、策略漂移检测（当部署的配置与批准的基线发生偏离时发出警报）以及策略影响分析（在部署之前预测对开发人员生产力的影响）的方向演进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;结论&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在企业级规模上实施VPC Service Controls表明，成功的安全不仅仅是技术，更关乎人员、流程和组织文化。VPC-SC在技术方面有着良好的口碑，并且相对简单。困难之处在于理解组织的独特需求，驾驭复杂的依赖关系，获得利益相关者的支持，并在实现业务敏捷性的同时保持安全严谨性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;核心原则超越了任何特定技术。安全的作用应该是促进而不是阻碍；严重损害生产力的控制措施需要规避。你应该设计避免不必要摩擦的安全防护，自动化可以进行大规模扩展，而手工过程难以做到这一点，因此要投资工具，使安全实践成为最简单的路径。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;指标很重要。无法衡量就难以改进：跟踪安全和运营的影响。完美是完成的敌人，请现在就部署有效的安全控制，而不是等待永远不会实现的完美控制。采用持续改进的方式，而非试图毕其功于一役。安全不是目的地，而是一种不断适应和完善的持续实践。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;VPC Service Controls为GCP环境提供了强大的数据窃取预防机制，但其有效性取决于详尽的设计、分阶段实施、组织协调以及与更广泛安全架构的集成。愿意投资于全面规划、接受迭代改进，并在安全与可用性之间取得平衡的组织，将发现VPC-SC是云安全战略中非常有价值组成部分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;威胁环境将继续演变，防御措施必须相应地发展。最重要的不是任何单一的技术，而是建立组织能力来评估风险、实施适当的控制措施、衡量效果，并持续改进能力，以服务于采用任意云平台或安全技术的组织。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/articles/preventing-data-exfiltration-google-cloud/&quot;&gt;Preventing Data Exfiltration: A Practical Implementation of VPC Service Controls at Enterprise Scale in Google Cloud Platform&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/QaR8toToJhEANT6gdQ6s</link><guid isPermaLink="false">https://www.infoq.cn/article/QaR8toToJhEANT6gdQ6s</guid><pubDate>Wed, 11 Feb 2026 02:31:35 GMT</pubDate><author>作者：Shijin Nair</author><category>大数据</category></item><item><title>千问发布最新图像模型Qwen-Image-2.0，支持1K token超长文字输入和2K高分辨率</title><description>&lt;p&gt;2月10日，阿里巴巴正式发布新一代图像生成及编辑模型Qwen-Image-2.0。据介绍，Qwen-Image-2.0集生图和编辑于一体，在AI Arena文生图评测中斩获1029分，超过Seedream4.5、Flux2-Max等模型，仅次于谷歌Nano Banana Pro和GPT Image1.5。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/83/83cfb6dd0c5fbd8506d351ef9bb95cfc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;AI Arena文生图评测中，Qwen-Image-2.0位居第三&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Qwen-Image-2.0支持1K token的超长文字输入和2K高分辨率，可准确渲染复杂指令，生成专业的PPT及信息图；同时，千问新模型拥有极强中文汉字渲染能力，数百字的古文全文几乎都能完全渲染在图片中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Qwen-Image-2.0在Qwen-Image和Qwen-Image-Edit两大模型基础上全新升级，首次将图像生成和编辑统一到一个模型中去，以更轻量的模型架构，实现了生图和改图性能的大幅提升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Qwen-Image-2.0 生图质感进一步提升，生成的人物、自然、建筑等常用图片更加逼真。在权威评测AI Arena中，千问新模型在图像生成中得分1029，位列第三；在图片编辑中得分1034，仅次于Nano Banana Pro。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/17/170cafb63ad908bde8359a00384f463f.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;Qwen-Image-2.0生图，以瘦金体写诗配图&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在中文汉字渲染方面，官方表示Qwen-Image-2.0 不但可以以多种字体准确渲染汉字，而且写得又多又准，效果比 Nano Banana Pro更优。千问新模型将输入提示词扩展到1K token，可详尽描述任务，实现更专业的文字渲染，在专业PPT、高级海报、多格漫画等复杂图片方面有不错表现，比如以小楷字体几近完全渲染《兰亭集序》数百字的全文配图，以自然语言生成论文格式配图的复杂PPT等。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/da/da0795cfaf18b0dea35ee0ded31a16e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;Qwen-Image-2.0生图，多文字复杂PPT一键生成&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，基于Qwen-Image-2.0模型，用户可与AI协同创作出更丰富、更实用的图片，比如一句话生成宫保鸡丁的做法流程图，杭州两日旅游攻略图，4x6的多格漫画组图，儿童绘本图，写实风格的电影海报，极为逼真的绿色丛林等等；同时，用户也可上传数张图片进行编辑，生成诸如九宫格多手势自拍，真人配字表情包，双人逼真AI合影，诗词配图等。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/8a/8a6a92a9fd10000108fdab5f3917ea14.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;Qwen-Image-2.0编辑图片&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据了解，阿里云百炼上已开通API邀测，开发者也可通过Qwen Chat免费体验新模型。&lt;/p&gt;</description><link>https://www.infoq.cn/article/b8LJJIs08XT0h9dRflsH</link><guid isPermaLink="false">https://www.infoq.cn/article/b8LJJIs08XT0h9dRflsH</guid><pubDate>Wed, 11 Feb 2026 02:09:10 GMT</pubDate><author>褚杏娟</author><category>AI&amp;大模型</category></item><item><title>模力工场 032 周 AI 应用榜：桌面 Agent 强势来袭，阶跃登顶本周榜首</title><description>&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;a href=&quot;https://agicamp.com/?utm_source=20260210infoQ&quot;&gt;模力工场&lt;/a&gt;&quot;新鲜事&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://agicamp.com/?utm_source=20260210infoQ&quot;&gt;模力工场&lt;/a&gt;&quot;邀你用 AI 一键生成新年财运红包封面！2月5日至25日，设计松鼠 × 模力创意红包，即可赢金币参与多轮现金抽奖。扫码进群，马上开启你的开年好运！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ca/cafd85344e3eb0dfc0714172e79b1126.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;032 周上榜应用精选（附用户热评）&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;模力工场 32 周 AI 应用周榜来啦～本周共有 25 款应用上架新榜，所有排名均来自用户真实使用、测评与社区讨论热度。本期用户讨论最高的是：桌面 Agent 形态的出现。AI 正在从“对话框里的助手”，走向“接管桌面的执行者”。AI 开始在真实桌面环境中，操作网页、处理本地文件、生成办公文档，甚至能把多个应用里的任务一口气跑完。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们从中精选出十款最具声量的应用，聚焦五大垂直领域，为你更详细地解读榜单背后的 AI 行业风向：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;一、桌面 Agent 类&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【关键词】：接管桌面｜跨应用操作｜真实执行&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://agicamp.com/products/stepfun-desktop?utm_source=20260210infoQ&quot;&gt;阶跃AI桌面伙伴 📍上海&lt;/a&gt;&quot;：一个更懂中文办公的国产桌面 AI 伙伴，无需复杂设置，全平台支持，深度整合钉钉、飞书等本土工具，用截图提问、智能整理、定时任务等贴心功能，为你打造真正懂中文、懂场景、懂流程的下一代智能工作台。&lt;/p&gt;&lt;p&gt;    &lt;/p&gt;&lt;p&gt;【用户热评】：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/36/3660388f8cfbad8960e33fd0215d44f3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://agicamp.com/products/workany?utm_source=20260210infoQ&quot;&gt;WorkAny 📍广州&lt;/a&gt;&quot;：艾逗比开发的开源跨平台桌面智能体，可以通过安全沙盒执行各类脚本，无缝处理文件整理、文档生成、网页制作等办公任务，更支持自定义模型与并行处理，用本地订阅打造你的专属 AI 生产力中心。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【用户热评】：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/72/72fd4ee7cf65a17a99ff9138019d141c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;二、学习 / 知识管理类&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【关键词】：结构化学习｜知识转写｜理解与记忆&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://agicamp.com/products/chatglm?utm_source=20260210infoQ&quot;&gt;智谱清言 AI 学习搭子&lt;/a&gt;&quot;：植入在智谱清言生态中的学习辅助模块，擅长把教材、文档和概念转化为知识地图、卡片和讲解内容，并配套随堂测试，更偏“陪伴式学习”和知识消化。&lt;a href=&quot;https://agicamp.com/products/thetawaveai?utm_source=20260210infoQ&quot;&gt;Thetawave AI&lt;/a&gt;&quot;：偏重输入端的学习整理工具，支持录音、视频、文档、网页等多源内容转写，并生成结构化笔记、思维导图和测验，适合学生和知识工作者做系统性复盘。&lt;a href=&quot;https://agicamp.com/products/notebooklmgoogle?utm_source=20260210infoQ&quot;&gt;Notebook LM&lt;/a&gt;&quot;：Google 推出的研究型笔记工具，更偏“资料理解与问答”。围绕用户上传的 PDF、网页、视频等材料进行摘要、提问和交互式研究整理，适合研究与长期项目。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;三、内容与视频创作类&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【关键词】：内容工业化｜全流程生成｜效率提升&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://agicamp.com/products/daoying?utm_source=20260210infoQ&quot;&gt;道影 AI 📍杭州&lt;/a&gt;&quot;：AI 视频全链路生产平台，面向短剧、漫剧等专业内容创作者。从剧本到成片一体化设计，强调流程贯通与规模化生产，而非单点创意工具。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;四、开发 / 编程协作类&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【关键词】：Vibe Coding｜一体化开发｜任务式编程&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://agicamp.com/products/zaizhi?utm_source=20260210infoQ&quot;&gt;OpenCode&lt;/a&gt;&quot;：为 Vibe Coding 场景设计的 AI 编程工具。把聊天、代码编辑、文件树和终端放在同一界面，支持 skill 封装与多模型切换，对编程新手非常友好。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【用户热评】：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/03/0398aaa68bffa221cef5510894d6bccb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;五、专业与底层能力类&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【关键词】：专业生成｜算力平台｜企业与垂直场景&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://agicamp.com/products/mureka?utm_source=20260210infoQ&quot;&gt;Mureka V8&lt;/a&gt;&quot;：昆仑万维推出的 AI 音乐生成平台，从自然语言或歌词直接生成结构完整、编曲成熟、人声自然的音乐作品，面向专业音乐创作场景。&lt;a href=&quot;https://agicamp.com/products/Prism?utm_source=20260210infoQ&quot;&gt;Prism&lt;/a&gt;&quot;：OpenAI 的 Prism 是一个不错的学术写作结构梳理与格式排版工具。它尤其适合在开题与文献综述阶段，帮你将思路系统化、可视化，并接手繁琐的 LaTeX 排版与参考文献管理。&lt;a href=&quot;https://agicamp.com/products/lanyun?utm_source=20260210infoQ&quot;&gt;蓝耘元生代 📍北京&lt;/a&gt;&quot;：以自研 MetaGen 智能算力操作系统为核心，面向企业提供集算力调度、模型服务与数据生成于一体的智算云平台，支撑 AI 应用落地。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;榜单之外但有趣的应用&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【应用名称】：&lt;a href=&quot;https://agicamp.com/products/Flora?utm_source=20260210infoQ&quot;&gt;Flora&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【关键词】：节点式创作｜无限画布｜创意工作流&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;【模力小A推荐】：Flora 是一款节点式创意 AI 平台，通过“无限画布”把文本、图像和视频生成串成可复用的工作流，适合品牌视觉、广告概念等跨媒介创作场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;本周上榜应用趋势解读&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从本期榜单可以清晰看到一个信号：AI 的主战场正在从“会不会回答问题”，转向“能不能把事做完”。桌面 Agent 的集中出现，是这一变化最直观的体现。相比以往停留在对话框里的助手，本周讨论热度最高的产品，已经开始直接接管桌面环境，真实操作网页、处理本地文件、生成办公文档，甚至跨多个应用连续执行任务。用户关注的核心不再是模型能力，而是执行稳定性、流程完整度和对真实工作场景的适配程度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与此同时，学习、内容创作和编程类应用的演进路径也在发生变化：它们不再强调“单次生成”，而是围绕结构化理解、完整流程和长期使用进行设计。无论是学习工具对多源资料的系统整理，还是内容平台对从创意到成片的全链路打通，本质上都在向“可持续使用的生产力工具”靠拢。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整体来看，本期周榜反映出的并非某一个爆款应用，而是一种明确趋势：AI 正在从能力展示，进入到执行与交付阶段。谁能真正嵌入用户的工作流，承担连续、可验证的任务，谁才更有可能成为下一阶段被长期留下来的 AI 应用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最后再介绍一下模力工场的上榜机制和加入榜单的参与方式，欢迎大家继续积极参与提交 AI 应用～&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;模力工场AI 应用榜并非依靠“点赞刷榜”，而是参考以下权重维度：&lt;/p&gt;&lt;p&gt;评论数（核心指标，代表社区真实反馈）&lt;/p&gt;&lt;p&gt;收藏与点赞（次级指标）&lt;/p&gt;&lt;p&gt;推荐人贡献（注册推荐人可直接为好应用打 Call）&lt;/p&gt;&lt;p&gt;加入榜单的参与方式：&lt;/p&gt;&lt;p&gt;如果你是开发者：上传你的 AI 应用，描述使用场景与核心亮点；&lt;/p&gt;&lt;p&gt;如果你是推荐人：发现好工具，发布推荐理由；&lt;/p&gt;&lt;p&gt;如果你是用户：关注榜单，评论互动，影响榜单权重，贡献真实声音。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;One More Thing，对于所有在模力工场上发布的 AI 应用，极客邦科技会借助旗下各品牌资源进行传播，短时间内触达千万级技术决策者与开发者、AI 用户：&lt;/p&gt;&lt;p&gt;InfoQ 全媒体矩阵&lt;/p&gt;&lt;p&gt;AI 前线全媒体矩阵&lt;/p&gt;&lt;p&gt;极客时间全媒体矩阵&lt;/p&gt;&lt;p&gt;TGO 鲲鹏会全媒体矩阵&lt;/p&gt;&lt;p&gt;霍太稳视频号&lt;/p&gt;</description><link>https://www.infoq.cn/article/5MpkYtE3SNEXSvkAYM03</link><guid isPermaLink="false">https://www.infoq.cn/article/5MpkYtE3SNEXSvkAYM03</guid><pubDate>Tue, 10 Feb 2026 12:00:00 GMT</pubDate><author>霍太稳@极客邦科技</author><category>AI&amp;大模型</category><category>AGICamp</category></item><item><title>为 ChatGPT 和 Claude 提供“地基”的那家公司，在担心什么</title><description>&lt;p&gt;过去一年，关于 AI 的讨论出现了一种明显的反差：一边是模型能力不断刷新上限，另一边却是越来越多企业开始质疑——为什么真正落地依然这么难？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从概念验证到生产系统，从 60% 的“看起来可用”到 99.99% 的“不得不可靠”，企业级 AI 面对的从来不是算力或参数规模的问题，而是数据、决策责任、合规流程以及现实系统复杂性。而这些恰恰是大多数新闻叙事里最容易被忽略的部分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;正是在这样的背景下，这期播客给出了一种罕见的“现实视角”。对话并没有继续渲染模型能力的指数级增长，而是把焦点放在一个更基础、也更棘手的问题上：AI 要真正进入企业和关键业务流程，还缺什么？答案指向了一个长期被低估的环节——数据，以及数据背后的人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;本期节目的对话者，正是站在这一环节核心位置的人。他所领导的公司，长期为几乎所有一线大模型实验室提供训练所需的基础数据；而在加入这家公司之前，他曾把一个看似边缘的想法，在极短时间内推演成一家年收入 200 亿美元的业务，也亲身经历过科技创业中最极端的法律与商业风险。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这场对谈中，他系统性地拆解了几个被反复误解的问题：&lt;/p&gt;&lt;p&gt;为什么大模型至今仍然离不开人类专家？&lt;/p&gt;&lt;p&gt;为什么绝大多数企业数据对 AI 来说毫无价值？&lt;/p&gt;&lt;p&gt;以及，当模型开始转向“智能体”和决策能力时，真正的瓶颈到底在哪里？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以下是播客整理翻译：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;精华摘要&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Lenny：最近有不少反对的声音，认为AI并没能满足人们对技术的全部想象，特别是在企业应用领域。您怎么看这个问题？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：AI方案往往需要半年到一年才能真正发展壮大，实现关键业务流程的自动化。跟以往的任何一次重大技术革命一样，新闻媒体总是过度乐观，而实际操作却没那么简单。互联网时代，宽带的铺设过程需要覆盖全国的每一条道路，还要跨大洲之间建立海底光缆，这些都需要时间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：关于未来两到三年的AI模型发展趋势，你觉得当前大家的普遍认知还有哪方面缺失？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：目前的总体趋势是从模型到模型功能的过渡。接下来最关键的问题是，大模型能为我们做什么，智能体如何替我们做出决策？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您在数据、标记、训练等领域都是当之无愧的技术先驱，您能不能展望一下AI领域在过去一年半以来的发展轨迹？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：一年半之前，大模型的能力极限就是生成一本短篇小说，不同模型生成的小说之间有优劣之分。而现在的大模型已经能帮哪怕最顶尖的Web开发者直接生成完整网站了，或者是就癌症诊疗问题给出相当全面且中肯的建议，而这些都需要专业人士耗费几个小时为其提供准确的统计数据。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您向来以严苛的业务衡量标准著名。那从创业的角度来看，您的核心理念是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：这个问题的实质，是大家对于未来机遇的洞察，包括这种洞察来自哪里。为什么你能够在数百万头脑聪慧、乐于尝试的创业者当中脱颖而出，掌握其他人所没有洞察力。谁能做到这一点，谁就可以领先一步。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;收购之后，Scale 还是 Scale 吗？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：欢迎今天到场的嘉宾Jason Droge，请先简单向大家介绍一下您的背景。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我是Scale AI的新任CEO，这也是我在接替Alex Wang接受Meta收购之后参与的首次采访。Alex现在领导Meta旗下的超级智能团队。在加入Scale AI之前，我与Travis Calendar曾共同创立一家公司，再向前追溯还在Uber等几家初创公司工作。我最知名的成果应该是创立并领导了Uber Eats，跟团队的同事一道把这个点子培养成了如今市值数十亿美元的企业。在COVID期间，Uber Eats几乎是以一己之力支撑起了因社交隔离而陷入瘫痪的Uber业务体系。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：这次采访的主题是AI模型如何拥有真正的智能。您觉得Scale AI在其中扮演了什么角色？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我们在ChatGPT和Claude身上看到了诸多改进。目前各个前沿领域都存在领军级别的模型，各家实验室则聘请专家填补这些大模型的知识空白，校正其对于事物运作方式的理解。而Scale是这一领域的先驱，也可以说是创造了这种业务形态。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：我们都很关心Scale的近况以及被Meta收购之后的变化。Scale目前情况如何？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：Scale仍然是一家完全独立的公司。在此次交易中，Meta投入140多亿美元以换取Scale公司49%的无投票权股份，且未获得新的董事会席位。Scale的董事会保持不变，治理结构几乎未肥影响，Meta对于Scale的任何资源也都不具备优先访问权。我们跟Meta一直在数据业务方面保持着长期合作关系，随着双方关系更进一步，各方面合作也有望持续扩大。但我们与其他各方的合作不会受到影响，Meta无法访问任何之前不对其开放的信息，例如隐私和数据安全政策等。事实上，此次交易只涉及约15位员工的变动，而Scale共拥有约1100名员工。现在我们旗下拥有两大业务部门，其营收都达到了数亿美元规模。公司内部相当于两家独角兽，支撑着每月的业务增长。总之，我们很高兴能够继续构建并交付数据，维持之前的工作模式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;数据不是苦力活：标注为何变成专家工作&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您提到 Scale主要面向AI数据市场，那能不能解释一下数据标注工作是怎么从当初的低成本劳动力转向如今的专家处理形式？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：没问题。首先，我认为其他竞争对手目前的定位是错误的，所以我先从这个角度切入，再逐渐延伸其他方面。这里我先花点时间介绍一下Scale的发展史，还有自2016年以来的发展脉络。Alex很早就意识到，数据对于模型来说至关重要。那时候他只有19、20岁，但他已经在考虑要如何围绕这个基本前提建立业务。他最初选择的方向是为自动驾驶做标注。标注数据的质量越高，汽车的行驶表现也会更好。之后这股浪潮演变成了计算机视觉，我们开始跟国防部门建立合作关系，为他们提供标注服务，到这里时间已经来到2020年。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来大模型的性能越来越强、愈发完善，需要的数据类型也更为丰富。所以我们一直在不断调整以提供所需的数据类型。在此期间，行业本身也在不断变化。记得两、三年前这些大语言模型刚出现的时候，经常会闹出幻觉问题，比如给出特别浅显的错误答案等等。但情况变化很快，我们也一直在随之改变。Scale一直走在前沿，开始为更复杂的任务提供专家级的数据标注服务。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;要聊过去一年半的情况我其实不太够格，因为我才加入公司13个月。刚加入时，我一直在做模型性能的测试。那时候大模型的能力极限就是生成一本短篇小说，不同模型生成的小说之间有优劣之分。而现在的大模型已经能帮哪怕最顶尖的Web开发者直接生成完整网站了，或者是就癌症诊疗问题给出相当全面且中肯的建议，而这些都需要专业人士耗费几个小时为其提供准确的统计数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们的专家中，有80%的同事拥有学士学位证书，这跟其他竞争对手的定位完全不同。其中约有15%的员工对相关行业有深入了解。这些高知人群通过为模型添加标签、贡献专业知识来赚取丰厚的收入。我很喜欢我们这种以专家级别进行数据标注的业务定位，这能帮助公司与研究人员保持联系、了解他们的需求。我们内部也很早意识到大模型在高度专业的领域上表现欠佳，所以我们会主动联系开发基座模型的大厂，表示我们注意到了这个问题，而且有专家团队可以搞定。我喜欢这种与众不同的定位，这跟竞争对手的想法完全不同。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：那Scale是怎么接洽并挽留这些专家贡献群体的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：确实不太容易接触得到，所以得制定相应的策略。具体的方式肯定不止一种，最主要的就是让专家们相互内推，而且他们很喜欢这种用自己的专业知识为AI做贡献的感觉，很酷。比如一位特定领域的博士在面对具体主题时，发现大模型的表现根本无法令人满意。那这时候他就可以通过有偿的方式提供专业建议，并借此赚取数百甚至数千美元。当然，我们也会推动校招，直接跟学校里的教授和学生们交流，询问有没有人愿意参与进来。当然，LinkedIn等传统渠道也是开放的，但效果最好的还是线下接洽和内推网络。这样能够为参与者提供良好的体验，因为他们的贡献一方面是为了赚钱，但更多是出于为AI模型做贡献的成就感。而且这个过程也是在替他们自己解决问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;智能体要学会做事：没有捷径，只有环境&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：有报道认为整个AI经济生态都将转向强化学习，您对此有何看法？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：强化学习当然非常重要，我觉得这种趋势性判断也很有道理。强化学习环境就相当于AI智能体的沙箱，它们可以在沙箱中学会如何达成目标。我们在这方面也尝试了一年有余。比如在Salesforce实例当中，AI智能体要如何实现导航？襳中包含哪些需要识别的数据？这要求智能体执行一套可靠性极高的业务流程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另外，智能体还得知道如果无法完成预期任务，或者判断正确完成任务的可能性较低，那要怎么向人类反馈以获取指引。所有这些都需要训练，而且不存在什么神奇的捷径。唯一的办法就是把AI智能体放进能代表人类正确操作的环境当中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;可以想象，现实世界中此类环境的数据和其中的不同目标可以说是无穷无尽，所以我们花了一年多跟模型开发商保持良好的合作关系，共同观察在不同任务/环境下的通用性表现。很明显，这类环境、软件系统、配置、数据类型、规模和用户数量各有不同，复杂性也差异巨大。这&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;就要求我们制定一种策略，让模型开发商能够收集到足够的通用数据以支撑广泛用例，而不必直接面对上万亿种任务和环境指标的排列组合。有些工作和数据之间具有更强的通用性，可以用一种简单的方式完成任务——比如在日历上找到要参与的访谈，让智能体浏览日历内容并弹出相应提示。接下来要做的，就是把智能体推广到一切日历搜索和日程管理操作。总之数据通用性越强，价值也就越大。我们的工作就是为模型开发商提供最有价值的数据，从而确保智能体尽可能为最终用户提供良好服务。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;企业AI不是演示：从 95% 到‘五个9’，差着一个世界&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：那您能举例聊聊具体向模型实验室提供哪些数据吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：当然可以。比如说我们的业务分为两个方面：其一是向模型开发商提供数据，也就是出售数据。其二则是向医疗保健系统、保险系统之类客户出售应用程序和服务解决方案。比方说我们跟一家医疗保健系统开发商合作，这套系统目前存在很多问题，部分专家需要定期处理少数罕见病例。因为专家人手不够，所以罕见病例会大量积压。这家医疗保健机构希望接诊更多病人，提供更好的护理体验并减少复诊次数，也就是在第一时间给出准确的诊断并制定治疗方案。如果没有AI的帮助，医生得耗费大量时间阅读长达两、三百页的病历文件。而我们开发的工具能帮助他们阅读这些文件，并指出其中最值得注意的五到十条内容。举例来说，某些过敏症状看似不起眼，但却可能跟医生开具的治疗药物发生冲突。AI工具可以快速提取这种人脑难以容纳的关联性要素，表现出相当完善的诊疗能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这方面，现成的模型肯定会有一定局限性，迫使医疗保健系统内部的人员亲自进行数据标注。不少企业乃至政府部门也会这么做，但仅靠现成模型加上一些零散数据没办法实现特别好的效果。毕竟很多银行或者医院一年的数据量就多达上百PB，他们自己根本没法判断哪些数据对模型有用。大多数数据都没价值，可怎么从中挑选出少数有价值的？而作为专业服务商，我们在数据的评判、挑选和专业知识储备方面非常出色，能够帮助客户顺利攻克这些瓶颈。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：要保证AI变得越来越聪明，咱们人类到底还要参与多久？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：首先，数据标注本身就是一段不断创新的历程，就跟自动驾驶汽车一样。现在我们需要的数据标注量已经远远少于过去了，什么时候我们不再需要外部数据、模型的训练不再需要人工数据时，那就已经发展到新的阶段了。换言之，这意味着那时人类提供的一切技能和知识都已经不重要，没办法推动模型的进一步提升了。但对于Scale这样的企业，我们一直在研究如何刹那起能够发现新需求，并与贡献者网络合作的运营体系。我们会邀请专家贡献者来挖掘这些数据和信息。另外，他们的很多才能并不会第一时间就表现出价值。比如一年前很多知识对模型没用，但现在却突然有了大用。这是个不断进步的过程，需要将越来越多的数据输入到模型当中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;出于经济动机，我们相信人类永远会在其中占据一席之地。这不只是种商业判断，更是我的个人信念，就像AI系统永远要为人类服务一样。我甚至觉得随着脑力岗位的逐渐消失，这就是未来知识工作者的主要转型方向。而且从我对部分客户身上观察到的情况，这种转变很可能在未来一到两年内发生。我当然希望这种颠覆别来得太快，但目前来讲确实是一切皆有可能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;至于从长远来看，新技术总会替代旧方案，比如收音机淘汰了现场播讲之类。人类还是很善于适应这种变化的，技术的发展史就是人类适应新模式的过程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您经常会提到“评估”这个词。那评估工作在专家们的日常工作中占比多少？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：占比还是相当高的。在企业和政府客户中，大部分业务内容就是评估，因为需要有人来设定“好”的基准。以之前提到的医疗保健来讲，医生在工作中就会评估病历报告和记录内容，然后对“好”做出明确的定义。这样慢慢累积起来的“好”和“正确”，就会让模型变得越来越可用。当然，AI的能力仍然有局限。对于那些人工流程的准确率很低的场景来说，AI就特别重要，因为能够切实帮上大忙。如果AI在其中能够达到50%、60%甚至70%、80%的准确率，那大家就乐疯了。但对于剩余的情况，比如人工流程的准确率能够达到98%，希望AI能解决余下的2%，那就很困难了。正因为如此，我们才需要明确定义“好”，让自己构建的系统能够代表使用者做出判断。在这样的设计思路下，AI系统就能像人类一样根据当前的信息尽可能给出最佳建议或者行动方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：很多人觉得AI是基于海量历史数据训练出来的，那AI在智能水平上怎么超越人类呢？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：这种理解对，但也不对。首先，跟以往的任何一次重大技术革命一样，新闻媒体总是过度乐观，而实际操作却没那么简单。互联网时代，宽带的铺设过程需要覆盖全国的每一条道路，还要跨大洲之间建立海底光缆，这些都需要时间。而且这些铺设工作总得有人去做。负责任地讲，作为从业者，我对于如今大模型在一致性和准确性方面的提升仍然感觉喜出望外。现在大家可能已经习惯了大模型越来越先进也越来越靠谱，但短短三年前这个问题还相当复杂，需要综合考虑多种因素。总之，大模型的发展是算力、模型本体和数据改进的共同产物，而这三条确实在同时进步。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：关于未来两到三年的AI模型发展趋势，你觉得当前大家的普遍认知还有哪方面缺失？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：大家对这个问题讨论得倒是不少，新闻报道也是层出不穷。具体怎么理解，要看我们选择怎样的视角。目前的总体趋势是从模型到模型功能的过渡。接下来最关键的问题是，大模型能为我们做什么，智能体如何替我们做出决策。一旦到了这个阶段，我们之前提到的应用环境就非常重要了。比如怎么让智能体在医疗保健系统内正确导航、如何在手机上的天气应用中导航，又怎么替我们做出决策。目前这一切才刚刚起步，我也期待看到后续的更多变化。而这也是大家相对不太了解的层面，对于改进的方式也是莫衷一是。如果选择最乐观的判断，那这一切就是经济体系下的又一波正常变动。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;换言之，AI普及不再是技术问题，而是人力和政策层面的问题。虽然目前还没到这个程度，但我确实相信未来两到三年之内，AI技术会发展到中心让治理层和政策制定者认真对待的阶段。现在已经离那个状态不远了，也就是两到三年的事。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：最近有不少反对的声音，认为AI并没能满足人们对技术的全部想象，特别是在企业应用领域。您怎么看这个问题？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：主要还是炒作得太狠了。我们的工作是打造出真正能够为客户创造价值的产品，并真正在解决复杂性上有所突破。还是以医疗保健系统为例，我们就在为医保公司提供理赔流程管理。这样的财务决策其实就是个可以自动化的过程，但在具体落地上学问就大了。很多人觉得概念验证能达到60%、70%的成功率就行，但这跟规模化应用还差得远。以数据中心为例，正常运行时间、可靠性和备份稳定性方面每增加一个“9”对应的都是又一个数量级的投入。比如四个“9”基本就是大学生自架服务器的水平，而五个“9”看起来只高了一点点，但其实完全是另一个世界。比如说很多人认为95%是个挺高的标准，但一旦用这个标准处理采购订单，那必然会面对无穷无尽的故障和投诉。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;总之，企业在应用AI时需要一步步完成法律批准、政策批准、监管批准和变更管理等各个环节，确保精度能让所有人满意。因此，AI方案往往需要半年到一年才能真正发展壮大，实现关键业务流程的自动化。所以大家一定要分得清新闻炒作跟实践落地。就像我自己的教育背景，博士这个头衔说起来轻，但背后需要付出的努力远超大多数人的想象。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;所有好生意，都是在不确定中被验证出来的&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您参与建立了Uber Eats，还创办过其他几家初创企业。关于获客户这个问题，您有没有什么独家心得可以分享？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我是那种愿意尝试一切新鲜事物的人，而且我总觉得创业是个非常清晰而且可把握的过程。我自己的思路是这样：在实际行动之前，先质疑自己听到的每一句话。我不会从字面上理解客户的表达，而是从产品管理的角度来审视。这个大家已经讨论得足够多了，比如说别按他们说的做、而要按他们预期的效果来做，这才是真正值得关注的问题。总之我会关注客户的潜在动机，而这种动机并不总是经济性质的，也往往跟自尊心和职业发展相关。比如说如果我们要向某人推销企业软件，那就得让对方相信你的软件能帮他们做好工作、建立起信任让对方接受你参与到大的项目中来。这个过程中重要的不只是产品，更要思考他们想得到怎样的建议、需要我们提供什么、需要怎么做才能找到正确的产品实现方向等等。我知道这话听起来有点陈词滥调，但只要让我准确把握住对方的真实动机，我就能拿出正确的结果。我再举个例子，当初在发布Uber Eats之前，我有认真考察业务。在获客方面，我们其实还给不出餐厅导览的功能，对餐饮行业也一无所知。但在Uber，我们最想解决的是接下来该拓展哪些其他业务。在考察了大量企业之后，我们觉得外卖业务最值得尝试，结果也证明这是正确的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了搜集数据，我们找了一家餐厅供应商并拿到一份基础目录，比如说一份典型的餐食要用多少火腿、多少奶酪、多少面包和多少片生菜，再据此推断食材成本有多少、人工成本是多少，进而建立起基准数据。把这些因素综合起来，我们就能把餐食品类建立起清晰的认知。我们发现食材在每份餐食中的成本大约占20%到30%，人工又占20%到30%，10%是房租和其他开销。总之这就是一种链条，而结合核算出的附加价值之后，我们决定收取账单总价的30%。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;餐厅刚开始会觉得这个数字太高了，本能性地想要拒绝。我们解释了自己的核算方式，说服对方做起来试试。事实证明餐厅的判断是正确的，这个比例确实太高了，最终确定下来的抽成是25%——跟我们的判断也相差不远。在这样的基础之上，我们再分析餐厅的主要价值实现形式是什么。对于游客型餐厅来讲，增加需求就是最关键的。在固定的餐厅店租、人力支出和食材成本都不变的前提下，需求增加三倍并不会增加人力支出，单纯的食材用量增加可以让产品的毛利率提升至70%到80%。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;基于这样的洞察，我们有信心在抽取一定费用之后店家和消费者都能接受。这就是市场经济的基本逻辑——不会只满足单独一方的所有需求，各方牺牲一点利益来保障自己余下的利益。Uber Eats就是这样的典型案例。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您向来以善于独立思考闻名，这种能力为什么如此重要？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：从创始人的角度来论述，在Uber我确实享受到了很多优势。我其实不算真正的创始人，只是参与了创业的流程。创业是涉及很多要素的，比如在97年创办第一家公司时，体验其实也就那样。但现在的创业可不一样了，每个人都在做自己的探索。但问题是，我们的研究方向多少都要受到周围言论的影响，那就没办法拥有独立的洞察力。所以最重要的独立思考，坚定去践行自己的判断。因此从创业的角度讲，我认为独特性非常重要。所以核心考验的就是人的洞察力，至于为什么我会幸运地拥有这种洞察力。这个问题的实质，是大家对于未来机遇的洞察，包括这种洞察来自哪里。为什么你能够在数百万头脑聪慧、乐于尝试的创业者当中脱颖而出，掌握其他人所没有洞察力。谁能做到这一点，谁就可以领先一步。也许是因为我有点“遗世独立”，也可能是因为我是那种擅长逆向思维的人，总会在寻求其他人不相信的真理，有时候这也挺有效的。而且最难的部分是，我们愿不愿意在自己的判断上押上五到十年时间？人们总会犯错，只能尽量跟客户沟通，试着解决困扰他们的问题。创业就是这样，我们必须有这种强烈的自我表达意愿，不断摧毁自己曾经坚信的东西。更难的一点在于，我们又要有能力超越自己的观点，不能自大到总认为自己就是全世界最了不起的独立思考者。这个事很辩证，但最终就是要靠结果来证明和支撑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您向来以严苛的业务衡量标准著名。那从创业的角度来看，您的核心理念是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：有时候最靠谱的创业方向，并不在于所谓最好的思路和机会。当然，对于我这种职业生涯已经超过25年的从业者，那选择空间和容错面会大得多。我认为一种业务的成功可以有两种途径：其一，也可以说是最重要的一种，就是创始人长期保持一股自我迭代和更新的力量。但这种年复一年的坚持其实很艰难。第二点是，可以直接去照搬其他人的经验，比如什么是好的商业模式、什么是差的商业模式、什么是好的市场定位、什么是差的市场定位。哪怕是拥有再强大的知识储备，哪怕理论上要进入的是一种比较差的市场定位，那只需要全身心投入，那随着时间推移也会逐渐显现回报。当然，我个人不会选择这种方式，我认为还是要根据市场需求走。纵观顶尖风投企业投资的项目，就会发现他们的投资组合是有规律的，至少是在对应价值数百亿美元的商业模式方面是有共性的，而且是具有网络效应的。规模大的业务就是比规模小的业务更有价值。比如我在Uber做过的新业务筛选，淘汰不好的想法其实挺快的，费不了多少时间。至于在筛选剩下的业务中，那就可以根据自己的直觉和热情去推动了。总而言之，我觉得大多数人对于哪些业务有机会增长到千亿美元规模缺少基本的理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您推动了Uber Eats的上线。那在确定选择外卖赛道之前，你还探索过哪些其他想法？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我肯定不是那种绝顶聪明的人，所以我会尽可能长期保持自己开放的态度，直到把各种有价值的元素都融合起来。有些想法刚开始看也许觉得比较差，但只需要不断挖掘，最终的对错判断很可能会反转。有一天，我在旧金山到处乱逛，看到了711之类的便利店。我就会想，大家要买到自己想要的东西需要转多少个拐角？难道不能直接把想要货品直接放进购物车吗？比如按下购物车上的按钮，它就直接把想要的货品送过来。毕竟叫“便利”店嘛，就得足够便利。所以我们在华盛顿特区推出了这项服务，在路上投放了大约十辆这样的卡车，里面装了大约250个吐货口。刚开始的情况很糟糕，根本就没多少人来买。于是我们意识到自己在下意识地找痛点，并不清楚便利店的核心吸引力是什么。我们的卡车不卖烟、不卖啤酒、不卖豌豆泥，我们不清楚大家最想买哪些商品。但说实话，工会的力量太强了，所以我天然地认为别用人工是最安全、成本最低的。我们很出色地解决了这个非经济学层面的问题，实现了便捷交付。但结果呢？我们做了Uber Spot还是什么，但跟点对点配送的Uber Direct一样，刚起步就表现不好。也就是说，消费者并没这方面需求，企业才有这种需求。2014年我们刚做尝试时，就没找到市场需求。后来我们持续更新了15个版本，最终发现外卖业务的表现才更出色，也拥有可靠的经济回报。这是个很酷的问题，我们可以用这些工具来支持夫妻店，让他们具备跟大企业竞争的资格。我们可以把房地产因素排除在外，让店面选址不再决定一切。只要你的餐食好吃，就完全可以吸引更多顾客。所以我觉得这是个很有趣的问题，真正促进当地经济发展。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：Uber Eats最终在Uber的危机时刻拉了母品牌一把，现在业务规模发展到多大了？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我们是2015年12月在多伦多推出了这项服务，大约两小时内销售额就达到了2万美元，简直是疯狂。我们很快意识到这个路子是对的，而且经济效益很好。我在Uber待了六年左右，用了一年半左右才把这个项目真正做起来，并在四年半之后把销售额做到了200亿美元。必须承认，Uber非常擅长扩大业务规模，但竞争激烈的市场上其他友商也做得不错。我们击败了很多对手，也有一些对手确实压我们一头。目前业务规模正在向着800亿美元迈进，时间才过去了短短四年半。我想COVID在其中也发挥了很大的推动作用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：众所周知，您曾经反对麦当劳加入Uber Eats。能分享一下这个故事吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：这事说起来就有意思了。或许有时候不想太多反而会让人意外找到正确的原因。我们发布的Uber Eats在全球范围内获得了广泛成功，而其中的基本愿景很简单：让小餐馆也能跟大规模连锁餐厅正面竞争。以巴黎来说，大家去巴黎旅行肯定不想吃大牌连锁餐厅，而更想发掘本地特色小店。这是现实需求，我们也决定参与其中。但后来麦当劳联系了我们，表示想跟我们一起做外卖业务。我们拒绝了，哪怕对方强调他们的日均消费者高达8000万。在拖了四、五个月之后，我们团队觉得我肯定是疯了，他们想促成这件事、而且愿意为之倾力投入。最终，我们还是跟麦当劳建立了独家合作关系，获得了大量连锁店客户。那时候大家都担心每单收益还能不能保证，毕竟订单规模到了单日几千万级别，这肯定是笔大钱。面对现实问题，Uber的企业文化就是缩小配送半径、在必要时提高某些食物的价格，反正总有办法解决的。三个月之后又有新的问题出现，业务再次陷入困境……总之很多同事觉得我在跟麦当劳合作方面太固执了，但我觉得最终至少还是达成了一笔很棒的交易。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：你一直很关注毛利率，能不能具体说说？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我是这样的，当然这只是我的评判标准之一。当然，也有不少企业本身很好，但毛利率也不高，比如说好市多、沃尔玛之类。亚马逊也有类似的情况。但总的来说，高毛利率加上相对较低的客户流失曲线，对企业来说肯定是个很健康的运营信号。毕竟生意的本质就是增加价值，这就像一块客观的试金石。我们在开展新业务的时候肯定也受到过毛利率问题的困扰，比如刚开始先试试毛利率40%的方案，发现可行再试着提升到60%——这时候商家就觉得不能接受了，大家再坐下来交流。至于离岸外包公司，他们的毛利率是多少？查了一下，大概在20%，而且已经运营了很长时间。那按这个规律来讲，我们的毛利率最终也将不可避免地从40%下降到20%，除非真能找到差异化的突破，否则必然要陷入这个巨坑。所以我认为毛利率只是个很粗糙的指标，远不能算是完美的工具。但至少它可以是种快速高效的过滤器，可以考查突然跳出来的想法能不能通过初步评估。比如说核算之后发现毛利率很低，就只能通过后续销量来弥补，那这事恐怕就不大行得通。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您提到“不输”是获得成功的先决条件，能不能给我们具体解释一下这个理念？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我们的科技文化是由投资者来建立投资组合，很多叙事是由投资者掌控。坦率地讲，创始人肯定也会参与其中。这种情况当然是比较理想的，只是我们没法确定自己会不会有这份运气。如果真说自己人生中只有一次尝试的机会，那我肯定不会轻易去行动，必须得三思而后行。虽然没有这方面数据做支撑，但我发现自己朋友圈里的企业家和最出色的创业者，会审视自己做决策时的风险状况，并在整个过程中都持续做出均衡和积极的决策调整。很多时候我们会忘记决策背后是对应着风险的。这里还有很多可以讨论的部分，因为我觉得用高风险决策最终取得成功是种特别不可取的文化现象，连培训当中都会认可这种思路。毕竟高风险决策必然带来巨大的波动，这对创始人最重要的特质——也就是坚持下去的能力是种直接挑战。大多数人在寻求最佳时机、与客户建立良好关系和将合适产品推向市场之前，就已经放弃退出了。而科技行业瞬息万变，我们确实可能在短时间内从平凡之人变成技术英雄，但大概率这会是个漫长的过程，得先活下来才能谈成功。而当前我们正身处炒作周期，每个人都想尝试、全力投入，但却没意识到客户会一直在，希望自己的问题能得到解决。总之，生存是一切的前提，我们要尽量别把业务发展置于危及的境地。当然，我也不是说完全拒绝任何冒险，这是个需要认真权衡利弊的大问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;快问快答&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您肯定也经历过失败，能不能分享一条从痛苦经历中汲取到的教训？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：我还是认为多花点时间提前思考，可以避免后续的很多麻烦。我之前确实做过一些尝试，但结果一般就不细聊了。在2001年互联网泡沫破裂之后，我曾打算筹资创办一家公司、而且是能赚钱的公司，成果就是Scour。坦白讲，当时我没在科技行业发现什么好机会，所以我开始在网上卖二手高尔夫球杆，还真赚了不少钱。那会我才22岁，考虑得并不周全，而且我的预期也不高，因为我觉得这生意什么人都能做。但我确实赚了很多钱，甚至想过把全美国所有的二手高尔夫球杆都买下来，直接操控整个市场的交易价格。我太年轻、太自负了，根本没认真思考过这件事的可行性。总之我就这样进入了这个行业，还靠这个赚了几百万美元。但整个过程都让我很痛苦，因为&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您对招聘人才和组建团队很有见解，能不能聊聊自己的理念？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：最近我对这个问题又有了更具体的理解。比如某些职位，就必须要有对当前市场丰富的观察和理解。毕竟市场发展太快，没时间慢慢去培训，所以要找的就是那些哪怕其他条件弱些、但真正理解市场和能够跟客户建立良好关系的人。有了这个前提，其余的部分才能跟公司共同成长，并建立起理想的职业发展轨迹。当然，这类职位只能在公司中只占5%，但它们对于产品的快速上市非常重要。比如在面试当中，我就只考查三点：对于解决问题是否抱有足够的好奇心，是不是擅长把自己的想法准确表达出来，还有能不能很好地跟其他人合作、特别是扮演好领导者。我相对不那么看重专业知识，毕竟我自己肯定有能力边界，不可能在所有专业知识上都做出准确判断。但只要能成功做好这几点，对方的成功几率就相当高。面对世界的持续变化，我们需要的就是具备极强适应能力的人。以Uber Eats为例，当初组建项目管理团队时，我总会通过招人把团队设计成一个优势互补扔 机体，同时尽量减少团队中除运营以外的大部分冲突。而且从一无所有到高达200亿美元的估值，我的这个理念始终没有动摇。我一直坚信团队成员间了解彼此的优势和劣势，而且能够相互弥补，这比传统上的各种考核标准都要靠谱。换句话说，我必须得学会相信员工，因为我不可能亲自掌控一切。当然，人事系统是非常复杂的，不可能基于我简单的几句话就生搬硬套。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：在日常生活和工作当中，你发现了哪些AI应用方式？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：说实话，我在加入Scale之前是在消费电子领域工作，也参与过政府层面的一些应用项目。AI这个领域发展太快了，每当有新概念出现我都会认真学习，也会向公司里的其他同事请教技术细节，比如说数据和产品的技术特征。但他们的时间也有限，更多新概念还得靠自己主动学习。大家可能不相信，我的主要工作并不是处理跟AI相关的工程问题，而是管理这个组织。为了避免频繁打扰同事，很多时候我也会直接跟AI学习，在上下班的路上跟它聊天。这已经变成我生活中的一种习惯，也是我从业以来见证过的最不可思议的奇迹。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;比如之前采访Perplexity创始人的时候，对方就介绍他们要求同事在提出任何问题之前，必须先请教AI。那时候这还是种很疯狂的工作方式，但现在看来他们的领先恰恰体现在这里。至于在工作当中，我会上传一份内部文件，然后边亲自阅读边比较它的提炼结果。让人震惊的是，AI的表现真的非常出色，而且帮我节约了大量时间。在大规模组织中，我们经常会遇到这样的难题：我不知道你想让我说什么，我也不知道自己需要了解什么，这就导致大家各有议程、自说自话。那面对这样的传播挑战，AI确实能帮上大忙，太神奇了。我现在会用它来处理法律文件，比如快速了解对手打算怎么对付我、我又该怎么应对。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您还有什么想跟听众们分享吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：有啊。我想向大家强调Scale团队的卓越贡献。我们一直非常努力，持续为客户提供巨大的价值。任何语言在这份努力面前都显得苍白无力，更无法体现客户在此基础之上解决的无数问题。我认为这份付出配得上一切尊重和回报。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您最近发现什么自己特别喜欢的产品了吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：应该说是Veo 3吧，虽然不算全新产品。高中时我曾梦想当个编剧，还认真写过剧本。所以这次我找出第一页、拍下照片，再上传到Veo 3。结果真的让我震惊，居然一张剧本照片也能生成相应的视频画面。现在我在考虑怎么把这些工具用来生成家庭录像，再利用其他工具让内容更加生动。虽然还有进一步迭代的空间，但这种体验真的很有趣。这类工具真的会改变人们的情感生活，比如让祖父母、亲戚或其他很久没见的人在照片中动起来，这会产生很大的情感冲击。训练出这套模型的技术人员很厉害，而帮助他们做专家级数据标注的服务者也很厉害。这种直接把文字转化成光景的能力很棒，也很酷。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：您最喜欢的人生格言是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：终点永远不是终点。这是我最喜欢、也深深牢记心中的格言。这跟之前关于生存才是第一要务的观点差不多，只有先活下来才有机会获得成功。纵观自己的创业历程，我觉得这条的指导意义最大。每个人都会经历艰难的旅程，但只要能在这段旅程中坚持五年，那大家的精神承受力绝对会比99.9%的人强。更具体地讲，我们在努力工作时会深切感受到这句话的意义。有时候我们觉得自己太累了，想要停下来，但事实上只要继续前进，似乎就又可以坚持下去了。我牢记这句话，提醒自己任何一个节点都不是真正的终点，仍然有更远的标的有待探寻。所以无论当下的解决方案到底完不完美，我们都可以先勇敢接受，然后抖擞前行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：如果想要与您交流或者了解更多关于Scale的信息，应该怎么安排？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Droege：当然可以，大家可以关注我的邮箱，随时了解最新动态。如果是招聘方面的诉求，可以直接访问scale.com、进入我们的招聘页面，目前公司开放了250个空缺职位。我们的业务仍在扩展，包括应用程序业务、数据业务和服务业务都在疯狂增长。我们需要更多人手来帮助我们推进这段旅程。我们还刚刚跟政府签下了巨额合同，金额是21亿美元——而且不是一份，而一个月内签了两份。我们的政府业务做得很好、企业业务做得很好、国际政府业务同样做得很好。公司市场需求很大，也让不少销售人员拿到了丰厚的佣金。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.lennysnewsletter.com/p/first-interview-with-scale-ais-ceo-jason-droege&quot;&gt;https://www.lennysnewsletter.com/p/first-interview-with-scale-ais-ceo-jason-droege&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description><link>https://www.infoq.cn/article/LtKGv3oRvYQHSzUir3O6</link><guid isPermaLink="false">https://www.infoq.cn/article/LtKGv3oRvYQHSzUir3O6</guid><pubDate>Tue, 10 Feb 2026 11:43:36 GMT</pubDate><author>核子可乐,Tina</author><category>生成式 AI</category></item><item><title>Java探索载体类以扩展面向数据编程</title><description>&lt;p&gt;OpenJDK的&lt;a href=&quot;https://openjdk.org/projects/amber/&quot;&gt;Amber项目&lt;/a&gt;&quot;发布了一份全新的设计说明，名为“&lt;a href=&quot;https://openjdk.org/projects/amber/design-notes/beyond-records&quot;&gt;Java面向数据编程：超越记录类（Record）&lt;/a&gt;&quot;”，阐述了一种探索性的方案，以便将类似记录类的特性拓展至更灵活的类设计中。该文档引入了载体类（carrier class）与载体接口（carrier interface）的概念，目标是提炼记录类的核心优势并进行通用化适配，同时不再强加严格的表述规则。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Java 16引入了记录类，为不可变数据载体的建模提供了简洁的方式。如下这种记录类的声明：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;java&quot;&gt;record Point(int x, int y) { }
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;编译器会自动为其生成规范的构造器、访问器方法，以及equals、hashCode和toString方法的实现。记录类还支持解构（deconstruction）模式，可以配合instanceof和switch关键字使用。结合密封类与模式匹配特性，记录类能实现Java中代数数据类型的建模。例如，HTTP客户端或网关可以按如下方式定义不同的响应类型：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;java&quot;&gt;public sealed interface HttpResponse permits HttpResponse.Success, HttpResponse.NotFound, HttpResponse.ServerError {
    record Success(int status, String body) implements HttpResponse {}
    record NotFound(String message) implements HttpResponse {}
    record ServerError(int status, String error) implements HttpResponse {}
}
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基于这样的响应类型层级，我们可以通过穷举式模式匹配进行统一处理：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;java&quot;&gt;static String handle(HttpResponse response) {
   return switch (response) {
       case Success(var code, var body) -&amp;gt; &quot;OK (&quot; + code + &quot;): &quot; + body;
       case NotFound(var msg) -&amp;gt; &quot;404: &quot; + msg;
       case ServerError(var code, var err) -&amp;gt; &quot;Error (&quot; + code + &quot;): &quot; + err;
   };
}
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此示例中，编译器会强制检查是否覆盖了所有允许的响应类型。若新增一种响应类型，必须同步更新该switch表达式，从而降低不完整错误处理的风险。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在近期的一次讨论中，甲骨文公司的Java语言架构师&lt;a href=&quot;https://www.linkedin.com/in/briangoetz/&quot;&gt;Brian Goetz&lt;/a&gt;&quot;指出，这些特性的组合虽然能实现强大的数据建模能力，但实际落地却经常会受到长期形成的面向对象设计习惯制约。他发现，即便现代语言特性已能大幅减少间接代码，开发人员仍会习惯性地设计用于中介数据访问的API。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这份设计说明重点聚焦于记录类无法适用的场景。实际开发中，许多数据类型需要派生值或缓存值、可选的内部表示形式、可变性或继承特性。在这种情况下，开发人员只能退而求其次，使用传统类，并重写大量的样板代码。文档将这种转变形容为“断崖式回落”，对记录类的基准模型做微小调整，就会导致代码量的大幅增加。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了缓解这一问题，文档提出了载体类的设计思路。载体类以类似记录类头信息的状态描述作为开头，其余行为则与普通类完全一致：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;java&quot;&gt;class Point(int x, int y) {
    private final component int x;
    private final component int y;
}
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其中，状态描述用于定义类的逻辑组件，编译器可基于这些组件自动生成访问器、对象方法及解构模式。与记录类不同，载体类不要求将所有状态仅存储在这些组件中，这也是其核心灵活性所在。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种灵活性能实现记录类难以表达的设计模式，例如缓存派生值的场景：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;java&quot;&gt;class Point(int x, int y) {
    private final component int x;
    private final component int y;
    private final double norm;

    Point { norm = Math.hypot(x, y); }
    double norm() { return norm; }
}
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此例中，派生值norm在构造阶段计算完成，并且未纳入状态描述，但该类仍能借助编译器为其组件自动生成的方法，减少样板代码编写。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;载体类同样设计为可与模式匹配深度集成，用法与记录类一致：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;java&quot;&gt;if (obj instanceof Point(var x, var y)) {
    // use x and y
}
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;设计说明中还进一步探讨了载体类与未来重构特性的兼容性，例如，针对记录类的&lt;a href=&quot;https://openjdk.org/jeps/468&quot;&gt;JEP 468&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除载体类外，该提案还引入了载体接口的概念，接口可声明自身的状态描述，并且所有实现类都能参与统一的模式匹配：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;java&quot;&gt;interface Pair&lt;t, u=&quot;&quot;&gt;(T first, U second) { }

switch (pair) {
    case Pair(var a, var b) -&amp;gt; ...
}
&lt;/t,&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种设计能简化日常开发中常见的元组式抽象，同时保留Java强类型的优势。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这份设计说明将载体类置于Java向面向数据编程整体转型的背景下，通过结合记录类、密闭类型、模式匹配，再加上潜在的载体类，Java正逐步引导开发者直接建模数据结构，而非依赖层级繁杂的API。Goetz认为，当前的核心挑战在于，帮助开发者意识到，在将“数据”作为首要抽象时，大量的支撑性代码都可被省略。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，“超越记录类”还属于探索性的文档，官方尚未公布具体的语法定义、JEP提案及版本发布时间表。但这份文档释放了明确的信号，那就是Amber项目将持续推进相关研发，进一步减少Java的样板代码，并将现代语言特性拓展至更复杂的类设计中，而这些探索，也许会将影响未来版本中Java开发者构建以数据为核心的 API的方式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/02/java-beyond-records/&quot;&gt;Java Explores Carrier Classes to Extend Data-Oriented Programming Beyond Records&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/PoMHdgGXx5dywm8pYDme</link><guid isPermaLink="false">https://www.infoq.cn/article/PoMHdgGXx5dywm8pYDme</guid><pubDate>Tue, 10 Feb 2026 11:26:42 GMT</pubDate><author>作者：A N M Bazlur Rahman</author><category>编程语言</category></item><item><title>谷歌推出托管AlloyDB连接池</title><description>&lt;p&gt;谷歌云&lt;a href=&quot;https://docs.cloud.google.com/alloydb/docs/release-notes#December_18_2025&quot;&gt;正式发布&lt;/a&gt;&quot;AlloyDB for PostgreSQL通用托管连接池，将类似PgBouncer的功能直接集成到数据库服务中。按照谷歌的说法，与直接连接相比，这一特性能够提供3倍多的客户端连接和高达5倍的事务吞吐量，帮助开发者解决了运行高并发工作负载时面临的扩展挑战。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;连接池并不是什么新鲜事。多年来，为了重用数据库连接而不是为每个请求创建新的连接，开发者们将&lt;a href=&quot;https://www.pgbouncer.org/&quot;&gt;PgBouncer&lt;/a&gt;&quot;或&lt;a href=&quot;https://www.pgpool.net/docs/latest/en/html/&quot;&gt;pgpool&lt;/a&gt;&quot;作为单独的基础设施进行了部署。现在，AlloyDB可以自动完成这些工作了。开发者可以通过控制台复选框或API调用来启用它，连接池使用6432端口，而常规连接使用5432端口。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;托管连接池会缓存预先建好的连接，将它们分配给传入请求，并在使用完成后将它们返回给连接池，而不是关闭它们。谷歌表示，这可以消除“运维负担”，作为AlloyDB实例的一部分，连接池会自动升级和扩展。连接池和数据库之间的通信在谷歌云的网络内运行，可能比外部连接池设置的延迟小。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于Cloud Run或Cloud Functions上的无服务器部署，其优势更为显著。这些平台会启动多个实例，每个实例都会打开数据库连接，在流量高峰时往往会超出PostgreSQL的连接限制。对于这种情况，连接池是一个很好的缓冲，它利用现有的连接处理请求，而非强制数据库同时处理数百个新的连接尝试。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;UKG高级首席架构师Jeff Bogenschneider在早期测试期间描述了其影响：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;AlloyDB的架构使我们能够在单个集群中部署的数据库数量远超其他Postgres托管服务。此前我们曾担心连接限制问题，而托管连接池可以帮助我们确保全球的客户都能获得最佳的性能，让我们得以自由地扩展业务，而不用担心在高峰使用时段遇到连接限制问题。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;运行微服务的开发者应该考虑将应用端连接池与AlloyDB的托管连接池配对。在&lt;a href=&quot;https://medium.com/google-cloud/elastic-microservices-rigid-databases-connection-exhaustion-8cdc558f212a&quot;&gt;Medium&lt;/a&gt;&quot;上，Adarsha Kuthuru和Kumar Ramamurthy详细描述了这种“双池”模式：像HikariCP这样的应用连接池为每个实例维持5-10个到AlloyDB连接池的连接，后者通过多路复用将这些连接连接到数量更少的后端数据库连接。这个方案可以避免为50个微服务实例各建立20个连接时，1000个并发连接冲击数据库的场景。作者建议为每个vCPU配置15-20个连接器连接，并协调各层的超时设置，避免连接重置错误。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该功能提供两种连接池模式。事务模式（默认）通过为每个事务分配独立的连接来最大化可扩展性；会话模式完全兼容PostgreSQL的功能。开发者可以通过AlloyDB API中的标准PgBouncer参数调整连接池规模、超时设置及空闲阈值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该功能存在一些限制。托管连接池不适用于AlloyDB Auth Proxy或语言连接器——开发者需要直接连接。这妨碍了依赖身份验证代理进行凭据轮换或简化TLS配置的部署模式。在2024年11月前部署的实例上启用连接池功能时，由于要更新VPC设置，会引发短暂的网络中断（持续时间少于15秒）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于已经单独运行PgBouncer的开发者而言，迁移至托管连接池主要在于整合基础设施——减少一个需要打补丁的组件。对于新增部署，尤其是无服务器或高并发工作负载，启用该功能所需的投入极少，却能防患于未然，在扩展问题爆发前将其及时化解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌提供了&lt;a href=&quot;https://docs.cloud.google.com/alloydb/docs/configure-managed-connection-pooling&quot;&gt;配置托管连接池&lt;/a&gt;&quot;的文档和在现有实例上&lt;a href=&quot;https://docs.cloud.google.com/alloydb/docs/configure-managed-connection-pooling#enable-managed-connection-pooling&quot;&gt;启用该特性&lt;/a&gt;&quot;的最佳实践。对于双池模式，发表在Medium上的博文提供了一份部署指南。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/alloydb-managed-connection-pool/&quot;&gt;https://www.infoq.com/news/2026/01/alloydb-managed-connection-pool/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/zjNtBfmQQa580Aoc9Rud</link><guid isPermaLink="false">https://www.infoq.cn/article/zjNtBfmQQa580Aoc9Rud</guid><pubDate>Tue, 10 Feb 2026 11:21:10 GMT</pubDate><author>Steef-Jan Wiggers</author><category>Google</category><category>大数据</category></item><item><title>突发！继杨格过劳病离职后，xAI又一位联创出走，疑单独创业</title><description>&lt;p&gt;&lt;/p&gt;&lt;h2&gt;刚刚，xAI 又损失一位华人联创&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;几个小时前，全球首富马斯克旗下人工智能公司 xAI 再迎联合创始团队成员离职。xAI 公司联合创始人 Yuhuai (Tony) Wu（音译：吴玉怀）在x上发文称，今天正式从 xAI 辞职了。他写道：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;“这家公司——以及我们之间如同家人般的情谊——将永远铭刻在我的记忆中。我会深深怀念这里的人们、作战室，以及我们并肩作战过的所有战役。&amp;nbsp;我的人生新篇章即将开启。这是一个充满无限可能的时代：一支配备人工智能的小团队可以移山填海，重新定义一切皆有可能。”&amp;nbsp;致埃隆 &lt;a href=&quot;https://x.com/elonmusk&quot;&gt;@elonmusk&lt;/a&gt;&quot;，感谢你们相信我们的使命，也感谢你们带给我们这段毕生难忘的旅程。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f3/f34f72fba29a82e49db7cc369f6d2cdc.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;据 LinkedIn 资料和媒体相关报道，吴是著名人工智能研究者与企业家，因联合创立 xAI 而广为业界所知。吴在 xAI 的任职期间被视为技术与研究团队核心成员之一，负责推动推理与数学智能相关方面的研发工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;根据吴的LinkedIn个人资料显示，在加入该公司之前，他曾在谷歌工作近两年，担任研究科学家（Research Scientist），参与与神经网络、数学推理相关的大型语言模型等研究项目。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;博士阶段曾分别在 DeepMind 工作约 11 个月，并在 OpenAI 担任过科研实习岗位（数月）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在学术贡献上，他是多个顶级国际会议论文的作者或共同作者，例如关于大语言模型与数学推理、定理证明等的研究成果。其部分成果被视为推动 AI 数学与符号推理能力前沿的重要贡献。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e3/e3feb6b2078bfe074af6af03e07f2213.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;值得一提的是，吴玉怀是过去一年中第四位离开公司的联合创始人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在他离职之前，xAI 公司的另外几位创始人 Christian Szegedy 于去年2月离职，Igor Babuschkin 于去年8月离职，而杨格上个月表示，由于健康原因，他已暂时退出公司事务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;给马斯克工作，压力太大？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;首先提出离职的是 Christian Szegedy，但他并没有在x上透露过多关于未来去向的信息，也未明确解释离职原因。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但他离职后，去年8月的 Igor Babuschkin 在离职时在x上发了长文感慨和马斯克一同创业的时光，他首先回顾了2023 年初，几位创始人创建公司的初心。他们确信：人类正在逼近通向超级智能的“配方”。一切迹象都在表明，AI 很快就可能在推理能力上超越人类。那随之而来的问题是——人类该如何确保，这项技术被用于善的方向？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;多年来，马斯克始终警示强大 AI 所潜藏的风险。正是在这样的背景下，他们发现彼此拥有完全一致的愿景：让 AI 造福全人类。于是，他们集结了一群志同道合的工程师，xAI 正式启程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Igor Babuschkin还首次揭秘的创业时的艰辛，并称自己从马斯克身上学到了两条无价的准则：&lt;/p&gt;&lt;p&gt;第一，永远不要畏惧亲自下场解决最棘手的技术问题；&lt;/p&gt;&lt;p&gt;第二，保持一种近乎偏执的紧迫感。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在帖子的结尾，Igor Babuschkin 表达了自己离职的根本原因不是挫折或失败，而是个人使命的聚焦与升华。他表示自己已经创办了新公司，名为： Babuschkin Ventures，希望获得更多关注和支持。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;帖子翻译如下：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我依然清楚地记得第一次见到埃隆的那一天。我们围绕人工智能以及它可能塑造的未来，连续聊了好几个小时。那次交谈中，我们达成了一种几乎无需言说的共识：这个世界，需要一家使命不同、方向不同的全新 AI 公司。&amp;nbsp;构建真正推动人类前进的人工智能，是我一生的梦想。&amp;nbsp;苏联解体后，我的父母离开俄罗斯联邦，踏上移民之路，只为给孩子寻找一个更好的未来。作为移民，生活从来谈不上轻松。但即便在最艰难的时刻，他们依然坚信：人类的价值是无价的——勇气、同理心，以及对理解世界的永恒好奇。&amp;nbsp;童年时期，我仰慕理查德·费曼、马克斯·普朗克这样的科学家。他们不懈地推动物理学的边界，只为更接近宇宙的真理。后来，我在 CERN 攻读粒子物理博士，满怀激情地希望自己也能为这一使命贡献力量。然而，寻找“新物理”变得越来越困难——需要更庞大的对撞机，却换来越来越稀少的突破。&amp;nbsp;于是我开始思考：解开宇宙之谜的钥匙，或许并不是更大的对撞机，而是超级智能。&amp;nbsp;AI 是否能够构建一套自洽的量子引力理论？AI 是否有一天能证明黎曼猜想？&amp;nbsp;2023 年初，我逐渐确信：我们正在逼近通向超级智能的“配方”。一切迹象都在表明，AI 很快就可能在推理能力上超越人类。那随之而来的问题是——我们该如何确保，这项技术被用于善的方向？&amp;nbsp;多年来，埃隆始终警示强大 AI 所潜藏的风险。正是在这样的背景下，我们发现彼此拥有完全一致的愿景：让 AI 造福全人类。于是，我们集结了一群志同道合的工程师，xAI 正式启程。&amp;nbsp;xAI 的早期并不轻松。质疑者告诉我们：我们入局太晚了，从零开始打造一家顶级 AI 公司几乎不可能。但我们选择相信“不可能”。&amp;nbsp;从零创业，意味着事无巨细、亲力亲为。最初，我亲手搭建了公司大量底层工具，用于启动和管理模型训练任务。后来，我负责统筹公司相当一部分工程工作，涵盖基础设施、产品以及应用型 AI 项目。&amp;nbsp;xAI 的人，是我见过最投入、最坚定的一群人。&amp;nbsp;在血汗与泪水中，我们以惊人的速度建成了孟菲斯超级算力集群，并以前所未有的节奏交付了前沿模型。&amp;nbsp;从埃隆身上，我学到了两条无价的准则：第一，永远不要畏惧亲自下场解决最棘手的技术问题；第二，保持一种近乎偏执的紧迫感。&amp;nbsp;xAI 的执行速度，快到近乎疯狂。&amp;nbsp;业内资深人士曾断言：在 120 天内建成孟菲斯超级集群，根本不可能。但我们依然选择相信“不可能”。&amp;nbsp;在期限临近时，集群节点之间的 RDMA 通信频频出现诡异问题。埃隆决定亲自飞往数据中心，我们随即跟上。基础设施团队在深夜抵达孟菲斯，几乎没有休息，立刻投入排查。&amp;nbsp;在翻阅了数万行 lspci 输出后，我们终于锁定了罪魁祸首——一个错误的 BIOS 设置。埃隆一直陪着我们奋战到深夜。当训练任务终于跑通时，他在凌晨 4:20 发帖庆祝，那一刻我们忍不住大笑出声。&amp;nbsp;我永远不会忘记那一夜的肾上腺素飙升，也不会忘记那种“我们真的在一起并肩作战”的情感联结。那晚入睡时，我们都清楚地意识到：自己正身处人生中最激动人心的时刻。&amp;nbsp;我对 xAI 这个大家庭，怀有无比深厚的感情。&amp;nbsp;你们是我合作过的最投入、最顽强的一群人。能够如此迅速追赶并站上技术前沿，靠的不是奇迹，而是每一个人的拼劲与团队精神。&amp;nbsp;感谢每一位与我并肩走过这段旅程的人。我想向你们的付出、时间与牺牲致敬——这些从来都不容易。我会永远记得那些灯火通明的深夜，记得我们一起熬过的每一次极限冲刺。&amp;nbsp;今天，当我驱车离开时，心情就像一位送孩子远行上大学的父母——骄傲、欣慰，眼眶湿润。我会继续注视着这家公司成长、成熟。&amp;nbsp;迈向人生的下一章节时，我再次想起父母当年的移民选择——为了让下一代生活在更好的世界。不久前，我与“未来生命研究所”创始人 Max Tegmark 共进晚餐。他给我看了自己年幼儿子的照片，然后问我：“我们该如何安全地构建 AI，才能确保我们的孩子真正繁荣成长？”&amp;nbsp;这个问题深深触动了我。&amp;nbsp;在更早的职业生涯中，我曾担任 DeepMind 的 AlphaStar《星际争霸》智能体技术负责人，亲眼见证了强化学习在规模化后所释放的惊人力量。随着前沿模型在更长时间尺度、更广任务范围内变得愈发“具备代理性”，其能力也将不断放大——这使得 AI 安全研究变得前所未有地重要。我希望继续自己的使命：推动安全、对人类有益的人工智能。&amp;nbsp;今天，我正式宣布创立 Babuschkin Ventures，专注支持 AI 安全研究，并投资于推动人类进步、探索宇宙奥秘的 AI 与智能体系统初创公司。&amp;nbsp;如果你愿意交流，欢迎通过 ventures@babuschk.in 联系我。奇点正在逼近，但人类的未来依然光明。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;再然后就是前不久，1月21日，xAI 的另一位联创 Greg Yang (音译：杨格）也在x上发文称已经离职。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;杨此前曾在微软公司工作，是马斯克 2023 年人工智能初创公司的创始成员之一。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;杨在x上发文表示，他可能在一段时间前感染了莱姆病，症状是在 xAI 高强度工作期间变得明显的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种疾病是由蜱虫叮咬引起的，会导致炎症。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/04/046ac82a85ffa5fa401966fa7d1e264a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;杨在x 上发文称，其实自己生病的症状在很久以前就已经感染了，只是一直到高强度投入 xAI 的研发构建、免疫系统被持续消耗之后，症状才真正显现出来。这里很容易读出他的言外之意——超高强度工作，伤害了身体。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但他表示从整体来看，反而觉得自己是幸运的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;莱姆病是一种严重的疾病，拖得越久，治疗难度越大。很多患者在五六十岁时才被发现，情况往往要艰难得多。它甚至可能让人长期卧床、丧失行动能力。而他，至少现在仍然可以正常生活，照顾好自己。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;杨还表示：“所以，尽管有人对我说不该把自己逼得这么狠。但我并不后悔。正因为我曾那样拼命，我才得以及早发现问题；而现在，我可以修复它——这样，当我重新站起来时，就能比以往走得更远。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;值得玩味的是，尽管&amp;nbsp;Igor Babuschkin离职后发表了长篇大论解释了离职原因，但在离职后，他也公开吐槽了科技公司对工程师缺乏耐心：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;许多AI公司未能给工程师足够的时间和心态去做出最好的工作，导致代码和系统不可靠。良好的公司文化，注重卓越、专注和足够休息，能带来更好的成果。早期Google就是这种文化的典范，创始人们应该借鉴他们的策略。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最后，就是今天刚刚宣布离职的吴，但从他发文中可以隐约提到的将开启人生新篇章，并表示这是一个充满无限可能的时代，一切皆有可能，外界猜测他离职的原因是要单独创业。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;世界首富也睡过车间地板&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在科技圈乃至大众媒体中，马斯克既被视为颠覆行业的创新者，也常因其极端的工作和管理方式而成为争议焦点。无论是在特斯拉、SpaceX，还是他于 2022 年收购后的微博（Twitter，后更名为 X）、以及最新的 xAI，马斯克对效率、速度和结果的近乎苛刻追求，塑造了一种鲜明而强烈的企业文化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;马斯克本人对生产和执行的标准极高，这一点体现在多个层面：无论是火箭发射、汽车量产，还是 AI 平台的快速迭代，他都要求以超出常规的节奏推进。对他而言，工作不是常规的职业任务，而是一种总体使命的极致实践。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;马斯克长期以身作则，亲自展示“全员投入”的文化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在特斯拉 Model 3 产能冲刺阶段，他曾公开表示自己多次睡在工厂地板上，与团队同吃同住，以身作则推动生产进度。此举被他本人解释为希望自己的处境比其他员工更“糟糕”，以此激发团队极限投入的精神。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在他接手推特后，类似的高强度工作节奏再次出现。据报道，高管和员工为了赶项目上线与平台改造，不得不在办公室过夜，有人甚至将办公室布置成临时卧室。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种文化也延续到了新的业务单位。在 xAI，有员工因此张贴自己连续 36 小时未睡工作的照片，并获得同行与马斯克本人的回应，成为“极致奉献”的象征。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些事例并非孤立现象，而是马斯克管理体制的核心体现：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;全员以任务完成为唯一衡量标准，在不惜个人生活成本的条件下追求快速执行。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;马斯克对组织流畅和成本效率的执念，也体现在他接手推特后大规模裁员与重新设定公司节奏的做法上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他接管后短时间内削减了约 50% 的员工，以期通过快速精简来降低成本并重塑团队结构。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，他的内部沟通中强调“长时间高强度工作是继续留任的前提”，并要求员工亲自回到办公室工作、放弃远程安排。这样的政策在推特内部引发了大量讨论与反弹。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种以极限 KPI 和严格劳动投入作为衡量绩效指标的方式，反映出马斯克对“成果优先、短期快速推进”的坚定信念，但也因此产生了显著的压力文化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;长期以来，马斯克管理方式的成功也伴随着争议。批评者认为他的严苛要求置工作效率于健康和心理福祉之上，尤其是在后疫情时代的职场环境中，这种风格显得格格不入。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，马斯克在推特上曾要求员工在特定期限内选择接受“高强度工作”或离职与三个月遣散费的方案，这种二选一的选择在劳动力市场中引发了关于员工权利与企业管理伦理的广泛讨论。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;尽管马斯克支持者认为这种做法有助于推动快速创新和执行效率，但批评者指出，这种过度强调短期指标和工作时长的文化，可能会导致高离职率、身心健康问题，以及长期人才流失。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;尽管存在争议，马斯克模式背后却有其一致性逻辑：他不满足于常规的“业务增长”，而试图推动技术、生产、产品乃至整个人类文明的极限。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;无论是加速电动汽车普及、实现火箭可复用、还是构建被他视为下一个关键技术节点的人工智能系统，所有这些目标在他眼中都不容许“慢与保守”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他本人也强调领导者的角色不仅仅是分配任务，更是“培养能思考的人”，希望员工不仅知道“做什么”，更要知道“如何思考”以解决复杂问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种极端使命感驱动的管理哲学，既是他能够成功推进多个行业边界的动力来源，同时也是造成高压力工作文化的重要根源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://yuhuaiwu.github.io/?utm_source=chatgpt.com&quot;&gt;https://yuhuaiwu.github.io/?utm_source=chatgpt.com&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.businessinsider.com/elon-musk-xai-loses-cofounder-tony-wu-2026-2?utm_source=chatgpt.com&quot;&gt;https://www.businessinsider.com/elon-musk-xai-loses-cofounder-tony-wu-2026-2?utm_source=chatgpt.com&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/VLJ1Pkm0fYtW0iYTN9vg</link><guid isPermaLink="false">https://www.infoq.cn/article/VLJ1Pkm0fYtW0iYTN9vg</guid><pubDate>Tue, 10 Feb 2026 10:54:35 GMT</pubDate><author>李冬梅</author><category>生成式 AI</category></item><item><title>星海图首席科学家许华哲创业，刚获内部投资！目标：“让机器人做一道松鼠鳜鱼”？</title><description>&lt;p&gt;整理 | 华卫&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;近日，有消息称，星海图孵化首席科学家许华哲创业，新公司将会切入具身智能C端应用赛道，已获得星海图种子轮投资。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“让机器人做一道松鼠鳜鱼”，是许华哲在多次公开提到的具身智能终极设想。他曾表示，处理活鱼、改刀、油炸到摆盘，其复杂的物理交互是验证机器人智慧程度的最好指标。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;知情人士透露，为了更深入探索具身智能在 2C 领域的技术与应用，许华哲在2025年8月曾主动与星海图团队进行了沟通，表达了希望专注深耕这一方向的想法，星海图团队表示了支持，并对许华哲的新公司启动内部孵化。今年2月，星海图通过直接投资的方式，支持许华哲创立并运营新公司。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据悉，星海图正通过一系列秘密投资，围绕“数据+应用”构建起一套闭环的生态，许华哲此次创业正是该生态布局在 C 端应用的重要一步。下一步，星海图将计划通过产业基金的方式参股或控股关键技术环节和应用方，整合上下游，为其具身智能产品的量产与商业化提供保障。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;作为具身智能领域的明星创业公司，星海图于2023年9月成立，连续完成A4 轮及A5 轮战略融资，合计融资金额超过1亿美元。2026年1月，公开信息披露星海图已经完成股份制改造。另据可靠消息透露，星海图已于近期完成新一轮融资，估值已突破100亿人民币。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description><link>https://www.infoq.cn/article/EO57dfMthXCaFfjgajlL</link><guid isPermaLink="false">https://www.infoq.cn/article/EO57dfMthXCaFfjgajlL</guid><pubDate>Tue, 10 Feb 2026 10:34:59 GMT</pubDate><author>华卫</author><category>具身智能</category></item><item><title>为什么开发者放弃框架而选择原生 JavaScript</title><description>&lt;p&gt;本文最初发布于博客TheNewStack。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/66/66cba611274058a8f7d62c7cf83eeb9e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;图片来自 Unsplash+&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;前端开发者正在回归原生 JavaScript。以下是原生 API 和 AI 工具如何使原生 JS 成为框架疲劳的解药。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;每个人都累了，&lt;a href=&quot;https://thenewstack.io/javascript-framework-reality-check-whats-actually-working/&quot;&gt;框架疲劳不再只是一个梗&lt;/a&gt;&quot;：它是一种集体倦怠。曾经竞相掌握 React、Vue 和 Svelte 的开发者们，现在正悄悄回归他们曾经抛弃的简单性：原生 JavaScript。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Web 的天平正在向极简主义倾斜。原生浏览器 API 的兴起、注重性能的开发理念和 AI 辅助编码的浪潮，不仅让原生 JavaScript 开发再次变得可行，而且重新焕发了生机。这是在经历多年的&lt;a href=&quot;https://thenewstack.io/the-react-component-pyramid-scheme-an-over-engineering-crisis/&quot;&gt;代码膨胀&lt;/a&gt;&quot;、抽象概念和 npm 依赖噩梦之后的&lt;a href=&quot;https://thenewstack.io/stop-blaming-react-for-your-state-management-hangover/&quot;&gt;一剂宿醉解药&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;框架时代的临界点&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;多年来，框架一直是开发者的默认选择。它们承诺带来规范性、可扩展性和社区支持。但随着框架的发展，其复杂性也随之增加。打包器变得越来越重，构建时间不断增加，运行“Hello World”项目的一行代码平均就需要数兆字节的依赖。开发者开始质疑：所有这些脚手架真的值得吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;问题不在于框架本身，而在于&lt;a href=&quot;https://thenewstack.io/how-to-build-framework-agnostic-uis-with-web-components/&quot;&gt;围绕它们发展起来的文化&lt;/a&gt;&quot;。每个月都有新的框架涌现，每个都声称修复了上一个框架的问题。企业为了跟上不断变化的生态系统，重构了整个产品。结果呢？无休止的迭代，&lt;a href=&quot;https://www.atlassian.com/agile/software-development/technical-debt&quot;&gt;伪装成创新的技术债务&lt;/a&gt;&quot;，以及陷入重学循环的开发者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;到 2025 年，人们意识到：Web 不需要另一层，它需要的是重置，而这个重置以原生 JavaScript 的形式出现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;原生 API 已经成熟&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;现代浏览器不再是过去那个不稳定的沙箱。在过去的几年中，像 Fetch、&lt;a href=&quot;https://thenewstack.io/web-components-are-the-comeback-nobody-saw-coming&quot;&gt;Web 组件&lt;/a&gt;&quot;和 ES 模块这样的 API 已经发展为成熟的生产级工具，取代了框架曾经提供的功能。曾经那些需要 React 钩子或状态管理库才能完成的任务，现在使用原生解决方案，只要几行简洁的代码就能顺利运行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;特别是 Web 组件标准改变了游戏规则。它为开发者提供了框架的模块化和封装性，而又不会有框架锁定的问题。结合 Shadow DOM、自定义元素和模板字面量，开发者现在可以构建可重用、自包含的小部件，它们可以在任何地方运行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种成熟度的提升意味着开发者终于可以使用浏览器提供的原生功能来构建动态、可维护的响应式界面。由依赖项、构建工具和样板代码带来的“框架税”不再是强制性的。选择原生 JS 不是因为复古，而是因为它再次变得高效。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;性能成为新货币&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如今的 Web 讲究速度。&lt;a href=&quot;https://arounda.agency/blog/ux-statistics&quot;&gt;用户期望近乎即时的交互&lt;/a&gt;&quot;，搜索引擎算法会惩罚速度缓慢的页面。严重依赖框架的应用可以做得很复杂，但它们难以提供一致的性能，尤其是在移动设备上。开发者重新认识到，最好的优化不是添加另一个优化库，而是编写更少的代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2025 年，&lt;a href=&quot;https://thenewstack.io/5-technical-trends-to-help-web-developers-stand-out-in-2025/&quot;&gt;原生 JavaScript 重新进入主流&lt;/a&gt;&quot;，主要是因为应用程序启动更快、渲染更快、调试更容易。没有庞大的捆绑包、水合脚本或协调算法，加载时间大幅下降。每节省一千字节，就能留住一个用户。这种转变是务实的：响应速度提高 50 毫秒的价值远高于 JSX 语法糖或响应式绑定带来的价值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这并非意味着框架的死亡，它们仍然主导着企业环境，但在那些注重敏捷性和性能而非遗留架构和抽象概念的项目中，Web 的天平已经向“无框架区”倾斜。这剂宿醉解药不是关于反叛，而是关于清晰度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;AI 工具使简单再次强大&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;讽刺的是，&lt;a href=&quot;https://thenewstack.io/how-ai-changes-developer-portfolios/&quot;&gt;AI 加速了回归简单的过程&lt;/a&gt;&quot;。现在，开发者使用基于 AI 的编码助手来生成样板代码、调试程序和建议简洁的原生代码。语法越直接，AI 就越有效，而框架的专有约定和抽象层，常常使这些系统感到困惑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有了 AI 处理那些重复的模式，开发者不再需要框架来提高生产力。一个简单的提示就可以利用原生 JS 直接构建响应式 UI 或实现事件处理，完全避免了框架带来的认知负担。突然之间，“框架节省时间”的旧论点不再成立。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，&lt;a href=&quot;https://devoxsoftware.com/blog/through-the-code-maze-ai-vs-manual-refactoring/&quot;&gt;AI 辅助重构&lt;/a&gt;&quot;使梳理遗留框架变得更容易。团队可以逐步迁移，用原生等价物替换框架组件。这不是对早期 Web 的怀旧，而是在智能工具盛行的时代有意识地回归本源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;微前端和无构建架构的兴起&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;越来越多的现代项目采纳了&lt;a href=&quot;https://thenewstack.io/the-case-for-microfrontends-and-moving-beyond-one-framework/&quot;&gt;微前端&lt;/a&gt;&quot;原则：独立的小型 UI 模块单独加载并通过共享契约通信。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种模块化转变也符合现代容器的安全实践，其中的独立单元在部署和更新时可以施加更严格的控制，最小化攻击面。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;同样，这种理念与原生 JS 完美契合。没有集中化的构建系统或复杂的依赖树，开发者可以按模块推送更新，并保持各团队的灵活性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;无构建运动与此相辅相成。像 &lt;a href=&quot;https://thenewstack.io/how-vite-became-the-backbone-of-modern-frontend-frameworks/&quot;&gt;ESBuild 和 Vite&lt;/a&gt;&quot; 这样的工具已经将编译简化到了几乎看不见的程度，但最终目标是完全不需要构建步骤。原生模块导入使得这一愿景成为现实。开发者可以直接从编辑器将更新推送到生产环境，无需等待管道进行转译或打包。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种转变&lt;a href=&quot;https://thenewstack.io/what-is-lightweight-software-revisiting-the-definition/&quot;&gt;重新定义了“轻量级”的真正含义&lt;/a&gt;&quot;。2026年，现代的原生 JavaScript 项目绝不是原始粗糙的，而是精准如手术刀的。它只恰到好处地完成需要做的事，不多也不少。在一个痴迷于速度和控制的世界里，这不仅仅是优雅，还是竞争优势。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;学习曲线倦怠和开发者自主性&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;开发者们已经筋疲力尽。每隔几个月，就有一个新的框架承诺带来救赎，但结果只是用另一个抽象替换前一个。紧跟“最新”发展所带来的认知负担变得不可持续。原生 JavaScript 提供了一个减压阀，一个不会随着下一个 GitHub 公告而过期的公共基础。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;你不需要记住一个新的钩子系统、状态 API 或指令语法。你只需要理解这门语言，重拾自主性，让编程创作的掌控权回到开发者手中。他们可以专注于解决问题，而非死记硬背语法模式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;随着教育系统的跟进，JavaScript 训练营和高校开始重新强调基础知识。其结果将是：&lt;a href=&quot;https://darktechinsights.com/hidden-dangers-of-frameworks/&quot;&gt;依赖框架的开发者减少&lt;/a&gt;&quot;，能够在核心层面推断性能、结构和行为的开发者增多。这种重置既是文化的，也是技术的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;生态系统再平衡&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回归原生 JavaScript 并不意味着框架的灭绝，但它确实重新定义了它们的目的。框架正在演变成可选层，而不是默认配置。它们的存在是为了解决特定的大规模问题，而不是嵌入到每一个登录页和小部件中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;React 、Vue 和 Svelte 正在悄悄地精简冗余，提升互操作性。生态系统正在围绕原生标准而不是专有语法凝聚共识。框架作者如今秉持“渐进式采用”的设计理念，这意味着开发者可以选择某个框架而不被锁定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种再平衡也反映了其他技术领域的发展轨迹。正如DevOps逐渐从工具导向转向&lt;a href=&quot;https://thenewstack.io/best-practices-for-adopting-a-devops-culture/&quot;&gt;文化导向&lt;/a&gt;&quot;，2026年的前端开发也将更注重使用效率而非工具选择。原生 JS 并非一种厌弃，而是重新校准。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;框架宿醉不是永久的，它是一个警钟。开发者们终于意识到，进步不是关于抽象的堆叠，而是掌握它们下面的基础知识。原生 JavaScript，曾经被认为“太简陋”，现在已经演变成了一个更简洁的 Web 背后的强大引擎。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2026年，用原生 JavaScript 编写代码并不意味着你在倒退，反而意味着你在前进——清晰、可控以及一个五年后仍然有意义的代码库。框架将继续演变，工具将继续增多，但解决方案将保持不变：剥离掉所有不必要的部分，回归到真正支撑 Web 运行的核心。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;声明：本文为InfoQ翻译，未经许可禁止转载。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://thenewstack.io/why-developers-are-ditching-frameworks-for-vanilla-javascript&quot;&gt;https://thenewstack.io/why-developers-are-ditching-frameworks-for-vanilla-javascript&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/UJtGxoHgrizoaUI1HsdG</link><guid isPermaLink="false">https://www.infoq.cn/article/UJtGxoHgrizoaUI1HsdG</guid><pubDate>Tue, 10 Feb 2026 10:29:24 GMT</pubDate><author>Alexander T. Williams</author><category>架构/框架</category></item><item><title>字节发布最新模型 Seedream 5.0，但没打过Nano Banana Pro？</title><description>&lt;p&gt;&lt;/p&gt;&lt;p&gt;发布时机把握得很好，在所有人都被 Seedance 的视频热度吸引时，字节又推出了全新文生图模型Seedream  5.0。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该版本集成了网络搜索功能，并支持 2K 原生输出，使其成为 Nano Banana Pro 的高性价比替代方案。该模型现已上线 CapCut、剪映和 Skylark平台，并在即梦AI平台开启灰度测试。目前在 CapCut上，有限时20次免费图片生成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;官方表示，新版本在理解图像内容、生成速度和视觉效果方面均有显著提升。它能更精准地解读上下文、风格和细节，从而减少重复编辑的需求，在Dreamina 中创建图像更加流畅可靠。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/21/21e169e419fa048792e50534cf64f6f4.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，在生成后，用户可以通过交互式笔刷编辑，对画面元素进行精准、智能的调整；同时，视角控制能力的提升，也让场景扩展与画面构图更加灵活多样，拓展画面空间与表现视角。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ad/ad8cf2c96b6f38c1aed5d1c30a2804ff.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该功能还使 Seedream 5.0 在生成图像时能够利用更加全面、更新及时的信息。通过融合对网络层级内容的理解，AI 生成的画面在内容上更加贴近现实背景和时代语境，尤其适用于热点话题、现代设计以及对场景语境要求较高的视觉创作，最终呈现出更加丰富、贴合需求的视觉效果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b2/b2b8bc5083f7b6dccd615a2d7bc85b1f.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;有用户表示，在 4K 分辨率下，人物皮肤纹理表现有所提升，同一组图像的多样性更好，整体氛围感也很出色。不过，文字渲染效果看起来相比 4.5 版本并没有明显改进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/29/2905485ea5b894215aabccd9176b6f5d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;有网友评价，图像生成的竞争已经不再只是比拼审美表现。Seedream 5.0 将重点放在检索准确性、4K 级放大能力以及工作流层面的精度控制上。字节跳动押注的是“实用性”而不是“艺术性”，认为真正推动专业用户采用的关键在于效率与可靠性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;至于能不能取代 Nano Banana Pro，我们让两者同时生成了一份稍微复杂些的北京菜单，Nano Banana Pro 速度上更快，而效果似乎也赢了。（上图中，横版是Nano Banana Pro，竖版是Seedream 5.0，具体表现很直观了）就像网友说的，可能还需要一段时间才能实现取代。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.infoq.cn/resource/image/d1/48/d199fcbb586d86139b7b7ef76b6db748.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.infoq.cn/resource/image/ae/4d/ae6c6c0287605ae5f58df3da85903f4d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><link>https://www.infoq.cn/article/xmRTBdskIJ0SNlwgGMYh</link><guid isPermaLink="false">https://www.infoq.cn/article/xmRTBdskIJ0SNlwgGMYh</guid><pubDate>Tue, 10 Feb 2026 10:24:11 GMT</pubDate><author>褚杏娟</author><category>AI&amp;大模型</category></item><item><title>未来两年软件工程展望：从写代码到管 AI，程序员正分化成两种职业</title><description>&lt;p&gt;本文最初发布于Addy Osmani的个人博客。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;软件行业正处在一个奇怪的转折点上。AI编程已经从增强型的自动补全发展成了能够自主执行开发任务的智能代理。曾经推动科技行业招聘热潮的经济繁荣已经让位于效率至上的要求：企业现在往往更倾向于盈利而非增长，更倾向于经验丰富的员工而非应届毕业生，更倾向于组建配备更好工具的小团队。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，新一代的开发者带着不同的职业观步入职场：他们注重职业稳定性，对拼搏文化持怀疑态度，并且从入行第一天起就使用AI辅助工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;接下来会发生什么确实还难以预料。以下这五个关键问题可能会决定2026年软件工程的发展，每个问题都对应两种截然不同的情景。这并非真正的预测，而只是一个观察的视角，帮助人们为应对软件工程的未来发展做好准备。我们的目标是基于现有数据，结合本领域特有的健康的怀疑精神，通过制定清晰的路线图来应对即将到来的挑战。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;1. 初级开发者问题&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要点：随着AI将入门级任务自动化，初级开发者的招聘可能会暴跌，也可能会随着软件渗透到各行各业而强力反弹。两种未来需要不同的生存策略。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“学习编码，获得初级工作，成长为高级”，这一传统的职业路径正在动摇。&lt;a href=&quot;https://www.finalroundai.com/blog/ai-is-making-it-harder-for-junior-developers-to-get-hired&quot;&gt;哈佛对6200万工人的研究&lt;/a&gt;&quot;发现，当公司采用生成式AI时，初级开发者就业率在六个季度里下降了大约9-10%，而高级开发者的就业率基本保持不变。过去三年，&lt;a href=&quot;https://restofworld.org/2025/engineering-graduates-ai-job-losses/&quot;&gt;大型科技公司招聘的应届毕业生减少了50%&lt;/a&gt;&quot;。&lt;a href=&quot;https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html&quot;&gt;正如一位工程师冷嘲热讽地说&lt;/a&gt;&quot;：“花9万美元雇个初级程序员，为什么不用成本更低的AI编程助手？”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这不仅仅是AI的问题。大约在2022年，&lt;a href=&quot;https://www.2ndorderthinkers.com/p/are-junior-level-jobs-really-killed&quot;&gt;利率上升和大流行后的调整等宏观经济因素&lt;/a&gt;&quot;就已经开始显现，这时AI工具尚未广泛使用。但AI加速了这一趋势。如今，在AI的帮助下，一名高级工程师可以完成过去需要一个小团队来完成的工作。企业正在悄然减少招聘初级员工，其幅度甚至超过了裁员规模。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;相反的情景：AI解锁了每个行业对开发者的巨大需求，而不仅仅是技术行业。医疗保健、农业、制造业和金融业都开始嵌入软件和自动化技术。AI不是取代开发者，而是成为一个力量倍增器，将开发工作扩展到从未雇佣过编码人员的领域。我们将看到更多不同的入门级角色：为特定细分市场快速构建自动化和集成的“AI原生”开发者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;美国劳工统计局&lt;a href=&quot;https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html&quot;&gt;预测&lt;/a&gt;&quot;，从2024年到2034年软件工作仍然将增长约15%。若企业利用AI扩大产出而非单纯裁员，就需要人类把握AI创造的机遇。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;悲观情景的长期风险经常被忽视：今天的初级开发者是明天的高级工程师和技术领导者。如果完全切断人才管道，那么在5-10年内就将出现一个领导力真空。行业老兵称这为“缓衰”：一个停止培训接班人的生态系统。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;我们该如何做？&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;初级开发者：使自己精通AI并成为多面手，证明一名初级开发者加上AI可以匹配一个小型团队的产出。使用AI编码代理（Cursor/Antigravity/Claude Code/Gemini CLI）构建比较大的功能，但要能理解并解释大部分代码行。聚焦不容易被AI替代的技能：沟通、问题分解、领域知识。将相邻角色（QA、DevRel、数据分析）视为切入点。构建一个项目集，特别是集成AI API的项目。考虑参与学徒计划、实习、外包或开源项目。不要成为“只是又一个需要培训的新毕业生”，而是成为一个学习速度快、立即就能发挥作用的工程师。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;高级开发者：初级开发者减少意味着你的日常工作增加。利用自动化工具来完成例行任务，不要什么事都自己做。利用CI/CD、linter和AI辅助测试来捕捉基本问题。通过开源项目或指导其他部门同事开展非正式的导师工作。向管理层如实说明全由资深员工组成的团队所面临的风险。若初级人才需求回升，需做好高效接纳新人的准备，并运用AI进行任务分配。你的价值在于提升整个团队的产出，而非个人的代码产出。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;2. 技能问题&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要点：随着AI编写大部分代码，核心编程技能可能会退化，或者因为人类开发者需要监督AI而使这些技能变得比以往任何时候都更加关键。未来几年将决定我们是否会为追求速度而牺牲对代码的理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://stackoverflow.blog/2025/09/10/ai-vs-gen-z/&quot;&gt;现在有84%的开发者定期使用AI辅助工具&lt;/a&gt;&quot;。对许多人来说，面对错误或新功能需求的第一反应不是从头开始编写代码，而是编写提示并组合AI生成的代码片段。初级程序员正在跳过“艰难的入门阶段”：他们可能永远不会从头开始构建二叉搜索树或独立调试内存泄漏。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;开发者的技能集正在从实现算法转变为知道如何向AI提出正确的问题并验证其输出。现在，&lt;a href=&quot;https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html&quot;&gt;入门的第一个要求是提示和验证AI的输出&lt;/a&gt;&quot;，而不是展示原始编码能力。一些高级工程师担心，这会产生一代不能独立编码的人，导致开发者技能退化。AI生成的代码可能会引入一些微妙的错误和安全漏洞，不太有经验的开发者可能会漏掉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;相反的情景：AI处理80%的常规工作，人类专注于最难的20%。架构设计、复杂集成、创意设计、边缘情况，这些问题是机器无法单独解决的。AI的普及并没有使深厚的知识积累过时，反而使人类专业知识变得比以往任何时候都更重要。这就是“高杠杆工程师”，他们将AI作为一种力量倍增器，但必须深入理解系统才能有效使用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果每个人都有AI编码代理访问权限，那么区分优秀开发者的关键在于知道AI何时出错或不够优化。&lt;a href=&quot;https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html&quot;&gt;正如一位高级工程师所说&lt;/a&gt;&quot;：“最好的软件工程师不是最快的编码者，而是那些知道何时不信任AI的人。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;编程转变：需要输入的样板代码减少，把更多的精力用在审查AI输出的逻辑错误、安全漏洞和与需求不匹配的问题。关键技能变成了软件架构、系统设计、性能调优和安全分析。&lt;a href=&quot;https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html&quot;&gt;AI可以快速生成一个Web应用程序，但专家工程师需要确保AI遵循了安全最佳实践，并且没有引入竞态条件。&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2025年，开发者中间出现了分歧。一些人坦言，他们几乎不“亲手”编写代码，并认为编码面试应该做出改变。其他人则认为，跳过基础知识面试会导致AI输出出现问题时需要完成的应急处理工作增加。&lt;a href=&quot;https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html&quot;&gt;行业开始期望工程师同时具备&lt;/a&gt;&quot;AI的效率和保障质量的基本知识。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;我们该如何做？&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;初级开发者：将AI当作学习工具，而不是拐杖。对于AI编码代理（Cursor/Antigravity/Claude Code/Gemini CLI）的建议，要通过审查代码了解其工作原理并识别薄弱环节。偶尔禁用你的AI助手，从头开始编写关键算法。优先考虑计算机科学基础：数据结构、算法、复杂性、内存管理。将项目实现两次，一次用AI，一次不用AI，然后对两者进行比较。学习提示工程，并掌握相关工具。通过严格的测试训练自己：编写单元测试，自己阅读堆栈跟踪信息而不是立即询问AI，熟练使用调试工具。深化AI无法复制的互补技能：系统设计、用户体验直觉、并发推理。证明你既能用AI快速解决问题，也能在AI失败时自己处理棘手的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;高级开发者：将自己定位为质量和复杂性的守护者。磨练你的核心专长：架构、安全、扩展、领域知识。练习用AI组件进行系统建模并思考故障模式。随时关注AI生成代码中的漏洞。拥抱你作为导师和审查者的角色：定义什么时候可以使用AI，以及什么时候必须手动审查（支付或安全代码）。侧重于创造性和战略性工作；让初级开发者和AI一起处理常规API连接，而你决定构建哪些API。投资软技能和跨领域知识。随时关注新工具和最佳实践。加倍重视人类开发者不可或缺的因素：准确的判断、系统性思维和导师带徒。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;3. 角色问题&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要点：开发者的角色职责可能缩减为有限的审计（监督AI生成的代码）工作，也可能扩展为设计和管理AI驱动系统的关键协调者。无论哪种情况，创造价值都远不止于编写代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此处的两极分化非常明显。在前一种情景中，开发者的创造性职责被削弱。他们不再专注于构建软件，而是更多地审核和监管AI产出。AI系统（或使用无代码平台的“公民开发者”）负责生产环节；人类开发者则审查自动生成的代码，检查错误、偏见或安全问题，并审批部署。创造者沦为检查者。编写代码的喜悦被风险管理的焦虑所取代。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有报道称，工程师将花更多时间评估AI生成的拉取请求和管理自动化管道，而不是从头开始编写代码。编程感觉更像是合规性检查，而不是创造性地解决问题。正如一位工程师感叹：“我不想沦为一个代码清洁工，整天收拾AI留下的烂摊子。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一种未来则有趣得多：开发者演变成高级协调者，兼具技术、战略和道德责任。AI“工人”意味着人类开发者承担架构师或总承包商的角色，负责设计整个系统，决定哪些任务分配给哪些AI或软件组件，并将活动部件组合成解决方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html&quot;&gt;有一家低代码平台的首席执行官阐述了这个情景&lt;/a&gt;&quot;：在“智能代理”开发环境中，工程师将转型为“作曲家”，指挥由AI代理和软件服务组成的“乐团”。他们无需亲自谱写每个音符，但会定义旋律，即架构、接口以及代理间的交互方式。这个角色兼具跨学科性和创造性：既是软件工程师，又是系统架构师，同时也是产品战略家。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;乐观看法：随着AI承担起一些重复性工作，开发者的角色必然转向更高价值的活动。工作可能变得更加有趣。必须有人决定AI应该构建什么，验证产品是否合理，并持续改进它。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;向哪个方向发展取决于组织选择如何整合AI。将AI视为劳动力替代工具的公司可能会缩减开发团队，并要求剩下的工程师保持相关任务自动化运行。将AI视为团队能力增强工具的公司可能会保持人员数量基本不变，但让每位工程师承担更费时耗力的项目。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;我们该如何做？&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;初级开发者：不要局限于编写代码，要寻找其他机会。自愿参与测试用例编写、CI流水线设置或应用监控，培养与审计员/监管人角色相一致的技能。通过个人项目保持你的创造性编码能力，以免失去构建乐趣。培养系统思维：学习组件之间如何通信，怎样设计出良好的API。阅读工程博客和系统设计案例研究。熟悉除代码生成之外的AI和自动化工具：编排框架、AI API。提升书面与口头沟通能力。撰写文档时秉持向他人阐述的标准。向资深同事提问时，不仅要问“代码是否运行正常？”更要问“我的考量是否到位？”。准备好成为验证者、设计者和沟通者，而非仅是编码者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;高级开发者：把更多精力放在领导和架构责任上。打造供AI和初级团队成员遵循的标准和框架。定义代码质量检查清单和符合伦理的AI使用策略。随时关注与AI生成软件合规性和安全性相关的话题。专注于系统设计和集成知识；自愿绘制服务间的数据流并识别故障点。熟悉编排平台（Kubernetes、Airflow、无服务器框架、代理编排工具）。投入双倍精力履行技术导师角色：更多地参与代码审查、设计讨论、技术指导。提升快速评估他人代码并给出高层次反馈的能力。培养产品和商业意识；了解为什么构建一个功能以及客户关心什么。向产品经理学习或参加客户反馈会议。通过原型、黑客马拉松或新兴技术研究来保持你的创造激情。从编码者演变为指挥者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;4. 专家与通才问题&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要点：专业领域过于狭窄的专家会面临自身领域被自动化取代或逐渐淘汰的风险。在快速变化、AI深度渗透的时代背景下，T型工程师更受青睐——他们既具备广泛的适应能力，又拥有一个或两个有深厚知识积累的专业技能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;考虑到模型、工具和框架的快速兴衰，将职业生涯押注在单一技术栈上是有风险的。当新型AI工具能以极少需要人工干预的方式处理传统框架时，该领域的专家可能会突然发现自身需求锐减。那些专注于“单一技术栈、框架或产品领域”的开发者，某天醒来时或许会发现，该领域已日渐式微甚至被淘汰。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;想想那些在行业转型时未能及时转型的人：COBOL开发者、Flash开发者或移动游戏引擎专家。如今不同的是变革速度。AI自动化能让某些编程任务变得微不足道，削弱了因这些任务而存在的工作岗位。只精通单一技能的专家（比如调整SQL查询参数、将Photoshop设计切片为HTML代码）可能会发现，90%的工作已被AI取代。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;招聘经理们总在追逐最新的小众领域。几年前人人都想要云基础设施专家；如今AI/ML工程师需求激增。那些精通昨日技术的人，随着该领域的发展放缓，会感到职业发展陷入了停滞。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;相反的结果是形成一种新的专业化形式，即“多面手专家”或&lt;a href=&quot;https://www.youtube.com/watch?v=IMHneaMO-dg&quot;&gt;T型开发者&lt;/a&gt;&quot;。他们在一两个领域拥有深厚的造诣（竖线），同时又广泛涉猎其他众多的领域（横线）。&lt;a href=&quot;https://medium.com/nerd-for-tech/beyond-full-stack-the-rise-of-the-t-shaped-developer-a4afd757d976&quot;&gt;他们成了跨学科团队的“粘合剂”&lt;/a&gt;&quot;，既能与各领域专家沟通协作，又能在必要时填补技术空白。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/nerd-for-tech/beyond-full-stack-the-rise-of-the-t-shaped-developer-a4afd757d976&quot;&gt;企业不再需要知识深度或广度不够的开发人员&lt;/a&gt;&quot;；他们想要一个强大的核心竞争力，以及能够跨栈工作的能力。其中一部分原因是效率考量：一个T型工程师通常可以独立解决端到端问题，无需等待上下游交接。其中一部分原因是创新考量：知识的交叉传播可以带来更好的解决方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;实际上，AI工具增强了通才的能力，使一个人更容易处理多个组件。后端工程师可以在AI的帮助下构建出合理的UI；前端专家可以借助AI生成服务器样板代码。一个提供丰富AI功能的环境让人们能够完成更广泛的工作。与此同时，深度专家可能会发现，他们的专业领域有一部分被自动化取代，却难以开拓新领域。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://medium.com/nerd-for-tech/beyond-full-stack-the-rise-of-the-t-shaped-developer-a4afd757d976&quot;&gt;现在近45%的工程角色期望能够精通多个领域的知识&lt;/a&gt;&quot;：编程加云基础设施知识，或是前端开发加熟悉ML。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;我们该如何做？&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;初级开发者：尽早打下广泛的基础。即使被雇佣为特定的角色，也要了解那个岗位之外的知识。如果你是在做移动开发，不妨学习下后端基础知识；如果你是在做前端开发，则可以尝试编写一个简单的服务器。学习部署过程和工具，如Docker或GitHub Actions。找一两个真正让你感到兴奋的领域深入学习，使它们成为你垂直领域的专业知识。将自己定位成混合型人才：“全栈开发人员，专注于云安全”或“前端开发人员，具有UX专业知识”。借助AI工具快速学习新领域的知识；如果你是后端新手，可以让ChatGPT生成入门API代码并学习它。养成不断学习新技能的习惯。参加黑客马拉松或跨职能项目，强迫自己进入通才模式。告诉你的经理，你想要接触项目的不同部分。适应性是职业生涯早期的超能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;高级开发者：绘制你的技能图谱：你在哪些领域是专家，哪些相关领域你只是浅尝辄止？选择一到两个相邻领域并努力精通。如果你是一个后端数据库专家，不妨熟悉一个现代前端框架或学习机器学习（ML）流水线的基础知识。借助AI的帮助，在你的弱项领域做一个小项目。将你深厚的专业知识与新环境相结合；如果你专门从事Web应用性能优化，可以探索如何将这些技能应用于ML推理优化。支持或争取将你的角色设计成跨职能的，自荐成为涉及多领域项目的“集成负责人”。指导他人，传播技能，同时也从中学习新东西。更新简历体现多元化能力。利用你的经验识别模式和可转移知识。成为T型人才的典范：在你的专业领域深耕（建立权威和信心），并积极拓展横向能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;5. 教育问题&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要点：计算机科学（CS）学位是保持黄金标准，还是被更快的学习路径（训练营、在线平台、雇主培训）所取代？大学可能难以跟上每几个月就有重大变化的行业发展。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;四年制计算机科学学位一直是进入软件领域的主要途径。但这一传统正在受到质疑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一种未来：大学仍然重要，但难以保持相关性。学位仍然是默认的资格凭证，但受制于缓慢的课程更新周期和官僚审批流程，课程设置落后于快速发展变化的需求。学生和雇主均感觉学术界与行业脱节，学校教授的理论或过时的做法无法转化为工作技能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最近的毕业生报告指出，他们在攻读学位期间从未学习过云计算、现代DevOps或AI工具。如果大学需要投入很多的时间和资金，但却只能提供低相关性教育，那么它们就有被视为昂贵守门人的风险。但出于惯性，许多公司仍然要求应聘者具备学士学位，因此压力就转到了应聘者身上，他们需要通过训练营、在线课程和自学项目来弥补这方面的不足。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://campustechnology.com/articles/2025/10/21/solving-the-talent-crisis-starts-in-higher-ed.aspx&quot;&gt;学生贷款是一笔巨大的债务，而公司也要花费数十亿美元培训新毕业生&lt;/a&gt;&quot;，因为他们缺乏工作场所需要的技能。大学可能会在这里增加一门AI伦理课程，在那里增加一门云计算选修课，但当他们真正实施时，行业工具已经又向前发展了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;颠覆性场景：传统教育日益为新教育体系所取代。编码训练营、在线认证、自学作品集、雇主创建的培训学院层出不穷。许多知名雇主（谷歌、IBM）已经取消了某些技术角色的学位要求。到2024年，&lt;a href=&quot;https://campustechnology.com/articles/2025/10/21/solving-the-talent-crisis-starts-in-higher-ed.aspx&quot;&gt;近45%的公司计划至少取消部分职位的学士学位要求&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;训练营体系已经相当成熟，他们培养的毕业生与CS毕业生一起被顶级公司雇佣。这些项目周期更短（12周强化），并且专注于教授实用技能：当前流行的框架、云服务、团队合作。招聘标准正在瞄准在线作品集、微证书和已认证技能。出色的GitHub作品集或公认的认证可以免除学位要求。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;由雇主推动的教育正在兴起：企业自主搭建培训体系或与编程训练营合作。部分科技巨头已经为非传统背景的人才设立了内部“大学”。AI本身也开辟了全新的学习路径：AI导师、交互式编程沙盒、校外个性化教学。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;模块化的学习生态远比昂贵的四年制学位更容易获取。在计算机科学专业实力薄弱的国家，孩子们也能修读Coursera的课程，构建与硅谷人士同样的个人作品集。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;我们该如何做？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有志向的开发者/初级开发者：在学习传统的计算机科学课程时，不要完全依赖课程进行学习。要通过实际的项目补充课程内容：构建Web应用，参与开源项目。寻找实习或合作机会。如果你的课程中没有包含热门话题，则通过在线平台学习它们。考取行业认可的认证（GCP、亚马逊云科技、Azure）以证明自己的实践能力。如果是你在自学或参加了训练营，则一定要专注于创建一个引人注目的作品集：至少要有一个文档良好的重点项目。积极参与开发者社区：参与开源项目，撰写技术文章。通过LinkedIn、聚会以及开发活动建立人际关系网络。争取资深开发者为你背书。考虑到技术技能的半衰期非常短，务必要不断学习。将AI作为个人导师。用具体的方式证明自己的能力：作品集、认证证书以及能清晰阐述工作成果的能力，这些将为你打开机遇之门。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;高级开发者和领导者：你不能永远依赖于证书。要在继续教育方面进行投资：在线课程、研讨会、会议、认证。通过新的方式验证你的技能，为通过实际问题评估应聘者当前能力的面试做好准备。维护使用了新技术的业余项目。重新评估工作要求：你真的需要新员工拥有计算机科学学位，还是需要他们具备某些技能和学习能力？推动以技能为先的招聘，扩大你的人才库。支持内部培训计划或学徒制岗位。为没有正式大学背景的初级开发者建立导师制小组。与学术界及其他机构合作：加入顾问委员会、举办客座讲座、对课程存在的问题提出反馈。将这种合作融入自身的职业发展中：实际的成果和持续的学习比额外的学位更重要。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;小结&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这些情景并不是相互排斥的。现实将融合所有要素。一些企业将缩减初级岗位的招聘，另一些则会在新的领域扩大招聘规模。AI会将常规编码工作自动化，同时又提升人类编写的代码的质量标准。开发者或许会在上午审核AI生成的代码，下午则专注于设计高级架构。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一个贯穿始终的主题是：变化是唯一的常数。紧盯技术趋势（并保持审慎态度），避免被炒作或末日论所蒙蔽。通过更新技能、拓展能力、聚焦人类特有的优势（创造力、批判性思维、协作能力），你才能始终保持竞争力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;无论未来是迎来编程复兴，还是进入自动编码时代，那些具备全局思维、持续学习能力并能推动技术发展解决实际问题的工程师，始终会受到市场的青睐。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;预测未来的最佳方式就是积极地塑造它。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;声明：本文为InfoQ翻译，未经许可禁止转载。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://addyosmani.com/blog/next-two-years/&quot;&gt;https://addyosmani.com/blog/next-two-years/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/UtPXQMUagxqNoPE2PaT0</link><guid isPermaLink="false">https://www.infoq.cn/article/UtPXQMUagxqNoPE2PaT0</guid><pubDate>Tue, 10 Feb 2026 10:08:31 GMT</pubDate><author>Addy Osmani</author><category>生成式 AI</category></item><item><title>达摩院开源RynnBrain：首个支持移动操作的具身大脑基础模型</title><description>&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;具身智能蓬勃发展的当下，具有泛化性的具身能力至关重要。为了追求这个终极目标，业界发展出了两条技术路线。一条路线从机器人末端动作输出入手，发展出可以直接操作物理世界的VLA模型。但是VLA模型由于其数据稀缺性无法实现泛化。因此有了第二条路线，从本身拥有泛化能力的VLM入手，加速VLM从数字世界迈向物理世界。我们将在此路线上探索的模型称之为具身基础模型。诚然，已经有一些研究开始了对具身基础模型的初步探索。例如，RoboBrain系列模型在单个视觉语言模型中统一了理解、定位和规划，以促进复杂的具身任务。Robix模型为任务执行期间更自然的人机交互做出了贡献。 然而，这些当前的具身基础模型动态认知受限，且普遍存在物理幻觉，难以适应人形机器人上的复杂任务。主页：&lt;a href=&quot;https://alibaba-damo-academy.github.io/RynnBrain.github.io/&quot;&gt;https://alibaba-damo-academy.github.io/RynnBrain.github.io/&lt;/a&gt;&quot;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;简介&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们提出了RynnBrain，首个可移动操作的具身基础模型。其具有以下三个关键要点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（1）时空记忆：RynnBrain能够在其完整的历史记忆中定位物体、目标区域，甚至预测运动轨迹，从而赋予机器人全局时空回溯能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（2）物理空间推理：不同于传统的纯文本推理范式，RynnBrain 采用文本与空间定位交错进行的推理策略，确保其推理过程紧密扎根于物理环境。大大减弱了具身任务中的幻觉问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（3）良好的可拓展性：我们在RynnBrain基础模型上微调了视觉语言导航和精准操作规划模型，效果轻松实现SOTA。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过完备的实验，RynnBrain在16项具身任务Benchmark上全面超越了Cosmos Reason 2和Gemini Robotics ER 1.5等强大模型实现了SOTA，并且在8项域外Benchmark上验证了超越其他具身基础模型的通用泛化性。特别的，我们开源了业界首个MOE具身基础模型RynnBrain-30B-A3B，其只需要3B的推理激活参数就全面超越了当前规模最大的具身基础模型Palican-VL-72B。使用我们的MOE模型可以让机器人在保持最强大感知和规划能力的基础上拥有更加快速的动作响应和更加丝滑的行为模式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为推动领域发展，我们同步开源：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;✅ 全系列模型（含全尺寸基础模型与后训练专有模型）&lt;/p&gt;&lt;p&gt;✅ 全新评测基准RynnBrain-Bench（评测时空细粒度具身任务）&lt;/p&gt;&lt;p&gt;✅ 完整的推理与训练代码&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;RynnBrain首次实现了“大脑”对物理世界的深度理解与可靠规划，为大小脑分层架构下的通用具身智能迈出关键一步。我们期待它加速 AI 从数字世界走向真实物理场景的落地进程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/81/8115b8a12c872c0203164ba95e3092b9.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;RynnBrain模型体系架构&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/72/72cc6dca6545915445809d2b0531a752.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（1）模型结构&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;RynnBrain在Qwen3-VL基础上进行训练。 使用自研的RynnScale架构对Dense模型和MOE模型均进行了训练速度的优化，使得在同等资源下训练加速两倍。在输入端RynnBrain可以接受任意分辨率的图片、多图和视频输入，满足用户任意形式的视觉输入的需求。同时RynnBrain可以输出区域、轨迹、点集、夹爪位姿、文本等多种具身相关模态，从而支持多样化具身任务的执行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（2）训练优化&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;RynnBrain是一款面向高泛化的具身基础模型，使用视频、图像和文本等多模态数据进行训练，覆盖从定位、空间感知等短任务到长篇多模态描述与复杂推理等多种场景。由于样本序列长度差异大且呈长尾分布，直接在数据并行训练中平均分配样本会引发“拖尾效应”，影响整体吞吐。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为此，我们引入在线负载均衡：训练时根据图像大小与文本token数预估序列长度，将同一DP组内样本统一重分配，使每个worker的累计序列长度尽量均衡，并用优先分配长序列的贪心策略在数据预取阶段快速完成，避免训练卡顿且无需额外数据预处理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时，由于重分配会造成各worker样本数不均，我们采用按样本的损失归约方式，保证训练前后损失一致性与收敛稳定，并显著提升训练效率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在工程实现上，我们结合ZeRO、梯度检查点、输出token过滤等技术降低显存占用；在更大规模模型中引入ZeRO-2与专家并行（EP），并通过优化MoE 计算与跨卡分发提升吞吐。训练与推理框架基HuggingFace Transformers，并已开源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;根植于物理世界的时空预训练&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要制造出一种能够与周围环境进行自然互动的通用型机器人，需要具备两项基本能力：一、时空记忆：通过历史视觉记忆，机器人必须建立涵盖空间、位置、事件、轨迹等多维度的表征，从而能够适应复杂多变的环境。二、忠实于物理世界：所有机器人的认知过程都必须从根本上扎根于物理世界的客观现实之中。本章主要介绍了RynnBrain的预训练，该方法正是基于上述两点见解而制定的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（1）训练策略&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为赋予RynnBrain以上所述的时空记忆与物理世界落地能力，我们设计了一个统一的预训练框架，将多模态输入整合到共享的语义空间中。我们的训练方案聚焦于两大核心支柱：统一的输入输出表示，以及物理感知的优化策略。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;统一的时空表示&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为培养时空记忆，我们将图像与视频视为统一的输入模态。这样，RynnBrain能够在视频序列中学习时间因果关系与轨迹动态，这对于理解运动与事件至关重要。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;根植于物理世界的输出空间&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为实现物理世界，我们对输出空间进行严格形式化，以连接高层认知与低层执行。不同于标准视觉语言模型将数字作为自由文本处理，我们引入离散的坐标token来表示物理位置。我们将所有空间坐标归一化到固定区间，并用整数token表示。这种量化将连续的物理控制转化为离散的分类问题，使模型能够使用与语言生成相同的自回归机制输出精确位置（例如抓取点或导航目标）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（2）数据准备&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们为RynnBrain的预训练准备了两千万的数据对，具体数据细节如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a2/a24b1419cde4aad6819ee06cec20515c.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通用多模态训练数据&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们复用了团队自研的Video-Llama 3视频大模型的训练数据，并融合了LLaVA-OV-SI、LLaVA-Video等多个开源视频问答数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具身认知数据&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;物体认知、空间认知和计数相关数据复用了团队自研的RynnEC模型训练数据，并且引入了Sensenova-SI、VSI-590k、Molmo2等提高模型的空间理解和动态计数能力。此外，我们自己生成了100万对自我为中心的OCR问答数据，其中即有直接的OCR问题，也有需要识别视频中多个文字才能回答的情景问题。我们还收集了EgoRe-5M、Egotaskqa和RoboVQA等自我为中心的多样化问答数据以增强RynnBrain的自我为中心任务理解能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具身定位数据&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;RynnBrain拥有5项具身定位能力，分别为：物体定位、区域定位、操作点定位、轨迹定位和夹爪位姿定位。我们为每项定位任务标注了大量额视频以及图像数据，使得RynnBrain在室内的定位能力上拥有突出的泛化性。我们还用ADE20K、Grasp-Anything、PACO-LVIS等开源数据平衡整体数据集。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;规划数据&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;规划任务包含导航和操作两类。导航使用了R2R和RxR数据和ScaleVLN的开源数据。并且将数据格式变成了流式的格式。操作规划数据源来自OpenX-Embodiment和AGIBot。首先，我们将这两个数据集中所有的规划数据都整合成时间段和子任务标注一对一匹配的格式。然后我们让人工标注出每个子任务规划中跟物体、区域和操作相关的名字。例如：“拿起香蕉放到桌子的左下角”，在这句话中与物体相关的词语是“香蕉”，与区域相关的词语是“桌子的左下角”，与操作相关的词语是“拿起”。然后人工再将这些词语和图像中的位置信息做对应，操作词语与图像中的操作点对应，物体词语与图像中物体的检测框对应，区域词语与图像中的区域点对应。最终得到文本和定位信息穿插的子任务标注数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;基于RynnBrain的后训练-让具身拓展无限可能&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（1）物理空间推理模型&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，大多数多模态推理模型采用纯文本推理范式。虽然一些方法通过工具使用（例如放大）来缓解视觉识别中的挑战，但这种推理范式存在泛化能力有限的问题，只能解决一小部分问题。此外，探索在推理过程中进行视觉想象的替代方法通常会受到生成图像中严重幻觉的困扰。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;鉴于具身大脑在现实世界中运行，进行物理空间推理的能力变得至关重要。因此，在RynnBrain中，我们提出了一种交错推理方法，该方法将实体化与文本信息直接结合在以自我为中心的视频流中。这种范式有效地弥合了语言与物理世界之间的认知鸿沟，确保推理过程牢固地扎根于现实之中。下面详细介绍了RynnBrain在物理空间推理领域的贡献和探索。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们设计了5类空间推理任务——计数、物体定位、操作点定位、区域定位和轨迹预测，来验证RynnBrain新提出的“文本-空间交织”推理范式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;训练策略：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们采用组相对策略优化（GRPO）来使模型与物理空间推理任务对齐。不同于标准PPO需要价值函数来估计优势项，GRPO通过对同一提示下生成的多个采样输出的组内得分来估计基线。这显著降低了显存占用与训练复杂度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;训练从我们的冷启动模型初始化。我们使用SGLang推理引擎以高效生成rollout，组大小设为5。训练共进行10个epoch，batch size为128。我们采用余弦学习率调度进行策略优化，并进行3% 的warmup。为保证稳定性，我们将截断范围设为[0.2, 0.28]，KL系数0.02。最大序列长度设为16,384个token，以适配长上下文的第一视角视频推理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;数据构建采用“AI生成+人工精标”策略：&lt;/p&gt;&lt;p&gt;从自采第一人称视频中抽取样本；多模态大模型生成初步推理链，并用方括号标记关键实体（如“[白色花图案的墙纸]”）；由大语言模型初步分类实体为“物体”或“区域”；人工标注员最终审核并精标：对“对象”标注边界框，对“区域”标注代表性点集，并选择最清晰的视频帧作为参考帧。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所有定位结果以结构化格式&lt;object area=&quot;&quot;&gt;: ...; (coordinates)&lt;!--...--&gt; 融入推理文本，实现语言与空间的对齐。&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其中，计数任务特别强调“先定位再计数”，共构建 7万条高质量样本，显著提升模型在复杂场景下的时空感知能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（2）视觉语言导航&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;导航任务采用与当前SOTA模型StreamVLN相同的数据设置。首先使用r2r rxr EnvDrop ScaleVLN数据在RynnBrain基础模型上做第一阶段训练。然后利用这个第一阶段模型在r2r rxr EnvDrop环境中采集Dagger数据。具体而言，使用第一阶段模型在r2r rxr EnvDrop的模拟器环境中进行导航，如果发现导航路径偏离了正确路径，则使用最短路径算法得到一个从当前位置到目标点的最短路径。因此，Dagger得到的导航数据可以有效纠正第一阶段模型的导航错误。使用Dagger数据我们可以进行第二阶段的训练得到最终的RynnBrain-Nav导航模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（3）操作规划任务&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;由于预训练语料库包含了以规划为中心的数据，基础模型本身就具备了固有的规划能力。然而，要将这种能力应用于复杂的、长周期的操作任务，模型需要保持有效的记忆。为此，我们利用了一个小型的自采集数据集，其格式为多轮对话，其中交互历史充当了明确的记忆缓冲区，以保存历史推理结果。这种结构使模型能够将单个规划步骤整合成一个连贯的长周期策略。至关重要的是，为了与这种顺序推理相匹配，我们仅在每个对话轮的最后一步应用grounding标注，确保当前决策既取决于即时观察，也取决于累积的记忆。通过实验证明，这种方法具有很高的数据效率：仅使用几百个样本进行微调就足以使模型具备强大的长周期规划能力和泛化能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;RynnBrain亮眼的实战成绩单&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（1）基础模型能力全面&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/01/01861b2d0e2ba3364444472e02284db8.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;鉴于当前开源Benchmark在具身时空细粒度任务上的缺失。我们推出了RynnBrain这一多维度基准测试工具，用于评估时空细粒度具身能力。 该测试涵盖了四个关键维度：物体认知、空间认知、物体定位以及具身点预测，旨在突出对记忆视频序列中细粒度的理解以及时空的定位能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/17/170c7343c0d92adf321708a2d23a4ed3.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;RynnBrain测评了20项具身相关的认知与定位Benchmark。在这些具身能力上，RynnBrain全面领先Mimo-Embodied等最先进的具身大脑模型，在许多能力上甚至有30%以上的涨幅。在具身领域之外的通用视觉理解方面，RynnBrain很好的保持了Qwen3-VL的强大通用视觉能力，甚至在AI2D、DocVQA等Benchmark上超越了Qwen3-VL。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（2）后训练潜力巨大&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;导航后训练&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/47/47c6da2f970f0a97aa97efa17a2c23e9.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们使用当前的导航SOTA模型StreamVLN的训练数据微调RynnBrain模型。在没有进行任何架构改进的情况下RynnBrain-Nav比StreamVLN的导航成功率提高了2%-3%。我们在Qwen3-VL基础模型上利用相同的数据训练后发现，RynnBrain作为基础模型可以让微调出的导航模型能力提升5%。这充分证明了在具身相关任务中，RynnBrain的预训练作用巨大。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;操作规划后训练&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/24/2495e2769ddd687fa96dd0dc6473a40f.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;规划任务需要拥有强大的预测能力和场景解析力。只使用几百条数据微调之后RynnBrain-Plan-30B(A3B)即可在域内和域外的任务上全面超越Gemini&amp;nbsp;3 Pro。这充分体现了文本与定位交错的规划方式更加适用于多变复杂的物理世界。&lt;/p&gt;&lt;/object&gt;&lt;/p&gt;</description><link>https://www.infoq.cn/article/rA7dxxttFjqurKCzfGmI</link><guid isPermaLink="false">https://www.infoq.cn/article/rA7dxxttFjqurKCzfGmI</guid><pubDate>Tue, 10 Feb 2026 09:53:06 GMT</pubDate><author>达摩院</author><category>AI&amp;大模型</category><category>开源</category></item><item><title>WASI 1.0：WebAssembly可能在2026年悄然普及</title><description>&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;本文介绍了WebAssembly及其关键标准WASI 1.0在2026年的普及前景。随着WASI 0.3.0的发布，WebAssembly将在更多场景（如边缘设备、无服务器环境等）替代传统容器。WebAssembly已经走出浏览器，凭借组件模型、接口类型等新规范，降低了开发门槛，提升了互操作性和安全性。WASI的标准化进程虽漫长，但每一步都推动了WebAssembly的广泛应用，未来将实现高性能、可组合并发和零拷贝流式处理等关键特性，进一步加速WebAssembly的落地和普及。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;本文最初发表于&lt;a href=&quot;https://thenewstack.io/wasi-1-0-you-wont-know-when-webassembly-is-everywhere-in-2026/&quot;&gt;The New Stack网站&lt;/a&gt;&quot;，由InfoQ中文站翻译分享。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://thenewstack.io/webassembly/&quot;&gt;WebAssembly&lt;/a&gt;&quot;在Wasm 3.0和组件模型（Component Model）发布后取得了巨大进展。然而，通往WebAssembly真正成熟落地的“最后一公里”，预计将随着&lt;a href=&quot;https://wasi.dev/roadmap&quot;&gt;WASI 0.3.0&lt;/a&gt;&quot;在2026年（很可能在2月份）的正式发布而完成。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一标准化工作的最终阶段将使WebAssembly能够在越来越多的场景中替代传统&lt;a href=&quot;https://thenewstack.io/introduction-to-containers/&quot;&gt;容器&lt;/a&gt;&quot;，因为无论是否运行在&lt;a href=&quot;https://thenewstack.io/kubernetes/&quot;&gt;Kubernetes&lt;/a&gt;&quot;中，容器本身并不适合某些应用场景。这些场景包括：边缘设备、异步与事件驱动架构、无服务器（serverless）环境，以及需要通过单次发布同时部署到大量（甚至无限数量）终端节点的场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;远超浏览器环境的WebAssembly&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;事实上，WebAssembly早已走出浏览器。在2025年&lt;a href=&quot;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/&quot;&gt;KubeCon + CloudNativeCon&lt;/a&gt;&quot;北美大会期间，微软Azure Core Upstream的首席产品经理&lt;a href=&quot;https://github.com/squillace&quot;&gt;Ralph Squillace&lt;/a&gt;&quot;在&lt;a href=&quot;https://cncf.io/?utm_content=inline+mention&quot;&gt;CNCF&lt;/a&gt;&quot;主办的&lt;a href=&quot;https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/co-located-events/wasmcon/&quot;&gt;WasmCon&lt;/a&gt;&quot;活动闭幕致辞中表示：“WebAssembly几乎能够在所有环境可靠地运行于生产系统中，包括浏览器、服务器、CDN和后端服务，这充分证明了其成熟度和广泛适用性。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Squillace指出，尽管WebAssembly核心有意设计为层级较低且难以直接使用，但近期的规范化工作已支持更高层次的抽象。引用类型（Reference Types）和 接口类型（Interface Types）使得组件能够暴露有意义的API，而开发者无需深入理解WASM内部的机制，从而大幅降低了使用门槛。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于那些特别关注组件的人来说，Squillace表示，&lt;a href=&quot;https://thenewstack.io/webassembly-to-let-developers-combine-languages/&quot;&gt;Bytecode Alliance&lt;/a&gt;&quot;对工程师免费开放。该联盟的重点在于支持工程师和开源开发，而非营销，并提供了包括文档在内的各种资源，使开发者能够从零开始使用WebAssembly组件。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Squillace还指出，这些选择并非相互排斥的。WebAssembly及其组件模型的目的并非取代编程语言、模块或容器，而是致力于实现互操作性、安全性，并拓展软件在不同语言和环境之间所能实现的功能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;WebAssembly并不是完美无缺的，但Squillace表示，这并非重点。真正重要的是它所赋能的能力。这是一个由自愿参与者共同构建的激动人心的领域，正因如此，他说道，这次“结束”实际上是一次“开启”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;核心规范&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管WebAssembly核心有意设计为层级较低且难以直接使用，但近期的规范工作已支持更高层次的抽象。Squillace指出，引用类型（reference types）和接口类型（interface types）使得组件能够暴露有意义的API，而开发者无需深入了解WebAssembly的内部机制。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Squillace表示，“在核心层面开展的规范工作……正是让组件模型能够传递复杂的结构、从而形成合理API的关键所在”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前，基于Wasm的解决方案尚不能作为容器的即插即用替代方案，但它已经在越来越多的场景中得到了应用，这些场景充分利用了WebAssembly的优势。“即便组件模型仍处于早期阶段，但它依然是采用Wasm的一个强有力的理由”。&lt;a href=&quot;https://endor.dev/&quot;&gt;Endor&lt;/a&gt;&quot;的首席执行官兼联合创始人&lt;a href=&quot;https://www.linkedin.com/in/ridruejo/&quot;&gt;Daniel Lopez&lt;/a&gt;&quot;告诉我，“WebAssembly已经被广泛应用于众多无服务器和边缘计算场景中。许多用户（很可能绝大多数）甚至并未意识到它正在幕后运行，尤其是在SaaS和无服务器服务中。Wasm已经支撑了大量应用和场景。随着开发者和行业参与者的广泛支持，进一步的标准化只会加速这一采用进程。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Wasm 3.0并未包含组件模型的最终定稿。尽管Endor项目已非常接近，但像Docker那样“魔法时刻”（即几乎任何应用都能被打包进一个Wasm模块，并可随意部署、传输并在任意地方运行）仍未完全实现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;标准化完成之后，应用程序将能以任意语言编写，并通过Wasm模块分发，同时（甚至异步地）部署到任意终端节点。组件模型最终定稿后，WebAssembly就能将其应用场景从网页浏览器和服务器进一步拓展。用户将能够在成千上万个终端节点上，以极高速度同时运行多个轻量级模块中的不同应用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在2025年北美KubeCon + CloudNativeCon大会期间，由CNCF主办的WasmCon开幕致辞中，Cosmonic公司首席技术官&lt;a href=&quot;https://www.linkedin.com/in/baileyhayes/&quot;&gt;Bailey Hayes&lt;/a&gt;&quot;阐述了WebAssembly的核心优势：近乎为零的冷启动延迟、高工作负载密度，以及即使在资源受限环境中也能高效运行的轻量级、可移植运行时。展望未来，Hayes将即将发布的WASI 0.3.0视为一个重要里程碑。他表示，该版本预览了多项定义下一代WebAssembly计算浪潮的关键特性，包括，与语言深度集成的并发能力（并提供针对不同语言的惯用绑定）、跨语言组件的可组合并发，以及通过底层I/O和零拷贝数据处理实现的高性能流式传输。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;下一波浪潮的关键特性&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Hayes 表示，“我想重点强调三项让我最为期待的下一代计算关键特性：语言集成的并发、跨语言组件的可组合并发，以及支持底层I/O与零拷贝的高性能流式处理。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一切在很大程度上要取决于组件模型的最终确定，尤其是其与WASI的关系，WASI是连接WebAssembly模块与组件的标准接口或API。它将支持构建所谓的WebAssembly “世界”，即由一组由兼容的Wasm组件所构成的互连基础设施，其功能类似于 Kubernetes，但无需依赖容器。2024年发布的WASI Preview 2在标准化方面取得了重大进展，但我们尚未抵达终点。2025年或许仍无法实现“圣杯（Holy Grail）”目标，但可能会带来一些令人欣喜的突破。有传言称，WASI 0.3.0可能无法在今年最终定稿，或将推迟其发布，进而延缓可用组件模型的落地。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lopez表示，“WASI的标准化过程很漫长，但每一次新的预览版发布都让我们离0.3.0更近一步，鉴于该标准的广泛影响和基础性地位，哪怕耗时超出预期，也必须确保其尽可能完善。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://thenewstack.io/wasi-1-0-you-wont-know-when-webassembly-is-everywhere-in-2026/&quot;&gt;https://thenewstack.io/wasi-1-0-you-wont-know-when-webassembly-is-everywhere-in-202&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/HA0BPPlTU2jOYuSDC7Ul</link><guid isPermaLink="false">https://www.infoq.cn/article/HA0BPPlTU2jOYuSDC7Ul</guid><pubDate>Tue, 10 Feb 2026 09:50:50 GMT</pubDate><author>B. Cameron Gain</author><category>性能优化</category></item><item><title>Andy Pavlo：数据库年度回顾</title><description>&lt;p&gt;本文最初发布于Andy Pavlo的个人博客。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;又一年过去了。我本希望能多写几篇文章，而不仅仅是年终的长篇大论，但我在春季学期&lt;a href=&quot;https://bsky.app/profile/andypavlo.bsky.social/post/3lsvwhx2ixk2v&quot;&gt;差点丧命&lt;/a&gt;&quot;，那占用了我所有的时间。尽管如此，我还是会回顾一下过去一年中数据库领域我认为重要的趋势和事件。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;数据库领域有许多激动人心且前所未有的发展。氛围编程（&lt;a href=&quot;https://twitter.com/karpathy/status/1886192184808149383&quot;&gt;Vibe Coding&lt;/a&gt;&quot;）成了日常用语。Wu-Tang Clan宣布启动&lt;a href=&quot;https://www.youtube.com/watch?v=4u-bttzVubs&quot;&gt;时间胶囊项目&lt;/a&gt;&quot;。Databricks未选择上市，而是进行了&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2026/01/2025-databases-retrospective.html#random-fundings&quot;&gt;两轮巨额融资&lt;/a&gt;&quot;，而不是只进行一轮大规模融资。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，其他事件也都在预料之中，不那么令人惊讶。Redis公司在“抽走地毯（&lt;a href=&quot;https://redis.io/blog/redis-adopts-dual-source-available-licensing/&quot;&gt;rugpull&lt;/a&gt;&quot;）”一年后换回了他们的许可（我&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2025/01/2024-databases-retrospective.html#licenses&quot;&gt;去年&lt;/a&gt;&quot;就预测到了这一点）。SurrealDB&lt;a href=&quot;https://blog.cf8.gg/surrealdbs-ch/&quot;&gt;因为没有将写入的数据刷写到磁盘而丢失了数据&lt;/a&gt;&quot;，但他们的基准测试数据却非常好。Coldplay可以&lt;a href=&quot;https://www.reddit.com/r/WatchPeopleDieInside/comments/1m239rb/astronomer_ceo_and_cpo_caught_having_an_affair_on/&quot;&gt;破坏婚姻&lt;/a&gt;&quot;。不过Astronomer倒是从最后这件事里&lt;a href=&quot;https://www.youtube.com/watch?v=vich2C-Tl7Q&quot;&gt;尝到了不少甜头&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在开始之前，我想先回答我每年都会在评论中看到的问题。人们总是问我，在我的分析中，为什么没有提到特定的&lt;a href=&quot;https://www.reddit.com/r/programming/comments/1hr3xor/databases_in_2024_a_year_in_review/m4vone0/&quot;&gt;系统&lt;/a&gt;&quot;、&lt;a href=&quot;https://news.ycombinator.com/item?id=42566660&quot;&gt;数据库&lt;/a&gt;&quot;或&lt;a href=&quot;https://news.ycombinator.com/item?id=34225377&quot;&gt;公司&lt;/a&gt;&quot;。我只能写这么多，除非过去一年中发生了一些有趣或值得注意的事情，要不就没有什么可讨论的。但也并不是所有值得注意的数据库事件，我都适合发表意见。例如，最近有人试图&lt;a href=&quot;https://twitter.com/CeolinWill/status/2005601763051856293&quot;&gt;揭露AvgDatabase首席执行官的真实身份&lt;/a&gt;&quot;，我认为是可以接受的，但&lt;a href=&quot;https://news.ycombinator.com/item?id=46403128&quot;&gt;MongoDB自杀诉讼案&lt;/a&gt;&quot;则不属于此类。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;好了，我们开始吧。这些文章每年都在变长，所以我给读者朋友们提前道个歉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;之前的文章：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2025/01/2024-databases-retrospective.html&quot;&gt;2024年数据库年度回顾&lt;/a&gt;&quot;&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2024/01/2023-databases-retrospective.html&quot;&gt;2023年数据库年度回顾&lt;/a&gt;&quot;&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2022/12/2022-databases-retrospective.html&quot;&gt;2022年数据库年度回顾&lt;/a&gt;&quot;&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2021/12/2021-databases-retrospective.html&quot;&gt;2021年数据库年度回顾&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;PostgreSQL延续了其统治地位&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;早在2021年，我就写到，PostgreSQL正在&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2021/12/2021-databases-retrospective.html#dominance-of-postgresql&quot;&gt;吞噬数据库世界&lt;/a&gt;&quot;。这一趋势还在持续，因为数据库领域里最有趣的发展还是与PostgreSQL有关。该DBMS在2025年11月发布了最新版本（&lt;a href=&quot;https://www.postgresql.org/about/news/postgresql-18-released-3142/&quot;&gt;v18&lt;/a&gt;&quot;），其中最突出的功能是新增的&lt;a href=&quot;https://www.cybertec-postgresql.com/en/postgresql-18-and-beyond-from-aio-to-direct-io/&quot;&gt;异步I/O存储子系统&lt;/a&gt;&quot;，它使PostgreSQL终于摆脱了对操作系统页面缓存的依赖。它还增加了对&lt;a href=&quot;https://www.pgedge.com/blog/postgres-18-skip-scan-breaking-free-from-the-left-most-index-limitation&quot;&gt;跳过扫描&lt;/a&gt;&quot;的支持；即使缺少前缀，查询仍然可以使用多键B+树索引。查询优化器也做了一些改进（如&lt;a href=&quot;https://betterstack.com/community/guides/databases/postgresql-18-new-features/#optimizer-and-query-planning-improvements&quot;&gt;移除多余的自连接&lt;/a&gt;&quot;）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;精通数据库的行家们会立刻指出，这些功能并不是什么突破性的创新，其他DBMS多年前就已经有这些功能了。PostgreSQL是唯一仍然依赖操作系统页面缓存的主流DBMS。&lt;a href=&quot;https://richardfoote.wordpress.com/2008/03/10/index-skip-scan-does-index-column-order-matter-any-more-warning-sign/&quot;&gt;Oracle自2002年（v9i）以来就支持跳过扫描了&lt;/a&gt;&quot;！因此，你可能会问，为什么我说2025年数据库领域里最热门的事情是与PostgreSQL有关的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原因在于，数据库领域的大部分精力和活动都投入到了与PostgreSQL相关的公司、产品、项目及其衍生系统上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;收购+发布&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在过去的一年里，最热门的数据初创公司（&lt;a href=&quot;https://www.databricks.com/&quot;&gt;Databricks&lt;/a&gt;&quot;）为一家PostgreSQL DBaaS公司（&lt;a href=&quot;https://neon.com/&quot;&gt;Neon&lt;/a&gt;&quot;）&lt;a href=&quot;https://www.wsj.com/articles/databricks-to-buy-startup-neon-for-1-billion-fdded971&quot;&gt;支付&lt;/a&gt;&quot;了10亿美元。接下来，世界上最大的数据库公司之一（&lt;a href=&quot;https://www.snowflake.com/en/&quot;&gt;Snowflake&lt;/a&gt;&quot;）为另一家PostgreSQL DBaaS公司（&lt;a href=&quot;https://www.crunchydata.com/&quot;&gt;CrunchyData&lt;/a&gt;&quot;）&lt;a href=&quot;https://www.wsj.com/articles/snowflake-to-buy-crunchy-data-for-250-million-233543ab&quot;&gt;支付&lt;/a&gt;&quot;了2.5亿美元。然后，地球上最大的科技公司之一（微软）&lt;a href=&quot;https://techcommunity.microsoft.com/blog/adforpostgresql/announcing-azure-horizondb/4469710&quot;&gt;推出&lt;/a&gt;&quot;了一个新的PostgreSQL DBaaS（&lt;a href=&quot;https://azure.microsoft.com/en-us/products/horizondb&quot;&gt;HorizonDB&lt;/a&gt;&quot;）。Neon和HorizonDB沿袭了Amazon Aurora在2010年代初的&lt;a href=&quot;https://doi.org/10.1145/3035918.3056101&quot;&gt;高级架构&lt;/a&gt;&quot;，采用单主节点模式分离计算与存储功能。目前，Snowflake的PostgreSQL数据库即服务（DBaaS）使用了和标准PostgreSQL相同的核心架构，它们均基于&lt;a href=&quot;https://www.crunchydata.com/products/crunchy-bridge&quot;&gt;Crunchy Bridge&lt;/a&gt;&quot;构建。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;分布式PostgreSQL&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我上面列出的所有服务都是单主节点架构。也就是说，应用程序将写入发送到主节点，然后主节点将这些更改发送到从副本。但在2025年，有两个新项目宣布要为PostgreSQL创建扩展（即水平分区）服务。2025年6月，Supabase宣布聘请&lt;a href=&quot;https://www.linkedin.com/in/sougou/&quot;&gt;Sugu&lt;/a&gt;&quot;——Vitess的共同创建者和前PlanetScale联合创始人/CTO——来领导&lt;a href=&quot;https://multigres.com/&quot;&gt;Multigres&lt;/a&gt;&quot;项目，为PostgreSQL创建分片中间件，类似于Vitess对MySQL进行分片的机制。Sugu在2023年离开PlanetScale，迫不得已休息了两年。如今，他或许已经摆脱了所有的法律纠纷，可以在Supabase大展身手了。你知道，一位数据库工程师加入一家公司不是个小事，因此&lt;a href=&quot;https://supabase.com/blog/multigres-vitess-for-postgres&quot;&gt;公告&lt;/a&gt;&quot;更多地关注个人而不是系统。&lt;a href=&quot;https://www.linkedin.com/in/adam-prout-0b347630/&quot;&gt;SingleStore联合创始人兼CTO&lt;/a&gt;&quot;在2024年加入了微软，&lt;a href=&quot;https://www.linkedin.com/posts/adam-prout-0b347630_im-happy-to-share-that-im-starting-a-new-activity-7167922823800324096-v1OD&quot;&gt;领导HorizonDB项目&lt;/a&gt;&quot;，但微软（错误地）没有大力宣传。Sugu加盟Supabase的震撼程度，堪比&lt;a href=&quot;https://en.wikipedia.org/wiki/Ol%27_Dirty_Bastard&quot;&gt;Ol&#39; Dirty Bastard（RIP）&lt;/a&gt;&quot;&lt;a href=&quot;https://youtu.be/TDXKvYQ3Xb4&quot;&gt;服刑两年后假释&lt;/a&gt;&quot;出狱，次日便宣布&lt;a href=&quot;https://www.nme.com/news/music/odb-3-1383866&quot;&gt;签下新唱片合约&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在关于Multigres的新闻发布一个月后，PlanetScale&lt;a href=&quot;https://planetscale.com/blog/planetscale-for-postgres#neki-vitess-for-postgres&quot;&gt;宣布&lt;/a&gt;&quot;了自己的Vitess-for-PostgreSQL项目&lt;a href=&quot;https://www.neki.dev/&quot;&gt;Neki&lt;/a&gt;&quot;。2025年3月，PlanetScale推出了其&lt;a href=&quot;https://planetscale.com/blog/announcing-metal&quot;&gt;PostgreSQL DBaaS&lt;/a&gt;&quot;的初始版本，但核心架构仍然是单节点的老搭配&lt;a href=&quot;https://planetscale.com/blog/planetscale-for-postgres#performance-and-reliability&quot;&gt;PostgreSQL和pgBouncer&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2026年1月5日更新：有人发邮件提醒我，&lt;a href=&quot;https://pgdog.dev/&quot;&gt;PgDog&lt;/a&gt;&quot;也是一个寻求支持PostgreSQL水平分片的开源中间件系统。在心理上，我将PgDog和连接池代理（PgBouncer）归为了一类，但实际上它是Multigres和Neki的竞争对手。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;商业格局&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着微软在2025年推出HorizonDB，所有主要的云供应商现在都有自己的PostgreSQL产品项目了。亚马逊自2017年起提供了&lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2017/04/announcing-open-preview-of-amazon-aurora-with-postgresql-compatibility/&quot;&gt;Aurora PostgreSQL&lt;/a&gt;&quot;。谷歌在2022年推出了&lt;a href=&quot;https://venturebeat.com/data-infrastructure/google-announces-alloydb-a-faster-hosted-version-of-postgresql&quot;&gt;AlloyDB&lt;/a&gt;&quot;。ServiceNow在2024年推出了&lt;a href=&quot;https://www.investing.com/news/company-news/servicenow-unveils-raptordb-pro-and-future-knowledge-graph-93CH-3609528&quot;&gt;RaptorDB服务&lt;/a&gt;&quot;，其基础是他们2021年&lt;a href=&quot;https://www.zdnet.com/article/servicenow-acquires-database-performance-company-swarm64/&quot;&gt;收购&lt;/a&gt;&quot;的Swarm64。即使是IBM自2018年起也有了&lt;a href=&quot;https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-postgresql-relnotes&quot;&gt;云版本的PostgreSQL&lt;/a&gt;&quot;。甲骨文在2023年发布了其&lt;a href=&quot;https://docs.oracle.com/en-us/iaas/releasenotes/changes/9a4b73b5-d4d6-4c89-bd31-b1fa2098fa34/index.htm&quot;&gt;PostgreSQL服务&lt;/a&gt;&quot;，尽管有传言说，其内部PostgreSQL团队在2025年9月的&lt;a href=&quot;https://www.theregister.com/2025/09/11/oracle_slammed_for_mysql_job/&quot;&gt;MySQL OCI裁员&lt;/a&gt;&quot;中受到了附带伤害。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前仍然有一些独立的（ISV）PostgreSQL DBaaS公司。按实例数来说，&lt;a href=&quot;https://supabase.com/&quot;&gt;Supabase&lt;/a&gt;&quot;可能是这些公司中最大的。其他公司包括：&lt;a href=&quot;https://www.yugabyte.com/&quot;&gt;YugabyteDB&lt;/a&gt;&quot;、&lt;a href=&quot;https://www.tigerdata.com/&quot;&gt;TigerData&lt;/a&gt;&quot;（之前的Timescale）、&lt;a href=&quot;https://planetscale.com/&quot;&gt;PlanetScale&lt;/a&gt;&quot;、&lt;a href=&quot;https://xata.io/&quot;&gt;Xata&lt;/a&gt;&quot;、&lt;a href=&quot;https://www.pgedge.com/&quot;&gt;PgEdge&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.thenile.dev/&quot;&gt;Nile&lt;/a&gt;&quot;。Xata原本基于&lt;a href=&quot;https://xata.io/blog/serverless-postgres-platform#:~:text=AWS%20Aurora%20under%20the%20hood&quot;&gt;Amazon Aurora&lt;/a&gt;&quot;构建了其架构，但今年，他们宣布&lt;a href=&quot;https://xata.io/blog/xata-postgres-with-data-branching-and-pii-anonymization&quot;&gt;切换到自己的基础设施&lt;/a&gt;&quot;。&lt;a href=&quot;https://www.paradedb.com/&quot;&gt;ParadeDB&lt;/a&gt;&quot;尚未宣布其托管服务。&lt;a href=&quot;https://www.tembo.io/&quot;&gt;Tembo&lt;/a&gt;&quot;则在2025年放弃了其&lt;a href=&quot;https://tembo-io.notion.site/Tembo-Cloud-Migration-Guide-1de7c9367d6a80349570e7469ba7f17b&quot;&gt;托管PostgreSQL产品&lt;/a&gt;&quot;，转而开发一种可以完成部分数据库优化的编码代理。&lt;a href=&quot;https://www.hydra.so/&quot;&gt;Hydra&lt;/a&gt;&quot;和&lt;a href=&quot;https://postgresml.org/&quot;&gt;PostgresML&lt;/a&gt;&quot;已于2025年倒闭（见倒闭一节），所以他们退出了游戏。其他系统提供了一个兼容Postgres的前端，但后端系统并非源自PostgreSQL（如&lt;a href=&quot;https://www.cockroachlabs.com/docs/stable/postgresql-compatibility&quot;&gt;CockroachDB&lt;/a&gt;&quot;、&lt;a href=&quot;https://cedardb.com/docs/compatibility/&quot;&gt;CedarDB&lt;/a&gt;&quot;、&lt;a href=&quot;https://docs.cloud.google.com/spanner/docs/postgresql-interface&quot;&gt;Google Spanner&lt;/a&gt;&quot;）。还有一些托管公司提供PostgreSQL DBaaS以及其他系统，如&lt;a href=&quot;https://aiven.io/&quot;&gt;Aiven&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.tessell.com/&quot;&gt;Tessel&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Andy的观点&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;在Databricks和Snowflake收购PostgreSQL公司之后，不知道下一个大买家会是谁。而且，每家主要的技术公司都已经拥有了Postgres产品。EnterpriseDB是最古老的PostgreSQL ISV，但在过去的五年中，他们错过了两次最重要的PostgreSQL收购。但他们可以暂时依靠贝恩资本，或者寄希望于惠普收购他们，尽管那个&lt;a href=&quot;https://community.hpe.com/t5/oem-solutions/recap-hpe-greenlake-launch-discover-2017-madrid/ba-p/6991195&quot;&gt;合作伙伴关系&lt;/a&gt;&quot;是八年前的。PostgreSQL领域的并购格局令人联想到2000年代末期的OLAP收购浪潮：当&lt;a href=&quot;https://techcrunch.com/2011/03/03/teradata-buys-aster-data-263-million/&quot;&gt;AsterData&lt;/a&gt;&quot;、&lt;a href=&quot;https://techcrunch.com/2010/07/06/emc-acquires-data-warehousing-and-analytics-company-greenplum/&quot;&gt;Greenplum&lt;/a&gt;&quot;和&lt;a href=&quot;https://news.microsoft.com/source/2008/07/24/microsoft-to-acquire-datallegro/&quot;&gt;DATAllegro&lt;/a&gt;&quot;相继被收购后，&lt;a href=&quot;https://investor.hp.com/news-events/news/news-details/2011/HP-to-Acquire-Vertica-Customers-Can-Analyze-Massive-Amounts-of-Big-Data---at-Speed-and-Scale/default.aspx&quot;&gt;Vertica&lt;/a&gt;&quot;成了最后一个在公交站等车的玩家。&amp;nbsp;好消息是竞争性的分布式PostgreSQL项目已经发展到了三个（&lt;a href=&quot;https://multigres.com/&quot;&gt;Multigres&lt;/a&gt;&quot;、&lt;a href=&quot;https://planetscale.com/neki&quot;&gt;Neki&lt;/a&gt;&quot;、&lt;a href=&quot;https://pgdog.dev/&quot;&gt;PgDog&lt;/a&gt;&quot;）。并非第一次有人尝试这样做：用于OLAP工作负载的&lt;a href=&quot;https://www.vmware.com/products/app-platform/tanzu-greenplum&quot;&gt;Greenplum&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/ParAccel&quot;&gt;ParAccel&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.citusdata.com/&quot;&gt;Citus&lt;/a&gt;&quot;已经存在了二十年。Citus支持OLTP工作负载，但他们从2010年开始专注于&lt;a href=&quot;https://www.citusdata.com/blog/2018/06/07/what-is-citus-good-for/#:~:text=we%20focused%20on%20building%20a%20fast%20database%20to%20power%20analytics&quot;&gt;分析领域&lt;/a&gt;&quot;。对于OLTP，15年前，NTT RiTaDB项目与&lt;a href=&quot;https://wiki.postgresql.org/wiki/GridSQL&quot;&gt;GridSQL&lt;/a&gt;&quot;合作创建了&lt;a href=&quot;https://wiki.postgresql.org/wiki/Postgres-XC&quot;&gt;Postgres-XC&lt;/a&gt;&quot;。Postgres-XC的开发人员创建了&lt;a href=&quot;https://dbdb.io/db/stormdb&quot;&gt;StormDB&lt;/a&gt;&quot;，后来&lt;a href=&quot;https://translattice.com/pr/TransLattice_Acquires_StormDB_to_Enhance_TransLattice_Elastic_Database.shtml&quot;&gt;Translattice&lt;/a&gt;&quot;在2013年收购了它。&lt;a href=&quot;https://postgres-x2.github.io/&quot;&gt;Postgres-X2&lt;/a&gt;&quot;是一次对XC进行现代化改造的尝试，但开发人员放弃了这项工作。Translattice将StormDB开源为&lt;a href=&quot;https://en.wikipedia.org/wiki/Postgres-XL&quot;&gt;Postgres-XL&lt;/a&gt;&quot;，但该项目自2018年以来一直处于休眠状态。&lt;a href=&quot;https://www.yugabyte.com/&quot;&gt;YugabyteDB&lt;/a&gt;&quot;于&lt;a href=&quot;https://www.yugabyte.com/blog/yugabyte-has-arrived/&quot;&gt;2016&lt;/a&gt;&quot;年推出，可能是部署最广泛的分片PostgreSQL系统（并且仍然是&lt;a href=&quot;https://github.com/yugabyte/yugabyte-db&quot;&gt;开源&lt;/a&gt;&quot;的！），但它是一个硬分叉，只与&lt;a href=&quot;https://docs.yugabyte.com/stable/api/ysql/&quot;&gt;PostgreSQL v15&lt;/a&gt;&quot;兼容。亚马逊云科技在2024年宣布了自己的分片PostgreSQL（&lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon-aurora-postgresql-limitless-database-is-now-generally-available/&quot;&gt;Aurora Limitless&lt;/a&gt;&quot;），但是闭源的。&amp;nbsp;我知道微软在2019年收购了Citus，但由于他们总给自己的产品起一些令人困惑的名称，所以很难追踪他们在推出HorizonDB之前做了什么。Citus在2019年被重新命名为&lt;a href=&quot;https://techcommunity.microsoft.com/blog/adforpostgresql/azure-database-for-postgresql---hyperscale-citus-now-generally-available/1014865&quot;&gt;Azure Database for PostgreSQL Hyperscale&lt;/a&gt;&quot;，然后在2022年被更名为&lt;a href=&quot;https://learn.microsoft.com/en-us/azure/postgresql/elastic-clusters/concepts-elastic-clusters&quot;&gt;Azure Cosmos DB for PostgreSQL&lt;/a&gt;&quot;。但他们还有使用Citus的Azure Database for PostgreSQL with Elastic Clusters，而该服务与以Citus为基础的Azure Cosmos DB for PostgreSQL并不相同。2023年，微软终止了&lt;a href=&quot;https://techcommunity.microsoft.com/discussions/azuredatabaseforpostgresql/announcement---retiring-azure-postgresql-single-server-in-march-2025-and-introdu/3820887&quot;&gt;Azure PostgreSQL Single Server&lt;/a&gt;&quot;服务，但保留了Azure PostgreSQL Flexible Server。他们有各种各样的Azure服务。这有点像亚马逊云科技忍不住在&lt;a href=&quot;https://docs.aws.amazon.com/aurora-dsql/latest/userguide/what-is-aurora-dsql.html&quot;&gt;DSQL&lt;/a&gt;&quot;的名字前加上 &quot;Aurora&quot;。无论如何，至少微软足够明智，将他们的新系统命名为 &quot;Azure HorizonDB&quot;（目前）。&amp;nbsp;PlanetScale团队&lt;a href=&quot;https://youtu.be/CvgIRHhyRQE?t=143&quot;&gt;对他们的对手没有好感&lt;/a&gt;&quot;，并且已知会对&lt;a href=&quot;https://blog.alexoglou.com/posts/database-decisions/&quot;&gt;Neon&lt;/a&gt;&quot;和&lt;a href=&quot;https://twitter.com/samlambert/status/1984010289348780137&quot;&gt;Timescale&lt;/a&gt;&quot;大打出手。数据库公司之间互相攻击并不新鲜（见&lt;a href=&quot;https://www.linkedin.com/posts/bobdoyleyugabyte_cockroach-labs-activity-7311530387271237634-xR78/&quot;&gt;Yugabyte vs. CockroachDB&lt;/a&gt;&quot;或&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2025/01/2024-databases-retrospective.html#gangwar&quot;&gt;Databricks vs. Snowflake&lt;/a&gt;&quot;）。我怀疑，随着PostgreSQL战争的升温，未来我们将看到更多这样的情况。我建议这些小公司&lt;a href=&quot;https://twitter.com/samlambert/status/1996035931057652125&quot;&gt;呼吁&lt;/a&gt;&quot;下，让那些大型的云供应商相互之间&lt;a href=&quot;https://youtu.be/0dT9siTP70Y&quot;&gt;不要提及对方的名字&lt;/a&gt;&quot;。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;每个数据库都开始支持MCP！&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果说2023年是&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2024/01/2023-databases-retrospective.html#vector&quot;&gt;所有数据库管理系统（DBMS）纷纷添加向量索引&lt;/a&gt;&quot;的一年，那么2025年就是所有DBMS都开始支持Anthropic公司&lt;a href=&quot;https://en.wikipedia.org/wiki/Model_Context_Protocol&quot;&gt;模型上下文协议&lt;/a&gt;&quot;（MCP）的一年。MCP是一种标准的客户端-服务器JSON-RPC接口，使大型语言模型（LLM）能够与外部工具和数据源交互，而无需自己编写粘合代码。作为中间件，MCP服务器位于数据库管理系统前面，暴露DBMS提供的工具、数据及操作清单。MCP客户端（如Claude或ChatGPT等LLM宿主）通过向MCP服务器发送请求来发现并使用这些工具，扩展其模型能力。对于数据库场景，MCP服务器会将查询转换为对应的数据库指令（如SQL）或管理命令。换言之，MCP如同一个&lt;a href=&quot;https://youtu.be/VXuwljCWZMU&quot;&gt;中间人&lt;/a&gt;&quot;，使数据库与LLM之间可以建立起足够的信任以开展协作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Anthropic公司在2024年11月&lt;a href=&quot;https://www.theverge.com/2024/11/25/24305774/anthropic-model-context-protocol-data-sources&quot;&gt;发布&lt;/a&gt;&quot;了MCP，但在2025年3月OpenAI宣布将&lt;a href=&quot;https://techcrunch.com/2025/03/26/openai-adopts-rival-anthropics-standard-for-connecting-ai-models-to-data/&quot;&gt;在其生态系统中支持MCP&lt;/a&gt;&quot;后，它才真正起飞。在接下来的几个月里，所有数据库管理系统（DBMS）供应商都发布了适用于所有系统类别的MCP服务器：OLAP（如&lt;a href=&quot;https://github.com/ClickHouse/mcp-clickhouse&quot;&gt;ClickHouse&lt;/a&gt;&quot;、&lt;a href=&quot;https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-agents-mcp&quot;&gt;Snowflake&lt;/a&gt;&quot;、&lt;a href=&quot;https://github.com/firebolt-db/mcp-server&quot;&gt;Firebolt&lt;/a&gt;&quot;、&lt;a href=&quot;https://yellowbrick.com/blog/application-development/yellowbrick-mcp-server-llms-cutting-code-time-and-speeding-up-etl-development/&quot;&gt;Yellowbrick&lt;/a&gt;&quot;）、SQL（如&lt;a href=&quot;https://www.yugabyte.com/blog/yugabytedb-mcp-server/&quot;&gt;YugabyteDB&lt;/a&gt;&quot;、&lt;a href=&quot;https://blogs.oracle.com/database/introducing-mcp-server-for-oracle-database&quot;&gt;Oracle&lt;/a&gt;&quot;、&lt;a href=&quot;https://planetscale.com/docs/vitess/connecting/mcp&quot;&gt;PlanetScale&lt;/a&gt;&quot;）和NoSQL（如&lt;a href=&quot;https://www.mongodb.com/company/blog/announcing-mongodb-mcp-server&quot;&gt;MongoDB&lt;/a&gt;&quot;、&lt;a href=&quot;https://github.com/neo4j-contrib/mcp-neo4j&quot;&gt;Neo4j&lt;/a&gt;&quot;、&lt;a href=&quot;https://github.com/redis/mcp-redis&quot;&gt;Redis&lt;/a&gt;&quot;）。由于Postgres MCP服务器没有官方的，所以每个Postgres DBaaS都发布了自己的服务器（如&lt;a href=&quot;https://github.com/timescale/pg-aiguide&quot;&gt;Timescale&lt;/a&gt;&quot;、&lt;a href=&quot;https://github.com/supabase-community/supabase-mcp&quot;&gt;Supabase&lt;/a&gt;&quot;、&lt;a href=&quot;https://xata.io/blog/built-xata-mcp-server&quot;&gt;Xata&lt;/a&gt;&quot;）。云供应商则发布了多数据库MCP服务器，可以与他们托管的任何数据库服务进行通信（如&lt;a href=&quot;https://aws.amazon.com/blogs/database/supercharging-aws-database-development-with-aws-mcp-servers/&quot;&gt;亚马逊云科技&lt;/a&gt;&quot;、&lt;a href=&quot;https://learn.microsoft.com/en-us/azure/developer/azure-mcp-server/tools/azure-sql&quot;&gt;微软&lt;/a&gt;&quot;、&lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/mcp-toolbox-for-databases-now-supports-model-context-protocol&quot;&gt;谷歌&lt;/a&gt;&quot;）。允许单一网关与异构数据库通信，几乎已经实现了理想中的&lt;a href=&quot;https://en.wikipedia.org/wiki/Federated_database_system&quot;&gt;联合数据库&lt;/a&gt;&quot;，但还不完全。据我所知，在这些MCP服务器中，每个请求每次仅针对单个数据库，因此需要应用程序负责执行跨源连接操作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;除了供应商的官方MCP实现方案外，几乎每种数据库管理系统（DBMS）都存在&lt;a href=&quot;https://github.com/TensorBlock/awesome-mcp-servers/blob/main/docs/databases.md&quot;&gt;数百种&lt;/a&gt;&quot;非官方的MCP服务器实现方案。其中部分方案试图支持多个系统（如&lt;a href=&quot;https://dbhub.ai/&quot;&gt;DBHub&lt;/a&gt;&quot;、&lt;a href=&quot;https://github.com/FreePeak/db-mcp-server&quot;&gt;DB MCP Server&lt;/a&gt;&quot;）。关于PostgreSQL MCP服务器，DBHub曾发布过&lt;a href=&quot;https://dbhub.ai/blog/state-of-postgres-mcp-servers-2025&quot;&gt;一篇不错的综述&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有一个有趣而又已经证明对代理有帮助的特性是数据库分支。虽然不特定于MCP服务器，但分支允许代理快速测试数据库更改，而不影响生产应用程序。2025年7月，Neon报告说，代理&lt;a href=&quot;https://www.linkedin.com/posts/amitkumarvsingh_ai-agents-are-creating-more-databases-on-activity-7336398117862371328-Q6pO/&quot;&gt;创建了80%的数据库&lt;/a&gt;&quot;。Neon从一开始设计就支持&lt;a href=&quot;https://dev.to/semaphore/a-first-look-at-neon-a-postgres-database-that-branches-10e6&quot;&gt;分支&lt;/a&gt;&quot;（早先在这个系统还叫&lt;a href=&quot;https://dbdb.io/db/neon#history&quot;&gt;Zenith&lt;/a&gt;&quot;时，Nikita就向我做过演示），而其他系统则是后来才添加了分支支持。要了解更多信息，可以看下Xata最近发表的一篇关于数据库分支的&lt;a href=&quot;https://xata.io/blog/neon-vs-supabase-vs-xata-postgres-branching-part-1&quot;&gt;对比文章&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Andy的观点&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;一方面，我很高兴现在有一个标准，可以用来向更多的应用程序暴露数据库的功能。但没有人应该信任一个拥有无限数据库访问权限的应用程序，无论是通过MCP还是系统的常规API。而且，只授予账户最小权限仍然是一个好习惯，特别是在未监控的代理可能在你的数据库中疯狂操作时，对账户做限制显得尤为重要。这意味着，当大型语言模型开始大范围流行时，为每个账户授予管理员权限或所有服务使用同一个账户，诸如这样的懒散做法将彻底行不通。当然，如果你们公司不介意把数据库向&lt;a href=&quot;https://www.theregister.com/2025/01/30/deepseek_database_left_open/&quot;&gt;全世界开放&lt;/a&gt;&quot;，并导致某家最富有的公司市值&lt;a href=&quot;https://www.theregister.com/2025/01/30/deepseek_database_left_open/&quot;&gt;暴跌6000亿美元&lt;/a&gt;&quot;，那么恶意MCP请求就不是你最需要担心的问题了。&amp;nbsp;从我对一些MCP服务器实现的粗略检查来看，它们是简单的代理，只是负责将MCP JSON请求转换为数据库查询，并没有通过深入的自省来理解请求的目的以及它是否合适。有人会尝试在你的应用程序中&lt;a href=&quot;https://www.youtube.com/watch?v=DF8Pny3VTg8&quot;&gt;订购18000个水杯&lt;/a&gt;&quot;，你需要确保它不会导致数据库崩溃。有些MCP服务器有基本的保护机制（如ClickHouse只允许&lt;a href=&quot;https://clickhouse.com/docs/use-cases/AI/MCP#clickhouse-mcp-server&quot;&gt;只读查询&lt;/a&gt;&quot;）。DBHub提供了一些额外的&lt;a href=&quot;https://dbhub.ai/#why-dbhub&quot;&gt;保护&lt;/a&gt;&quot;，如限制每个请求返回的记录数并实现了查询超时。Supabase的文档提供了MCP代理的&lt;a href=&quot;https://supabase.com/docs/guides/getting-started/mcp#recommendations&quot;&gt;最佳实践指南&lt;/a&gt;&quot;，但也得人类遵循它们才行。当然，如果你依赖于人类做正确的事情，那么&lt;a href=&quot;https://www.generalanalysis.com/blog/supabase-mcp-blog&quot;&gt;坏事就在所难免&lt;/a&gt;&quot;。&amp;nbsp;企业DBMS有着开源系统缺乏的自动化护栏和其他安全机制，对于智能代理生态系统，它们做了更好的准备，比如，&lt;a href=&quot;https://www.ibm.com/docs/en/gdp/12.x?topic=overview-guardium&quot;&gt;IBM Guardium&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.oracle.com/security/database-security/audit-vault-database-firewall/&quot;&gt;Oracle Database Firewall&lt;/a&gt;&quot;能够识别并阻止异常查询。我不是在为这些大型科技公司做宣传。我知道，未来我们将看到更多智能代理妨害生活的例子，比如&lt;a href=&quot;https://twitter.com/emil_priver/status/1783399265366052877&quot;&gt;意外删除数据库&lt;/a&gt;&quot;。将MCP服务器与代理（如连接池）结合是引入自动化保护机制的绝佳机会。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;MongoDB起诉FerretDB&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;到现在，MongoDB作为NoSQL领域的中坚已经有二十年了。2021年，Percona高层启动了FerretDB项目，旨在提供一款中间件代理，将MongoDB查询转换为适配PostgreSQL后端的SQL。有了这个代理，不用重写查询就可以将MongoDB应用程序无缝地迁移至PostgreSQL。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;双方共存数年后，MongoDB于2023年向FerretDB发出&lt;a href=&quot;https://blocksandfiles.com/wp-content/uploads/2025/04/Letter-from-MongoDB-to-FerretDB_3-Nov-2023-signed.pdf&quot;&gt;停止侵权通知书&lt;/a&gt;&quot;，指控FerretDB侵犯其专利权、著作权及商标权，并违反了MongoDB文档及有线协议规范的许可条款。2025年5月，MongoDB就这些问题向FerretDB&lt;a href=&quot;https://youtu.be/11BlEYtj53Q&quot;&gt;提起&lt;/a&gt;&quot;&lt;a href=&quot;https://dockets.justia.com/docket/delaware/dedce/1:2025cv00641/89247&quot;&gt;联邦诉讼&lt;/a&gt;&quot;，使这封信件公之于众。双方争议的焦点之一是，FerretDB未经授权便宣称其产品可作为MongoDB“&lt;a href=&quot;https://blog.ferretdb.io/ferretdb-1-0-ga-opensource-mongodb-alternative/&quot;&gt;即插即用的替代品&lt;/a&gt;&quot;”。MongoDB的&lt;a href=&quot;https://storage.courtlistener.com/recap/gov.uscourts.ded.89247/gov.uscourts.ded.89247.1.0.pdf&quot;&gt;法庭文件&lt;/a&gt;&quot;列举了标准指控： (1) 误导开发人员；(2) 弱化商标价值；(3) 损害企业声誉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;让这个故事变得更加复杂的是，微软宣布将与MongoDB兼容的&lt;a href=&quot;https://documentdb.io/&quot;&gt;DocumentDB&lt;/a&gt;&quot;捐赠给&lt;a href=&quot;https://www.linuxfoundation.org/press/linux-foundation-welcomes-documentdb-to-advance-open-developer-first-nosql-innovation&quot;&gt;Linux基金会&lt;/a&gt;&quot;。该项目的网站提到，DocumentDB与MongoDB驱动程序兼容，并且旨在“&lt;a href=&quot;https://documentdb.io/#:~:text=our%20mission%20is%20to%20build%20a%20MongoDB%20compatible%20open%20source%20document%20database&quot;&gt;构建一个与MongoDB兼容的开源文档数据库&lt;/a&gt;&quot;”。还有其他主流的数据库供应商参与了该项目，如亚马逊云科技和Yugabyte。粗看之下，这种语言似乎与MongoDB指控的FerretDB的行为如出一辙。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Andy的观点&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我没有找到数据库公司因对方复制其API而起诉对方的例子。最接近的例子是Oracle起诉谷歌在安卓系统中使用了Java API的“清洁室副本”。最终，最高法院以公平使用为由&lt;a href=&quot;https://en.wikipedia.org/wiki/Google_LLC_v._Oracle_America%2C_Inc.&quot;&gt;支持了谷歌&lt;/a&gt;&quot;。这个案例影响了法律上对重新实现行为的处理方式。&amp;nbsp;我不知道如果这场诉讼真进入庭审阶段会如何发展。陪审团是由随机挑选的路人组成的，他们或许无法理解MongoDB有线协议的具体细节，但他们绝对清楚FerretDB最初的名字是&lt;a href=&quot;https://www.reddit.com/r/programming/comments/qlyalj/mangodb_a_truly_open_source_mongodb_alternative/&quot;&gt;MangoDB&lt;/a&gt;&quot;。要说服陪审团，相信你给公司起名时仅替换一个字母不是想转移客户，这将非常困难。更何况这根本不是个原创名称：早就有个恶搞数据库管理系统叫&lt;a href=&quot;https://dbdb.io/db/mangodb&quot;&gt;MangoDB&lt;/a&gt;&quot;，它会把所有数据写入/dev/null。&amp;nbsp;说到数据库系统的命名时，微软选择“DocumentDB”让人觉得遗憾。市面上已经有&lt;a href=&quot;https://aws.amazon.com/documentdb/&quot;&gt;Amazon DocumentDB&lt;/a&gt;&quot;（顺便说一下，它也&lt;a href=&quot;https://docs.aws.amazon.com/documentdb/latest/developerguide/compatibility.html#mongodb-80&quot;&gt;兼容&lt;/a&gt;&quot;MongoDB，不过亚马逊云科技可能为此付了费）、&lt;a href=&quot;https://docs.intersystems.com/irislatest/csp/docbook/DocBook.UI.Page.cls?KEY=GDOCDB_intro&quot;&gt;InterSystems DocDB&lt;/a&gt;&quot;和&lt;a href=&quot;https://docs.yugabyte.com/stable/architecture/docdb/&quot;&gt;Yugabyte DocDB&lt;/a&gt;&quot;。微软的“Cosmos DB”在2016年推出时的原始名称也是&lt;a href=&quot;https://auth0.com/blog/documentdb-with-aspnetcore/&quot;&gt;DocumentDB&lt;/a&gt;&quot;。&amp;nbsp;最后，MongoDB的法庭文件声称，他们“开创了‘非关系型’数据库”。这个说法是不正确的。第一个通用数据库管理系统是非关系型的，因为关系模型那时候还没有发明出来。通用电气的&lt;a href=&quot;https://en.wikipedia.org/wiki/Integrated_Data_Store&quot;&gt;Integrated Data Store&lt;/a&gt;&quot;（1964年）使用了&lt;a href=&quot;https://en.wikipedia.org/wiki/Network_model&quot;&gt;网络数据模型&lt;/a&gt;&quot;，IBM的&lt;a href=&quot;https://en.wikipedia.org/wiki/IBM_Information_Management_System&quot;&gt;Information Management System&lt;/a&gt;&quot;（1966年）使用了&lt;a href=&quot;https://en.wikipedia.org/wiki/Hierarchical_database_model&quot;&gt;层次数据模型&lt;/a&gt;&quot;。MongoDB也不是第一个文档数据库管理系统。这个头衔应该归属于1980年代末的面向对象数据库管理系统（如&lt;a href=&quot;http://www.versant.com/products/versant-object-database&quot;&gt;Versant&lt;/a&gt;&quot;）或2000年代的XML数据库管理系统（如&lt;a href=&quot;https://www.progress.com/marklogic&quot;&gt;MarkLogic&lt;/a&gt;&quot;）。只是与它们相比，MongoDB取得了压倒性的成功（也许IMS除外）。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;文件格式之争&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;文件格式是数据系统中过去十年间基本处于停滞状态的一个领域。2011年，Meta公司针对Hadoop发布了名为&lt;a href=&quot;https://en.wikipedia.org/wiki/RCFile&quot;&gt;RCFile&lt;/a&gt;&quot;的列式存储格式。两年后，Meta对RCFile做了优化，并推出了基于PAX的&lt;a href=&quot;https://orc.apache.org/&quot;&gt;ORC&lt;/a&gt;&quot;（Optimized Record Columnar File）格式。ORC发布一个月后，Twitter联合Cloudera推出了&lt;a href=&quot;https://parquet.apache.org/&quot;&gt;Parquet&lt;/a&gt;&quot;的首个版本。近十五年后，Parquet已成为开源领域占支配地位的文件格式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2025年，有五个新的开源文件格式发布，都在争取取代Parquet的地位：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/cwida/FastLanes&quot;&gt;CWI FastLanes&lt;/a&gt;&quot;&lt;a href=&quot;https://github.com/future-file-format/f3&quot;&gt;CMU + Tsinghua F3&lt;/a&gt;&quot;&lt;a href=&quot;https://vortex.dev/&quot;&gt;SpiralDB Vortex&lt;/a&gt;&quot;&lt;a href=&quot;https://github.com/AnyBlox&quot;&gt;德国人的AnyBlox&lt;/a&gt;&quot;&lt;a href=&quot;https://web.archive.org/web/20250802074742/https://github.com/microsoft/amudai&quot;&gt;微软Amudai&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以下是2024年发布的格式：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/facebookincubator/nimble&quot;&gt;Meta Nimble&lt;/a&gt;&quot;&lt;a href=&quot;https://lancedb.com/blog/lance-v2/&quot;&gt;LanceDB Lance&lt;/a&gt;&quot;&lt;a href=&quot;https://tsfile.apache.org/&quot;&gt;IoTDB TsFile&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://spiraldb.com/&quot;&gt;SpiralDB&lt;/a&gt;&quot;今年最引人瞩目的举措是宣布&lt;a href=&quot;https://www.linuxfoundation.org/press/lf-ai-data-foundation-hosts-vortex-project-to-power-high-performance-data-access-for-ai-and-analytics&quot;&gt;将Vortex捐赠给Linux基金会&lt;/a&gt;&quot;，并成立了多组织指导委员会。微软则在2025年底悄然&lt;a href=&quot;https://github.com/microsoft/amudai&quot;&gt;终止&lt;/a&gt;&quot;了Amudai项目（至少将其转为闭源）。其余项目（FastLanes、F3、Anyblox）均属学术原型，其中Anyblox今年斩获了&lt;a href=&quot;https://www.linkedin.com/posts/janagiceva_im-thrilled-and-honored-to-share-that-our-activity-7368909487023329281-mhDv/&quot;&gt;VLDB最佳论文奖&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种新的竞争点燃了Parquet开发社区对其功能进行现代化改进的热情。Parquet PMC主席&lt;a href=&quot;http://julien.ledem.net/&quot;&gt;Julien Le Dem&lt;/a&gt;&quot;对列式文件格式格局做了&lt;a href=&quot;https://sympathetic.ink/2025/12/11/Column-Storage-for-the-AI-era.html&quot;&gt;深入的技术分析&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Andy的观点&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Parquet的主要问题并非源于格式本身。该规范可以且已经经过演进。没有人会要求组织机构重写PB级的旧文件以更新至最新的Parquet版本。问题在于，人们用不同的语言实现了大量的读写库，而每个库只支持这个规范的特定子集。通过对实际环境中Parquet文件的&lt;a href=&quot;https://bsky.app/profile/andypavlo.bsky.social/post/3m256lckmec2z&quot;&gt;分析&lt;/a&gt;&quot;，我们发现，94%的文件仅使用了2013年发布的v1版本的特性，即便其创建时间戳晚于2020年。这种最低公约数意味着：当有人使用v2版本的特性创建文件时，系统能否正确读取该文件完全取决于其版本兼容性。&amp;nbsp;我与清华大学的&lt;a href=&quot;https://xinyuzeng.github.io/&quot;&gt;Xinyu Zeng&lt;/a&gt;&quot;、&lt;a href=&quot;https://dl.acm.org/profile/99661226655&quot;&gt;Ruijun Meng&lt;/a&gt;&quot;、&lt;a href=&quot;https://people.iiis.tsinghua.edu.cn/~huanchen/&quot;&gt;Huanchen Zhang&lt;/a&gt;&quot;、CMU的&lt;a href=&quot;https://www.cs.cmu.edu/~mprammer/&quot;&gt;Martin Prammer&lt;/a&gt;&quot;、&lt;a href=&quot;https://csd.cmu.edu/people/faculty/jignesh-patel&quot;&gt;Jignesh Patel&lt;/a&gt;&quot;以及&lt;a href=&quot;https://wesmckinney.com/&quot;&gt;Wes McKinney&lt;/a&gt;&quot;一起开发了F3文件格式。我们的重点是通过提供作为共享对象的原生解码器（Rust crates）和在文件中嵌入这些解码器的WASM版本来解决互操作性问题。如果有人创建了一种新的编码格式，而数据库管理系统尚未提供原生支持，那么它仍然可以使用WASM版本通过传递Arrow缓冲区来读取数据。每个解码器针对单个列，这使得DBMS能够针对单个文件同时使用原生解码器和WASM解码器。AnyBlox采用了一种不同的方法，生成单个WASM程序来解码整个文件。&amp;nbsp;我不知道谁会赢得文件格式之争。下一场较量很可能围绕GPU支持展开。SpiralDB似乎正在采取正确的举措，但Parquet的普及性将构成一个巨大的挑战。至于DuckLake如何寻求颠覆Iceberg，我甚至还没有讨论……&amp;nbsp;当然，每当这个话题出现时，总有人会贴出&lt;a href=&quot;https://xkcd.com/927/&quot;&gt;那幅关于标准竞争的xkcd漫画&lt;/a&gt;&quot;。我已经看过了，别再发邮件给我了。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;偶然事件&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;数据库是大生意。让我们逐一了解下。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;收购&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;市场上有很多动作。为了准备一笔收购，Pinecone在9月份&lt;a href=&quot;https://venturebeat.com/data-infrastructure/pinecone-founder-edo-liberty-appoints-googler-ash-as-ceo&quot;&gt;更换了CEO&lt;/a&gt;&quot;，但我没有听到任何其他的消息。以下是已经发生的收购：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.datastax.com/blog/ibm-plans-to-acquire-datastax&quot;&gt;DataStax → IBM&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这家Cassandra的坚定支持者年初被IBM收购，&lt;a href=&quot;https://www.linkedin.com/posts/nathanlatka_saas-datastax-activity-7300252058274672640-OQx_/&quot;&gt;估值30亿美元&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://quickwit.io/blog/quickwit-joins-datadog&quot;&gt;Quickwit → DataDog&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;作为Lucene替代方案的领军企业，全文搜索引擎&lt;a href=&quot;https://github.com/quickwit-oss/tantivy&quot;&gt;Tantivy&lt;/a&gt;&quot;已于年初被收购。好消息是，Tantivy的开发工作仍在继续。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.getdbt.com/blog/dbt-labs-announces-sdf-labs-acquisition&quot;&gt;SDF → dbt&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这次收购对dbt来说是一个很好的补充，也是他们今年发布的&lt;a href=&quot;https://www.getdbt.com/product/fusion&quot;&gt;Fusion&lt;/a&gt;&quot;的一部分，使他们能够在DAG中进行更严格的SQL分析。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.mongodb.com/company/blog/news/redefining-database-ai-why-mongodb-acquired-voyage-ai&quot;&gt;Voyage.ai → MongoDB&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;Mongo收购了一家初创AI公司，旨在&lt;a href=&quot;https://news.ycombinator.com/item?id=43160731&quot;&gt;增强&lt;/a&gt;&quot;其云产品中的RAG能力。在公告前一周，我&lt;a href=&quot;https://www.linkedin.com/in/wangpatrick57/&quot;&gt;最优秀的学生&lt;/a&gt;&quot;之一加入了Voyage。他以为自己不与数据库公司签约背叛了“家族”，结果最终还是加入了一家数据库公司。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://neon.tech/blog/neon-and-databricks&quot;&gt;Neon → Databricks&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;显然，这家PostgreSQL公司引发了一场竞购战，但Databricks以&lt;a href=&quot;https://www.wsj.com/articles/databricks-to-buy-startup-neon-for-1-billion-fdded971&quot;&gt;令人垂涎的10亿美元&lt;/a&gt;&quot;收购了它。Neon至今仍然作为一个独立服务存在，但Databricks迅速在其生态系统中将其更名为&lt;a href=&quot;https://www.databricks.com/product/lakebase&quot;&gt;Lakebase&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.wsj.com/articles/snowflake-to-buy-crunchy-data-for-250-million-233543ab&quot;&gt;CrunchyData → Snowflake&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;你知道Snowflake不会让Databricks在夏天独占所有风头，所以他们为CrunchyData这家有着13年历史的PostgreSQL公司支付了2.5亿美元。近年来，Crunchy从Citus吸引了一些顶级人才，并在Snowflake收购他们之前扩大了其DBaaS产品。Snowflake在2025年12月宣布公开预览其&lt;a href=&quot;https://www.snowflake.com/en/product/features/postgres/&quot;&gt;Postgres&lt;/a&gt;&quot;服务。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.cnbc.com/amp/2025/05/27/salesforce-informatica-deal.html&quot;&gt;Informatica → Salesforce&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;Informatica，这家1990年代的老派ETL公司被Salesforce以&lt;a href=&quot;https://finance.yahoo.com/news/salesforce-buys-informatica-8b-failed-150907984.html&quot;&gt;80亿美元&lt;/a&gt;&quot;的价格收购。这家公司于1999年上市，2015年转为PE，然后在2021年再次上市。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://investors.couchbase.com/news-releases/news-release-details/couchbase-be-acquired-haveli-investments-15-billion&quot;&gt;Couchbase → 私募股权&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;老实说，我一直不明白Couchbase在2021年是如何上市的，莫非是借了MongoDB的东风？几年前，通过整合加州大学欧文分校&lt;a href=&quot;https://www.couchbase.com/press-releases/couchbase-announces-first-commercial-implementation-of-sql-with-n1ql-for-analytics/&quot;&gt;AsterixDB项目&lt;/a&gt;&quot;的一些组件，Couchbase做了一些有趣的工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.reuters.com/business/finance/databricks-buy-sequoia-backed-tecton-ai-agent-push-2025-08-22/&quot;&gt;Tecton → Databricks&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;Tecton为Databricks提供了额外的代理构建工具。我的另一位学生曾在该公司工作，现在是在Databricks。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.fivetran.com/press/fivetran-acquires-tobiko-data-to-power-the-next-generation-of-advanced-ai-ready-data-transformation&quot;&gt;Tobiko Data → Fivetran&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这个团队开发了两个有用的工具：&lt;a href=&quot;https://sqlmesh.readthedocs.io/&quot;&gt;SQLMesh&lt;/a&gt;&quot;和&lt;a href=&quot;https://sqlglot.com/&quot;&gt;SQLglot&lt;/a&gt;&quot;。前者是唯一可与dbt（见下文，计划与Fivetran合并）抗衡的开源竞争者。SQLglot是一个便捷的SQL解析器/反解析器，支持启发式的查询优化器。未来几年，Fivetran与SDF将该技术与dbt相结合，将在该领域形成引人注目的技术布局。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.businesswire.com/news/home/20250910856970/en/SingleStore-Announces-Growth-Buyout-Led-by-Vector-Capital&quot;&gt;SingleStore → 私募股权&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;购买SingleStore的PE公司（&lt;a href=&quot;https://www.vectorcapital.com/&quot;&gt;Vector Capital&lt;/a&gt;&quot;）以前有管理数据库公司的经验。之前在2020年，他们曾经&lt;a href=&quot;https://www.businesswire.com/news/home/20201021005279/en/Vector-Capital-Completes-Acquisition-of-MarkLogic&quot;&gt;购买了XML数据库公司MarkLogic&lt;/a&gt;&quot;，并在2023年将其&lt;a href=&quot;https://investors.progress.com/news-releases/news-release-details/progress-announces-plans-acquire-marklogic&quot;&gt;转手给Progress&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.dbta.com/Editorial/News-Flashes/MariaDB-to-Acquire-Galera-Cluster-to-Enable-Deeper-Integration-of-Synchronous-Replication-Technology-169742.aspx&quot;&gt;Codership → MariaDB&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;在2024年被PE公司收购后，MariaDB公司今年开启了收购狂潮。首当其冲的是开发MariaDB扩展中间件Galera Cluster的公司。详见我2023年对&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2024/01/2023-databases-retrospective.html#mariadb&quot;&gt;MariaDB混乱局面&lt;/a&gt;&quot;的全面分析。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.crn.com/news/cloud/2025/mariadb-buys-back-skysql-in-database-flexibility-push&quot;&gt;SkySQL → MariaDB&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;然后是MariaDB的第二笔收购。为避免混淆，我需要说明一下：2010年的时候，最初为MariaDB提供支持的商业公司名为“SkySQL Corporation”，2014年，它更名为“MariaDB Corporation”。2020年，MariaDB Corporation推出名为SkySQL的MariaDB数据库即服务（DBaaS）。但因资金持续流失，该公司于2023年&lt;a href=&quot;https://www.businesswire.com/news/home/20231214486927/en/MariaDB-Finalizes-Spinoff-of-SkySQL&quot;&gt;将SkySQL Inc.剥离&lt;/a&gt;&quot;出去，成为一家独立的公司。而2025年，MariaDB Corporation&lt;a href=&quot;https://medium.com/@arbaudie.it/personal-opinion-mariadb-re-acquires-skysql-125181507358&quot;&gt;回购了SkySQL Inc.&lt;/a&gt;&quot;，兜了一圈后回到了原处。今年我的数据库宾果卡上可没有这一步。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.crystaldba.ai/blog/post/temporal-technologies-acquires-crystal-dba&quot;&gt;Crystal DBA → Temporal&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;自动化数据库优化工具公司Crystal DBA加入Temporal公司，帮他们自动优化数据库！很高兴得知Crystal创始人、伯克利数据库小组校友Johann Schleier-Smith在那里发展顺利。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.harvestmp.com/transactions&quot;&gt;HeavyDB → Nvidia&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这个系统（之前叫OmniSci，再之前叫MapD）是首批GPU加速数据库之一，于2013年推出。除了一家并购公司披露了这笔成功的交易外，我未能找到有关交易完成的官方公告。随后我们与英伟达召开会议，探讨潜在的数据库研究合作事宜，期间几位HeavyDB的伙伴也现身参与。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.prnewswire.com/news-releases/istari-digital-acquires-dgraph-to-strengthen-data-foundation-for-ai-and-engineering-302593246.html&quot;&gt;DGraph → Istari Digital&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;Dgraph之前&lt;a href=&quot;https://web.archive.org/web/20250806150448/https://hypermode.com/blog/the-future-of-dgraph-is-open-serverless-and-ai-ready&quot;&gt;在2023年被Hypermode收购&lt;/a&gt;&quot;。现在看来，Istari只是买了Dgraph，而不是Hypermode的其他部分（或者他们放弃了）。我还没见过任何积极使用Dgraph的人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.mews.com/en/press/mews-acquires-datachat&quot;&gt;DataChat → Mews&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这是最早支持“与数据库对话”的数据库之一，来自威斯康星大学的Jignesh Patel，现为CMU-DB教授。但后来被一家欧洲酒店管理领域的SaaS公司收购了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://siliconangle.com/2025/11/10/snowflake-acquires-database-migration-startup-datometry/&quot;&gt;Datometry → Snowflake&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;多年来，Datometry一直致力于将旧版SQL方言（如Teradata）自动转换至新型OLAP系统这一棘手的问题。Snowflake收购他们是为了扩展自己的&lt;a href=&quot;https://www.snowflake.com/en/blog/accelerate-data-migration-datometry-technology/&quot;&gt;迁移工具&lt;/a&gt;&quot;。更多信息参见&lt;a href=&quot;https://www.youtube.com/watch?v=cL1-BIaQSYE&amp;amp;list=PLSE8ODhjZXjagqlf1NxuBQwaMkrHXi-iz&amp;amp;index=23&quot;&gt;Datometry 2020年的CMU-DB技术讲座&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://clickhouse.com/blog/librechat-open-source-agentic-data-stack&quot;&gt;LibreChat → ClickHouse&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;像Snowflake收购Datometry一样，ClickHouse的这次收购是提升高性能通用OLAP引擎开发体验的典范。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.databricks.com/blog/mooncake-labs-joins-databricks-accelerate-vision-lakebase&quot;&gt;Mooncake → Databricks&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;在收购Neon之后，为了使PostgreSQL能够读写Apache Iceberg数据，Databricks收购了Mooncake。更多信息参见他们2025年11月的&lt;a href=&quot;https://www.youtube.com/watch?v=VqFZyWHGQVM&amp;amp;list=PLSE8ODhjZXjbEeW_bOCZ8c_nx_Jhoz-GW&amp;amp;index=8&quot;&gt;CMU-DB讲座&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.reuters.com/technology/ibm-nears-roughly-11-billion-deal-confluent-wsj-reports-2025-12-08/&quot;&gt;Confluent → IBM&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这是一个将草根开源项目发展为一家公司的经典案例。Kafka最初于2011年在Linkedin开发，随后在2014年，Confluent作为独立的初创公司分拆出来，于七年后的2021年成功上市。随后IBM斥巨资将其收购。与DataStax的情况相似，目前尚不确定IBM是会对Confluent采取&lt;a href=&quot;https://news.ycombinator.com/item?id=43200706&quot;&gt;惯常的企业收购策略&lt;/a&gt;&quot;，还是像RedHat那样使其保持独立运营。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.geldata.com/blog/gel-joins-vercel&quot;&gt;Gel → Vercel&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;前身为&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2026/01/2025-databases-retrospective.html#random-naming&quot;&gt;EdgeDB&lt;/a&gt;&quot;，在PostgreSQL之上提供了一种DSL，被Verel在2025年年底收购。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.geldata.com/blog/gel-joins-vercel&quot;&gt;Kuzu → ???&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这款诞生于滑铁卢大学的嵌入式图形DBMS在2025年被一家未具名的公司收购。然后KuzuDB公司宣布放弃该开源项目。&lt;a href=&quot;https://ladybugdb.com/&quot;&gt;LadybugDB&lt;/a&gt;&quot;项目旨在维护Kuzu代码的一个分支版本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;合并&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2025年10月，&lt;a href=&quot;https://www.fivetran.com/&quot;&gt;Fivetran&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.getdbt.com/&quot;&gt;dbt Labs&lt;/a&gt;&quot;宣布&lt;a href=&quot;https://www.reuters.com/business/a16z-backed-data-firms-fivetran-dbt-labs-merge-all-stock-deal-2025-10-13&quot;&gt;合并&lt;/a&gt;&quot;成一家公司，这个消息着实让人意外。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据我所知，数据库领域的上一次合并是2019年&lt;a href=&quot;https://techcrunch.com/2018/10/03/cloudera-and-hortonworks-announce-5-2-billion-merger/&quot;&gt;Cloudera和Hortonworks合并&lt;/a&gt;&quot;。但那笔交易只是两家在Hadoop领域苦苦寻找定位的公司试图通过合并成一家公司来扭转局面（剧透：他们没有成功）。2022年，MariaDB公司通过&lt;a href=&quot;https://en.wikipedia.org/wiki/Special-purpose_acquisition_company&quot;&gt;SPAC&lt;/a&gt;&quot;与&lt;a href=&quot;https://mariadb.com/newsroom/press-releases/mariadb-completes-merger-and-lands-on-nyse-as-mrdb/&quot;&gt;Angel Pond Holdings公司&lt;/a&gt;&quot;合并，技术上讲也算并购，但那是为了让MariaDB能够上市而采取的后门策略。对&lt;a href=&quot;https://www.bizjournals.com/sanjose/news/2022/12/19/mariadb-goes-public-in-spac-merger.html&quot;&gt;投资者&lt;/a&gt;&quot;来说，结果并不好。Fivetran和dbt的合并与这两者不同（更好）——这两家互补的技术公司正联手打造ETL领域的巨头企业，为近期开展正规的IPO做准备。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;融资&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除非我错过了，或者他们没有宣布，数据库初创公司的早期融资轮次并不算多。围绕向量数据库的炒作已趋于平息，风险投资公司现在只愿为LLM公司花钱。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Databricks：&lt;a href=&quot;https://www.databricks.com/company/newsroom/press-releases/databricks-surpasses-4-8b-revenue-run-rate-growing-55-year-over-year&quot;&gt;L轮40亿美元&lt;/a&gt;&quot;Databricks：&lt;a href=&quot;https://www.reuters.com/business/databricks-eyes-over-100-billion-valuation-investors-back-ai-growth-plans-2025-08-19/&quot;&gt;K轮10亿美元&lt;/a&gt;&quot;ClickHouse：&lt;a href=&quot;https://clickhouse.com/blog/clickhouse-raises-350-million-series-c-to-power-analytics-for-ai-era&quot;&gt;C轮3.5亿美元&lt;/a&gt;&quot;Supabase：&lt;a href=&quot;https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html&quot;&gt;D轮2亿美元&lt;/a&gt;&quot;Timescale：&lt;a href=&quot;https://www.tigerdata.com/blog/year-of-the-tiger-110-million-to-build-the-future-of-data-for-developers-worldwide&quot;&gt;C轮1.1亿美元&lt;/a&gt;&quot;Supabase：&lt;a href=&quot;https://supabase.com/blog/supabase-series-e&quot;&gt;E轮1亿美元&lt;/a&gt;&quot;Astronomer：&lt;a href=&quot;https://www.astronomer.io/press-releases/astronomer-secures-93-million-series-d-funding/&quot;&gt;D轮9300万美元&lt;/a&gt;&quot;Tessel：&lt;a href=&quot;https://www.tessell.com/press-releases/tessell-raises-60m-series-b-to-expand-ai-driven-multi-cloud-data-ecosystems&quot;&gt;B轮6000万美元&lt;/a&gt;&quot;LanceDB：&lt;a href=&quot;https://lancedb.com/blog/series-a-funding/&quot;&gt;A轮3000万美元&lt;/a&gt;&quot;Convex：&lt;a href=&quot;https://news.convex.dev/convex-raises-24m/&quot;&gt;B轮2400万美元&lt;/a&gt;&quot;SpiralDB：&lt;a href=&quot;https://www.axios.com/pro/enterprise-software-deals/2025/09/11/database-startup-spiral-22-million&quot;&gt;A轮2200万美元&lt;/a&gt;&quot;ParadeDB：&lt;a href=&quot;https://techcrunch.com/2025/07/15/paradedb-takes-on-elasticsearch-as-interest-in-postgres-explodes-amid-ai-boom/&quot;&gt;A轮1200万美元&lt;/a&gt;&quot;CedarDB：&lt;a href=&quot;https://www.munich-startup.de/en/109750/cedardb-secures-53-million-euros/&quot;&gt;种子轮590万美元&lt;/a&gt;&quot;TopK：&lt;a href=&quot;https://www.topk.io/blog/seed-round&quot;&gt;种子轮550万美元&lt;/a&gt;&quot;Columnar：&lt;a href=&quot;https://columnar.tech/blog/announcing-columnar&quot;&gt;种子轮400万美元&lt;/a&gt;&quot;SereneDB：&lt;a href=&quot;https://tech.eu/2025/12/03/serenedb-lands-21m-to-fuse-search-analytics-and-postgres-into-one-engine/&quot;&gt;前种子轮210万美元&lt;/a&gt;&quot;Starburst：&lt;a href=&quot;https://www.prnewswire.com/news-releases/starburst-announces-strategic-investment-from-citi-302456950.html&quot;&gt;未披露？&lt;/a&gt;&quot;TurboPuffer：&lt;a href=&quot;https://tpuf.link/comms&quot;&gt;未披露？&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&amp;nbsp;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;名称变更&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是我在年度总结中新增加的一个类别——数据库公司更改其公司或系统的名称。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.dbta.com/Editorial/News-Flashes/HarperDBs-Rebrand-Reflects-its-Commitment-to-Delivering-a-Full-Stack-Application-Delivery-Platform-168390.aspx&quot;&gt;HarperDB → Harper&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这家JSON数据库公司从名字里去掉了后缀&quot;DB&quot; ，旨在强调其作为数据库支持型应用平台的定位，类似于&lt;a href=&quot;https://www.convex.dev/&quot;&gt;Convex&lt;/a&gt;&quot;和Heroku。我很欣赏Harper的团队。2021年，他们在&lt;a href=&quot;https://www.youtube.com/watch?v=I5_xIs6xsJQ&amp;amp;list=PLSE8ODhjZXjbeqnfuvp30VrI7VXiFuOXS&amp;amp;index=7&quot;&gt;CMU-DB技术研讨会&lt;/a&gt;&quot;上提出的数据库管理系统构想可以说是我听过的最糟糕的方案。好在他们意识到该方案的缺陷后果断放弃，转而采用了LMDB技术。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.geldata.com/blog/edgedb-is-now-gel-and-postgres-is-the-future&quot;&gt;EdgeDB → Gel&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这是一个明智的举动，因为“Edge”这个名字传达了这样一个信息，它是一个用于边缘设备或服务的数据库（如&lt;a href=&quot;http://fly.io/&quot;&gt;Fly.io&lt;/a&gt;&quot;）。不过我也不确定“Gel”是否传达了项目更高层次的目标。感兴趣的读者可以观看下他们在&lt;a href=&quot;https://www.youtube.com/watch?v=RzLo-pdUJ7I&amp;amp;list=PLSE8ODhjZXjbpOIrZheFWxkYG8HD87xW1&amp;amp;index=10&quot;&gt;2025年CMU-DB技术研讨会上关于Gel查询语言（名称还是EdgeQL）的讲座&lt;/a&gt;&quot;，由CMU博士校友主讲。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.tigerdata.com/blog/timescale-becomes-tigerdata&quot;&gt;Timescale → TigerData&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;数据库公司为区别于其核心数据库产品而更名的案例实属罕见。通常情况是公司更名为数据库名称（如“Relational Software, Inc.”更名为“Oracle Systems Corporation”，“10gen, Inc.”更名为“MongoDB, Inc.”）。该公司有了新的定位——通用应用场景的增强版PostgreSQL，因此他们试图摆脱“专业化时间序列数据库管理系统”的固有印象，这一策略有它的合理性，毕竟前者所处的细分市场远小于后者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;倒闭&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;坦白说，我曾在其中两家失败的初创公司中担任技术顾问。截止目前，我的顾问成功率可以说是惨不忍睹。我也曾担任&lt;a href=&quot;https://dbdb.io/db/splice-machine&quot;&gt;Splice Machine&lt;/a&gt;&quot;公司的顾问，但该公司已于2021年倒闭。需要说明的是，我只和他们讨论技术构想，而不涉及商业策略。我确实建议Fauna增加SQL支持功能，但他们没有采纳我的建议。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoworld.com/article/3853569/fauna-to-shut-down-faunadb-service-in-may.html&quot;&gt;Fauna&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;Spanner是一款颇具特色的分布式数据库管理系统，基于&lt;a href=&quot;https://www.cs.umd.edu/~abadi/&quot;&gt;Dan Abadi&lt;/a&gt;&quot;的&lt;a href=&quot;https://vldb.org/pvldb/vol3/R06.pdf&quot;&gt;确定性并发控制研究&lt;/a&gt;&quot;。恰好在NoSQL热潮逐渐消退之际，它提供了强一致性事务处理能力，使事务处理功能再度成为焦点。不过该系统采用&lt;a href=&quot;https://faunadb-docs.netlify.app/fauna/current/learn/query/&quot;&gt;专有查询语言&lt;/a&gt;&quot;，并押注了GraphQL技术。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/postgresml/postgresml/issues/1688#issuecomment-3041057338&quot;&gt;PostgresML&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;从名字就可以看出来，该系统旨在使人们能够在他们的PostgreSQL DBMS内运行ML/AI操作。挑战在于，他们需要说服人们将现有的数据库迁移到他们提供的托管平台上。他们推出了&lt;a href=&quot;https://github.com/postgresml/pgcat&quot;&gt;pgCat&lt;/a&gt;&quot;，作为一个代理用于镜像数据库流量。其中一位联合创始人加入了Anthropic。另一位联合创始人创建了一个新的代理项目&lt;a href=&quot;https://pgdog.dev/&quot;&gt;pgDog&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/DERBY-7177&quot;&gt;Derby&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这是最早用Java编写的数据库管理系统之一，可以追溯到1997年（最初名为&quot;Java DB&quot;或&quot;JBMS&quot;）。2000年代，IBM将其捐赠给Apache基金会，并更名为Derby。2025年10月，该项目宣布这个系统将进入“只读模式”，因为没有人对它进行积极地维护了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.hydra.so/&quot;&gt;Hydra&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;尽管没有关于初创公司DuckDB-inside-Postgres的官方公告，但其联合创始人和员工都已经分散到了其他公司。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://twitter.com/MyScaleDB/status/1917163010311037327&quot;&gt;MyScaleDB&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这是Clickhouse的一个分支，借助Tantivy增加了向量搜索和全文索引。他们在2025年5月宣布关闭这项服务。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/aocsa_as-some-of-you-may-have-seen-voltron-data-activity-7395229870517022720-sGOP/&quot;&gt;Voltron Data&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;这个团队应该是数据库公司里的超级组合。想象一下，就像&lt;a href=&quot;https://youtu.be/G-S9mtYowPY&quot;&gt;Run the Jewels&lt;/a&gt;&quot;那样的团队。他们有来自Nvidia Rapids的顶级工程师、&lt;a href=&quot;https://en.wikipedia.org/wiki/Wes_McKinney&quot;&gt;Apache Arrow和Python Pandas的发明者&lt;/a&gt;&quot;，以及来自&lt;a href=&quot;https://github.com/BlazingDB/blazingsql&quot;&gt;BlazingSQL&lt;/a&gt;&quot;的秘鲁GPU奇才。然后再加上来自顶级公司的风险投资1.1亿美元，包括未来的英特尔CEO（以及&lt;a href=&quot;https://en.wikipedia.org/wiki/Lip-Bu_Tan&quot;&gt;一名CMU的董事会成员&lt;/a&gt;&quot;）。他们构建了一个GPU加速的数据库&lt;a href=&quot;https://arxiv.org/abs/2508.05029&quot;&gt;Theseus&lt;/a&gt;&quot;，但未能及时推出。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最后，尽管不是一个商业机构，但如果不提及&lt;a href=&quot;https://en.wikipedia.org/wiki/IBM_Research#Almaden_in_Silicon_Valley&quot;&gt;IBM阿尔马登研究中心&lt;/a&gt;&quot;的&lt;a href=&quot;https://www.siliconvalley.com/2025/07/10/ibm-san-jose-tech-data-ai-internet-property-real-estate-economy-web/&quot;&gt;关闭&lt;/a&gt;&quot;，那将是我的疏忽。这个研究中心是IBM在1986年建立的，几十年来一直是数据库研究的圣地。&lt;a href=&quot;https://twitter.com/andy_pavlo/status/306455280823177216&quot;&gt;我2013年曾去阿尔马登参加面试&lt;/a&gt;&quot;，发现那里的风景很美。IBM研究中心数据库小组&lt;a href=&quot;https://dl.acm.org/doi/10.1145/126482.126493&quot;&gt;已经不是过去的样子了&lt;/a&gt;&quot;。尽管如此，这个神圣的数据库研究场所的校友名单依然令人印象深刻：&lt;a href=&quot;https://en.wikipedia.org/wiki/Rakesh_Agrawal_(computer_scientist)&quot;&gt;Rakesh Agrawal&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Donald_D._Chamberlin&quot;&gt;Donald Chamberlin&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Ronald_Fagin&quot;&gt;Ronald Fagin&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Laura_M._Haas&quot;&gt;Laura Haas&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/C._Mohan&quot;&gt;Mohan&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Patricia_Selinger&quot;&gt;Pat Selinger&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Moshe_Vardi&quot;&gt;Moshe Vardi&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Jennifer_Widom&quot;&gt;Jennifer Widom&lt;/a&gt;&quot;和&lt;a href=&quot;https://scholar.google.com/citations?user=wUkamYwAAAAJ&amp;amp;hl=en&quot;&gt;Guy Lohman&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2026-01-05更新：我遗漏了Gel在2025年12月被Vercel收购的消息。[&lt;a href=&quot;https://www.geldata.com/blog/gel-joins-vercel&quot;&gt;致谢&lt;/a&gt;&quot;]&lt;/p&gt;&lt;p&gt;2026-01-05更新：我也遗漏了Supabase在2025年进行了两轮融资的消息。&lt;/p&gt;&lt;p&gt;2026-01-05更新：尽管TurboPuffer没有就融资发表官方声明，但他们的CEO提到，其团队中增加了来自Thrive Capital的成员。[&lt;a href=&quot;https://www.linkedin.com/in/julianlaneve&quot;&gt;致谢&lt;/a&gt;&quot;]&lt;/p&gt;&lt;p&gt;2026-01-05更新：显然，我需要一个更好的方法来跟踪融资信息，因为我还遗漏了LanceDB的A轮融资！[&lt;a href=&quot;https://twitter.com/brittwalker_/status/2008306941286904111&quot;&gt;致谢&lt;/a&gt;&quot;]&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Andy的观点&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;有人说，我是根据数据库开发公司筹集的资金数额来判断数据库的质量，显然不是这样。我之所以追踪这些动态，是因为数据库研究领域竞争激烈且充满活力。我不仅要与其他高校的学者“竞争”，还需要持续关注大型科技公司和小型创业公司推出的有趣的系统。行业研究实验室已经不是过去的样子了，只有微软研究院仍然在积极招聘顶尖人才，并做出令人难以置信的工作。&amp;nbsp;我曾&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2022/12/2022-databases-retrospective.html#:~:text=fate%20of%20database%20start%2Dups&quot;&gt;在2022年预测&lt;/a&gt;&quot;，2025年将有大量的数据库公司倒闭。确实，今年关闭的公司比往年多，但并没有达到我预期的规模。&amp;nbsp;Voltron的倒闭以及类似HeavyDB这样的收购兼并似乎延续了GPU加速数据库不可行的趋势。&lt;a href=&quot;https://twitter.com/KineticaHQ/status/1988983193870156171&quot;&gt;Kinetica&lt;/a&gt;&quot;多年来一直靠政府合同维持运营，而&lt;a href=&quot;https://sqream.com/&quot;&gt;Sqream&lt;/a&gt;&quot;似乎也是在勉强支撑。这些公司仍属于小众领域，至今无人能撼动CPU驱动型DBMS的主导地位。虽不便透露具体厂商的名字，但2026年必将有多家供应商发布GPU加速数据库的重要公告。这进一步印证了OLAP引擎的商品化趋势：现代系统的运行速度已经实现了飞跃，底层操作（扫描、连接）的性能差异微乎其微，系统间的差异化竞争正转向用户体验以及优化器生成的查询计划的质量。&amp;nbsp;Couchbase和SingleStore被私募股权（PE）公司收购可能预示着数据库行业未来的一个发展趋势。当然，PE收购以前也发生过，但似乎都是在最近：（1）&lt;a href=&quot;https://www.vectorcapital.com/investments/case-study/marklogic&quot;&gt;MarkLogic&lt;/a&gt;&quot;在2020年、（2）&lt;a href=&quot;https://techcrunch.com/2021/06/01/cloudera-to-go-private-as-kkr-cdr-grab-it-for-5-3b/&quot;&gt;Cloudera&lt;/a&gt;&quot;在2021年、（3）&lt;a href=&quot;https://techcrunch.com/2024/09/10/mariadb-goes-private-with-new-ceo-as-k1-closes-acquisition/&quot;&gt;MariaDB&lt;/a&gt;&quot;在2023年。我能找到的发生在2020年之前的收购只有2007年的&lt;a href=&quot;https://www.channelinsider.com/tech-companies/ibm-buys-database-software-firm/&quot;&gt;SolidDB&lt;/a&gt;&quot;和2015年的&lt;a href=&quot;https://www.aakashg.com/story-informatica-second-ipo/&quot;&gt;Informatica&lt;/a&gt;&quot;。PE收购可能会逆转那些数据库公司的发展趋势，它们在被控股公司收购后发展陷入停滞，而那些控股公司则通过榨取维护费持续获利（如Actian、Rocket）。即使是Oracle，也依然在从30年前收购的&lt;a href=&quot;https://www.oracle.com/database/technologies/related/rdb.html&quot;&gt;RDB/VMS&lt;/a&gt;&quot;上获利！&amp;nbsp;最后，向&lt;a href=&quot;https://www.linkedin.com/in/nikitashamgunov&quot;&gt;Nikita Shamgunov&lt;/a&gt;&quot;致敬。据我所知，他是唯一一位与人联合创立两家数据库公司（&lt;a href=&quot;https://hackernoon.com/founder-interviews-nikita-shamgunov-of-memsql-8a9ca8d33552&quot;&gt;SingleStore&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.madrona.com/building-a-modern-database-neon-nikita-shamgunov-serverless-postgres/&quot;&gt;Neon&lt;/a&gt;&quot;）且两家公司在同一年被收购的人。就像已故说唱歌手DMX在一年内推出两张冠军专辑（&lt;a href=&quot;https://en.wikipedia.org/wiki/It%27s_Dark_and_Hell_Is_Hot&quot;&gt;It&#39;s Dark and Hell Is Hot&lt;/a&gt;&quot;、&lt;a href=&quot;https://en.wikipedia.org/wiki/Flesh_of_My_Flesh,_Blood_of_My_Blood&quot;&gt;Flesh of My Flesh&lt;/a&gt;&quot;）那样，我认为短期内无人能打破Nikita的纪录。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;数据库元老的表现&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们来看看数据库元老拉里·埃里森的辉煌之年。这位81岁的老人在这一年间取得的成就，远超常人毕生所为。我将按时间顺序逐一梳理。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;拉里年初时位列全球富豪榜第三。想到自己身价可能不及马克·扎克伯格，他夜不能寐。有人说拉里的失眠源于饮食变化——自从&lt;a href=&quot;https://www.bbc.com/news/uk-england-oxfordshire-67221202&quot;&gt;买下英国的一家著名酒吧&lt;/a&gt;&quot;后，他馅饼吃多了。但我可以向各位保证，拉里坚持三十年的“&lt;a href=&quot;https://tech.yahoo.com/science/articles/80-old-billionaire-larry-ellison-105236014.html&quot;&gt;素食水瓶座饮食法&lt;/a&gt;&quot;”从未改变。直到2025年4月，我们得知拉里&lt;a href=&quot;https://www.msn.com/en-in/autos/photos/larry-ellison-becomes-second-richest-person-beats-zuckerberg-bezos-after-oracle-stock-soars/ar-AA1GKdbu&quot;&gt;重登全球富豪榜次席&lt;/a&gt;&quot;。他的睡眠质量稍有好转，但仍然远未达标。生活中的诸多烦忧仍在持续地折磨他——比如他终于决定出售那辆稀有的半合法&lt;a href=&quot;https://www.forbes.com/sites/maryroeloffs/2025/08/05/larry-ellisons-old-mclaren-f1-could-break-a-sales-record/&quot;&gt;迈凯伦F1超跑&lt;/a&gt;&quot;，车内手套箱里还完好地保存着原厂车主手册。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2025年7月，拉里在13年内发布了他的&lt;a href=&quot;https://twitter.com/larryellison/status/1945229587929337947&quot;&gt;第三条推文&lt;/a&gt;&quot;（拉里迷们称之为“#3”）。这条推文介绍了他在牛津大学附近创立的&lt;a href=&quot;https://eit.org/&quot;&gt;埃里森技术研究院&lt;/a&gt;&quot;（EIT）的近况。以EIT命名且与牛津大学关联，听起来像是纯研究性的非营利机构，类似于斯坦福的&lt;a href=&quot;https://en.wikipedia.org/wiki/SRI_International&quot;&gt;SRI&lt;/a&gt;&quot;或卡内基梅隆的&lt;a href=&quot;https://en.wikipedia.org/wiki/Software_Engineering_Institute&quot;&gt;SEI&lt;/a&gt;&quot;。但实际情况是，这是一家总部位于加州的有限责任公司旗下的多家营利性公司的统称。当然，不少怪咖在第3条的评论区说承诺提供&lt;a href=&quot;https://twitter.com/SFCryptoRounder/status/1946047224779030564&quot;&gt;基于区块链的低温冷冻技术&lt;/a&gt;&quot;或&lt;a href=&quot;https://twitter.com/JackSarfatti/status/1975985052204101709&quot;&gt;室温超导体&lt;/a&gt;&quot;。拉里告诉我他根本不理会这些。不过也有人像&lt;a href=&quot;https://twitter.com/aseemchandra/status/1945509650201301304&quot;&gt;这位网友&lt;/a&gt;&quot;一样真正理解其中的奥妙。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;今年（可能是本世纪）最大的数据库新闻出现在9月10日星期三美国东部时间大约下午3:00。经过几十年的等待，拉里·约瑟夫·埃里森终于&lt;a href=&quot;https://www.theguardian.com/technology/2025/sep/10/larry-ellison-dislodges-elon-musk-as-worlds-richest-person&quot;&gt;成了世界上最富有的人&lt;/a&gt;&quot;。那天早上，&lt;a href=&quot;https://finance.yahoo.com/quote/ORCL/&quot;&gt;$ORCL&lt;/a&gt;&quot;的股价上涨了40%，由于拉里仍然拥有公司40%的股份，所以他的总身价估计是&lt;a href=&quot;https://www.bbc.com/news/articles/cx2rp992y88o&quot;&gt;3930亿美元&lt;/a&gt;&quot;。从这个角度来看，这不仅使拉里成为世界上最富有的人，而且也是整个人类历史上最富有的人。约翰·D·洛克菲勒和安德鲁·卡内基（是的，CMU中的“C”）的峰值净资产，根据通货膨胀调整后，分别只有&lt;a href=&quot;https://www.buysidedigest.com/insights/the-top-10-wealthiest-historical-figures-adjusted-for-inflation/&quot;&gt;3400亿美元&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.celebritynetworth.com/richest-businessmen/richest-billionaires/andrew-carnegie-net-worth/&quot;&gt;3100亿美元&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在拉里登上世界之巅的同时，Oracle还参与了&lt;a href=&quot;https://www.npr.org/2025/12/18/nx-s1-5648844/tiktok-deal-oracle-trump&quot;&gt;收购控制TikTok的美国公司&lt;/a&gt;&quot;，拉里&lt;a href=&quot;https://variety.com/2025/tv/news/paramount-skydance-larry-ellison-irrevocable-personal-guarantee-warner-bros-discovery-1236614728/&quot;&gt;资助派拉蒙&lt;/a&gt;&quot;（由他第四次婚姻的儿子控制）&lt;a href=&quot;https://www.nytimes.com/2025/12/24/business/media/larry-david-ellison-warner-bros-discovery-cbs.html&quot;&gt;竞购华纳兄弟&lt;/a&gt;&quot;。美国总统甚至嘲笑拉里&lt;a href=&quot;https://www.theguardian.com/us-news/2025/nov/20/warner-bros-discovery-takeover-paramount-skydance-larry-ellison&quot;&gt;接管CNN新闻部门&lt;/a&gt;&quot;，因为拉里是派拉蒙的大股东。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Andy的观点&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我甚至不知道从哪里开始。当然，当我得知拉里·埃里森因数据库而成为世界上最富有的人时，我感到&lt;a href=&quot;https://twitter.com/andy_pavlo/status/1965865919223312495&quot;&gt;由衷地欣慰&lt;/a&gt;&quot;，我们的生活终于发生了一些积极的事情。我不在乎Oracle的股价，因为那些旨在构建AI数据中心而非传统软件业务的&lt;a href=&quot;https://www.investors.com/news/technology/oracle-stock-orcl-ai-analyst-targets/&quot;&gt;高调交易&lt;/a&gt;&quot;而被人为炒高了。我也不在乎他&lt;a href=&quot;https://www.bloomberg.com/news/articles/2025-11-21/oracle-slump-sends-ellison-sliding-down-ranks-of-world-s-richest&quot;&gt;两个月内个人损失1300亿美元&lt;/a&gt;&quot;导致排名下滑。这就像你我把一个月的薪水&lt;a href=&quot;https://www.reddit.com/r/gambling/comments/1j4xby2/blew_my_whole_paycheck/&quot;&gt;全砸在了FortuneCoins上&lt;/a&gt;&quot;——虽然有点心疼，还得靠从Taco Bell买来的过期辣酱拌豆子米饭撑两周，但总会好起来的。&amp;nbsp;有些人说拉里与普通民众&lt;a href=&quot;https://news.ycombinator.com/item?id=45413203&quot;&gt;脱节&lt;/a&gt;&quot;，或者说他因为参与和数据库无直接关系的事情而迷失了方向。他们列举了多个例子，比如他&lt;a href=&quot;https://techcrunch.com/2025/02/23/the-lesson-of-larry-ellisons-misadventures-in-farming/&quot;&gt;在夏威夷的机器人农场&lt;/a&gt;&quot;以每磅24美元（每公斤41欧元）的价格&lt;a href=&quot;https://beatofhawaii.com/the-most-expensive-lettuce-in-hawaii-billionaire-larry-ellisons-24-lb-experiment/&quot;&gt;出售生菜&lt;/a&gt;&quot;，又比如81岁的男人不可能&lt;a href=&quot;https://assets.sfstandard.com/image/994911177489/image_cooaesgkll0v99j57e84lobk7k/-S3840x2560-FPNG&quot;&gt;天生拥有金发&lt;/a&gt;&quot;。&amp;nbsp;事实是，拉里·埃里森已经征服了企业级数据库领域、&lt;a href=&quot;https://sg.finance.yahoo.com/news/why-oracle-founder-larry-ellison-205016907.html&quot;&gt;竞技帆船&lt;/a&gt;&quot;和&lt;a href=&quot;https://www.businessinsider.com/larry-ellison-hawaii-wellness-spa-sensei-lanai-photos-2021-2&quot;&gt;科技兄弟健康水疗中心&lt;/a&gt;&quot;。下一步显然是接管一个每天被成千上万在机场等待的人观看的有线电视频道。每次我和拉里交谈，他都清楚地表明他一点也不在乎人们对他的看法。他知道&lt;a href=&quot;https://twitter.com/HolgersenTobias/status/1945239198572712323&quot;&gt;他的粉丝爱他&lt;/a&gt;&quot;。&lt;a href=&quot;https://www.financialexpress.com/life/lifestyle-who-is-jolin-zhu-worlds-richest-man-larry-ellisons-fifth-wife-47-years-younger-than-him-3974373/&quot;&gt;他的（新）妻子爱他&lt;/a&gt;&quot;。毕竟，那才是最重要的。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;结论&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在结束本次回顾之前，我想快速地说出几个名字并提点建议。首先是PT，他在监禁期间仍在&lt;a href=&quot;https://turso.tech/blog/working-on-databases-from-prison&quot;&gt;有条不紊地参与Turso数据库的开发&lt;/a&gt;&quot;（外面见）。然后是对JT的遭遇表示遗憾，他因为经常在社交媒体上分享与&lt;a href=&quot;https://github.com/KevoDB/kevo&quot;&gt;KevoDB&lt;/a&gt;&quot;数据库开发有关的信息而&lt;a href=&quot;https://twitter.com/canoozie/status/1952305339824574576&quot;&gt;丢掉了工作&lt;/a&gt;&quot;。务必只在测试用数据库中放入假数据，&lt;a href=&quot;https://abcnews.go.com/Business/charlie-javice-founder-lied-175m-startup-faces-sentencing/story?id=126034577&quot;&gt;不要因为以1750万美元的价格出售自己的初创公司&lt;/a&gt;&quot;换得七年的监禁。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我和我的博士生们也成立了一家新的&lt;a href=&quot;https://sydht.ai/&quot;&gt;初创公司&lt;/a&gt;&quot;。希望很快就能有更多的信息带给大家。一言为定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;声明：本文为InfoQ翻译，未经许可禁止转载。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://www.cs.cmu.edu/~pavlo/blog/2026/01/2025-databases-retrospective.html&quot;&gt;https://www.cs.cmu.edu/~pavlo/blog/2026/01/2025-databases-retrospective.html&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/Zbb25ejwoK2xQSHHcTB3</link><guid isPermaLink="false">https://www.infoq.cn/article/Zbb25ejwoK2xQSHHcTB3</guid><pubDate>Tue, 10 Feb 2026 09:40:42 GMT</pubDate><author>Andy Pavlo</author><category>数据湖仓</category></item><item><title>在参与OpenAI、Google、Amazon的50个AI项目后，他们总结出了大多数AI产品失败的原因</title><description>&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;借助Coding Agent等工具，如今构建一个AI产品的技术门槛和启动成本已急剧降低。一夜之间，将想法变为可交互的原型变得前所未有的容易。但一个刺眼的矛盾也随之浮现：大多数AI产品仍在走向失败。如果技术实现不再是瓶颈，那么问题究竟出在哪里？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Aishwarya Naresh Reganti 和Kiriti Badam 曾在 OpenAI、Google、Amazon、Databricks 等公司参与构建并成功推出了 50 多个企业级 AI 产品。最近，他们在播客节目中，与主持人Lenny细致分享了当前AI产品开发中的常见陷阱与成功路径。基于该播客视频，InfoQ 进行了部分删改。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;核心观点如下：&lt;/p&gt;&lt;p&gt;今天构建的成本已经非常低了，真正昂贵的是设计，是你是否真正想清楚了产品要解决什么痛点。对问题本身和产品设计的执着，是被低估的，而单纯追求“快点做出来”，是被高估的。AI 不是答案，而是解决问题的工具。领导者需要重新回到“亲自上手”的状态，并不是要他们亲自实现系统，而是为了重建判断力，接受“我的直觉可能不再完全正确”这一事实。“忙碌但无效”的工作时代正在结束，你不可能再躲在角落里做对公司没有实质影响的事，而必须思考端到端的流程，以及如何创造更大的影响。在这个数据随时告诉你“你大概率会失败”的时代，保留一点愚蠢的勇气很重要。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;AI产品构建中的挑战&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Lenny：目前AI 产品构建的情况是怎样的？哪些进展顺利，哪些地方问题依旧明显？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：首先，怀疑态度明显减少。2024年还有很多领导者认为 AI 可能只是又一波“加密货币式”的泡沫，因此迟迟不愿真正投入。当时我看到的很多所谓“AI 用例”，更像仅仅是“在你自己的数据上套一层 Snapchat 滤镜”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而2025年，很多公司开始真正反思用户体验和业务流程，逐渐意识到：如果想构建成功的 AI 产品，必须先拆解现有流程，再重新构建。而消极的一面在于，执行依然非常混乱。这个领域只有三年左右的历史，没有成熟的方法论，也没有教材，大家基本都是边走边学。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;同时，AI 产品的生命周期与传统软件截然不同。这导致了以往在PM、工程师、数据团队之间形成的分工被打破。过去，PM、工程师各自优化各自的指标；现在，大家可能需要坐在同一间会议室里，一起看 agent 的执行轨迹，共同决定产品应该如何表现。这种协作更紧密，也更复杂。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：你之前说构建 AI 产品与构建非 AI 产品本质上非常不同，能具体谈谈吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：构建 AI 系统和传统软件系统之间确实存在大量相似之处，但也有一些根本性的差异，足以改变你构建产品的方式。其中一个经常被忽视的核心差异，是“非确定性”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与传统软件相比，你几乎是在与一个非确定性的 API 打交道。在传统软件中，决策引擎和流程往往是清晰、可预测的。以 Booking.com 为例：你有一个明确意图，比如在旧金山订两晚酒店，系统通过一系列按钮、选项和表单，把你的意图转化为具体操作，最终完成目标。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在 AI 产品中，这一层被一种高度流动的、以自然语言为主的界面所取代。用户可以用无数种方式表达同一个意图，这意味着你无法预判用户的输入行为。而在输出端，你面对的是一个概率性的、非确定性的 LLM，它对提示词极其敏感，本质上还是一个黑箱。你既无法完全预测用户会如何使用产品，也无法确定模型会给出怎样的回应。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;因此，你同时面对输入、输出和中间过程三方面的不确定性，只能在有限理解的基础上去预判行为并进行设计。到了 Agent 系统，这种复杂性会进一步放大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这也引出了第二个关键差异：代理性与控制权之间的权衡。很多人执着于构建高度自治的系统，希望 Agent 能替人完成所有工作。但每当你把决策权交给 AI，你就必然放弃一部分控制权。因此，只有当系统足够可靠、足以赢得信任时，才值得赋予它更高的自治能力。这正是“代理性—控制权权衡”的核心：自治越高，控制越少，而信任必须通过时间和表现来积累。&lt;/p&gt;&lt;p&gt;Kiriti：类比登山：如果你的目标是攀登一座高峰，你不会第一天就直接冲顶，而是先进行基础训练，逐步提升能力，最终才接近目标。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;构建 AI 产品也是如此。你不应该在第一天就打造一个拥有公司全部工具和上下文的全能 Agent，并期待它能正常工作。正确的做法，是刻意从影响范围小、人工控制强的场景开始，逐步理解当前能力边界，再慢慢增加自治性、减少人工干预。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这样做的好处在于，你会逐渐建立信心，清楚 AI 能解决问题的哪一部分，以及接下来需要引入哪些上下文和工具来改进体验。好的一面是，你不必一开始就面对复杂而炫目的 Agent 体系；挑战在于，你必须接受“循序渐进”的现实。但几乎所有成功的案例，都是从极简结构起步，再不断演化而来的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：你们一直强调“从低自治、高控制开始”，再逐步升级。能否用一个具体例子说明这种路径？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：客户支持是一个非常典型的场景。我们在发布产品时也经历过类似情况，随着新功能上线，支持请求会突然激增，而且问题类型非常多样。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一开始，并不是把所有支持中心文章一股脑塞进 Agent 就完事了。更合理的第一步，是让 AI 为人工客服提供建议，由人类判断哪些建议是有用的、哪些是无效的。通过这个反馈回路，你可以识别系统的盲点并进行修正。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当你建立起足够信心后，才可以让 AI 直接向用户展示答案。接着，再逐步增加复杂能力，例如自动退款、创建功能请求等。如果在第一天就把这些能力全部交给 Agent，系统复杂度会迅速失控。因此，我们始终建议按阶段构建，逐步提升自治水平。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：一开始是高控制、低自治，AI 只给建议，最终决策仍由人来做；当系统被验证可靠后，逐渐赋予更多自治权，同时减少人工干预。只要这一阶段进展顺利，就可以继续向前推进。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：从更宏观的角度看，AI 系统的核心在于“行为校准”。你几乎不可能在一开始就准确预测系统行为，因此关键在于避免破坏用户体验和信任。做法是，在不影响体验的前提下，逐步减少人工控制，并以不同方式约束自治边界。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以医疗保险预授权为例，某些低风险项目，比如血液检测或 MRI，只要患者信息齐全，就可以由 AI 自动审批；而高风险项目，如侵入性手术，则必须保留人工审核。在这个过程中，你还需要持续记录人类的决策行为，构建反馈飞轮，用于不断优化系统。这样既不会损害用户体验，也不会削弱信任，同时还能让系统持续进化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：你还给出过一些很好的分阶段示例，比如Coding Agent：第一阶段只做行内补全和样板代码建议；第二阶段生成测试或重构代码供人审查；第三阶段则可以自动提交 PR。营销助手也是类似路径：从文案草稿，到完整活动执行，再到自动 A/B 测试和跨渠道优化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：换个角度看，这种非确定性其实也是 AI 最迷人的地方。相比点击复杂的按钮，人类更习惯用语言交流，这大大降低了使用门槛。但问题在于，人类表达意图的方式极其多样，而你往往需要在非确定性的技术之上，达成确定性的业务结果，这正是复杂性的来源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：所以，当人们一上来就想直接跳到第三阶段，往往会陷入困境：系统既难以构建，也不可靠，最终只能被判定为失败。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：在达到高度自治之前，你需要对系统能力建立足够信心。如果一开始就从错误的切入点出发，你会面对成百上千种错误，却根本无从修复。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从小规模、低自治开始，不仅降低风险，也会迫使你认真思考“我要解决的到底是什么问题”。在 AI 快速发展的环境下，人们很容易沉迷于复杂解法，而忽视真正的问题本身。通过逐步提高自治层级，你可以清晰地拆解问题，并为未来扩展做好准备。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我最近读到一篇研究指出，约75% 的企业认为“可靠性”是他们在 AI 项目中面临的最大问题，这也是他们迟迟不敢将 AI 产品直接面向用户的重要原因。正因如此，目前很多 AI 产品更多集中在提升生产力，而不是彻底替代端到端流程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：在这期节目之前，我们还录了一期，专门深入讨论了提示注入（prompt injection）和越狱（jailbreaking）。在那期讨论里，我们意识到这对 AI 产品来说几乎是一个“生存级风险”：它可能既没有成熟解法，甚至在理论上也很难被彻底解决。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：一旦 AI 系统真正进入主流应用，这会成为一个非常严重的问题。现在大家还忙着把 AI 产品做出来，很少有人认真对待安全性，但这迟早会爆发。尤其是在面对非确定性 API 的情况下，你几乎无法完全防范。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：我们当时聊到的一个核心问题是：要诱导 AI 去做“不该做的事”，其实并不难。虽然大家都在构建各种护栏系统，但事实证明，这些护栏并不牢靠，总能被绕过。而正如你所说，当 Agent 越来越自治、甚至进入机器人系统时，这种风险会被成倍放大，确实让人感到不安。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：我同意这是一个真实存在的问题。不过从当前 AI 在企业中的采用阶段来看，大多数公司甚至还没真正走到能充分获益的程度。2025 年确实是 AI Agent 和企业尝试落地 AI 的一个高峰期，但整体渗透率依然不高，很多流程还远未被真正改造。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这种情况下，只要在关键节点引入“人在回路”（human-in-the-loop），其实可以规避相当一部分风险。我个人更偏向乐观的一侧：与其一开始就被潜在的负面场景吓退，不如先尝试去落地、去使用。我们在 OpenAI 接触过的企业中，几乎没有人会说“AI 在这里完全帮不上忙”，更多是发现它能在某些具体环节上带来优化，然后再思考如何逐步采用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：有哪些成功构建 AI 产品的模式和工作方式？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我们合作过的成功公司，通常都具备三个维度：优秀的领导者、健康的文化，以及持续推进的技术能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;首先是领导者。我们参与过不少企业的 AI 转型、培训和战略制定。很多领导者过去十到十五年积累的直觉，正是他们成功的基础，但在 AI 出现之后，这些直觉往往需要被重新学习。领导者必须愿意承认这一点，甚至需要一定程度的“脆弱感”。我曾和 Rackspace 现任 CEO Gajen 共事。他每天清晨都会预留一个固定时段，专门用来“补课 AI”——听播客、看最新资料，甚至在周末做白板推演。领导者需要重新回到“亲自上手”的状态，并不是要他们亲自实现系统，而是为了重建判断力，接受“我的直觉可能不再完全正确”这一事实。很多真正成功的团队，正是从这种自上而下的转变开始的。AI 几乎不可能靠纯粹的自下而上推动，如果领导层对技术缺乏信任，或者对能力边界有误判，整个组织都会受限。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第二个维度是文化。在传统企业中，AI 往往不是核心业务，但因为竞争对手在用、因为确实存在可行用例，企业不得不引入 AI。在这个过程中，恐慌文化非常常见，比如“FOMO”“你会被 AI 取代”等说法。问题在于，真正做出好 AI 产品，极度依赖领域专家；但很多专家却拒绝参与，因为他们担心自己的岗位被替代。这时，领导者需要建立一种“赋能型文化”，强调 AI 是用来增强个人能力、放大产出的工具，而不是威胁。只有这样，组织才会形成合力，而不是人人自危。事实上，AI 往往会创造更多机会，让员工做更多、更高价值的事情。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第三个维度才是技术本身。成功的团队通常对自身工作流有近乎执念般的理解，清楚哪些环节适合 AI，哪些地方必须有人参与。几乎不存在“一个 AI Agent 解决一切”的情况。通常是机器学习模型负责一部分，确定性代码负责另一部分。因此，关键不在于迷信技术，而在于为每个问题选择合适的工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，这些团队也非常清楚自己在和一个非确定性的 API 打交道，因此会以完全不同的节奏推进开发。他们迭代得非常快，但前提是不破坏用户体验，同时快速建立反馈飞轮。如今的竞争焦点，并不是谁最早上线 Agent，而是谁最早构建起持续改进的机制。凡是有人告诉我，“一个Agent，两三天就能在你系统里跑出显著收益”，我都会非常怀疑。这不是模型能力的问题，而是企业数据和基础设施本身就极其混乱。大量技术债、混乱的接口和命名方式，都需要时间去消化。真正能产生显著 ROI，通常至少需要四到六个月，即便你拥有最好的数据和基础设施。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：有些人认为评测（eval）是解决 AI 问题的关键，有些人则觉得它被严重高估，只要“感觉对了”就行。你们怎么看 eval？它在多大程度上真的能解决你们提到的那些问题？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：我觉得大家陷入了一种错误的二元对立：要么eval能解决一切，要么线上监控能解决一切。eval本质上，是把你对产品的理解、你的价值判断，编码进一组数据集：什么是重要的，什么是绝对不能发生的。而生产环境监控，则是在产品上线后，通过关键指标和用户行为，反馈真实使用情况。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种监控并不新鲜，但在 AI Agent 场景下，颗粒度变得更细了。除了显式反馈，比如点赞、点踩，还有大量隐式信号。例如用户不点踩，但反复要求重新生成回答，这本身就是强烈的负面反馈。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;真正的问题不在于“选哪个”，而在于你想解决什么。如果你的目标是构建一个可靠系统，那么上线前必须有底线测试，这可以是一小组关键问题，确保无论如何都不能出错。上线之后，你不可能人工检查所有交互轨迹，这时就需要监控来提示你哪里出了问题。当你发现新的失败模式，再反过来构建新的eval集。这个循环缺一不可。认为“只靠其中一种就够了”，在我看来是站不住脚的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我想稍微退一步，谈谈为什么“eval”这个词在 2025 年下半年被赋予了如此沉重的含义。你去找数据标注公司，他们说专家在写 eval；有人说 PM 应该写 eval，它们就是新的 PRD；还有人说 eval 本身就是产品改进所需的完整反馈回路。对初学者来说，这非常混乱。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;事实上，大家说的都不完全错，但指向的是不同层面的事情。律师和医生写的“评估”，并不等于他们在构建 LLM judge；PM 写 eval，也不意味着要写一个可直接上线的评判模型。很多时候，你事前根本无法判断是否需要 LLM judge，还是只依赖生产环境的用户信号。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Martin Fowler 曾提出过“语义扩散”这个概念：一个词被发明出来，随后被不断滥用，最终失去精确定义。我认为 eval 正处在这个阶段。不同人看到的是它的不同侧面。但如果你让一群实践者坐在一起问：“AI 产品是否需要一个可执行的反馈回路？”他们一定都会点头。至于怎么做，完全取决于具体场景。复杂用例下，盲目构建评判模型往往得不偿失，这时回到用户信号、快速修复、确认是否回退，反而更有效。最终，所有资深从业者都会告诉你一句话：一切取决于上下文，不要迷信固定方法论。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：现在“eval”已经变成一个可以指代无数不同东西的词，既包括标注、基准测试，也包括反馈机制，讨论起来反而更混乱了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我最近就遇到一个客户，说他们“在做 eval”。我问能不能看看数据集，他们说只是看了 LLM Arena 和一些第三方榜单，就选了模型。我只能说，那不是 eval，那只是模型对比。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：Claude Code 的负责人 Boris 曾公开表示：“我们在Claude Code 里不做 eval，一切靠感觉（vibes）。”能不能请你分享一下，Codex 以及 Codex 团队在eval这件事上的具体做法？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：在 Codex，我们采取的是一种相对平衡的方式：eval是必要的，但同时必须高度重视用户反馈。我们在产品上极度强调“把正确的产品做出来”，而其中非常重要的一部分，就是认真倾听用户的声音。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Coding Agent 和其他领域的 Agent 有一个本质差异：它们是为“可定制性”和“工程师”而生的。Coding Agent 并不是只解决五六个固定工作流的产品，而是需要以多种方式被定制和扩展。这意味着，产品会被嵌入到各种不同的集成环境、工具链和使用场景中。在这种前提下，几乎不可能为用户的所有交互方式提前构建一个完备的eval数据集。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但与此同时，你仍然需要确保，每一次改动至少不会破坏产品中那些最核心的能力。因此，我们确实会用eval来守住这些“底线”。同时，我们也投入大量精力去理解用户真实的使用方式。举个例子，我们最近推出了一个代码审查产品，增长非常快，既帮 OpenAI 内部发现了大量问题，也被外部客户广泛使用。如果我对代码审查相关的模型、或训练时采用的强化学习机制做了调整，在上线之前，我一定会通过 A/B 测试来验证：它是否还能准确找出关键问题，用户对结果的反应如何。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有时，用户一旦被错误的代码提示反复打扰，甚至会直接关闭这个功能。你需要确保，新版本确实在“做对的事情”。但老实说，很多这类场景在事前是很难预判的，也很难提前为它们构建对应的eval数据集。因此，这里面既有一定的“vibes判断”，也有大量来自真实用户的反馈。我们会非常主动地关注社交媒体，看看是否有人遇到特定问题，并尽快修复。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我并不认为有一套万无一失的eval指标，可以完全依赖它，其他什么都不用管。每当我们要发布一个新模型，团队都会聚在一起做集中测试，每个人关注不同的重点。我们手里有一份“高难度问题清单”，会把这些问题交给新模型，观察它的表现。这更像是每位工程师都有一套针对自身关注点的定制eval，用来帮助大家理解：在这个新模型下，产品到底发生了什么变化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;CC/CD框架&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Aishwarya：我们接触过大量公司，它们都承受着来自竞争对手的压力，因为“所有人都在做 Agent”，于是觉得自己也必须构建一个完全自治的 Agent。但很快发现一个问题：在一开始，你根本无法预知用户会如何与系统交互，也无法预判 AI 会给出哪些响应或采取哪些行动。当你的工作流包含四五个步骤、需要连续做出大量决策时，问题一旦出现，就会变得极其难以修复，结果往往是无休止的调试和热修复。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们曾为一个客服场景构建系统，后来，因为热修复多到失控，新的问题层出不穷，这个产品不得不被下线。与此同时，行业里也发生了不少令人警惕的事件，比如前段时间 Air Canada 的一个 Agent“臆造”了一条并不存在的退款政策，而公司因为法律原因不得不接受这个结果。这类案例让人意识到：如果设计不当，AI 系统可能会对企业本身造成非常严重的风险。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;正是在这样的背景下，我们开始思考：如何在不失去用户信任的前提下构建系统，同时又能形成一个持续改进的飞轮？这就是“CC/CD（Continuous Calibration, Continuous Development 持续校准、持续开发）”框架的出发点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/22/2284048821d07ccc10b93c93272d0e9e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;循环的一侧是“持续开发”。你先界定能力边界，整理数据，明确系统的预期输入和预期输出。在真正动手之前，这一步本身就非常有价值，因为它常常会暴露出团队内部对“产品该如何表现”的理解并不一致。此时，产品经理和领域专家的参与尤为关键。你并不需要一个覆盖所有情况的数据集，而是一个“足够好”的起点。接下来，搭建应用，并设计评估维度。我刻意使用“评估指标”这个说法，而不是简单地说 eval，是因为评估是一种过程，而指标只是你在过程中重点关注的维度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一侧是“持续校准”。当系统上线后，你一定会看到大量最初未曾预料到的用户行为模式。评估指标可以帮助你发现一部分问题，但很快你会意识到，它们同样不足以覆盖所有新出现的错误模式。这时，你需要分析真实行为，识别新的错误类型，一部分问题可以直接修复，而另一部分则需要催生新的评估指标。这并不意味着每一个错误都要转化为新的eval维度。有些只是偶发问题，比如工具定义不清导致的调用错误，修完即可继续前进。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;整体来看，这就是一个 AI 产品的典型生命周期。我们还特别强调，在迭代初期，应当采用“低自治、高控制”的方式：限制系统可做的决策数量，引入人在回路；随着理解加深，再逐步提高自治程度。这样做的本质，是在逐步建立对系统行为的认知飞轮。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/05/0552db707dbf2e73328871c90f690d19.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以客服 Agent 为例，我们通常会把演进过程拆成三个阶段。第一阶段只是“路由”，即判断工单该被分配到哪个部门。很多人会低估这个问题的复杂度，但在大型企业里，路由往往异常困难。层级混乱、分类标准失序的情况非常普遍，人类客服往往依赖大量隐性经验才能做出判断，而这些规则通常并未被文档化。如果直接把问题丢给 Agent，而不给足上下文，风险就会非常高。在路由阶段，即便 Agent 分错了部门，人类也可以介入纠正，控制风险。同时，这个阶段往往会暴露出大量数据问题，需要优先修复。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;等路由稳定之后，下一步是“副驾驶”：Agent 根据既有的标准操作流程生成回复草稿，由人工修改和确认。在这个过程中，你会自动记录人类的修改行为，从而几乎“免费”获得误差分析数据，并将其反馈到系统中。当你发现，大多数情况下人工已经不需要做太多修改时，才可以进入端到端的自动处理阶段，让 Agent 既生成回复，也完成问题的解决。这正是从低自治逐步走向高自治的过程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/07/0730a295de7b387816e5139414b6967c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们还整理了一张表，明确每个阶段你在做什么、能学到什么，以及这些信息如何被反馈回系统。需要强调的是，采用 CC/CD 并不意味着问题会一次性被解决。即便已经走到较高版本，你仍然可能遇到此前从未见过的数据分布。这个框架的意义，在于帮助你在完全自治之前，尽可能多地理解用户行为，从而降低整体风险。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，它还隐含地帮你建立了一套行为日志体系。单纯依赖评估指标，只能捕捉你“已经知道”的错误，而大量新模式，只有在真实使用中才会显现出来。通过这种低风险、渐进式的方式，你可以理解用户，而不至于在问题全面爆发时手忙脚乱。最终，这一切的核心目标只有一个：在持续校准系统行为的同时，不断维护并增强用户对产品的信任。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：这套方法的核心，在于把一切都设计成持续的、可迭代的过程，沿着“自治程度不断提高、控制逐步降低”的路径前进。“持续校准、持续开发”这个命名，本身就强调了它的迭代性。顺便说明一下，这个名字显然是在向 CI/CD（持续集成、持续部署）致敬，只不过这是 AI 时代的对应版本：不再只是不断跑单元测试、频繁部署，而是持续运行eval、观察结果、调整关注的指标，找出系统失效的地方，再不断迭代优化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这个框架本身上，还有没有什么你觉得特别重要、但我们还没提到的点？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我们最常被问到的问题之一是：我该如何判断，系统是否已经“校准得足够好”，可以进入下一个阶段？这件事并没有一套明确的规则手册，核心原则只有一个：尽量减少“意外”。比如说，如果你每一两天就做一次校准，而发现没有出现新的数据分布模式，用户的行为也相当稳定，那你从系统中获得的新信息就已经非常有限了。这往往就是一个信号，说明你可以考虑进入下一阶段了。到了这个时候，很大程度上其实是在凭经验判断：你是否感觉自己已经“准备好了”，是否还在持续获得新的洞察。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，也要意识到，有些外部事件会彻底打乱原有的校准状态。比如 GPT-4.0 被弃用，API 层面逐步迁移到 GPT-5，而新模型的行为特性完全不同，这时你的校准就会再次失效，需要重新走一遍流程。用户行为本身也会随时间演化。即便是消费级产品，我们今天和 ChatGPT 的交互方式，也和两年前完全不同，一方面是模型能力提升了，另一方面是用户在某个任务上尝到甜头后，会自然地把系统用于更多新场景。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们曾为银行的核保人员构建过一个系统。核保本身是一项非常繁琐的工作，贷款申请文件往往有三四十页。这个系统的初衷，是帮助核保人员快速查找政策和内部信息，从而更高效地审批贷款。最初三四个月，反馈都非常积极，核保人员的效率显著提升。但随后我们发现，正是因为他们对系统产生了信任，开始提出一些我们从未预料到的深度问题，比如直接把整份申请材料丢给系统，问：“像这种情况，之前的核保人员通常是怎么处理的？”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从用户角度看，这只是一个非常自然的延伸；但从产品构建角度看，底层逻辑却发生了质变。系统需要理解“类似情况”究竟指什么，再去检索历史案例、分析文档，最后给出综合判断。这已经远远超出了最初“查找某条政策”的设计范围。正是这种不断演化的用户行为，提醒你：是时候回到校准阶段，重新审视系统能力边界了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;AI 的未来&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Lenny：当下 AI 领域里，哪些东西被高估了？哪些被低估了？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：与其说“被高估”，不如说有些概念被严重误解。一个典型例子是多 Agent 系统。很多人会觉得：我有一个复杂问题，只要拆成几个子任务，分别交给不同的 Agent，再把它们连起来，就能实现所谓的“Agent 乌托邦”。现实并非如此。当然，成功的多 Agent 系统确实存在，但关键在于，你如何限制系统偏离轨道的方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，用一个监督型 Agent 来协调多个子 Agent，是一种非常成熟、有效的模式；但如果只是按功能拆分职责，期望这些 Agent 通过某种“点对点协作”自然形成整体能力，那在当前的模型能力和工程范式下，往往行不通。这并不是多 Agent 被高估，而是人们高估了它在现阶段能“自发协同”的程度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我觉得Coding Agent 仍然被低估了。你在 Twitter 或 Reddit 上会看到大量讨论，但你会发现它的真实渗透率依然很低，而潜在价值却极大。我认为2026 年会是集中优化这些流程、释放巨大生产力的一段时间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：相比预先设计一堆各司其职的 Agent，更现实的路径，可能是让一个更强的 Agent 自己完成任务拆解和协调？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：没错。你可以由人来编排多个 Agent，也可以由一个更大的 Agent 负责统筹。但如果让多个 Agent 以点对点的方式自由通信，尤其是在客服这类对输出高度敏感的场景中，几乎不可能精细地控制“到底是哪个 Agent 在对用户说话”，护栏成本会急剧上升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我认为eval是被误解的概念。它当然重要，但“不断切换工具、学习新工具”这件事被高估了。我依然是比较传统的看法：真正值得投入精力的，是对你要解决的业务问题保持极度专注，AI 只是工具而已。你当然需要了解最新进展，但不要把“快速构建”本身当成目标。今天构建的成本已经非常低了，真正昂贵的是设计，是你是否真正想清楚了产品要解决什么痛点。对问题本身和产品设计的执着，是被低估的，而单纯追求“快点做出来”，是被高估的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：从产品视角看，你们觉得未来一年 AI 会走向哪里？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：我非常看好“后台型”或“主动型” Agent。当前 AI 难以持续创造价值，很大程度上是因为它缺乏上下文，而原因在于它还没有真正接入工作发生的地方。一旦 Agent 被更深地嵌入真实工作流，获得更丰富的上下文，它就能理解你在优化什么指标、试图完成哪些活动。接下来顺理成章的一步，就是由 Agent 主动反过来提示你。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们已经在 ChatGPT Pulse 这样的功能中看到雏形，它每天推送一些你可能关心的更新，帮助你“唤醒思路”。把这一模式扩展到更复杂的任务中，比如Coding Agent 在你一天开始时告诉你：“我已经帮你修复了五个工单，这是补丁，看看就行。”我认为这会在 2026 年成为非常重要的产品方向。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我非常期待 2026 年的多模态体验。2025 年我们已经取得了不小进展，不只是生成能力，在理解层面也是如此。但到目前为止，LLM 仍然是最常用的模型形态，而人类本身是高度多模态的。语言其实是我们进化中相对靠后的表达方式。即便我们在对话中，也在不断接收视觉、表情、语气等信号，并据此调整表达。如果能构建真正丰富的多模态交互，将会更接近人类对话的真实复杂度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，还有大量“枯燥但重要”的任务等待被自动化。如今依然有无数手写文档、杂乱的 PDF，即便是最先进的模型也难以处理。一旦多模态理解能力真正成熟，我们就能解锁大量此前无法触及的数据资源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：如果有人想提升自己构建 AI 产品的能力，你认为最值得重点培养的一两项技能是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：从小处着手、快速迭代、建立正向飞轮等。但如果站在更高的视角来看，对于当下的产品构建者而言，实施成本在未来几年会变得极低，真正稀缺的将是设计能力、判断力和审美品位。无论是做产品还是规划职业路径，早期几年往往专注于执行层面的技术细节，而随着 AI 大幅降低上手门槛，几年之后，每个人的价值都会更多体现在品味、判断，以及那些“只属于你”的东西上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种能力并不一定来自年龄或多年经验。我们最近招了一位同事，团队一直在用一款价格不菲的任务管理工具，他却直接带着自己手写的应用来开会，当场把我们全部拉进去开始用。那种主动性和主人翁意识，敢于重新思考既有体验，正是最能拉开差距的地方。当然，这类自建工具在规模化后可能有维护成本，需要替换或升级，但在小团队阶段，这种“先做出来再说”的态度让我非常震惊。很多在 AI 时代成长起来的人，对“构建”的心理成本极低，也更愿意尝试新工具。这或许也是为什么很多 AI 产品存在留存问题，大家都太容易被新工具吸引了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;归根结底，真正重要的是主动性和责任感。“忙碌但无效”的工作时代正在结束，你不可能再躲在角落里做对公司没有实质影响的事，而必须思考端到端的流程，以及如何创造更大的影响。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：这让我想到我之前请过 Jason Lemkin 上节目。他把整个销售团队几乎都替换成了 Agent：原来 10 个销售，现在是2个人加 20 个 Agent。结果有位销售直接辞职了，因为他发现自己“什么都没干”，很快就会被系统识别出来。这也印证了你的观点——混日子会越来越难。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：坚持和承受“痛苦”的能力同样被严重低估。如今信息触手可及，几乎任何人都可以在极短时间内学习新东西，但真正的差别在于，是否愿意经历反复试错的过程——学习、实现、失败、再调整，真正理解什么有效、什么无效。我常说“痛苦是新的护城河”，这种在实践中积累的经验，无论对个人还是公司，都会沉淀为难以复制的优势。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;很多成功的公司，并不是因为抢先进入市场，或拥有多么炫目的功能，而是因为他们经历了足够多的痛苦，搞清楚哪些是不可妥协的核心点，并在模型能力、功能取舍之间不断权衡。这没有标准答案，也没有教科书，只能靠一轮又一轮的迭代。正是这些过程中的“痛苦”，最终塑造了个人能力和公司的长期竞争力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：专注于问题本身。AI 只是工具，关键在于你是否真正理解自己的工作流。很多所谓的 AI 工程师和 AIPM，把大部分时间花在理解业务流程、用户行为和数据上，而不是追逐最炫的模型。真正的差异化，永远来自对用户和问题的深度理解。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;闪电问答&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Lenny：你们最常推荐的书是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：《当呼吸化为空气》。作者 Paul Kalanithi 是一位神经外科医生，在三十出头被诊断出肺癌。这本书让我意识到，我们是否花太多时间“评估人生”，却忘了真正去生活。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：我更偏爱科幻，《三体》三部曲。它不仅讨论外星文明，也深入探讨科学、地缘政治与人类决策，对理解技术与文明的关系非常有启发。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：如果喜欢科幻和 AI，我还强烈推荐《深渊上的火》（A Fire Upon the Deep）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：最近最喜欢的影视作品？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：我在重刷《硅谷》，它出奇地不过时，如今的 AI 浪潮和当年的情景高度相似。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：我选一个游戏，《Expedition 33》。制作精良，故事、音乐和玩法都非常出色。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：最近发现并非常喜欢的一款产品？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：Whisper Flow。我没想到自己会这么依赖它，它能把语音自然地转化为指令，体验非常顺滑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：我偏好效率工具，比如 Raycast 和 caffeinate，让我在本地跑长时间任务时效率更高。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：你的人生信条？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：“人们说这件事做不到，但那个傻子不知道，于是他做成了。”在这个数据随时告诉你“你大概率会失败”的时代，保留一点愚蠢的勇气很重要。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：乔布斯那句话：你只能回头看时，才能把点连成线。所以不断前进、持续尝试就好。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lenny：你最欣赏对方的一点是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aishwarya：Kiriti 非常冷静、踏实，是我最重要的“回声板”，而且他是我见过最好的丈夫。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kiriti：Aishwarya 最大的特点是，她能把复杂问题讲得极其清楚，并且始终保持耐心和坚持，这在快速变化的 AI 时代非常珍贵。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：https://www.youtube.com/watch?v=z7T1pCxgvlA&lt;/p&gt;</description><link>https://www.infoq.cn/article/Ox3JQRBv6RX0pAggifej</link><guid isPermaLink="false">https://www.infoq.cn/article/Ox3JQRBv6RX0pAggifej</guid><pubDate>Tue, 10 Feb 2026 09:29:23 GMT</pubDate><author>傅宇琪,Tina</author><category>生成式 AI</category></item><item><title>不写、不看、不审查：这家安全公司决定不再让人类碰代码，还把这套模式开源了</title><description>&lt;p&gt;没人写代码，也没人看代码，软件照样交付？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2026 年 2 月，一家专注于基础设施安全的公司StrongDM 公开了一套“软件黑灯工厂”式的生产线成果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这个生产线里，人类不再直接写代码、也不承担代码审查；开发从交互式协作变成“把 spec 和场景喂给系统”。随后由 Agent 自动生成代码、运行测试/评测 harness，并在反馈回路里反复迭代，直到结果收敛、可以交付为止。团队把这套玩法写进章程，最重要的只有一句话——No hand-coded software。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/fe/fee3962709fe3b5932f0209d97707ae2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;StrongDM AI 还不寻常的开源了它们：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其中一个仓库是：&lt;a href=&quot;https://github.com/strongdm/attractor&quot;&gt;https://github.com/strongdm/attractor&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这是他们“软件工厂”体系中最核心的非交互式编码 Agent。不过，这个仓库本身一行代码都没有：里面只有三份 Markdown 文件，极其细致地描述了软件的完整规格说明（spec），以及 README 里的一句提示——把这些规格说明交给你选择的编码 Agent 去执行即可。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2f/2f8ccdf71ec3c0db322408c05a163708.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一个仓库 &lt;a href=&quot;https://github.com/strongdm/cxdb&quot;&gt;https://github.com/strongdm/cxdb&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这个则更接近传统意义上的软件发布：包含 1.6 万行 Rust、9500 行 Go，以及 6700 行 TypeScript。这是他们的 “AI Context Store”——一个用于存储对话历史和工具输出的系统，数据以不可变 DAG的形式组织。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d2/d2d913a49631d2de71136c119dfd514c.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 Hacker News 的讨论中，很快就有开发者按图索骥，实际跑了一遍这套流程。他表示，自己仔细阅读了 Attractor 仓库中的文档，并严格按照 StrongDM 提供的规范，让 Claude 基于 spec 构建了一个完整应用。最终生成的是一个可以直接使用 Claude API Key 的 AI 代理，其整体质量“明显好于让模型自由发挥时生成的结果”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;让他印象最深的，是这套规格说明的体量和细节程度：整套 spec 大约 6000–7000 行，覆盖了行为约束、接口语义以及系统边界。“我以前给代理布置项目时，规格说明最多也就一页纸，这次的细节密度让我非常震惊。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，这次开源并不是一个“打磨完毕”的展示版本。代码一经放出，Hacker News 上就有开发者迅速上手检查，指出其中存在疑似 bug、Rust 反模式，以及相对宽松的错误处理方式。对此，StrongDM AI 团队成员 Jay Taylor 在评论区回应称，这批项目“是最近几天才决定开源的”，尚未经过充分的技术优化，目前已经安排代理继续对 CXDB 进行清理和改进。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这套实践也很快得到了学界的点名。沃顿商学院研究 AI 与组织变革的教授 Ethan Mollick 在转发 StrongDM 的公开内容时直言，这是一次“真正激进的软件开发方式”：“几乎没有任何人类介入。即便这种方式未必适用于大多数场景，我们也需要更多这样的跳级式设想，去重新设计流程，而不是只把 AI 塞进旧流程里。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在他看来，真正有价值的进步，不是在原有流程上“多加一点 AI”，而是围绕 AI，把流程本身重做一遍。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/09/091c2451aa65664cc78b09ec9d4f4b25.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;一条“禁止手写代码”的内部实验线&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;StrongDM 是一家专注于基础设施访问与身份安全的公司，核心工作是管理人类与非人类身份如何安全地连接到数据库、云资源和各类内部系统。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而他们的 AI 团队成立于半年前， 2025 年 7 月 14 日这天，Jay Taylor、Navan Chauhan 与 StrongDM 的联合创始人兼首席技术官 Justin McCarthy 一起，正式把一条原本分散在内部的探索工作，独立成一个专门的团队。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;新团队成立后，第一天的工作并不是写代码，而是写一份章程。Justin McCarthy 在回顾中提到，在团队成立的第一个小时，他们就先明确了一组接下来必须遵守的约束条件。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;代码不得由人类编写。&amp;nbsp;代码不得由人类审查。&amp;nbsp;如果你今天在每位人类工程师身上花费的 token 成本还不到 1000 美元，那么你的软件工厂还有很大的改进空间。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 StrongDM 自己的回顾里，这个决定并不是一时冲动。其背景要追溯到 2024 年末。随着 Claude 3.5 在 2024 年 10 月的第二次修订发布，团队开始观察到一个此前并不常见的变化：在长时序的 Agentic 编程任务中，结果开始叠加正确性，而不再只是不断叠加错误。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/4c/4c45b808c5fdf4fe9c4b913d11672012.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;到了 2024 年 12 月，这一变化已经可以通过 Cursor 的 YOLO 模式清晰地观察到。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;StrongDM 在博客中写道，在此之前，将 LLM 反复用于编码任务，往往会累积误解、幻觉、语法错误、依赖不兼容等问题，最终让系统“慢慢坏掉”；而结合 YOLO 模式，Anthropic 的更新模型第一次展现出他们后来在内部称之为“非交互式开发”或“成长型软件”的雏形。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这样的背景下，新成立的团队从一开始就确立了一条极端的实验前提：不允许任何手写代码。在 2025 年 7 月，这听起来依然相当激进。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其中最耐人寻味的，是第二条规则：代码不得由人类审查。毕竟大家都很清楚，大语言模型极其容易犯下一些“非人类式”的错误；在这样的前提下，彻底放弃人工 code review，本身就显得反直觉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更何况，安全软件向来是最不愿意交给“未经人工审查的 LLM 代码”去支撑的一类系统。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f1/f1885ab657677fe963c449b8a18a4fb1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c5/c5a0f3c6b891d8a37b96f4f3fdc04912.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;规则落地后，问题也随之出现：如果什么都不手写，怎么确保代码真的能跑？让 Agent 自己写测试，只在一个前提下有用——它们不会“作弊”，比如直接写个 assert true。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这也迅速被他们提炼成一个更根本的问题：当实现和测试都由编码 Agent 生成时，你要如何证明自己交付的软件是可工作的？StrongDM 的答案，受到了场景测试（Scenario Testing，Cem Kaner，2003） 的启发。他们是这样描述的：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我们重新定义了“场景（scenario）”这个词，用它来表示一个端到端的“用户故事”。这些场景通常存放在代码库之外（类似模型训练中的“留出集”），既能被 LLM 直观理解，又可以灵活地进行验证。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;由于他们构建的软件本身往往就包含 Agentic 组件，StrongDM 也随之放弃了“测试全绿”这种布尔式成功定义，转而采用一种更接近真实体验的度量方式。他们引入了“满意度（satisfaction）”这个概念，用来量化验证结果：在所有场景中观察到的执行轨迹里，有多大比例可能令用户满意？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他们把这些场景当作“隔离集”，不存放在编码 Agent 能直接访问的地方，用来评估系统整体行为。这个设计本身就很有意思，它在某种程度上，模拟的是传统软件工程中一种极其昂贵、但也极其有效的做法——由外部 QA 团队执行的强力端到端测试。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/4e/4e2d1f6e9f6239dc134582410a94458e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;合成场景策划与塑造界面&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从软件工厂的整体原则来看，StrongDM 把这一切总结为一条清晰的流程：“种子 → 验证 → 反馈回路”。系统先接收一个最小起点——几句话、截图，或一个已有代码库；然后在尽量贴近真实世界的验证环境中跑场景，把输出持续反馈回输入，让系统在闭环中自我纠错、不断叠加正确性；循环会一直运行，直到所有被隔离出来的场景不仅通过，而且能持续通过。token 被他们形容为这条生产线的燃料。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ae/aede7b62703e13c62059031154c1764a.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;将“验收”交给spec？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 StrongDM 的软件工厂里，spec 并不是用来给人看的设计说明书，而是整个系统能够启动、纠偏和收敛的核心输入。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在传统开发流程中，spec 更多是一种“对齐工具”：它帮助工程师理解要做什么，但真正的实现细节、权衡和妥协，往往发生在代码和 code review 过程中。而在 StrongDM 的设定下，当“人不写代码、人不看代码”成为前提，spec 的角色被彻底前移——它不再是参考材料，而是事实上的控制面。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/cf/cf7d01c432b4545432ba654b2fcc4359.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;团队要求系统能够“从层层递进的自然语言规范中生长”，并且必须能够在“不对源代码做语义层面检查的情况下完成验证”。在这种设定下，“验收”本身也被重写了。spec 与场景（scenario）一起，构成一个不断运行的评测基准：模型生成的行为是否符合规范，不是靠人去读代码判断，而是靠它在这些场景中跑出来的结果是否持续满足预期。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b9/b961ee2d9ee54596576cd5439a8605b2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c0/c05e4f6c0283d41ce5709fdf101921f1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;换句话说，StrongDM 的方法把覆盖率从“人为写了多少测试”这一维度转向了“规范/场景是否足够多与足够准确”＋“验证生态能否在闭环中捕获异常”这一维度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;基于这一理念，StrongDM 还进一步提出了他们的另一个关键概念：数字孪生宇宙（Digital Twin Universe, DTU）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;StrongDM 的定义是：数字孪生宇宙是一组对第三方服务的行为级克隆体。他们构建了 Okta、Jira、Slack、Google Docs、Google Drive 和 Google Sheets 的孪生系统，复刻这些服务的 API、边界情况以及可观察到的行为。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f5/f51bd6e432680850d6f917f402f95b11.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有了 DTU，他们就能在远超生产环境限制的规模和速率下做验证：既能测试那些在真实服务上危险、甚至根本不可能尝试的失败模式，也能每小时运行成千上万个场景，而不必担心触及限流、触发滥用检测，或累积 API 成本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;那这些 Okta、Jira、Slack 的关键行为是怎么“克隆”出来的？答案是：用编码 Agent。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/fe/fe9ae51ebc9a21883424a7b6bd996cb3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2d/2d9f53ccf591c7f26906500837b51178.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有人将这套做法概括为一条可复用流水线：把某个服务的完整公开 API 文档直接喂进 Agent harness，让它生成一个自包含的 Go 二进制程序去模拟这些 API；然后在此基础上再快速搭一个简化 UI，方便把整套仿真跑通、跑顺。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;随后，DTU 的创建者 Jay Taylor 在 Hacker News 上补充了一些背景，分享了一条关键的提示策略：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我最初有一个关键洞察，最终形成了一套可重复的方法，用来确保 DTU 与官方 SaaS 服务之间具有高度一致性：以最流行、公开可用的官方 SDK 客户端库作为兼容性目标，始终追求 100% 兼容。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当这些不受限流和配额约束的服务克隆体跑起来后，一整支“模拟测试 Agent”队伍也就能彻底放开手脚。场景测试不再是一锤子买卖的验收环节，而是变成了 Agent 会反复、持续执行的脚本：系统一边搭建，一边就被不停拉出来跑场景、做验证。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他们的 Slack 孪生系统截图也直观展示了这种测试方式：一批模拟的 Okta 用户不断出现，并分别去申请访问不同的模拟系统。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/99/99a80be3da43e93b3de71da0c0bae7ec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;问题依然是：太烧钱了？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在惊艳之外，这次实验也迅速暴露出一个无法回避的现实问题：成本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 Hacker News 的实操反馈中，有开发者提到，按照 StrongDM 提供的 spec，让 Claude 构建完整应用时，TypeScript 路线的 token 消耗极高，不得不中途给账户充值，才能在一个晚上把流程跑完。他甚至计划改用 Rust 或 Go 再试一次，只是为了看看是否能把成本压下来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这个反馈并非个例，也不是枝节问题。StrongDM 团队在内部曾提出过一个颇具冲击力的衡量标准：如果你今天在每位人类工程师身上花费的 token 成本还不到 1000 美元，那么你的软件工厂还有很大的改进空间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这句话一旦落到现实，就更像是一个商业模式的探讨：你能否打造出一条足够盈利的产品线，从而负担得起以这种方式开发软件所带来的巨大成本？当任何竞争对手只需几个小时的编码代理工作就能克隆你的最新功能时，构建可持续的软件业务也变得截然不同。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另外，正如StrongDM 团队在回顾中所说，其实这一切技术上是可行的，只是以前从经济上来说不划算：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;“构建一个高保真 SaaS 应用的克隆在技术上一直可行，但在经济上从未现实过。几代工程师都可能想过，做一个完整、内存级的 CRM 副本来测试，但最终往往会在心里把这个提案按下去——‘算了，太不划算了’。”&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;即使对于那些不打算在 token 成本上一次性投入数千美元的团队和个人来说，StrongDM 这种做法依然有很多值得思考的地方，尤其是在人力成本和个人投入回报这一层面。对程序员个人而言，真正的问题或许不只是“现在贵不贵”，而是：当算力成本持续下降几乎成为共识时，你是否已经开始为新的角色和分工做技能投资——还是仍然把全部价值押在“写代码本身”上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/8f/8fce4cffe9d50c36e0be66a3ca390d93.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;这是个很有意思的观点，不过我想从另一个角度补充一下：如果按每个月 20 个工作日来算，那就是 2 万 × 12 = 24 万美元一年，差不多等于一个 FANG 新毕业生的总包（TC）。我和不少初级到中初级的软件工程师（SDE）共事过，说实话，其中 80% 的表现并不比 Claude 好。（我也见过一些 staff 级别的工程师写出的代码比 AI 还差，但他们通常会用领域知识和技术负责人职责把短板补回来。）&amp;nbsp;我确实看到，AI 正在把软件工程进一步推向一种金字塔结构：顶层只有极少数人类，其余大量工作由 AI 承担。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/eb/ebb0e1bcfd911fc3198571f2b16bfbb1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;虽然从按现在的成本算，AI“还没便宜到值得完全替代人”，但有网友认为成本下降也许能够预期：“我在想，这会不会只是软件工厂还处在非常早期、效率极低阶段的副产品。Yegge 和 Huntley 都承认，他们在做的自治工厂实验既昂贵又浪费。从制造业的历史经验来看，我反而会预期：随着方法逐渐成熟、流程被不断优化，成本会慢慢降下来。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而在博客中的最后，他们给出的结论，也为这条实验线画上了一个颇具警示意义的注脚：“我们这些构建软件工厂的人，必须刻意保持一种天真：主动识别并移除软件 1.0 时代留下的习惯、惯例和限制。数字孪生宇宙（DTU）就是最好的证明——六个月前还不可想象的事情，如今已经成了日常。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://factory.strongdm.ai/&quot;&gt;https://factory.strongdm.ai/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://simonwillison.net/2026/Feb/7/software-factory/&quot;&gt;https://simonwillison.net/2026/Feb/7/software-factory/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=46924426#46931812&quot;&gt;https://news.ycombinator.com/item?id=46924426#46931812&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/iwKHqENNONoXQDEsvobG</link><guid isPermaLink="false">https://www.infoq.cn/article/iwKHqENNONoXQDEsvobG</guid><pubDate>Tue, 10 Feb 2026 09:22:34 GMT</pubDate><author>Tina</author><category>生成式 AI</category></item><item><title>Daggr 发布：用于构建与检查 AI 工作流的开源 Python 库</title><description>&lt;p&gt;Gradio 团队发布了 &lt;a href=&quot;https://huggingface.co/blog/daggr&quot;&gt;Daggr&lt;/a&gt;&quot;，这是一个新的开源 Python 库，意在简化多步骤 AI 工作流的构建与调试。Daggr 允许开发者以 Python 代码的方式定义工作流，同时会自动生成一个可视化画布，展示流水线中每个步骤的中间状态、输入和输出。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Daggr 通过将工作流组织为有向图的形式，简化了应用型 AI 的开发过程，使每一个节点都可以被单独检查和重新执行。这种方式有效缓解了应用开发中常见的一个问题：当错误发生在流程后期时，需要重新运行整个流水线，导致实验过程缓慢且结果不够清晰。通过节点级别的复现与检查，Daggr 提升了调试效率，也加快了迭代速度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该库采用以代码为核心的设计思路。开发者直接在 Python 中定义节点及其连接关系，Daggr 再根据代码渲染出对应的可视化界面用于检查。这与以 GUI 为中心的工作流构建工具形成对比，后者往往牺牲版本控制能力和灵活性。使用 Daggr 时，可视化层是从代码派生出来的，而不是取代代码本身，从而保证了工作流的可复现性，也更便于审查和协作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Daggr 支持三种主要的节点类型。GradioNode 可直接连接到 Gradio 应用或 Hugging Face Spaces，使已有的演示和工具能够作为工作流组件复用。FnNode 用于封装任意 Python 函数，方便插入自定义的预处理或后处理逻辑。InferenceNode 则用于对接通过 Hugging Face Inference Providers 提供的模型服务，使托管模型能够无需额外适配即可集成进工作流。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其中一个关键特性是状态持久化。Daggr 会自动保存工作流状态、缓存结果、输入值以及画布布局，使开发者可以在不中断上下文的情况下暂停和恢复工作。单个节点也可以在修改输入后单独重新运行，这在调试长流水线或对比某一步的不同实现方案时尤其有用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;由于 Daggr 由 Gradio 团队开发，它与 Gradio 生态系统实现了紧密集成。工作流既可以在本地启动，并通过浏览器访问可视化画布，也可以利用 Gradio 的隧道功能通过公共链接进行分享。对于需要长期运行的场景，同样的工作流还可以通过将 Daggr 作为依赖，部署到 Hugging Face Spaces 上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;开发者的早期反馈主要集中在编程式控制与可视化反馈相结合这一点上。Sebastian Buzdugan 在评论该发布时&lt;a href=&quot;https://x.com/sebuzdugan/status/2017183567273406571?s=20&quot;&gt;写道&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;把接口和 Gradio 混在一起用，真的是一个非常聪明的组合。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;也有其他用户&lt;a href=&quot;https://x.com/OriOridev/status/2017000978227122383?s=20&quot;&gt;指出&lt;/a&gt;&quot;，Daggr 在快速实验和原型验证方面尤其有价值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Daggr 目前是一个轻量级、实验性质的项目，仍处于 beta 阶段。随着用户的使用，其 API 可能会发生变化。尽管工作流状态是存储在本地的，但更新过程中仍可能导致数据丢失，这也进一步表明它的定位更偏向于开发和原型工具，而非直接用于生产环境的解决方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Daggr 现已作为开源 Python 包发布，支持 Python 3.10 及以上版本，可通过 pip 或 uv 进行安装。其源代码、示例和文档已发布在 &lt;a href=&quot;https://github.com/gradio-app/daggr&quot;&gt;GitHub&lt;/a&gt;&quot; 上，团队也邀请社区在项目逐步成熟的过程中提供反馈并参与贡献。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;https://www.infoq.com/news/2026/02/daggr-open-source/&lt;/p&gt;</description><link>https://www.infoq.cn/article/1xUSbEXlzBqHKsh3pSFy</link><guid isPermaLink="false">https://www.infoq.cn/article/1xUSbEXlzBqHKsh3pSFy</guid><pubDate>Tue, 10 Feb 2026 03:00:00 GMT</pubDate><author>作者：Robert Krzaczyński</author><category>软件工程</category></item><item><title>从分散存储到统一分析，Apache Doris 在快手万亿规模广告场景的应用实践</title><description>&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;导读：面对万亿级广告数据存量、日均 3 亿行增量及数千个复杂查询模板的挑战，快手广告数据平台如何突破性能瓶颈、实现架构统一与体验跃升？本文系统介绍了快手广告团队从 ClickHouse on ES 混合架构，全面迁移至 Apache Doris 的统一分析实践，最终实现查询性能提升 20～90%，写入吞吐提升 3 倍，存储效率提升 60%。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本文整理自快手高级计算引擎研发工程师 周思闽 在 Doris Summit 2025 中的演讲内容，并以演讲者第一视角进行叙述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;快手是国内日活过亿的短视频平台，其广告投放平台是商业化外部广告主与快手电商商家进行广告投放的主要阵地，支持客户在平台上进行广告物料搭建、物料管理、策略变更、数据查看等操作，这对底层数据系统的存储、计算与查询性能提出了极高要求。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要支撑如此大规模的广告投放与实时分析，底层数据架构面临巨大挑战。当前，快手的广告数据包括：由投放系统产生的物料数据以及用于数据分析的效果数据，这些数据呈现出三个显著特征：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;数据存量巨大：广告物料累计已达千亿级别，且随业务发展正向万亿规模迈进，存储体量位居公司前列，对架构扩展性提出极高要求。数据增长迅猛：仅 2025 年第一季度，日均新增广告物料数据同比激增 3.5 倍，要求底层引擎具备强大的实时写入与弹性扩展能力。数据模型复杂：整个数据体系涵盖约 700 个核心字段，涉及物料、投放、用户、效果等多个维度；同时，为应对多样化分析场景，沉淀的查询模板已超 4000 个，对查询引擎的兼容性与性能均是严峻考验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;架构演进：从分散存储到统一分析&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;01 早期架构及挑战&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;早期存储架构中，物料数据由 MySQL、Elasticsearch 协同存储；效果数据主要存储与 Clickhouse 中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;数据分析时，将分散在 MySQL、Elasticsearch 中的物料数据与 ClickHouse 中的效果数据进行高效关联查询，从而为广告主提供完整、及时的投放效果洞察。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/3c/3c247f9ec4b67b6612011bf2aedc7beb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在如上所说的 ClickHouse on ES 架构中，用户提交的查询通常包含 Elasticsearch 外表（a）与 ClickHouse 内表（b）。ClickHouse 会解析查询中外表部分，将其转换为 Elasticsearch 查询语句，通过 HTTP 请求获取数据并封装为 Block，最后在引擎内部完成与内表的关联计算。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f6/f6c7f67f64a49cd0ea8b411124049604.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然而，随着 Elasticsearch 中数据量持续增长，该架构逐渐暴露诸多问题：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;查询性能恶化：慢查询率上升至 35%，平均查询耗时达到 1.4 秒；存储瓶颈：Elasticsearch 单分片难以支撑 10 亿级以上数据量，扩容与数据重分布成本高；运维复杂度高：数据链路依赖组件多，运维与监控成本显著上升；问题定位困难：缺少 ClickHouse 与 Elasticsearch 之间的全链路可观测手段，出现查询延迟、数据不一致等问题时，需跨系统排查，耗时较长。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;02 选型目标及调研&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基于上述问题及挑战，我们为新架构设定了明确目标：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;慢查询率低于 5%；运维排查耗时降低至分钟级；支持单表万亿级别数据存储；保障数据实时性，延迟低于 5 分钟。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基于以上目标，我们对 Apache Doris、ClickHouse、Elasticsearch 等主流 OLAP 引擎进行了全面的调研与性能压测。测试涵盖了写入吞吐、查询延迟、存储压缩率、全文检索性能等关键维度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/da/da9240cbfe6a23bb6131a78ace804f9a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这过程中，ClickHouse 首先被排除，因其不支持唯一键模型，而广告物料数据存在大量更新场景，要求引擎具备主键更新能力。因此，重点在 Elasticsearch 与 Apache Doris 之间进行对比。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;综合测试结果，Apache Doris 在写入性能、查询效率、存储成本及运维复杂度等方面均表现优异，不仅能够满足既定架构目标，还在多个场景下显著优于 Elasticsearch。因此，我们最终选定 Apache Doris 作为下一代广告数据分析引擎。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;03 基于 Apache Doris 的统一分析引擎&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在实际应用中，我们引入 Apache Doris（计算引擎） 替换了原先架构中的 Elasticsearch、ClickHouse，设计了统一分析引擎 Bleem。通过在外部表模块中引入数据缓存层与元数据服务层，有效提升了跨源查询效率，使数据湖外表的查询性能接近内表水平，实现了关键的性能突破。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a2/a2eadf662145651fb29d4f0c73a45647.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体来看，Bleem 架构自下而上分为 5 层：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;存储层：数据湖中的 Hive/Hudi 数据存储于 HDFS；存算分离模式下的内表数据存放于对象存储 BlobStore；存算一体模式下的内表数据则存储于本地磁盘。缓存层：将 Hive/Hudi 外部表数据缓存至 Alluxio，保障 I/O 稳定性，提升数据读取效率。计算层：Apache Doris 为核心引擎。不同项目组对应不同的 Doris 集群，以实现计算资源物理隔离，用户可按需申请计算资源。依托于 Doris 湖仓查询能力，可直接对 Doris 内表与外部 Hive/Hudi 数据查询。同时，Doris 也支持存算一体与存算分离两种部署方式，可根据实际需求灵活选择。服务层：元数据缓存服务实时监听 Hive 元数据变更，并同步至缓存中，以提升湖仓外部表的查询效率。接入层：将 OneSQL 作为统一查询接入网关，提供集群路由、查询改写、物化改写、查询鉴权、限流与阻断等功能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;依托 Doris 强大的 OLAP 计算与湖仓一体能力，将此前分散的数据湖分析、实时 OLAP 查询、在线报表及全文检索等多种场景，统一整合至同一套引擎架构中，实现了技术栈的收敛与提效。该架构在实际落地中已带来显著收益：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;性能大幅提升：慢查询率低于 5%，整体查询性能提升了 20%～90%；存储扩展高效：支持万亿级别数据存储，水平扩容效率较 Elasticsearch 提升 10 倍以上；运维大幅简化：一套引擎覆盖全部查询场景，系统依赖组件少，运维复杂度显著降低；可观测性全面加强：Doris 支持全链路追踪与全面监控，平均问题排查时间降低 80%。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;迁移实践及调优经验&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整个迁移过程分为三个阶段，稳步推进以确保业务平稳过渡：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一阶段（试点验证）：选取关键词推广场景进行试点，跑通全量与增量数据导入流程，搭建双链路并行验证数据一致性与查询正确性。第二阶段（主体迁移）：迁移原 ClickHouse on ES 查询链路，将 Elasticsearch 中全量物料数据导入 Doris，完成业务切换后下线 Elasticsearch 集群。第三阶段（收尾统一）：迁移剩余纯 ClickHouse 场景，将无需关联 Elasticsearch 的查询任务及其数据全部迁移至 Doris，完成整体架构统一。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在架构升级及迁移过程中，我们收获了许多实践及优化经验，在此逐一分享。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;01 解决极端场景下数据一致性问题&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在数据导入层面，我们基于 SeaTunnel 实现流式数据同步，该方式支持批处理场景下的 Overwrite 语义，所有导入均采用两阶段提交机制，以确保数据同步的最终一致性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而在基于 SeaTunnel 和 Spark 的数据同步过程中，我们遇到了极端场景下的数据重复问题。主要有两种情况：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Spark 推测执行时，两个 Task 同时写入同一份数据并均完成 Doris 两阶段提交，尽管 Driver 只认定一个 Task 成功，但数据已重复。Spark Task 完成 Doris 提交后，在向 Driver 汇报前因抢占或异常退出，Driver 重启 Task 并重新写入数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为解决该问题，我们在 Doris 的两阶段事务提交环节引入了 ZooKeeper 分布式锁机制，通过记录并校验事务状态来保证批同步的一致性。具体流程如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;准备提交阶段，先获取 ZooKeeper 临时锁，确保同一时间只有一个事务进入提交流程；获取锁后，将 Prepare 状态写入 ZooKeeper 临时节点，并记录当前事务 ID；查询上一个事务的状态：若不存在，直接提交当前事务；若上一事务处于 Prepare 状态，则先回滚上一事务，再提交当前事务；若上一事务已 Commit，则直接回滚当前事务；最终将 Commit 状态写入 ZooKeeper 持久节点，完成本次提交。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b7/b70fab501f654841586df0927ccdb14a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;02 Stream Load 机制优化&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为应对高并发数据导入，我们对 Apache Doris 的 Stream Load 机制进行了调优。通过合理配置任务优先级与合并（Compaction）参数，显著提升了写入吞吐与稳定性。Doris 内部通过 Load Channel 进行任务调度，以区分高优与普通优先级通道。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/16/165c346b4f34f3418f8e6615e227e4a3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;调优的核心在于合理配置相关参数，例如当 Stream Load 任务指定的 timeout 时间小于 300 秒时，系统会将其判定为高优任务并分配至高优通道。参数优化如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;sql&quot;&gt;load_task_high_priority_threshold_second=300
compaction_task_num_per_fast_disk=16
max_base_compaction_threads=8
max_cumu_compaction_threads=8
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;03 差异化的建表策略&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;OLAP 引擎的查询性能很大程度上取决于表结构设计。因此，我们针对不同业务场景制定了差异化的建表策略：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;物料表（高频更新与大规模检索）：该表数据量极大且需支持实时更新。业务查询主要基于 account_id 进行过滤，而非原 MySQL 的自增 ID。为充分发挥 Doris 前缀索引与排序键的优势，在保证业务逻辑等价的前提下，我们将 account_id 与 id 组合为联合主键，并将account_id 设为首个排序键及分桶字段，大幅提升查询过滤效率。同时配置倒排索引以支持多维检索，并选用 ZSTD 压缩算法平衡存储与 IO 性能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;sql&quot;&gt;-- 建表语句参考
CREATE TABLE ad_core_winfo
(account_id BIGINT NOT NULL,
id BIGINT NOT NULL, 
word STRING,
INDEX idx_word (`word`) USING INVERTED...) 
UNIQUE KEY(account_id,id) 
DISTRIBUTED BY HASH(account_id) BUCKETS 1000;
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;效果表（多维聚合分析）： 相较于物料表，效果表侧重于数仓指标的累加与聚合。因此，我们直接采用聚合模型，并按照“天”或“小时”粒度设置分区。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;sql&quot;&gt;-- 建表语句参考
CREATE TABLE ad_dsp_report
(__time DATETIME, 
account_id BIGINT, ...
`ad_dsp_cost` BIGINT SUM,
...) 
AGG KEY(__time,account_id,...) 
AUTO PARTITION BY RANGE(date_trunc(`__time`,&#39;hour&#39;))()
DISTRIBUTED BY HASH(account_id) BUCKETS 2;
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;04 大账户数据倾斜治理&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在数据压测中，我们发现不同 Account ID 对应的数据量差异极大，小至个位数、大至百万级别，导致 BE 节点 CPU 负载严重不均。通过 SHOW DATA SKEW 命令进一步确认，Tablet 存储分布明显倾斜：大 Tablet 占用空间达 3–4 GB，小 Tablet 仅 100-200 MB，且大账户查询延迟较高。为此，我们实施了以下两点优化：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;A：按账户范围进行分区&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;经分析，Account ID 为 5–8 位数字，且未来不会超过 10 位。因此使用 FROM_UNIXTIME 函数将 Account ID 转换为 Datetime 类型，按月对历史数据进行分区，共划分出 33 个历史分区。每个分区可容纳 2,592,000 个 Account ID，后续每新增约 200 多万个 Account ID 才会新增一个月份分区。同时，针对历史分区，根据数据存量进行手动分桶，新分区则默认设置为 256 个分桶。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该方案通过分区裁剪有效过滤了大量无关数据，同时为未来数据膨胀预留了扩展空间（物料表日均增量约 3 亿），显著降低分区增长对查询性能的影响。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;B：对 Account ID 进行二次哈希&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为缓解单个 Account ID 数据量差异过大导致的分布不均，我们选取与 Account ID 无关的 ID 字段，通过 ID MOD 7 计算得到一个取值在 0～6 之间的 mod 字段。将原本仅基于 account_id 的哈希分桶键调整为 (account_id, mod) 联合键，从而将同一 Account ID 的数据分散到 7 个 BE 节点上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/51/5102e16741d03083ce073f76f898aab9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;优化后，各 Tablet 大小基本均衡稳定在 1GB 左右，数据存储与查询负载得以在多个 BE 间均匀分布，有效解决了 此前 CPU 负载不均的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;05 万级分区下的查询优化&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当分区数量达到万级别时，简单点查 SQL 的耗时达到 250 毫秒，远超 100 毫秒的预期。通过分析，耗时主要集中在 Plan 阶段，原因是 Doris（2.1 版本）在分区裁剪时，会遍历所有分区进行匹配，万级分区的顺序遍历开销巨大。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为此，我们将顺序遍历改为二分查找：对万级分区先进行排序，再利用二分查找快速定位目标分区，将时间复杂度从 O(n) 降至 O(log n)。优化后，该查询耗时从 250 毫秒降至 12 毫秒，性能提升超过 20 倍。目前，二分查找已在 Doris 3.1 版本中实现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;06 并发调优&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在查询优化过程中，我们发现：多数查询经过条件过滤后，实际命中的数据量并不大，即便在大账户场景下，命中数据量也仅在百万级别。然而，Profile 显示这类查询的 Total Instance 数高达 800 个，其默认并发数为 32，存在明显的过度并发。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为此，我们调整以下参数降低并发开销：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;sql&quot;&gt;set global parallel_exchange_instance_num=5;
set global parallel_pipeline_task_num=2;
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;调整后，同一查询的 Total Instance 数量降至 17 个，查询耗时也显著缩短。这说明在小数据量点查场景下，适当降低并发可有效减少 RPC 开销，从而降低延迟（220ms 降至 147ms）。同时，这一优化也提升了系统的整体 QPS 承载能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;收益及规划&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;经过上述架构迁移与深度优化，我们在三个核心维度取得了显著收益：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;查询性能大幅提升：关键词推广页平均查询延迟下降 64%，创意推广页延迟下降超过 90%，整体查询体验实现跨越式提升。写入能力显著增强：单节点写入承载能力提升 3 倍以上，单表实时导入峰值突破 300 万行/秒。存储效率优化明显：通过分区策略与 ZSTD 压缩算法，存储效率较 Elasticsearch 提升约 60%，并可轻松支撑万亿级数据存储。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;未来，我们将深度探索 Apache Doris ，重点围绕两方面展开：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;增强全文检索与分词能力：引入社区在 Doris 4.0 版本中推出的 BM25 打分功能，以及 IK 分词器等更多分词组件，实现按业务场景灵活选用最优分词方案。增强向量索引：基于 Doris 4.0 版本，在内表和数据湖外表场景下对向量检索的性能和边界能力做验证与优化。&lt;/p&gt;</description><link>https://www.infoq.cn/article/X19PzkXgJux5tYL9ULBR</link><guid isPermaLink="false">https://www.infoq.cn/article/X19PzkXgJux5tYL9ULBR</guid><pubDate>Tue, 10 Feb 2026 01:52:00 GMT</pubDate><author>SelectDB</author><category>数据库</category></item></channel></rss>