<?xml version="1.0" encoding="UTF-8"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>InfoQ 推荐</title><link>https://www.infoq.cn</link><atom:link href="http://10.0.0.5:1200/infoq/recommend" rel="self" type="application/rss+xml"></atom:link><description>InfoQ 推荐 - Powered by RSSHub</description><generator>RSSHub</generator><webMaster>contact@rsshub.app (RSSHub)</webMaster><language>en</language><lastBuildDate>Sun, 01 Feb 2026 15:05:28 GMT</lastBuildDate><ttl>5</ttl><item><title>彩讯股份携手稳准智能发布垂直行业数据大模型“数擎”大模型</title><description>&lt;p&gt;彩讯股份携手稳准智能发布垂直行业数据大模型“数擎”大模型1 月 31 日，彩讯科技股份有限公司（简称：彩讯股份）受邀出席雄安新区“人工智能+”创新生态系列活动分会场—通用数据大模型赋能产业发展大会暨极数（LimiX）系列成果展示交流活动，与稳准智能（雄安）科技有限公司（简称：稳准智能）联合发布首个运营商行业数据大模型——“数擎”大模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;彩讯股份CEO白琳、董事会秘书兼财务总监王欣、数行事业部总经理朱彩霞与生态伙伴稳准智能首席科学家崔鹏、CTO张兴璇、COO何玥共同参与发布仪式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2f/2fb2e00633b0a17eeede15495c65f792.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;（从左至右依次是：稳准智能COO何玥，稳准智能CTO张兴璇，稳准智能首席科学家崔鹏，彩讯股份CEO白琳，彩讯股份董事会秘书兼财务总监王欣，彩讯股份数行事业部总经理朱彩霞）&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基于对行业共性问题的长期观察与实践，彩讯股份依托在 ToB 领域二十余年的行业经验积累，并以自主研发的 Rich AIBox 企业级平台化能力为核心，构建起覆盖多业务场景的全栈 AI 能力；在此基础上，结合稳准智能在结构化数据大模型（LDM）领域的技术优势，双方共同启动运营商领域专属大模型的联合研发，并推动结构化数据智能在运营商场景中的系统级落地。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此次发布的“数擎”大模型被认为是业界首个围绕运营商核心业务流程打造的行业专属大模型。该模型构建覆盖数据建模、业务理解与智能决策的业务智能中枢，具备轻量、高效、可解释等特点，能够在资源受限、适用于多类对实时决策和规模化应用要求较高的行业场景。在此过程中，稳准智能在结构化数据建模与因果分析方面的技术能力作为关键能力模块被引入，用于增强模型在复杂业务场景下的推理与决策支撑能力；彩讯股份则依托长期服务运营商核心系统的工程化经验，承担模型能力与业务流程及既有系统的集成与落地实施工作，保障智能能力在真实生产环境中的稳定、可靠运行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，该模型已在运营商行业的精准营销、经营分析、终端服务等多个核心场景中成功应用，推动相关业务从“经验驱动”向“数据智能驱动”转变。例如，在营销与预测场景中，模型能够基于多维业务数据进行关联分析与策略推演，不仅提升了预测准确率，还支持业务从“事后评估”向“事前干预”转变，提升运营决策的精准性与前瞻性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;面向下一阶段发展，双方将进一步围绕“更深”与“更广”两大方向推进模型演进：一方面，持续增强模型对业务逻辑和策略影响的理解能力，提升智能决策对实际业务结果的支撑效果；另一方面，通过彩讯股份 Rich AIBox 等企业级平台化能力，推动结构化与非结构化数据的协同分析，探索更多行业场景中的规模化复制与应用落地。&lt;/p&gt;</description><link>https://www.infoq.cn/article/gbW5LmM3U3dXoQhTXY31</link><guid isPermaLink="false">https://www.infoq.cn/article/gbW5LmM3U3dXoQhTXY31</guid><pubDate>Sun, 01 Feb 2026 09:19:09 GMT</pubDate><author>InfoQ</author><category>AI&amp;大模型</category></item><item><title>打造让员工蓬勃发展的软件组织</title><description>&lt;p&gt;Matthew Card在&lt;a href=&quot;https://qconlondon.com/&quot;&gt;Qcon&lt;/a&gt;&quot;伦敦关于&lt;a href=&quot;https://www.infoq.com/presentations/inclusive-leadership/&quot;&gt;包容性领导力&lt;/a&gt;&quot;的演讲中提到，持续学习、适应能力和强大的支持网络是团队蓬勃发展的基础。信任是通过始终如一的、公平的领导力和及早处理有害行为、偏见和微侵犯来建立的。通过培养成长、心理安全和责任感，以人为本的领导力推动团队的韧性、合作和绩效。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card表示，打造一个能让员工真正蓬勃发展的组织始于有意为之。这不仅仅是组建一个拥有合适技术技能的团队，更是要营造一个让员工感到安全、受到重视并能充分发挥自身能力的环境。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card解释说，鼓励持续学习是关键所在：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;人们在成长时会蓬勃发展，不仅是在技术领域，还包括像韧性和适应性这样的软技能。我经常在一对一的交流和评审中通过帮助团队成员设定个人发展目标来支持这一点，这些目标加强了这些能力。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card说，在我们这种快速变化的行业中，培养灵活性和适应能力至关重要。蓬勃发展并不总是意味着在压力下蓬勃发展。这意味着要为人们创造适应、试验和恢复的空间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card认为，建立支持网络和员工社区至关重要。这些为人们提供了交流、反思和恢复精力的渠道，并有助于强化关怀和协作的文化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card表示，必须处理有害行为，理想情况下应立即处理。忽视它会发出错误的信号。如果已经确立了明确的行为标准，并且团队也知道你是公平、一致、以价值为导向的，那么处理起来就会容易得多。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card解释说，处理有害行为没有一劳永逸的方法，这取决于其严重程度：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;对于不太严重的情况，我将其视为成长的机会。你可以将其视为学习的机会，并引导人们进行纠正。花时间深思熟虑地处理这些情况可能在短期内需要更长的时间，但从长远来看，对团队文化和信任的影响是值得的。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;信任是通过日常的小互动逐渐建立起来的。当人们知道在困难时刻彼此的期望和如何互动时，信任就形成了，Card说道。一旦信任根深蒂固，团队就更有可能冒险，敢于让自己犯错，并快速失败，而神奇的事情往往就在此时发生。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card表示，你需要积极应对偏见和微侵犯行为。如果放任不管，它们会悄然侵蚀信任和归属感。积极主动、公平且始终如一地处理这些行为，能向整个组织清晰地传达你的价值观。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Card总结道，这一切的核心在于相信以人为本的领导力就是绩效领导力。当我们花时间打造包容、有韧性的文化时，成功就会随之而来，不仅对业务有利，对组织内的每个人都有益。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ 采访了&lt;a href=&quot;https://www.linkedin.com/in/matthew-card-93027914/&quot;&gt;Matthew Card&lt;/a&gt;&quot;，探讨了心理安全、信任和韧性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：心理安全和信任在塑造企业文化方面发挥着怎样的作用？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Matthew Card：在我看来，心理安全感是信任环境的更高层次。两者都是任何健康、高效文化的基石。没有它们，人们就会有所保留；他们不太可能分享想法、承认错误或挑战现状。这意味着你的团队不会成长、创新或建立牢固的关系。&amp;nbsp;如果你想建立一个持久的文化，让人们蓬勃发展，而不仅仅是生存，那么建立信任和安全就不是可有可无的。这必须是有意为之。一旦建立起来，它就会解锁其他一切：合作、韧性、问责和成长。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;InfoQ：你在组织中采取了哪些措施来增强韧性？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Card：我倡导它、传授它，而且最重要的是，积极践行它。&amp;nbsp;在一对一交流和绩效评估中，如果合适的话，我会鼓励我的直接下属设定个人发展目标，重点放在软技能上，包括韧性——比如变得更适应变化、培养成长型思维、提高情商以及增强自我意识。情商本身就是一个庞大的话题，还有太多内容值得深入探讨——它常常引发更深层次的交流。这些目标有助于将韧性确立为领导力的核心能力。&amp;nbsp;在团队环境中，我会通过自身行动来展现韧性——无论是做决策的方式，还是应对棘手情况的态度。以身作则能传递出强有力且始终如一的信息。&amp;nbsp;我还做过演讲和主持过工作坊，鼓励自我反思，并剖析韧性的核心要素——如果你还记得 C.A.P.S.，就永远不会忘记它们：自信、适应力、目标感和社交支持。这些活动为人们提供了在各自情境中探索韧性含义的空间。&amp;nbsp;最后，我还协助创建并支持员工社区和网络，为他们提供同伴联系、安全的宣泄渠道和共同学习的机会。这些空间在组织内强化韧性方面发挥着关键作用，确保员工感到被支持和被关注。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/organisations-people-thrive/&quot;&gt;https://www.infoq.com/news/2026/01/organisations-people-thrive/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/bg0pzN0dZQm6HhRMliej</link><guid isPermaLink="false">https://www.infoq.cn/article/bg0pzN0dZQm6HhRMliej</guid><pubDate>Sun, 01 Feb 2026 00:00:00 GMT</pubDate><author>作者：Michael Redlich</author><category>管理/文化</category></item><item><title>硬杠 Meta NLLB！Google 发布 TranslateGemma，机器翻译的“性价比”被卷到了极致</title><description>&lt;p&gt;Google 近日正式发布了&amp;nbsp;&lt;a href=&quot;https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/&quot;&gt;TranslateGemma&lt;/a&gt;&quot;，这是一套基于&amp;nbsp;&lt;a href=&quot;https://deepmind.google/models/gemma/gemma-3/&quot;&gt;Gemma 3&lt;/a&gt;&quot;&amp;nbsp;架构构建的全新开源翻译模型。该系列涵盖了 4B、12B 和 27B 三种参数规模，旨在攻克跨越 55 种语言的机器翻译挑战。这些模型旨在适应多样化的运行环境，涵盖了从移动端、边缘设备到消费级硬件及云端加速器的各类场景。目前，该系列模型已正式开源，供全球开发者与研究人员使用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://huggingface.co/collections/google/translategemma&quot;&gt;TranslateGemma&lt;/a&gt;&quot;&amp;nbsp;的诞生源于一种高度关注效率的训练工艺，其核心在于将大型商业系统的知识迁移至轻量化模型。Google 采用了一种结合了&lt;a href=&quot;https://en.wikipedia.org/wiki/Fine-tuning_%28deep_learning%29&quot;&gt;监督微调&lt;/a&gt;&quot;与&lt;a href=&quot;https://en.wikipedia.org/wiki/Reinforcement_learning&quot;&gt;强化学习&lt;/a&gt;&quot;的两阶段训练方案。在监督微调阶段，基础版 Gemma 3 模型在由人工翻译和 Gemini 模型生成的合成数据组成的平行语料库上进行训练。这种混合数据集旨在扩大对各类语种（包括低资源语言）的覆盖范围，同时确保翻译质量的稳定性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在强化学习阶段，Google 利用一组自动奖励信号对模型进行了优化。这些信号包括&amp;nbsp;&lt;a href=&quot;https://github.com/google-research/metricx&quot;&gt;MetricX-QE&lt;/a&gt;&quot;&amp;nbsp;和&amp;nbsp;&lt;a href=&quot;https://arxiv.org/abs/2308.07286&quot;&gt;AutoMQM&lt;/a&gt;&quot;&amp;nbsp;等机器翻译评估指标，旨在超越简单的参考译文匹配，从而更精准地捕捉翻译的充分性与流利度。据 Google 称，这种方法显著提升了参数效率。在&amp;nbsp;&lt;a href=&quot;https://llm-stats.com/benchmarks/wmt24++&quot;&gt;WMT24++ 基准测试&lt;/a&gt;&quot;中，12B 规模的 TranslateGemma 所表现出的错误率甚至低于体量更大的 27B Gemma 3 基准模型，而 4B 模型的表现也已逼近 12B 的基准水平。此次评估覆盖了高、中、低资源设置下的 55 种语言。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除了核心的基准测试语言外，Google 还针对近 500 种额外的语言对训练了 TranslateGemma。尽管这些扩展语向尚未经过全面评估，但 Google 表示，将它们纳入其中是为了支持社区进行更深入的研究和微调，尤其是针对那些代表性不足的弱势语言。此外，这些模型还继承了 Gemma 3 的多模态能力。在基于&amp;nbsp;&lt;a href=&quot;https://vistra-benchmark.github.io/&quot;&gt;Vistra 基准&lt;/a&gt;&quot;的内部测试中，即便没有进行额外的多模态专项微调，文本翻译能力的提升也直接带动了图像内嵌文本翻译表现的优化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;根据模型大小的不同，其部署场景也各具侧重。4B 模型： 专注于移动端和边缘侧推理，适用于内存和功耗限制较严苛的环境。12B 模型： 旨在普通消费级笔记本电脑上运行，无需专用加速器即可进行本地开发和实验。27B 模型： 专为云端部署设计，可在单块高端 GPU 或 TPU（如 H100 级别加速器）上顺畅运行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;社区对该模型的发布反应热烈，讨论焦点集中在 Google 宣称的卓越效率以及开源决策上。社交平台上的研究人员和开发者特别关注 12B 模型超越大型基准模型的表现，认为其在成本敏感型部署和设备端翻译应用中极具潜力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员&amp;nbsp;&lt;a href=&quot;https://x.com/avaisaziz/status/2011899797008237004&quot;&gt;Avais Aziz&lt;/a&gt;&quot;&amp;nbsp;评价道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;TranslateGemma 为世界带来了强大的开源翻译能力，其质量和效率令人印象深刻。很高兴看到 Gemma 3 能够发挥如此深远的全球影响力，干得漂亮！&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与此同时，用户 Darek Gusto 分享道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;太棒了！像 X（原Twitter）这类平台提供的自动翻译功能，对我们非母语用户意义重大。而开源权重模型正是推动这项功能普及、成为行业标准的关键。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与&amp;nbsp;&lt;a href=&quot;https://ai.meta.com/research/no-language-left-behind/&quot;&gt;Meta 的 NLLB&lt;/a&gt;&quot;&amp;nbsp;系列或针对翻译适配的多语言大语言模型相比，TranslateGemma 更侧重于小尺寸模型下的翻译效率。虽然竞品模型通常强调极广的语种覆盖面或通用能力，但它们往往需要更大的参数量或额外的微调。不同于追求规模的路径，TranslateGemma 优先保障了低计算成本下的高质量翻译，精准切中了成本受限场景与设备端运行的痛点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/google-translategemma-models/&quot;&gt;https://www.infoq.com/news/2026/01/google-translategemma-models/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/h2pqxbjh27gCsekUWKFT</link><guid isPermaLink="false">https://www.infoq.cn/article/h2pqxbjh27gCsekUWKFT</guid><pubDate>Sat, 31 Jan 2026 04:00:00 GMT</pubDate><author>作者：Daniel Dominguez</author><category>Google</category><category>AI&amp;大模型</category></item><item><title>BigQuery 新功能：SQL 直调 17 万 + AI 模型，3800 万行数据处理成本仅 2 美元</title><description>&lt;p&gt;Google 近期针对&amp;nbsp;&lt;a href=&quot;https://cloud.google.com/bigquery&quot;&gt;BigQuery&lt;/a&gt;&quot;&amp;nbsp;推出了面向开源模型的第三方生成式 AI 推理功能。这一更新允许数据团队直接使用简单的 SQL 语句，部署并运行来自&amp;nbsp;&lt;a href=&quot;https://huggingface.co/&quot;&gt;Hugging Face&lt;/a&gt;&quot;&amp;nbsp;或&amp;nbsp;&lt;a href=&quot;https://cloud.google.com/model-garden&quot;&gt;Vertex AI Model Garden&lt;/a&gt;&quot;&amp;nbsp;的任何模型。该接口目前处于预览阶段，其最大的亮点在于消除了对独立机器学习（ML）基础设施的需求，系统会自动启动计算资源、管理端点，并在任务完成后通过&amp;nbsp;&lt;a href=&quot;https://docs.cloud.google.com/bigquery/docs/introduction-sql&quot;&gt;BigQuery 的 SQL&lt;/a&gt;&quot;&amp;nbsp;接口自动清理资源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这项新功能解决了困扰数据团队已久的痛点。在过去，运行开源模型往往意味着需要管理 Kubernetes 集群、配置端点以及在多种工具之间反复切换。Virinchi T 在一篇关于此次发布的 Medium&amp;nbsp;&lt;a href=&quot;https://medium.com/google-cloud/bigquerys-managed-inference-for-open-models-your-warehouse-is-now-an-ai-engine-d83fbb6eccd1&quot;&gt;文章&lt;/a&gt;&quot;中指出：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;这一过程需要多种工具协同、不同的技能储备以及巨大的运维开销。对于许多数据团队来说，这种摩擦意味着即便模型本身是免费且公开的，AI 能力依然显得遥不可及。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然而，得益于 BigQuery 的 SQL 接口，整个工作流现在被简化为仅需两条 SQL 语句。用户首先通过一条&amp;nbsp;&lt;a href=&quot;https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model-open#create_model_syntax&quot;&gt;CREATE MODEL 语句&lt;/a&gt;&quot;来创建模型，只需指定 Hugging Face 的模型 ID（例如 sentence-transformers/all-MiniLM-L6-v2）或 Vertex AI Model Garden 中的模型名称。BigQuery 会根据默认配置自动分配计算资源，部署过程通常在 3 到 10 分钟内即可完成，具体时长取决于模型大小。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;部署完成后，用户可以使用&amp;nbsp;&lt;a href=&quot;https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-generate-text&quot;&gt;AI.GENERATE_TEXT&lt;/a&gt;&quot;（针对语言模型）或&amp;nbsp;&lt;a href=&quot;https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-generate-embedding&quot;&gt;AI.GENERATE_EMBEDDING&lt;/a&gt;&quot;（针对嵌入模型）直接对 BigQuery 表中的数据进行推理查询。平台通过 endpoint_idle_ttl 选项管理资源的生命周期，该功能会自动关闭闲置端点以节省费用。此外，在批处理任务结束后，用户还可以通过 ALTER MODEL 语句手动卸载端点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了满足生产环境的需求，该功能还支持高度定制化。用户可以直接在 CREATE MODEL 语句中设定机器类型、副本数量以及端点闲置时间。通过 Compute Engine 预留功能，还可以锁定 GPU 实例以确保性能稳定。当不再需要某个模型时，只需执行一条简单的&amp;nbsp;&lt;a href=&quot;https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-drop-model&quot;&gt;DROP MODEL 语句&lt;/a&gt;&quot;，系统便会自动清理所有关联的 Vertex AI 资源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Google 在官方博客中将该系统描述为提供“精细的资源控制”和“自动化的资源管理”，旨在让团队在不脱离 SQL 环境的情况下，找到性能与成本之间的最佳平衡点。2025 年 9 月发布的一篇&lt;a href=&quot;https://cloud.google.com/blog/products/data-analytics/use-gemini-and-open-source-text-embedding-models-in-bigquery&quot;&gt;早期博客&lt;/a&gt;&quot;曾展示，利用类似的开源嵌入模型处理 3800 万行数据，成本仅需约 2 到 3 美元。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，该功能已支持超过 1.3 万个 Hugging Face 文本嵌入模型和超过 17 万个文本生成模型，涵盖了&amp;nbsp;&lt;a href=&quot;https://en.wikipedia.org/wiki/Llama_%28language_model%29&quot;&gt;Meta 的 Llama 系列&lt;/a&gt;&quot;和&amp;nbsp;&lt;a href=&quot;https://ai.google.dev/gemma/docs/core&quot;&gt;Google 的 Gemma 家族&lt;/a&gt;&quot;。需要注意的是，所选模型必须符合 Vertex AI Model Garden 的部署要求，包括区域可用性和配额限制。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Virinchi T 强调了这一变革对不同角色的意义：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;对于数据分析师而言，你现在可以无需离开 SQL 环境，也不必等待工程资源支持，就能直接实验 ML 模型。对于数据工程师而言，构建由机器学习驱动的数据管道变得极其简单，再也不用维护独立的 ML 基础设施。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此次发布标志着 BigQuery 将与&amp;nbsp;&lt;a href=&quot;https://select.dev/posts/snowflake-cortex-ai-sql-overview-and-cost-monitoring&quot;&gt;Snowflake 的 Cortex AI&lt;/a&gt;&quot;&amp;nbsp;以及&amp;nbsp;&lt;a href=&quot;https://www.databricks.com/product/model-serving&quot;&gt;Databricks 的 Model Serving&lt;/a&gt;&quot;&amp;nbsp;展开直接竞争，后两者同样提供基于 SQL 的 ML 推理能力。而 BigQuery 的竞争优势可能在于其与 Hugging Face 庞大模型库在数据仓库内的深度集成，这对于已经在 Google Cloud 上运行业务的用户具有极强的吸引力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，关于&amp;nbsp;&lt;a href=&quot;https://docs.cloud.google.com/bigquery/docs/generate-text-tutorial-gemma&quot;&gt;Gemma 模型&lt;/a&gt;&quot;的文本生成以及&lt;a href=&quot;https://docs.cloud.google.com/bigquery/docs/generate-text-embedding-tutorial-open-models&quot;&gt;嵌入生成&lt;/a&gt;&quot;的相关文档和教程已正式上线。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/bigquery-sql-huggingface-managed/&quot;&gt;https://www.infoq.com/news/2026/01/bigquery-sql-huggingface-managed/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/V52Rsbxl71Ampa74ottq</link><guid isPermaLink="false">https://www.infoq.cn/article/V52Rsbxl71Ampa74ottq</guid><pubDate>Sat, 31 Jan 2026 03:00:00 GMT</pubDate><author>作者：Steef-Jan Wiggers</author><category>Google</category><category>数据库</category></item><item><title>为什么你的系统一出事就“查不清”？Railway 给出可观测性的标准答案</title><description>&lt;p&gt;&lt;a href=&quot;https://railway.com/&quot;&gt;Railway&lt;/a&gt;&quot;&amp;nbsp;的工程团队近日发布了一篇关于&lt;a href=&quot;https://blog.railway.com/p/using-logs-metrics-traces-and-alerts-to-understand-system-failures&quot;&gt;可观测性的系统性指南&lt;/a&gt;&quot;，详细讲解了开发者和 SRE 团队如何协同使用日志（logs）、指标（metrics）、追踪（traces）和告警（alerts），以理解并诊断生产环境中的系统故障。这篇文章主要面向现代分布式系统的使用者，梳理了各类遥测信号的实用定义、优势与局限，并强调将它们组合使用，能够显著提升根因分析的速度和准确性。尽管文中信息并非全新观点，但仍为团队理解可观测性领域提供了有价值的参考视角。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;文章指出，可观测性并不等同于传统监控。与仅基于预设阈值进行响应的监控不同，可观测性强调工程师能够在问题尚不明确时，实时探索系统内部状态。Railway 将可观测性拆解为四大核心支柱：日志用于提供事件级别的详细上下文；指标用于反映系统整体健康状况；追踪用于描绘请求在分布式架构中的完整路径；告警则作为&lt;a href=&quot;https://www.ibm.com/think/topics/service-level-objective&quot;&gt;服务级别目标&lt;/a&gt;&quot;（SLO）的早期预警机制。当一次告警能够关联到指标的异常波动、追踪中暴露的性能瓶颈，以及日志中记录的具体错误时，团队就能迅速还原故障背后的完整链路。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在具体定义上，Railway 将日志描述为带有时间戳的离散事件记录，能够提供单个事件的完整上下文，适用于调试、审计以及合规场景。指标则是高效的数值信号，支撑仪表盘展示、趋势分析和告警触发，但其缺点是缺乏细粒度上下文。追踪可以捕捉一次请求在多个服务之间的完整流转过程，帮助定位延迟问题或依赖瓶颈；告警则是主动通知机制，用于暴露异常行为或 SLO 违规情况。文章同时指出，每一种支柱都存在盲区，例如指标缺乏细节、日志不擅长实时趋势识别，但当它们被组合使用时，便能构建出一套完整的可观测性工具体系。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Railway 还分享了多项落地实践建议，包括：使用结构化日志，并通过关联 ID 或&amp;nbsp;&lt;a href=&quot;https://last9.io/blog/correlation-id-vs-trace-id/&quot;&gt;trace ID&lt;/a&gt;&quot;&amp;nbsp;将日志与追踪数据打通；定义有意义的指标，并关注分位值（如&amp;nbsp;&lt;a href=&quot;https://oneuptime.com/blog/post/2025-09-15-p50-vs-p95-vs-p99-latency-percentiles/view&quot;&gt;p95、p99&lt;/a&gt;&quot;），以更真实地反映用户体验；以及构建以用户影响为导向的告警阈值，而非基于过于底层的信号。告警还应按照严重程度进行路由，并与运行手册（runbook）绑定，帮助值班工程师在不被告警噪音淹没的情况下，高效完成响应。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;相比单体应用，分布式系统的复杂度和不透明性显著提升，传统监控手段在系统故障发生时往往难以还原完整事实。Railway 的这份指南再次强调了多模态可观测性的重要性，这一理念也与当前主流的 SRE 最佳实践高度一致，能够显著提升开发者对故障的预判、发现与诊断能力，从而减少停机时间并提升系统可靠性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在实际工程经验中，&lt;a href=&quot;https://www.reddit.com/r/Observability/comments/1qj14am/whats_your_strategy_for_correlating_logs_metrics&quot;&gt;Reddit&lt;/a&gt;&quot;&amp;nbsp;上的不少工程师也指出，相比单纯收集大量遥测数据，打通不同信号之间的上下文关联往往更有价值。例如，通过共享标识符和集中化工具，将指标、日志和追踪串联起来，可以让工程师从一次指标告警快速跳转到相关日志和追踪数据，避免在不同系统间来回切换、浪费时间。这种以“上下文连通”为核心的模式，正逐渐成为可观测性工作流中的主流做法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;总体来看，Railway 的这篇文章为可观测性提供了一套清晰且实用的框架，有助于其他团队提升对系统故障的理解和处置能力，推动工程实践从被动“救火”转向更加主动的可靠性工程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/railway-diagnosing-failure/&quot;&gt;https://www.infoq.com/news/2026/01/railway-diagnosing-failure/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/9QaYwTAYLedFhScRPsOp</link><guid isPermaLink="false">https://www.infoq.cn/article/9QaYwTAYLedFhScRPsOp</guid><pubDate>Sat, 31 Jan 2026 02:00:00 GMT</pubDate><author>作者：Craig Risi</author><category>可观测</category></item><item><title>Swift跨平台框架Skip现已完全开源</title><description>&lt;p&gt;Skip是一款通过Swift/SwiftUI代码库创建iOS和Android应用程序的解决方案，经过三年的开发，Skip团队宣布他们决定将&lt;a href=&quot;https://skip.dev/blog/skip-is-free/&quot;&gt;该产品完全开源&lt;/a&gt;&quot;，以促进采用和社区贡献。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在此之前，Skip是一个付费解决方案，需要订阅和许可密钥才能创建应用，除非你是独立开发者或开发免费应用。Skip解释说，这种模式有助于在没有外部投资的情况下启动产品，但“事实是，开发者希望免费获得他们的工具”。随着最近决定转向开源，Skip现在与iOS和Android的主要开发工具保持一致，包括Xcode、Android Studio、流行框架和其他基本工具，这些工具都是免费的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但Skip表示，促使他们做出这一决定的不仅仅是成本问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;除了价格，还有一个更深层的担忧是持久性。开发者对于在小公司的付费闭源工具上构建整个应用策略持谨慎态度是可以理解的。如果公司倒闭了怎么办？被收购然后关闭了怎么办？他们的应用程序怎么办？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;简而言之，这就是Skip决定开源的原因：即使当前的开发团队消失了，解决方案也会继续存在，保护开发者在其中所做的投资。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;根据Skip团队的说法，Android和iOS上UI框架的快速发展，包括Material Expressive和Liquid Glass，造成了使用传统跨平台UI框架可能导致“过时的界面、较弱的用户体验和真正的竞争劣势”的局面。相比之下，Skip能够在两个平台上实现完全原生的用户体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;事实上，Skip框架通过将SwiftUI桥接到Jetpack Compose上，将其引入Android。这种方法允许iOS开发者在相同的代码库中编写应用程序的业务逻辑和UI，而无需额外的努力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当Skip还是一个封闭源码的付费产品时，它的一些早期使用者在Reddit上分享了他们的经验。Reddit用户jestecs&lt;a href=&quot;https://www.reddit.com/r/SwiftUI/comments/1nzgdih/comment/ni1zrpb/&quot;&gt;指出&lt;/a&gt;&quot;：“总的来说，使用起来相当愉快，虽然偶尔会遇到一些问题，但总体上令人惊讶地愉快”。此外，JEHonYakuSha&lt;a href=&quot;https://www.reddit.com/r/SwiftUI/comments/1nzgdih/comment/ni26xec/&quot;&gt;进一步阐述&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;有些问题是因为某些弃用的构造函数不受支持，因此你可能习惯于用较旧的方式来定义视图修饰符或组件，但一旦你习惯了稍微发挥创意并确认什么是受支持的，它就非常好。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;JEHonYakuSha还指出，你可以使用 //SKIP INSERT 将Kotlin代码片段混合到Swift代码库中，并且iOS端只支持Swift包管理器，这可能会使管理内部依赖关系变得有些棘手。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Skip的文档中有一个重要的警告，&lt;a href=&quot;https://skip.tools/docs/gettingstarted/#existing_development&quot;&gt;即该框架最适合外部依赖较少的新项目或应用程序&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;将现有的应用程序迁移到Skip并不简单。大多数应用都包含许多仅针对iOS的依赖，这使得移植到Android平台变得非常困难。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Skip三年前开始作为swift到kotlin的转译器，后来增加了对Android上最广泛使用的SwiftUI API的支持。在此期间，他们成立了Swift Android工作组，发布了&lt;a href=&quot;https://www.infoq.com/news/2025/10/swift-sdk-android/&quot;&gt;Swift Android SDK&lt;/a&gt;&quot;，实现了在Android上原生编译Swift代码。今天，Skip支持许多流行的集成框架，与数千个跨平台Swift包互操作，并提供全面的SwiftUI实现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://swiftcrossui.dev/&quot;&gt;SwiftCrossUI&lt;/a&gt;&quot;是一个开源的替代方案，它为跨macOS、Linux、Windows的UI提供了类似SwiftUI的API，并对Android提供了一些新生支持。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Skip可以在&lt;a href=&quot;https://github.com/skiptools&quot;&gt;GitHub&lt;/a&gt;&quot;上克隆，而所有文档、博客和案例研究都转移到了&lt;a href=&quot;https://skip.dev/&quot;&gt;skip.dev&lt;/a&gt;&quot;上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/swift-skip-open-sourced/&quot;&gt;https://www.infoq.com/news/2026/01/swift-skip-open-sourced/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/TflNBc7EvNHoKCyDEdj3</link><guid isPermaLink="false">https://www.infoq.cn/article/TflNBc7EvNHoKCyDEdj3</guid><pubDate>Sat, 31 Jan 2026 01:00:00 GMT</pubDate><author>Sergio De Simone</author><category>Android/iOS</category></item><item><title>摩擦解决之道：改变关键要素</title><description>&lt;p&gt;当Andrew Harmel-Law邀请演讲者参加QCon伦敦大会时，他首先想到的是：“让Diana和Cat一起登台！”这完全是出于一种顽皮的冲动。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Cat Morris是一位产品经理。Diana Montalion是一位系统架构师。我们都专门从事软件系统和平台开发。我们都把对方视为我们所有痛苦的根源。不是个人层面的，我们从未一起工作过，但我们都认为对方所代表的角色是问题所在。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但我们也致力于改善我们的工作方式。如果我们能够消除我们之间存在的摩擦……那对每个人来说都是一件好事，对吧？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;首先，我们对参与的每一个重大项目做了建模分析。我们发现，每一个项目的结局都像泰坦尼克号一样：撞上了冰山。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们发现了以下这些改变职业生涯的真相：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们的工作有很多重合的地方。我们需要彼此。合作会带来更好的结果。我们思考问题的方式不同但互补。我们要解决的不是技术问题。技术挑战不难解决。困难之处在于消除摩擦。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;摩擦是阻碍变革的无形暗流。摩擦并非孤立存在的，而是一个系统性问题，其来源是人、团队与技术之间的关系。解决之道不在于Kubernetes、云计算或人工智能，而在于改变我们的思维模式、沟通方式和组织架构。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;本文描述了在每一个项目中都会反复出现的六种摩擦：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;反直觉行为拒绝改变效率与控制产品与技术角色之间相互指责线性管道思维交付能力不足&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;每一种摩擦都让我们忙于重写相同的代码库或重绘相同的组织结构图。摩擦导致很多无益于我们避开冰山的工作浪费。这篇文章将帮助你弄清楚如何应对这些问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;反直觉行为&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们怪错了对象。因此，我们做错了事情。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;反直觉行为，由系统科学家Jay Forrester定义，是指复杂的社会和管理系统倾向于用让问题变得更糟糕的解决方案来应对问题。例如，为一个处于后期的项目增派更多的工程师，加快项目进度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;面对系统性挑战时，我们人类会倾向于指责他人。遗憾的是，我们怪错了对象。我们责怪工程团队工作效率低下，或者断定是因为团队太小，却未能意识到甘特图不过是虚构的简化模型，它过度简化了复杂的动态过程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;“任何系统的输出结果都是其内在设计的必然产物‌。”——W. Edwards Deming&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当我们改变一个系统的运作方式时，我们也需要改变塑造系统的底层模式、结构和心智模型。例如，不是在本已臃肿的数据库上放上GraphQL就能称之为图，而是需要重新构建我们思考数据的方式。我们需要创建异步事件，而不是把什么都塞进管道，我们需要创建反馈循环，让我们能及时知道数据在跨系统移动时出现了异常。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这可以解释为什么工程师们会工作到很晚。他们一边忙着给猪涂口红，一边又要完成甘特图上没有预料到的工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;解决之道：理解系统&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;反直觉行为具有引力，会将我们吸入其中，卷入漩涡。至少，我们的感受是这样：感觉像是在行动，在前进，而实际情况是，我们就像烘干机里的衣物，在原地打转。自始至终，我们都是从同一个狭小的视角凝视问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;解决方法是暂时停下来，找准方向再行动。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;首先是确定核心领域。系统的目标是什么？对于联邦快递来说，是快速递送包裹。很可能，你所经历的反直觉行为，源于人们的说法一致但前进方向不同。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;每个参与的人都清楚变革与核心领域的关系吗？怎么才能加快包裹递送而不产生负面影响？系统本身如何导致了问题的产生？当前的流程和模式会产生什么样的心态？系统中的关系如何强化了这些模式？有什么你没有看到的变革需求吗？开始绘制这些模式，确定你的核心领域，所需的变革自然便会显现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;拒绝改变&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;每个试图变革的组织都有这样一些人：守门人、地牢主、自封的10倍速工程师，他们对组织非常了解，并且拥有一个魔法词：不。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他们说，“我们已经尝试过迁移。我们已经尝试过平台迁移或重构。我们已经尝试过重组。都行不通。别费心了。”他们掌握着生产环境或管道或某个关键系统的控制权，你没法忽视他们。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对此，人们很容易把责任归咎于那人的固执性格。但他展现的行为模式，正是长期的奖励与强化所形成的。通过管理遗留系统的复杂性，他已成为不可或缺的存在。要改变他，必须改变整个组织的思维方式，否则，又会冒出另一个类似的角色取而代之。仅靠技术手段无法从根本上解决问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;拒绝改变是会传染的。当那个人关闭了好奇心，其他人也会转向固定思维模式。人们首先做的是怀疑而不是实验。组织无法在规避风险和尝试新事物之间找到平衡。变革陷入了停滞。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“变革之所以困难，是因为人们高估了他们所拥有的东西的价值，低估了他们放弃这些东西可能获得的价值。” ——《&lt;a href=&quot;https://www.goodreads.com/book/show/1434394&quot;&gt;会飞的水牛：卓越腾飞，学会让员工引领&lt;/a&gt;&quot;》（Belasco和Stayer，1999年）&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;解决之道：解雇那个人&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;好吧，这可能有点极端。你可能无法解雇他们，但你可以限制他们的影响。你不是他们的导师、母亲或心理医生。不要陷入那种角色。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;把他们装进盒子里。给他们一个静态领域，让他们可以保留自己的脚本和遗留代码，而你去改变系统的其余部分。用“是”的力量去平衡他们“不”的力量。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;是的，这并不意味着认同所有观点。这意味着探索可能性。将对话引向可以向前推进的方向。找到愿意做出改变的人，并帮助他们解决自己的问题，而不是等待守门人为他们开锁。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;效率与控制&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;效率带来安全感。控制带来责任感。二者结合，便形成了现代组织中最诱人的反模式：效率与控制。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当它们占据主导地位时，我们关注的焦点便会缩小到产出：发布特性、关闭工单、满足截止日期。工作以速度来衡量，而不是价值。组织最小化互动和反思，坚信速度等于进步。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在复杂的系统中，只讲效率会使系统变得脆弱。你按时交付了错误的东西。你得到了与蓝图相匹配的结果，但忽略了变化的环境。你得到了短期的解决方案，而那最终会成为未来的障碍。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们制定了一个有预算有时间表的路线图，而唯一的上下文是一堆令人困惑的架构。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;要求我们增加控制，但又理不清头绪。效率不过是掩盖混乱的遮羞布。其结果是一场组织作秀：Jira工单、自信满满的时间表，以及追踪一切却唯独忽略意义的指标。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;截止日期不可更改。功能已锁定。缺的是什么呢？一个明确的目标和协同一致的成果，同时又留有空间，允许在学习过程中进行调整。包裹配送时间没有改善，客户体验也未见提升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;解决之道：设计知识流&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;让团队注重效能而非过度追求效率。如何确保时间、精力和注意力都用在塑造真正重要的成果上？用协同取代控制：建立能让正确信息在正确时间传递给正确人员的工作机制，让信息跨越边界自由流动，无需高管做微观管理。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;思考你目前正在开展的项目。你是在度量产出还是成果？截止日期是反映了现实还是一厢情愿的想法？如何改善信息流，而不是构建一个工厂式的交付过程？做工作与交付价值不是一回事；改善知识流能让你更快地获得价值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;产品 vs. 技术&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Andrew让我们聚在一起，因为我们有类似的挫败感。我们都面临着用Kubernetes解决系统性问题的压力。当然，我们做不到。我们也因为反直觉行为，养成了互相指责对方角色的习惯。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;工程团队不喜欢产品经理给他们施加压力，要求他们在一个紧迫的时间表内完成特性交付。他们不明白，他们正在做的改变怎么能提高代码质量。基础设施、架构和DevSecOps人员则抱怨说，他们需要的改进从未被优先考虑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;产品团队不喜欢工程师表现出的抵触和消极态度。他们不明白，为什么一些简单的事情需要那么长时间来构建。他们抱怨说，过度工程化浪费了大量的会议时间，而那些时间本来可以用在寻找前进的方法上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在许多组织中，产品和工程是相互隔离的孤岛。双方对效率与控制的定义截然不同，成了两股相互对立的势力。产品部门只需将需求抛过隔离墙，便坐等可运行的代码返回；而工程部门则被要求加快编码速度，无暇顾及系统设计。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;即使这两个角色坐在一起，他们相互冲突的方法和控制欲也会加剧摩擦。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;解决之道：向学习驱动型转变&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Carol Dweck博士描述了两种心态：&lt;a href=&quot;https://www.littlebrown.co.uk/titles/carol-dweck/mindset-updated-edition/9781472139955/&quot;&gt;固定型和成长型&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;固定型心态认为，擅长某事就意味着那件事应该很容易做到。如果某事很难，则说明你缺乏天赋。在这种模式下，人们会回避挑战，将反馈视为批评，将他人的成功视为威胁。其结果是团队很脆弱，他们要保护自己的地盘，而不是一起学习。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;成长型心态认为，能力可以通过实践、反馈和坚持来提升。你不能只是做Netflix所做的事。在这种模式下，人们欢迎挑战，将努力视为精通之道，将挫折当作改进的数据基础。其结果是个人和团队都更有韧性，他们会适应而不是抵触。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当每个人，无论什么角色，都采用成长型思维时，他们就会一起学习。同理心是一项关键能力。它不同于单纯的同情，而是从多个角度理解情境的能力——对用户和代码的影响；产品团队与技术团队之间的流程和协作模式所导致的顽固问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了共同做出有影响力的决策，我们需要成长型思维，借鉴他人的经验来丰富我们的世界观，并引导自己获得更深刻的洞察力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;线性管道思维&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还记得过去软件中某个地方有Bug的日子吗？修复一行代码就能解决问题。现在，在微服务和分布式系统构成的复杂世界中，Bug通常存在于各部分之间的关联关系中。系统架构的艺术和科学在于设计和编排。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;每天，我们都会经历摩擦，因为我们在一个异步世界中交付线性管道。或许我们称其为平台，但真正的平台是精心设计的不同技术与流程之间的关联体系。它们能用不同的方式响应不同时间发生的各类事件。平台的各部分相互协同，达成单个组件无法独立实现的成果。这种现象被称为涌现（emergence）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;面向涌现的设计需要综合多方视角，理解如何调整整个系统以实现包裹快速配送，而又不破坏异步关系。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;综合意味着不能单打独斗。你需要其他人贡献他们的专业知识，并将这些专业知识与你的知识整合在一起。当我们无法构建能整合组织知识与经验的实践体系时……我们就无法设计（或调试）平台。于是我们交付了一条管道，而所有人都将它的缺陷归咎于不充分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;解决之道：构建关系&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与其用线性思维处理异步情境，不如退一步思考以下问题：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在你的系统中，关系如何产生效果？系统各部分之间如何通过关系实现它们不直接做的事情？信息如何在技术系统中流动？痛点和瓶颈在哪里，以及如何优化关系以消除这些阻碍？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果你的组织不支持这项工作，就组建一个秘密小组。无论身处何种角色，都要将多元视角融入建议的更改方案中。确保信息在人员之间顺畅流动，从而实现服务之间的无缝衔接。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当具有不同观点的团队（如架构师Diana和产品经理Cat）共同构建这些模式时，一切都会变得更加轻松。与其他团队交流，观察用户使用系统的过程，向基础设施团队了解他们的痛点，并将这些洞察融入解决方案之中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;交付能力不足&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们以为我们专注于目标，而实际上我们是在专注于需求。目标是一个可衡量的成果，比如，提高包裹递送速度。如果我们提高了系统的能力，我们就实现了目标，而不是简单地添加另外一项功能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于内部平台团队而言，一个可能的例子是：团队被告知需将软件部署管道从Jenkins迁移至CircleCI。这明确告知了操作步骤，却未说明迁移背后的原因。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这里的隐藏目标是将开发者的管道维护工作量减少百分之五十。没有这些信息，团队可能会迁移了软件交付管道却没有达到预期的结果。他们也可能有一些想法，不需要昂贵的管道迁移就能实现目标。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;部署变更的能力早就已经存在。在这种情况下，交付流程会频繁出现各种断层。对于如何部署变更，每个人都有不同的想法。如果关注点是改变工具，那么这些想法将导致无尽的摩擦。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;解决之道：专注于目标&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;制定有意义的目标，并整合实现目标的各种方案。描述需要交付的具体且可衡量的效益或成果。确保目标紧密契合核心领域，即加速包裹配送。系统的所有功能都应该服务于这个目标。每次部署变更时，我们（期望）都在提升系统履行职责的能力。聚焦目标能确保每位贡献者都理解自身工作的价值。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;去尝试&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在，你可能感到不知所措。“我做不到这一切！我的工作已经很忙了！”这是真的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;幸运的是，你不需要全都做。选一件事来做就行。一个可以减少摩擦的小变革，可以是你最感兴趣的事情，也可以是给你的日常生活造成最大摩擦的事情。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;系统就是这样工作的……小变革可以扩展为大改进。摩擦在细节中，解决之道也在细节中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/articles/friction-fix/&quot;&gt;https://www.infoq.com/articles/friction-fix/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/ah0Xq4eGpFGrOEJOdfNX</link><guid isPermaLink="false">https://www.infoq.cn/article/ah0Xq4eGpFGrOEJOdfNX</guid><pubDate>Sat, 31 Jan 2026 00:00:00 GMT</pubDate><author>作者：Cat Morris, Diana Montalion</author><category>管理/文化</category></item><item><title>从三大支柱出发：Snowflake 平台的一次系统级升级</title><description>&lt;p&gt;生成式 AI 的投资回报远超预期？Snowflake 调研全球 1900 位企业与 IT 专业人士后发现平均 ROI 高达 41%！&lt;a href=&quot;https://www.infoq.cn/minibook/aja6h8SVCM1Smvggyvvu?utm_source=snowflakecn&amp;amp;utm_medium=snowflakecn&amp;amp;utm_campaign=snowflakecn&amp;amp;utm_content=snowflakecn&quot;&gt;点击下载&lt;/a&gt;&quot;完整报告&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这场以 What’s New for Snowflake Platform 为主题的技术发布中，Snowflake 产品管理高级总监 Artin Avanes，与产品管理团队成员 Christine 和 Raja Balakrishnan 一同，系统性地回顾并发布了 Snowflake 平台在过去一段时间内的重要进展。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不同于围绕单点功能的更新介绍，这场分享从一开始就明确了一个整体视角：Snowflake 正围绕 简洁性（Simplicity）、互联平台（Connected） 和 可信平台（Trusted） 三个关键支柱，持续重塑其作为数据与 AI 基础平台的能力边界。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;简洁性：把能用变成规模化可用&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Christine 在分享中重点展开了 Snowflake 的易用性支柱。她反复强调一个核心判断：真正的易用，并不是功能更少，而是在规模扩大之后依然可控、可理解、可管理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Snowflake 仍然坚持单一产品、单一引擎的平台形态，覆盖分析型、混合型以及事务型工作负载，并以全托管的方式承担大部分运维复杂度。在过去 12 个月中，Snowflake 针对核心分析型工作负载实现了 两倍性能提升，且这一优化由平台自动完成，而非依赖用户侧调优。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着越来越多企业在一个组织内拥有大量 Snowflake 账户和对象，组织级管理能力 成为此次更新的重点之一。Snowflake 正式推出组织账户（Organization Account），作为统一的全局管理入口；同时，通过组织级视图聚合各账户元数据，使使用情况、对象分布与成本消耗在组织层面变得可见。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在此基础上，Snowflake 进一步引入 组织用户与用户组 的管理模式，允许用户只在组织层定义一次，便可被授权至多个账户，避免重复配置。这一能力被视为大规模 Snowflake 部署的关键基础设施，目前已进入即将 GA 的阶段。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;从可扩展到可运营：SPCS 的持续演进&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;围绕 Snowpark Container Services（SPCS），Christine 也披露了一系列面向运营友好型的增强。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SPCS 的目标并非只是让用户把自定义应用带到 Snowflake 平台，而是在 Snowflake 的安全边界内，尽可能降低运行和维护这些应用的成本与复杂度。新引入的自动扩缩容、增强版自动扩缩容以及即将上线的自动暂停能力，使服务能够根据负载峰谷动态调整，避免资源闲置。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时，SPCS 在 Snowsight 中获得了更完整的可视化体验。开发者可以直接在 UI 中创建服务、执行作业，并查看历史日志、指标与平台事件，这些能力为应用与数据管道提供了内建的可观测性基础。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在性能层面，SPCS 即将支持 阶段挂载（Stage Mounts），为内部阶段提供更快速、稳定的文件访问能力，直接服务于 AI/ML 数据加载和管道吞吐需求。同时，块存储层新增的端到端加密能力，在不修改应用代码的前提下，增强了整体安全性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;互联平台：让数据真正跨系统流动&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在互联这一支柱下，Artin 将重点放在 跨云互操作、数据共享与协作能力上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先，OpenFlow 作为托管体验已正式 GA，使来自异构数据系统的数据更容易被引入 Snowflake。其次，Snowflake 宣布与 SAP 的双向集成能力，以及 Oracle CDC 即将进入公开预览，进一步拓展了平台在企业数据整合场景中的覆盖面。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在协作层面，Snowflake 对开放表格式的支持持续加深。用户现在不仅可以共享 Apache Iceberg 和 Delta Lake 表，还能够共享语义视图，用于支持更准确的 AI 和 BI 应用。同时，笔记本、用户自定义函数等对象也可以通过 Snowflake 原生应用框架进行打包与分发，使构建和交付数据与 AI 产品的路径更加完整。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;可信平台：为 AI 应用补上信任这一层&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Raja Balakrishnan 的分享，集中在 Snowflake 平台的可信性升级上。他将 Horizon Catalog 定位为一个核心枢纽：既是开放表格式互操作的目录，也是可扩展治理与 AI 数据上下文的载体。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过嵌入 Iceberg Open API 和 Apache Polaris API，Horizon Catalog 支持外部引擎直接读写 Snowflake 管理的 Iceberg 表，并在 Snowflake 内部展示来自外部数据源的血缘关系。在治理能力上，平台新增了多项目录功能，包括账户级 PII 自动检测、数据剖析与质量监控、非结构化数据中的 PII 识别，以及用于备份的数据快照能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 Trust Center 中，数据安全能力被进一步整合。PII 检测正式进入熟悉的安全管理界面，同时支持异常访问告警和组织级安全态势可视化。安全扩展也可以通过市场形式被合作伙伴提供。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;用 AI 治理 AI&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在演示环节，Raja 重点展示了一个新的 AI SQL 函数 AI Redact。该函数能够自动检测并编辑非结构化文本中的敏感信息，并允许用户精细控制哪些字段被视为 PII。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过一个客服通话记录的示例，他演示了如何在不暴露任何敏感信息的前提下，对文本进行情感分析：先对原始文本进行 PII 编辑，再将清洗后的数据输入 AI 分析函数。整个过程无需复杂流程，仅通过 SQL 即可完成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，Snowflake 在 Snowsight 中引入了全新的数据质量界面。系统可自动生成数据剖析结果，并在 AI 辅助下帮助用户快速配置质量监控规则。例如，在 Customer ID 列被识别为潜在主键后，平台会自动建议唯一性约束，并展示其推理逻辑，确保Human-in-the-loop。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在分享的最后，Artin 提到，随着平台能力的不断扩展，客户越来越关心如何用得更好。为此，Snowflake 正式推出 Well-Architected Framework，希望将多年积累的实践经验沉淀为一套可参考的方法论，覆盖从安全治理到成本优化等多个关键维度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原视频地址：&lt;a href=&quot;https://www.snowflake.com/en/build/americas/agenda/?login=ML&quot;&gt;https://www.snowflake.com/en/build/americas/agenda/?login=ML&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;🔥【活动推荐】2 月 2 日-6 日，&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;Snowflake Discover&lt;/a&gt;&quot; 重磅上线！这是一场免费、线上、可实时互动的技术活动，旨在帮助您全面提升数据与 AI 能力，深入了解如何更高效地管理、整合与分析数据。4 天时间 18 场技术干货分享，由来自亚太地区的一线技术专家亲自分享与讲解～&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/edm/resource/image/85/9a/852e6196c25c9abab4e7a7ee2767159a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;点击报名 Discover&lt;/a&gt;&quot;，更多 Snowflake 精彩活动请关注&lt;a href=&quot;https://www.infoq.cn/space/snowflake&quot;&gt;专区&lt;/a&gt;&quot;。&lt;/p&gt;</description><link>https://www.infoq.cn/article/4BOafAxF30X1K8AQd8qM</link><guid isPermaLink="false">https://www.infoq.cn/article/4BOafAxF30X1K8AQd8qM</guid><pubDate>Fri, 30 Jan 2026 11:44:26 GMT</pubDate><author>王玮</author><category>Snowflake</category><category>大数据</category><category>AI&amp;大模型</category></item><item><title>如何用 dbt MCP 服务器和 Snowflake 构建智能体工作流</title><description>&lt;p&gt;生成式 AI 的投资回报远超预期？Snowflake 调研全球 1900 位企业与 IT 专业人士后发现平均 ROI 高达 41%！&lt;a href=&quot;https://www.infoq.cn/minibook/aja6h8SVCM1Smvggyvvu?utm_source=snowflakecn&amp;amp;utm_medium=snowflakecn&amp;amp;utm_campaign=snowflakecn&amp;amp;utm_content=snowflakecn&quot;&gt;点击下载&lt;/a&gt;&quot;完整报告&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 Build 2025 的这场技术分享中，演讲者围绕 “如何构建真正可执行、可扩展的 Agentic Workflow” 展开了一次非常具体的实践讲解。不同于泛泛而谈 Agent 或自动化愿景，这次分享聚焦在一个明确的问题上：当大模型开始介入数据分析与工程流程时，如何让它们安全、可控、并且真正融入现有的数据工作流之中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本场分享由 Snowflake 与 dbt 生态的实践者——dbt Labs 的技术产品营销经理 Sarah Gawlinski，以及 dbt Labs 开发者体验和人工智能的高级经理 Jason Ganz 共同完成，核心案例是通过 dbt MCP Server 作为中介能力，让 Agent 能够理解、调用并执行 dbt 项目中的真实数据资产与逻辑，并最终运行在 Snowflake 之上。整场内容并不追求概念上的先进性，而是反复强调工程现实与可操作性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;从“能问答”到“能行动”&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;分享一开始，演讲者明确区分了两类常被混为一谈的 Agent 使用方式：一类是问答式 Agent，能够回答问题、生成文本；另一类是行动型 Agent，可以在理解上下文的基础上，执行一系列真实的系统操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在数据领域，真正有价值的 Agent 显然属于后者。但问题也随之而来：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Agent 要“行动”，就必须接触到真实的数据模型、表结构、血缘关系、以及一整套工程约束；而这些信息，往往分散在 dbt 项目、仓库元数据和团队约定之中，并不天然适合被大模型直接消费。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，分享者提出一个非常务实的判断：Agent 能否进入生产级数据流程，关键不在模型能力，而在是否存在一个可信的中间层，负责把工程世界翻译给模型，同时把模型的意图约束在安全边界内。dbt MCP Server，正是为此而被引入。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;dbt MCP Server 在架构中的角色&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在具体架构层面，dbt MCP Server 并不是简单地向 Agent 暴露一组 API。相反，它承担的是一个上下文协调器（Context Orchestrator）的角色。Agent 并不直接操作 Snowflake，也不会直接运行 SQL；它所“看到”的世界，是由 MCP Server 提供的、结构化后的 dbt 项目语义。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过 MCP Server，Agent 可以理解：&lt;/p&gt;&lt;p&gt;当前 dbt 项目中有哪些模型、它们的用途和依赖关系；某个指标或表背后对应的业务含义；哪些操作是只读的，哪些是可执行的；执行一次变更可能带来的影响范围。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种方式的关键价值在于，它避免了让大模型在“裸数据”和“裸 SQL”层面自由发挥，而是始终把 Agent 约束在 dbt 已经定义好的工程语义之内。换句话说，Agent 的智能，建立在人类工程师已经验证过的建模体系之上，而不是绕开它。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Agent 与 Snowflake 的协作方式&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 Snowflake 这一侧，分享者并没有把重点放在新能力或新接口上，而是强调 Snowflake 在整个 Agentic Workflow 中所扮演的角色：稳定、可审计、可扩展的执行环境。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体来说，Agent 并不控制 Snowflake。所有实际的数据查询、转换与计算，依然发生在 Snowflake 既有的执行体系内；Agent 只是通过 MCP Server，发起符合规范的请求。这意味着：&lt;/p&gt;&lt;p&gt;权限体系仍由 Snowflake 原生控制；执行结果可以被完整记录和回溯；性能与成本管理不会被 Agent 绕开。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;分享中特别提到，这种设计刻意避免了一个常见误区：让 Agent 成为超级用户。相反，它更像是一位受限但高效的协作者，在工程师设定的轨道上运行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;一个可复制的模式&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在分享的后半部分，演讲者总结了这种架构方式所带来的一个重要变化：Agent 不再是游离在数据体系之外的“智能外挂”，而是开始以内嵌方式进入数据工程流程本身。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;它可以帮助工程师更快理解项目结构、辅助定位影响范围、生成初步方案，但最终的执行路径、校验方式与责任边界，依然清晰地掌握在人类与平台手中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这也是整场分享最克制、也最有价值的一点结论：Agentic Workflow 的目标，并不是“自动化一切”，而是在不破坏既有工程纪律的前提下，引入新的效率杠杆。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从这场分享可以看出，真正进入生产环境的 Agent 架构，已经不再停留在模型能力本身，而是越来越多地回到工程基本功：上下文、边界、权限、可追溯性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;dbt MCP Server 与 Snowflake 的这次实践，并没有试图给出一个“通用答案”，但它清晰地展示了一条现实可行的路径：让 Agent 站在成熟数据工程体系之上。对于正在探索 Agent 在数据领域落地方式的团队而言，这无疑是一种更稳健、也更值得参考的思路。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原视频地址：&lt;a href=&quot;https://www.snowflake.com/en/build/americas/agenda/?login=ML&quot;&gt;https://www.snowflake.com/en/build/americas/agenda/?login=ML&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;🔥【活动推荐】2 月 2 日-6 日，&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;Snowflake Discover&lt;/a&gt;&quot; 重磅上线！这是一场免费、线上、可实时互动的技术活动，旨在帮助您全面提升数据与 AI 能力，深入了解如何更高效地管理、整合与分析数据。4 天时间 18 场技术干货分享，由来自亚太地区的一线技术专家亲自分享与讲解～&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/edm/resource/image/85/9a/852e6196c25c9abab4e7a7ee2767159a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;点击报名 Discover&lt;/a&gt;&quot;，更多 Snowflake 精彩活动请关注&lt;a href=&quot;https://www.infoq.cn/space/snowflake&quot;&gt;专区&lt;/a&gt;&quot;。&lt;/p&gt;</description><link>https://www.infoq.cn/article/lRtX3TRRZGq0dr6tl66q</link><guid isPermaLink="false">https://www.infoq.cn/article/lRtX3TRRZGq0dr6tl66q</guid><pubDate>Fri, 30 Jan 2026 11:21:33 GMT</pubDate><author>王玮</author><category>Snowflake</category><category>大数据</category><category>AI&amp;大模型</category></item><item><title>劈柴哥和哈萨比斯亲自站台！谷歌世界模型Project Genie刷屏，幕后团队揭秘60秒不是极限，内存是巨大约束</title><description>&lt;p&gt;世界模型真的变天了！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;今天，谷歌正式发布重磅世界模型原型产品“Project Genie”，只需一句话或一张图，就能一键生成可玩、可交互的实时虚拟世界。它的重磅程度，让谷歌“掌舵人”劈柴哥和Google DeepMind创始人哈萨比斯亲自为它站台。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/dd/dd6a37bc4e52bca469c0e9849efa6878.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/47/471ab6a435fa190a32bdaf517f222ea1.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 Project Genie 生成的虚拟世界中，你可以用 WASD 键移动角色、旋转视角、跳跃，在生成世界自由探索。更重要的是，其生成画面的精细度、整体完成度，已经明显超出以往研究型 Demo 的范畴，在观感上直逼成熟游戏产品。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去几年，世界模型一直被认为是通往AGI的重要路径，但始终存在一个根本问题：它们更像会动的视频，而不是真正的环境。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体来说，早期世界模型普遍存在几大短板：&lt;/p&gt;&lt;p&gt;生成世界质量偏低，结构简单难以实时交互，或只能交互一两步长期一致性差，画面和规则会“漂移”不符合物理和因果逻辑，更像梦境而非世界&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而 Project Genie，第一次把这些问题同时拉到了可用水平。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Project Genie 是一个基于 Genie 3、Nano Banana Pro 和 Gemini 构建的原型 Web 应用，其中的核心是谷歌最新的世界模型 Genie 3。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与以往“先生成完整视频”的方式不同，Genie 3 采用自回归生成机制：它会根据世界描述和用户操作，逐帧生成环境状态，而不是播放预先生成好的内容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这带来了几个关键变化：&lt;/p&gt;&lt;p&gt;长期一致性生成的世界可以在数分钟内保持稳定，不会快速崩坏；系统还能“记住”用户造成的关键变化，记忆时间最长可达约一分钟。真正的实时交互世界以 20–24 帧/秒运行，用户的操作会即时反馈到环境中，而非触发预设结果。更高质量的视觉表现生成画面分辨率约为 720p，整体真实感和细节水平明显高于以往世界模型，为智能体理解复杂环境提供了更可信的视觉基础。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;谷歌早在 2025 年就将 Genie 3 称为“通往 AGI 的关键一步”。而在 Project Genie的官方页面中，谷歌再次强调：&lt;/p&gt;&lt;p&gt;Genie 3 让智能体能够预测世界如何演化，以及自身行为如何影响世界，这是实现推理、规划和现实行动的基础。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;可以说，在 Project Genie 身上，已经释放出一个非常明确的信号：世界模型正在从长期的前沿研究方向，正式迈入可落地、可探索的关键阶段。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一旦世界模型能够稳定生成高质量、可交互、具备长期一致性的环境，其应用边界将被迅速打开。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;无论是自动驾驶中的复杂场景模拟、具身智能的环境理解与决策训练，还是游戏开发、影视制作、互动教育与新型媒体内容创作，世界模型都展现出极具想象空间的潜力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;据 The Verge 报道，谷歌选择在这一时间点推出 Project Genie，部分原因在于希望观察用户的真实使用方式，从而发现此前尚未预料到的新应用场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Google DeepMind 产品经理 迭戈·里瓦斯透露，谷歌内部已经对 Genie 在电影制作、互动教育媒体等领域，帮助创作者进行场景可视化与世界构建的潜力感到兴奋。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，Project Genie 仍是实验性产品：&lt;/p&gt;&lt;p&gt;单个世界最长探索 60 秒分辨率约 720p，帧率约 24fps仅向美国地区、18 岁以上的 Google AI Ultra 订阅用户开放&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Project Genie 发布后迅速引发热议。马斯克第一时间发文祝贺&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/85/85579d7d9dab73c5d0f4c381228253e6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关于Project Genie的讨论，也在X上迅速扩散，不少网友将其称为又一个“变革时刻”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a3/a3fb8c42bb19512c8783789adb722c7a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/40/4081b066da9e1809b558153dd3d8f49c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/9d/9d90c52846136975fee1e1a994bc81c6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e8/e83be3f6e3de7c74bbe215af6f14d168.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对此，Project Genie 负责人之一 Jack Parker-Holder 表示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Genie 3 感觉像是世界模型领域的一个分水岭。我们现在可以生成任何可想象世界的、持续数分钟的实时交互式模拟。这可能正是具身通用人工智能此前缺失的关键一环。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;网友们玩疯了，在游戏世界释放创意&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体来看，Project Genie 的使用流程并不复杂。进入页面后，用户可以直接从 Google 预设的多个世界模板中选择，也可以完全自定义环境和角色，构建一个专属的虚拟世界。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/cf/cfd807f4a169b4f6fa46da1db3c1b107.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为实现更精准的控制，Project Genie会用Nano Banana Pro的能力，先为生成世界打个“草稿”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整个页面被清晰地分成左右两部分：&lt;/p&gt;&lt;p&gt;左侧用于填写环境的 prompt，例如地形结构、视觉风格和整体氛围；右侧则用于描述主角的形象与设定，并可选择第一人称或第三人称视角，从而提前确定进入世界后的体验方式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;完成初步设定后，Genie 会先生成一个缩略图，可以对生成内容进行预览和微调。如果符合预期，就能进入生成世界，开始实时交互与自由探索。Genie 3 的响应延时非常低，在控制角色移动时，会带来强烈的沉浸感。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在官方案例中，你可以把自己变成一个球，在草原上自由滚动。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;可以看到，如果转换视角，球滚动留下的痕迹并不会消失，新生成的内容也不会覆盖旧区域。这一细节直观地体现了 Project Genie 所强调的世界一致性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在另一个官方案例中，你可以变成刷墙工人，想刷哪面墙就刷哪面，整个虚拟世界可以实时交互，且看起来十分合理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;谷歌表示，这是想象力空间的无限释放，无论是自然世界或现实场景，还是构建动画、小说中的奇幻世界，甚至是突破时间与空间限制的未来世界，都可以被创造出来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不少网友迅速上手，开始“放飞自我”式创作，其中，各类游戏风格世界不断涌现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比如在沙滩上骑摩托：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更绝的是直接制作山寨版“任天堂”游戏。比如马里奥系列，《塞尔达传说》，《银河战士》。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;即便抛开体验层面的不足不谈，Project Genie 在生成世界的质量与完成度上，依然足以令人震撼。这也难免让人产生进一步的联想，游戏从业者会不会大规模失业？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一担忧并非空穴来风。根据 Informa 本周发布的游戏开发者大会（GDC）报告，33% 的美国受访游戏开发者、以及 28% 的全球受访游戏开发者表示，他们在过去两年中至少经历过一次裁员。Project Genie可能会进一步扩大这种趋势。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过，围绕 Project Genie 的能力边界，也有人提出质疑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The Verge的记者亲自上手试验后认为，从“游戏”的角度来看，Project Genie 所生成的“可玩世界”显得相当单调。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;除了基础移动操作外，玩家几乎无事可做。没有任务目标，也缺乏音效反馈。更糟糕的是，输入延迟时有发生，甚至会出现角色失控、只能旋转视角的情况，严重影响整体体验的流畅度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该记者还提到，在仅有 60 秒 的探索时间内，世界的一致性并不稳定。系统有时会“忘记”此前生成的内容，例如滚动的小球留下的颜料痕迹会突然消失，已生成的道路也可能被重新覆盖为草地。这些现象让人难以确认模型是否能够持续、可靠地维护同一个世界状态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在内容生成层面，Project Genie 对知名游戏 IP 也存在明显限制。测试中，索拉、唐老鸭、高飞、杰克·斯凯灵顿等角色均无法直接用于生成可交互世界，相关内容在进入实际体验阶段会被系统拦截。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/55/55418fe66850ebe93c4f2e6ee0a26b3b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，与生成世界交互的智能体只能执行较为有限的操作，同一世界中多个模型之间也难以协同互动。此外，Genie 在渲染清晰文本、还原现实世界具体地点方面仍存在困难，智能体对控制指令的响应有时也会出现异常延迟。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对此，谷歌方面回应称，Genie 并非游戏引擎，团队更关注它在增强创意过程、提升构思能力以及加快原型制作方面所展现出的潜力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在Geinie 3官网上也特别强调，目前产品仍处于早期研究阶段，因此会有：生成的世界可能看起来并不完全逼真，也不一定总是严格遵循提示、图像或现实世界的物理规律；角色有时可能难以控制，或者控制延迟较高；生成时间受限等问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;Project Genie 团队深度揭秘关键问题&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 Project Genie 上线不久，其背后的核心团队第一时间接受采访，包括Google DeepMind研究总监Shlomi Fruchter、Google DeepMind的研究科学家Jack Parker-Holder、产品Diego Rivas，他们都对世界模型长期关注，在这次访谈中深度揭秘Project Genie的关键问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这次对话讨论了：什么是世界模型？为什么只能生成60秒？Project Genie的研发历程是什么？它未来真正可能改变的是哪些领域？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;他们首先承认Project Genie的强大确实源于谷歌视频生成技术的积累，但同时他们也强调，Genie并不是更强的“视频模型”，而是人类第一次可以实时走进、操控、改变的生成世界。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其中的核心差异是，世界模型是逐帧实时生成，能与过去保持物理与视觉一致性，并且用户可随时干预。这对延迟、内存、算力的要求，比普通视频生成高得多，也是更前沿、更有挑战的方向。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对不少人抱怨“60秒不够”的问题，他们表示这是在服务成本、系统稳定性和体验质量之间做出的权衡。他们其实已经做出过更长时间的生成世界，但在实际测试中发现，随着生成时间拉长，世界的动态感反而会逐渐减弱。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员表示“与其花两分钟体验一个世界，不如花一分钟体验两个不同的世界，体验感会更好。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对模型的生成速度，他们表示已经够快了，短期内进一步“加速”并没有太大意义。接下来，他们更重要的研发方向，是降低算力成本，让这种能力能够被更多人真正用得起。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在产品定位上，他们并不把 Genie 看作一款游戏，而更像是一个正在快速演化的实验场：&lt;/p&gt;&lt;p&gt;一方面，多人互动、长期一致性、复杂动态仍然是明确的技术瓶颈；另一方面，娱乐、教育、具身智能、机器人训练等方向，已经展现出非常清晰的应用前景&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回顾产品研发历程，从论文阶段的Genie 1，到今天普通用户可以亲自上手体验的Genie 3，这背后其实是谷歌一整套高度协同的跨部门合作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;谷歌实验室与谷歌创意实验室是研发的核心力量，而服务团队、基础设施团队和沟通团队则共同兜底，确保这项起源于强化学习的前沿研究，能够被真实用户理解、体验并持续使用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当团队回看去年八月时，他们很清楚，当时外界已经迫不及待想“走进这个世界”，但Genie仍然只是一个规模庞大的研究项目。即便如此，研发人员脑海中已经浮现出一系列潜在应用场景，其中最清晰的方向之一，正是具身智能。一个标志性的例子，是他们与 Simmer 项目的长期合作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Simmer 是由双子座模型驱动的目标导向智能体，能够在 3D 世界中执行复杂任务。过去，它只能在少数几个固定游戏环境中训练；而现在，借助Genie 3，只需一句文本指令，就能生成一个全新的、甚至是照片级写实的虚拟世界，把智能体直接“放进去”完成任务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从Nano Banana Pro 的图像创作，到谷歌视频生成的成熟，再到可交互的世界模型Project Genie ，生成式技术正在构成一个连续体，世界模型将成为第三次技术跃迁。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以下是播客的更多细节，欢迎来看：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;为什么只能60秒？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：我很好奇，这背后的物理逼真度，是不是和我们在 VO（谷歌的视频生成模型）项目上取得的研究突破有关？感觉两者之间有相似之处。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：二者绝对是相关的，而且世界模型的研发难度其实更高。普通的视频模型，能在整个视频的时间线上自由调整过去和未来的帧，自由度很高 —— 就像有一块画布，模型能随时间生成视频，在画面的各个位置做微调，让整体效果连贯美观。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但世界模型的难点在于，世界是持续演变的，每一帧的输入都是未知的，模型必须保证生成的画面既和过去的内容连贯，又能匹配用户当下的操作，所以技术难度会大很多。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其实开发Genie 1时，我们用的是 Imagine 模型，当时我们的模型效果并不好，而且想要生成合适的图像也非常困难。Nano Banana Pro 是在Genie 3之后推出的，技术进步的速度真的令人惊叹。也许未来某一天，我们定义虚拟世界的方式，将不再局限于图像和文本，但就目前而言，这种方式已经给了用户足够的创作灵活性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：这个模型的复杂度上限在哪里？比如能不能在同一个世界里加入大量并行的互动元素？模型会在什么情况下出现效果衰减？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其实 Nano Banana Pro 就是个很好的例子，如果一张图片里有 10 个人脸，想要对这张图进行编辑，模型就容易出问题。所以我想知道，Genie 3的自然性能边界在哪里？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：这个模型肯定不是完美的，目前它还只是一个研究预览版本。我们希望让大家亲自体验，看看它的优势在哪里，不足又在哪里，我们也能从用户反馈中学习和优化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前模型在各类创意环境的视觉呈现上做得不错，画面可以非常精致，但在世界的动态表现上还有短板 —— 有时候初期的动态效果很好，但时间久了，动态感会逐渐减弱，这也是我们正在优化的点。不过它的表现已经足够令人惊喜了，所以还是建议大家亲自上手试试，看看哪些玩法能达到理想效果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：不过说到延迟问题，还有很多技术点需要考虑。Genie 3的研发有一个核心约束：我们希望实现特定操作频率下的实时低延迟，也就是说，用户操作的往返延迟要极低。同时，内存也是一个巨大的约束 —— 模型的上下文长度越长，通常算力成本就越高，运行速度也会越慢。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以研发的核心挑战，就是平衡这些相互冲突的目标。而在研究层面，我们正在所有这些领域持续优化，我们相信，模型的性能会不断提升，变得更强大、更快、更经济，这也是行业的整体发展趋势。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：我还有个问题，模型的生成时长是人为限制在 60 秒，还是真的能实现 3 到 5 分钟的连续生成？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：其实我们已经做出过能连续生成更久的演示版本了，但我们觉得 60 秒是一个比较合适的时长 —— 既能让用户充分体验虚拟世界，又能保证为足够多的用户提供服务，这其实是在服务成本上做的权衡。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而且就像我们之前提到的，生成时间越长，世界的动态感会逐渐减弱。所以我们觉得，与其花两分钟体验一个世界，不如花一分钟体验两个不同的世界，体验感会更好。当然，如果用户反馈希望延长时长，我们也会做出调整。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这也和虚拟世界的类型有关，比如如果你在体验高山速降滑雪，两分钟的时长会很过瘾，因为整个过程是持续的动态体验；但如果只是探索图书馆，两分钟可能就没那么有趣了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：是啊，人们总是能很快适应新的技术体验。但对我来说，这个模型的表现依然令人难以置信。你之前被问到能不能让模型运行得更快，现在的速度已经到极限了吗？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：在当前实时交互需求下，生成速度已经足够快，短期内进一步加速的意义不大。因为模型是实时生成虚拟世界的，速度再快其实也没有意义了 —— 它的生成速度已经和用户的体验速度完全匹配。接下来我们的研发重点，会放在降低算力成本上，这样才能让更多人用上这款产品。同时，在保持速度的前提下，不断增加新功能，这本身也是一个巨大的挑战，我们希望在各个方面都把模型做得更好。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;背后的故事：谷歌跨团队协作&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：聊完当下的体验，我特别想知道模型的未来迭代方向。不过在聊未来之前，我们先回顾一下研发历程吧。我们八月份发布了Genie 3的首支演示视频，之后启动了可信测试，不断迭代产品、搭建基础设施。能不能跟大家快速讲讲，从一支惊艳的演示视频、小规模的早期测试，到正式推出面向用户的精灵计划，这中间都经历了什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：首先，八月份发布模型和演示视频后，我们让一小部分人体验了产品，核心是为了收集反馈 —— 因为这是一款全新的应用，一种全新的体验，我们需要思考如何负责任地将它推向市场。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从那以后，我们的大部分工作都集中在基础设施、服务架构和成本控制上，毕竟我们希望能让尽可能多的用户体验到它。而美国的谷歌 Ultra 订阅体系，能让我们触达足够多的用户，收集到第一手的反馈：比如用户觉得哪些功能有用，会如何和产品互动，哪些玩法体验最好。这段时间里，我们也在持续完善可信测试项目。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这其实是模型开发周期中最核心的阶段，因为我们能从不同类型的用户身上学到很多东西，无论是创意工作者，还是教育领域的从业者，都能给我们带来丰富的洞察，让我们知道模型目前的实际应用价值、未来的发展方向，以及哪些体验是用户最期待的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回头看八月份，当时我们知道大家肯定想体验这款产品，但它那时还只是一个大规模的研究项目。我们脑海里有很多应用场景，比如智能体、机器人这类具身智能领域，都能用到这项技术。去年年底还有一个和我们类似的项目发布，他们也用Genie 3来训练游戏智能体。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从消费端的角度来看，我们觉得这个产品会很有吸引力，所以想收集用户反馈，但当时也不确定是否已经到了面向更多用户发布的时机。而迭戈主导的可信测试项目，让我们发现，用户第一次上手这款产品时，都会有惊艳的体验。我们希望深入了解更多的应用场景，所以这次的发布，也是我们在这方面迈出的一大步。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一年前，我根本没想到这个模型能有这么强的吸引力，但现在它已经成为一款非常有趣的产品，我们也很期待大家会用它来做什么。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：聊完产品和技术，我们再来聊聊谷歌的跨团队合作吧。显然，从你们的分享和幕后工作来看，打造这款产品的难度非常大。谷歌内部有哪些团队参与了Genie 3和Genie的研发？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：幕后参与的团队非常多，谷歌实验室、谷歌创意实验室是核心 —— 画廊里的那些虚拟世界，大多是创意实验室的作品；还有服务团队、基础设施团队，基本上有一个完整的幕后团队在推动这项工作。从八月份发布模型到现在，我们一直在全力冲刺，所有团队的付出都堪称英勇。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们还和沟通团队深度合作，因为想要向大家解释一款全新的模型，一种大家从未体验过的技术，是一个非常细致的话题 —— 它起源于强化学习这个相对小众的领域，现在却被媒体、社交媒体上的各类人群广泛讨论，所以用正确的方式传递这项技术，非常重要。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回顾这个领域的研究起点，我们甚至不确定这项技术能否成功落地。而现在，我们让它实现了实时交互，达到了不错的画质，完成了从研究构想到发布模型，再到推出面向用户的体验产品的闭环，这一点让我非常兴奋。这并非理所当然，也充分体现了谷歌内部跨技术栈的团队协作能力，这种能力非常独特。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：我们在镜头外还聊过，不仅是Genie 3，谷歌所有模型的能力都在不断拓展，而这和模型的训练方式息息相关。杰克，你之前还尖锐地提到，这些模型其实并没有针对任何特定的应用场景进行训练，却能在各个领域实现很好的泛化能力，能不能再聊聊这一点？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：没错，我们一开始其实并不知道这个模型的具体应用场景。去年年底，Genie 团队还在做纯粹的研究项目，Genie 1最初只是一篇研究论文，和 VO（谷歌的视频生成模型）完全不同。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与此同时，我们还在做 Doom 游戏引擎的相关研究，这项研究充分展现了实时交互的潜力，但它仅适用于 Doom 这一个特定的游戏世界，迭戈可以再聊聊这一点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另外，2024 年 12 月 VO（谷歌的视频生成模型）2 的发布，在 AI 领域已经是很久以前的事了，但当时我看到它的效果时就觉得，视频生成技术已经成熟了，视觉质量达到了行业前沿，值得我们深入探索。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;于是我们达成共识，认为这项技术的潜力无限，随后组建了跨团队的研发小组，汇集了各个领域的专家 —— 他们都在不同的技术领域有积累，我们相信把这些技术结合起来，会产生不可思议的效果。而我们的研发，并非针对某个特定的下游应用场景，而是因为它蕴含着无数的应用可能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最酷的是，我们脑海里有一些预想的应用场景，比如和 Simmer 项目的合作，我们和这个项目的合作已经有很长时间了，他们也参与了Genie 2的研发，体验过Genie 2，现在已经基于Genie 3发布了相关产品。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Simmer 是我们最强大的目标导向智能体之一，能在 3D 世界中互动，是由双子座模型驱动的 —— 你可以在 3D 世界中向它输入文本指令，它就能完成各种不同的目标，泛化能力非常强，还能通过自我提升学习。这也是我们迈向通用人工智能、具身智能的重要方向。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;去年年底我们发布了这款智能体，他们就用Genie 3的虚拟世界来探索智能体的能力。要知道，Simmer 原本只在几款游戏中接受过训练，但现在借助Genie 3，你只需输入文本，就能创建一个全新的、甚至是照片级写实的虚拟世界，然后把智能体放进去，看它完成各种任务。这两个项目的结合，可以说是水到渠成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;未来的应用领域：娱乐、教育、具身智能&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：从应用层面来说，我个人对娱乐和教育领域的应用最期待。我们希望让更多人体验这款产品，看看凭借现有的技术，现在能打造出哪些应用。教育领域是我们重点关注的方向，比如让人们在虚拟世界里互动学习 —— 想象一下，能为用户打造一些他们在现实中无法体验的场景，比如一个孩子害怕蜘蛛，我们可以打造一个满是蜘蛛的房间，让孩子在虚拟世界里慢慢适应，克服恐惧。我的孩子就怕蜘蛛，所以我觉得这种个性化的全新体验，价值非常大，这也是我们近期的研发重点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另一方面，我们之前也聊过，机器人技术和具身智能领域的世界模型，潜力也非常大。当然这个领域还有很多研究工作要做，但我个人对它充满期待。简单来说，核心思路就是：如果一个模型能模拟现实环境，那我们就可以用它在虚拟世界里训练机器人，或是让具身智能体在虚拟世界里学习，甚至实时辅助智能体做出决策。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Genie 计划虽然现在已经很惊艳了，但它只是一个起点。未来我们会和谷歌实验室继续深度合作，不断优化产品的功能、操控方式、应用架构等；也会拓展更多的使用场景，不局限于Genie 计划这一个应用，还会推出开发者 API，让更多开发者参与进来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不得不说，开发者总能发掘出产品的商业价值，找到极具经济影响力的应用场景，这也是我觉得很有意思的一点 —— 除了娱乐，世界模型还能在哪些领域找到产品市场契合点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而且很多功能在不同的应用场景中是相通的，比如更广泛的交互性。可以肯定的是，机器人技术的发展，不可能只靠方向键来实现，未来的机器人助手需要更多的操控方式，而这和虚拟世界的交互研发是相通的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;八月份发布Genie 3，让我们成为首批推出这类模型的团队，也让我们能和谷歌内部的各个团队展开合作。我们会认真吸纳所有的用户反馈，把大家提出的建议都列出来，成为下一代模型的研发方向。我之前跟杰克说过，我们只实现了目标的 50%—— 因为我们总是会设定极具野心的目标，这个领域还有太多可以探索的地方，模型还有很多不足，需要我们不断优化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个领域的发展空间巨大，我们才刚刚起步。就像写论文一样，一个项目完成后，你马上就会想，下一个项目可以加入哪些功能，做得更好。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;现在社区里也出现了很多有趣的世界模型，有些和Genie 3很相似，但我们的目光已经放得更远了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;怎么玩这个产品？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：除了研发历程和未来规划，还有没有什么想跟大家分享的？比如对于即将体验这款模型的用户，你们有什么建议？毕竟你们比普通人花了更多时间研究和使用模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：我建议大家尝试个性化创作，打造属于自己的、其他系统无法实现的世界。当然，用它打造游戏环境也很有趣，但这类场景其他系统也能做到；而把现实中的专属事物 —— 比如一个玩具、一张照片，或是让自己以特定风格出现在真实的环境中，这种体验是独一无二的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这让我想起了 VO（谷歌的视频生成模型）早期的一个研究项目：有人用 VO（谷歌的视频生成模型）为阿尔茨海默病患者重现童年记忆，让他们在虚拟世界里重温过去，这个项目特别棒。所以我觉得，把个人专属的事物融入虚拟世界，让它们 “活” 过来，这种互动方式非常有价值，大家可以试试这个方向。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另外，大家肯定会发现，模型的提示词创作目前还不够完善，但这恰恰是机会。几年后当这个模型变得非常成熟时，大家会想起现在这个阶段，就像我们现在看待 VO（谷歌的视频生成模型）3 一样 —— 现在 VO（谷歌的视频生成模型）3 的每个提示词都能生成优质视频，精灵 3 号的每个提示词基本也能实现预期效果，但在早期，提示词的创作至关重要，甚至有人会花 10 到 20 分钟精心打磨一个提示词。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以如果第一次创作的效果不好，别放弃，这款全新的模型，可能会以你意想不到的方式呈现出惊喜的效果。而且亲自上手体验，你就不是在消费一款产品，而是在探索前沿技术。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：太认同了，“探索前沿技术” 这句话简直可以当作产品标语了。我还有一个觉得很有趣的点：当被动的媒体消费变成交互式的体验，会发生什么？这是一片全新的未知领域。过去也有人做过尝试，但现在有了这种真正定制化的交互式媒体叙事，它会给整个媒体和娱乐行业带来什么影响，真的太值得期待了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：还有一个玩法也很有趣，你可以在虚拟世界里设置挑战，把这个世界分享给别人，让对方完成任务，比如从 A 点走到 B 点。这是一种基础的、有目标的游戏体验，现在的模型已经能实现了。比如那个球的场景，你可以让别人用球写出自己的名字，这类简单的挑战都能设置。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;就像杰克说的，现在的体验虽然还比较基础，但它蕴含着巨大的创意潜力。比如还有一个带环的场景，你可以操控角色穿越环道，体验飞行的感觉，这也是用户发掘的玩法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;人们还经常问，行业的前沿在哪里，我们下一步要做什么。我经常会做一件事：长时间沉浸在Genie 3的第一人称写实世界里，然后看向窗外，对比虚拟和现实的差距。我认为最终，虚拟世界会和现实世界变得几乎无法区分，虽然今天我们不深入聊这个话题，但从模型的性能发展来看，这显然还有很长的路要走。但如果能生成和现实高度逼真的世界，在里面自由移动、互动、完成各种事情，那该多不可思议。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而这也是驱动我们开展这项研究的核心愿景：想象你拥有一个宇宙的副本，你可以在其中随心所欲。显然，这个副本有巨大的应用价值，能用到很多领域。这虽然是一个非常远大、甚至可能无法实现的目标，但它就像北极星一样，一直指引着我们。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比如我们这次把恐龙鲍勃放进虚拟世界，其实就是在重构现实空间，给现实事物做有趣的增强。未来这方面的探索，一定会非常有意思。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：那到Genie 5的时候，我们可能真的会分不清自己是在现实还是在模拟世界里了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;世界模型是第三次技术跃迁&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：我还有一个有点尖锐的问题想问问大家：你们觉得，大多数人体验到世界模型的时间线会是怎样的？世界模型会先通过企业端影响普通人的生活吗？比如企业利用世界模型提高生产效率，打造更好的日常产品；还是说，未来普通人的日常生活中，会直接和世界模型产生互动？如果是后者，这个时间线大概会是多久？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：这其实取决于你如何定义世界模型。如果是指交互式的视听体验类世界模型，我认为今年、明年，就会有越来越多的人接触到它，我们也会看到它在一些领域大放异彩，最终成为很多应用的基础功能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但就像现在的视频生成技术，虽然发展很快，但真正融入普通人日常生活的比例其实并不高，世界模型也需要时间来完成用户普及，找到合适的应用场景 —— 毕竟视频和图像不同，世界模型又和视频生成不同。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而如果是具身智能领域的世界模型应用，很难给出具体的时间线，但这个领域已经在取得不错的进展了。&lt;/p&gt;&lt;p&gt;另外，用户的人群特征也很重要：有些经常接触交互式媒体的人，会成为世界模型的早期使用者，他们知道该如何体验；但如果把它交给一个对前沿技术不感兴趣的家人，他们可能会觉得无从下手，体验不到产品的魅力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但具身智能相关的应用，可能在未来 1-2 年就会走进现实，普通人会在生活中直接接触到，所以最终的普及时间，还是取决于用户所处的技术接受曲线位置。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;还有一点，Genie计划也印证了一个趋势：生成式技术正在形成一个连续体，从 Nano Banana Pro 的图像创作，到 VO（谷歌的视频生成模型）的视频生成，再到现在Genie 3的交互式实时媒体创作，成为第三个核心支柱。我们希望未来有更多人能体验到这个连续体上的各类创作体验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：我特别期待看到行业的发展趋势，毕竟 VO（谷歌的视频生成模型）和 Nano Banana Pro 的发展过程中，都出现过一些爆红的玩法，都是我从未预料到的，太疯狂了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：世界模型的发展，和图像、视频生成还有些不同。图像和视频生成的作品，能被数百万人观看，一个人的创作可以被广泛传播，家人、朋友都能看到；而世界模型的独特之处在于，你可以在探索的过程中，不断改变周围的世界，这开辟了很多我们未曾考虑过的新途径、新玩法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;图像和视频生成，本质上是用新技术替代或自动化了过去的一些创作方式，当然也带来了新的能力和限制；但世界模型，实现了很多过去根本不可能做到的事情，这是它最大的不同，当然二者也有很多相似之处。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;还有一个我们非常兴奋的想法，大家在演示中也能看到端倪：用户可以在现有虚拟世界的基础上继续创作，这样就会形成很多有趣的世界分支，还能追溯创作源头。这方面的潜力非常大，值得我们深入探索。&lt;/p&gt;&lt;p&gt;Genie 计划上线时，用户可以下载自己的虚拟世界演示视频；未来我们还会探索更多的世界分享方式，让大家能以更有趣的方式在别人的世界基础上创作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：太酷了，我还想要一个 “世界档案” 功能，这样大家就能看到我所有的创意想法了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从世界模型的发展来看，技术进步的节奏是怎样的？显然我们已经看到了巨大的进步，图像生成、VO（谷歌的视频生成模型）视频生成、核心双子座模型，都取得了长足的发展。世界模型是不是也在遵循同样的发展轨迹，到处都是触手可及的技术突破，同时受益于算力规模和推理能力的提升？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;研究员：可以这么说。图像生成技术显然比视频生成更成熟，视频生成和世界模型之间的差距，我无法准确衡量，但可以肯定的是，世界模型是超越视频生成的前沿技术。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最新一代的视频生成模型，画质已经比Genie 3高很多了，我们也不指望Genie 3现在能生成极致精美的视频，因为实时交互的约束，是普通视频生成模型所没有的。所以世界模型的发展，可能会比视频生成稍慢一些，但它能带来全新的体验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;说实话，我们现在仍处于技术快速进步的阶段。硬件始终是一个巨大的约束，这对所有模型来说都是如此。行业的整体趋势是，在成本基本不变的情况下，让模型的运行效率越来越高。但最终，我们还是需要更易获取的硬件支持 —— 比如希望未来人们能直接在自己的设备上运行这类模型，实现无延迟的即时体验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前高性能的 TPU、GPU 还并非人人可得，硬件的发展速度因为一些实际原因，会比模型研发慢一些，但这也是我们的未来方向 —— 希望到Genie 5时，大家能在手机上运行完整的通用模拟系统。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一点我们也讨论过，谷歌拥有垂直技术栈的优势，这也是我们在谷歌、在深度思维工作的魅力所在：我们既能站在模型研发的前沿，又能利用谷歌最好的硬件来支持模型的运行。而且专门为世界模拟打造的硬件，本身也极具发展潜力，它就像通往另一个维度的入口，点击就能进入，充满了新鲜感。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;传送门：&lt;/p&gt;&lt;p&gt;https://labs.google/projectgenie&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;链接：&lt;/p&gt;&lt;p&gt;https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/&lt;/p&gt;&lt;p&gt;https://deepmind.google/models/genie/&lt;/p&gt;&lt;p&gt;https://www.youtube.com/watch?v=Ow0W3WlJxRY&amp;amp;t=4s&lt;/p&gt;&lt;p&gt;https://www.theverge.com/news/869726/google-ai-project-genie-3-world-model-hands-on?view_token=eyJhbGciOiJIUzI1NiJ9.eyJpZCI6ImZCakl0bmxFNGwiLCJwIjoiL25ld3MvODY5NzI2L2dvb2dsZS1haS1wcm9qZWN0LWdlbmllLTMtd29ybGQtbW9kZWwtaGFuZHMtb24iLCJleHAiOjE3NzAxNDAwNTYsImlhdCI6MTc2OTcwODA1OH0.q5OBTD_V36-65oc1EGqPxKYCZF00c7ODvifvagVcwbA&amp;amp;utm_medium=gift-link&lt;/p&gt;</description><link>https://www.infoq.cn/article/NC3jkcH9qgVjb8Q36sl2</link><guid isPermaLink="false">https://www.infoq.cn/article/NC3jkcH9qgVjb8Q36sl2</guid><pubDate>Fri, 30 Jan 2026 10:46:49 GMT</pubDate><author>高允毅</author><category>生成式 AI</category><category>Google</category></item><item><title>预算有限、技术空白：最刁钻的AI用户，是中小企业老板</title><description>&lt;p&gt;2026年，大模型已经不再稀缺，但它在中小企业的办公环境中处境却很骨感。市场部用通用聊天机器人写促销文案，结果因工具不理解“BOM表”“良品率”等术语，导致员工反复返工；法务人员还在逐字比对几十页合同，在密密麻麻的条款里找差异；客服团队被重复问题淹没，而公司花了几万元采购的AI工具，始终没能真正嵌入业务流程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;问题在于工具离场景太远。当算力和模型能力变得普及，企业要的不再是“更强的大模型”，而是一个能理解自己业务、快速跑起来、带来实际收益的智能助手。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;行业正在悄然转向。AI算力需求从训练转移至推理，推理算力需求增长4倍；算力消费模式从买卡转移到买Token，Token消耗量增长53倍；几乎所有企业都在通过智能体的方式消费Token。华为云和华为云伙伴都观察到，客户不再纠结参数规模，反而关心“它能帮我解决什么具体问题”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;华为云看准了这个拐点。今年1月23日，华为云在“华为云中国区销售伙伴产品方案发布会”上，隆重介绍了Flexus&amp;nbsp;AI智能体——一个专为中小企业设计的轻量化、场景化智能体平台。它聚焦于更专业的场景、追求更精准的效果，并致力于实现极简部署。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Flexus&amp;nbsp;AI智能体依托华为自研的搜索大模型，攻克了搜索精度的关键难题。在企业知识问答、智能数据查询等高频场景中，其准确率领先业界平均水平2至9个百分点。在发布会现场的实时对决中，面对权威数据集的严格考验，Flexus&amp;nbsp;AI智能体更以100%的准确率胜出，充分证明了其性能的领先性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该平台重点覆盖互联网、金融与保险、医疗健康、制造业、零售/电商、专业法律服务及教育等行业。其创新的&amp;nbsp;“Solution&amp;nbsp;as&amp;nbsp;Code”&amp;nbsp;功能，能将企业级应用场景打包成“即取即用”的模板，这使Flexus&amp;nbsp;AI&amp;nbsp;智能体超越了工具属性，成为优秀实践经验的高效载体。此外，华为云的“天筹AI求解器”还能为工业、物流等复杂场景提供最优决策支持，切实帮助企业降本增效。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Flexus&amp;nbsp;AI&amp;nbsp;智能体的目标十分明确：让即便没有专职AI团队的中小企业，也能在几天内部署一个真正“懂行”的智能助手。这背后，折射出华为云对AI商业化下半场的核心判断——最终的战场，在于帮助客户实现业务价值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;为中小企业制造的AI&amp;nbsp;智能体&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去十年，云计算在中小企业中完成了从“可选项”到“必选项”的演进。如今，人工智能正经历相似的关键跃迁。然而对广大中小企业而言，这场技术浪潮并非坦途：它们并不缺乏拥抱AI的意愿，却普遍困于三大现实挑战——应用场景模糊、技术门槛高企、投入产出难以量化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;华为云敏锐捕捉到这一结构性变迁，依托在工程化落地、场景理解与企业级服务领域的长期积累，将Flexus&amp;nbsp;AI智能体定位为通向长尾市场的“轻量化入口”。产品设计源于对典型中小企业客户的深度洞察：预算有限、缺乏专业IT团队、需求表达不清晰，却对数据安全与成本控制高度敏感。其目标清晰而务实——回应中小企业“用得起、用得上、用得好”的朴素诉求，同时在AI商业化深水区开辟差异化增长路径。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;作为面向泛行业中小企业的轻量化平台，Flexus&amp;nbsp;AI智能体以“开箱即用、高性价比、安全可控”为核心理念，通过四大能力直击AI落地痛点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;丰富模板库：提供40余个源自真实企业实践的预置场景，覆盖舆情监测、报告撰写、客服问答、知识检索等通用与行业需求，大幅降低启动成本；一站式平台：支持可视化编排与一键部署，无需编码即可完成智能体构建与发布，数日内即可上线业务助手；安全可控：支持公有云调用与私有化部署双模式，保障数据主权与合规要求；底座协同：深度集成华为云Tokens服务与昇腾AI算力，保障高并发稳定性，并自然带动ECS、数据库、KooSearch等云资源的协同消耗。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;相较于华为云生态内面向大型企业、强调深度定制的平台，Flexus&amp;nbsp;AI智能体聚焦轻量化通用场景，在办公、营销与服务等高频领域追求极致的简便与实用，形成清晰的差异化定位。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尤为关键的是，该产品精准破解了AI落地的“最后一公里”难题——企业知识问答。当前，企业普遍采用“检索增强生成（RAG）”技术赋予大模型专业知识，但效果瓶颈往往不在模型本身，而在于前端检索精度不足：传统关键词检索难以理解语义，易在海量知识库中漏检或错检，导致智能助手“答非所问”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对此，Flexus&amp;nbsp;AI智能体内置的企业级搜索服务成为破局关键：以华为自研的中文文本向量大模型为底座，具备出色的语义理解能力；其检索引擎在权威基准测试中表现优异，实现精准高效的语义匹配；通过架构优化，关键性能指标显著优于主流开源方案，同时有效控制成本。最终，企业获得的不再是一个“听起来聪明”的对话机器，而是一位真正精通业务、检索精准、响应迅捷的可靠数字助手。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一能力已在多行业实战中快速验证：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;互联网与出海企业：用于语义级信息检索、舆情监测及动态视频生成，一键部署覆盖电商、科研与物流的AI工具链；金融与保险：实现研报自动生成、财务风险预算、智能审计及反欺诈风控，部分保险场景复用自医疗行业的成熟实践；医疗健康：深入辅助诊疗、影像分析与报告解析，为医疗机构提供研发助手；制造业：应用于工业质检、包装检查、生产安全检测、设备预测性维护、高炉工艺控制和性能预测等领域；零售与电商：&amp;nbsp;场景涵盖用户运营、门店巡检等。某国内头部奶茶品牌一周内所有门店系统均上线智能体，月付费仅4万元；教育行业：可用于内容生成与学术支持、教学辅助等；法律行业：&amp;nbsp;Flexus&amp;nbsp;企业搜索服务在中国法律智能技术评测中斩获类案检索一等奖；某住宅设计公司已将Flexus&amp;nbsp;AI&amp;nbsp;智能体深度用于合同风险条款识别与合同比对中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这些案例背后，是一套真正为中小企业量身打造的AI落地路径：无需技术积累、不必重金投入，只需聚焦自身业务，就能快速用上AI。Flexus&amp;nbsp;AI智能体以“场景更专、效果更精、使用更易”为原则，提供开箱即用的模板和零代码操作体验，配合免费调优支持，真正做到“一天出Demo、一周上线见效”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;全流程测评：智能体如何进入内容生产？&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;作为专注于科技行业的内容创作者，我们始终在寻找能够提升信息处理深度与效率的工具。内容创作，尤其是科技领域，面临着信息过载、源头繁杂、热点更迭迅速的常态挑战。在策划一个深度选题时，从海量噪音中快速梳理出主线、定位核心矛盾，往往消耗大量精力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，我们对华为云Flexus&amp;nbsp;AI智能体进行了体验。我们最近正在研究中国AI硬件出海战略与挑战，这个方向既涉及复杂的技术趋势研判，又牵涉多变的国际贸易政策环境。为此，我们尝试使用华为云Flexus&amp;nbsp;AI智能体矩阵辅助完成前期调研。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们的测试分两步走：先让“深度研究报告撰写”智能体勾勒全球产业趋势图谱，再请“国家政策研究与比较”智能体扫描关键市场的准入壁垒。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当我们要求“深度研究报告撰写”智能体研究2020-2026年AI智能硬件的行业发展趋势时，智能体并未直接输出结论，而是首先展示其思考路径——将问题拆解为市场规模、产品形态、技术演进、竞争格局和应用场景五个维度，并据此构建报告结构。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种结构化处理带来了三个实际价值：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;节省框架搭建时间：几分钟内生成的研究提纲，覆盖了边缘AI设备渗透率、AI&amp;nbsp;PC出货量、NPU/GPU融合架构等关键议题，避免了从零开始的信息筛选。聚焦核心变量：通过数据表格（如各细分市场CAGR、厂商份额预测）和趋势关键词，帮助我们快速识别哪些是驱动变化的关键因子。提供可扩展基础：输出内容并非封闭结论，而是带有明确数据来源提示和逻辑节点的“半成品”，便于后续人工验证与观点深化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;紧接着，我们请“国家政策研究与比较”智能体“研究美国、欧洲和印度，在进口中国AI智能硬件时不同的海关政策。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;智能体没有给出模糊或笼统的结论，而是立即先建立了一个清晰的四维比较分析模型：关税结构与HS编码、技术性贸易壁垒（认证）、国家安全审查、政策演变趋势。这直接对应了企业出海实操中必须面对的四大关卡。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;差异化逻辑的提炼：在反馈中，智能体不仅罗列了FCC、CE、BIS等认证差异，更尝试归纳出不同市场的核心监管逻辑：美国的“科技遏制与长臂管辖”、欧盟的“规则主导与伦理审查”、印度的“贸易保护与产业替代”。这种对政策背后战略意图的解读，远比单纯列举条款更有洞察力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这些归纳虽需进一步验证，但已为后续针对性调研提供了清晰的问题清单和方向指引。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;综合来看，Flexus&amp;nbsp;AI&amp;nbsp;智能体的核心优势不在于“给出答案”，而在于“组织问题”。它通过结构化拆解，将模糊、宽泛的研究需求转化为可操作的分析路径，显著缩短了从信息搜集到洞察生成的链条。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一能力不仅适用于科技内容创作，在财经报道、政策简报、市场进入评估等需要快速处理多源信息并输出逻辑清晰内容的场景中，同样具备实用价值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Flexus&amp;nbsp;AI智能体的价值不在于炫技式的能力，而在于将AI真正嵌入中小企业的业务流。在AI从技术热词走向商业落地的关键阶段，华为云选择以轻量化、模板化、安全可控的方式切入长尾市场，既回应了中小企业“用得起、用得上、用得好”的核心诉求，也重新定义了AI产品的价值标准：不是参数多大，而是离业务多近。&lt;/p&gt;</description><link>https://www.infoq.cn/article/ZGQys2f6BuEpytzqNLUu</link><guid isPermaLink="false">https://www.infoq.cn/article/ZGQys2f6BuEpytzqNLUu</guid><pubDate>Fri, 30 Jan 2026 09:46:10 GMT</pubDate><author>杨过</author><category>云计算</category><category>AI&amp;大模型</category></item><item><title>“天下苦CUDA久矣！”KernelCAT率先掀桌，实现国产芯片无痛适配</title><description>&lt;p&gt;2026 年 1 月底，英伟达 CEO 黄仁勋再次来华，刻意亲民的“菜市场外交”插曲不仅又一次引发热议，也让很多人回想起老黄在 2025 年 1 月，宁愿缺席美国总统特朗普就职典礼，也要来中国参加分公司年会、维护客户的有趣往事。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;作为市值逾 4.5 万亿美元的 AI 巨头掌门人，老黄为何如此重视中国？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/wechat/images/88/882ad7697fdc8328b84b398e401f293d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种重视的根源，在于中国 AI 产业与英伟达 GPU 及 CUDA 生态之间的双向深度依赖。一方面，中国主流 AI 模型的训练仍高度依赖英伟达芯片，且需在 CUDA 生态中加速迭代，以此追赶美国闭源模型的实力；另一方面，中国庞大的 AI 市场、优质的 AI 人才，以及台积电、富士康等核心供应链企业，共同撑起了英伟达的庞大估值与商业霸权。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;智能的繁荣与底层的“枯竭”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;中国 AI 的表层繁荣有目共睹：大模型发布数量占全球 40% 以上，稳居世界第一；Qwen 登顶 Hugging Face 全球下载榜，累计下载超 10 亿次；“豆包”日均活跃用户数（DAU）破亿，2025 年国产 AI 应用总下载量达 25.7 亿。这一切营造出一种错觉：中国人工智能的道路已是一片坦途。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然而，剥开这层光鲜外衣，国产 AI 的根基却异常脆弱。尽管本土芯片厂商在硬件设计与制造上奋力追赶，软件生态的缺失却成为难以逾越的鸿沟。高昂的迁移成本、对 CUDA 的路径依赖，使得国产模型即便想用“国产芯”，也常因缺乏高效、兼容的算子支持而寸步难行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更严峻的是，这种依赖本质上是算力主权的交锋：国际芯片巨头每一分估值增长的背后，都可能是国内算力产业的被动与掣肘。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;要打破这一困局，关键不在造更多芯片，而在打通“算法—算子—硬件”之间的最后一公里，尽可能多得释放国产芯片的理论峰值性能，建设自己的国产芯片生态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其中最核心的一环，正是高性能算子的开发。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;KernelCAT：计算加速专家级别的 Agent&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;算子（Kernel），是连接 AI 算法与计算芯片的“翻译官”：它将算法转化为硬件可执行的指令，决定了 AI 模型的推理速度、能耗与兼容性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;算子开发可以被理解为内核级别的编程工作，目前行业仍停留在“手工作坊”时代——开发过程极度依赖顶尖工程师的经验与反复试错，周期动辄数月，性能调优如同在迷雾中摸索。若把开发大模型应用比作“在精装修的样板间里摆放家具”，那么编写底层算子的难度，无异于“在深海中戴着沉重的手铐，徒手组装一块精密机械表”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果，让 AI 来开发算子呢？传统大模型或知识增强型 Agent 在此类任务面前往往力不从心：它们擅长模式匹配，却难以理解复杂计算任务中的物理约束、内存布局与并行调度逻辑。唯有超越经验式推理，深入建模问题本质，才能实现真正的“智能级”优化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;正是在这一“地狱级”技术挑战下，KernelCAT 应运而生。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/wechat/images/8f/8faf0bf997be96bcfd5f8bcb5396620f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;KernelCAT 是一款本地运行的 AI Agent，它不仅是深耕算子开发和模型迁移的“计算加速专家”，也能够胜任日常通用的全栈开发任务，KernelCAT 提供了 CLI 终端命令行版与简洁桌面版两种形态供开发者使用。不同于仅聚焦特定任务的工具型 Agent，KernelCAT 具备扎实的通用编程能力——不仅能理解、生成和优化内核级别代码，也能处理常规软件工程任务，如环境配置、依赖管理、错误诊断与脚本编写，从而在复杂场景中实现端到端自主闭环。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/wechat/images/69/6920f6c41c59b89f3d72dd73255fd27b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;为国产芯片生态写高性能算子&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在算子开发中，有一类问题很像“调参”——面对几十上百种参数或策略组合，工程师需要找出让算子跑得最快的那一组配置。传统做法靠经验试错，费时费力，还容易踩坑。KernelCAT 引入了运筹优化的思路：把“找最优参数”这件事交给算法，让算法去探索调优空间并收敛到最佳方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以昇腾芯片上的 FlashAttentionScore 算子为例，KernelCAT 在昇腾官方示例代码上，可以自动对该算子的分块参数调优问题进行运筹学建模，并使用数学优化算法求解，在十几轮迭代后就锁定了最优配置，在多种输入尺寸下延迟降低最高可达 22%，吞吐量提升最高近 30%，而且而整个过程无需人工干预。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这正是 KernelCAT 的独特之处：它不仅具备大模型的智能，能够理解代码、生成方案；还拥有运筹优化算法的严谨，能够系统搜索并收敛到最优解。智能与算法的结合，让算子调优既灵活，又有交付保障。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在对 KernelCAT 的另一场测试中，团队选取了 7 个不同规模的向量加法任务，测试目标明确：在华为昇腾平台上，直接对比华为开源算子、“黑盒”封装的商业化算子与 KernelCAT 自研算子实现的执行效率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;结果同样令人振奋，在这个案例的 7 个测试规模中，KernelCAT 给出的算子版本性能均取得领先优势，且任务完成仅仅用时 10 分钟。这意味着，即便面对经过商业级调优的闭源实现，KernelCAT 所采用的优化方式仍具备竞争力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/wechat/images/90/90a7b4e9f17290018d9342b3ed31e0a4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这不仅是数值层面的胜利，更是国产 AI Agent 在算子领域的一次自证。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;没有坚不可破的生态，包括 CUDA&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;全球范围内，目前超过 90% 的重要 AI 训练任务运行于英伟达 GPU 之上，推理占比亦达 80% 以上；其开发者生态覆盖超 590 万用户，算子库规模逾 400 个，深度嵌入 90% 顶级 AI 学术论文的实现流程。黄仁勋曾言：“我们创立英伟达，是为了加速软件，芯片设计反而是次要的。”这句话揭示了一个关键真相：在现代计算体系中，软件才是真正的护城河。英伟达的持续领先，源于其从底层算法出发、贯通架构与编程模型的全栈掌控能力。参考 AMD 的历史经验，即使在架构与制程上具备充足的竞争力，缺乏成熟的生态系统也仍然难以撼动英伟达的地位。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这场中美 AI 的角力中，上一次有中国企业对英伟达这只 AI 巨兽形成冲击，并不是因为推出新款芯片，而是算法与算子带来的效率提升。2025 年 1 月 27 日，英伟达股价暴跌近 17%，单日市值蒸发高达 5888 亿美元，创下美股史上单日市值蒸发新纪录，其主要原因是 Deepseek 通过高性能算子（尤其是 DeepGEMM）这一关键技术，以 1/20 的训练成本实现了 OpenAI O1 级的性能，这成功地证明了大模型性能≠堆砌芯片性能和数量，而是取决于算法创新 + 算子优化 + 硬件适配的协同。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果国产芯片厂商也能拥有足够丰富的高性能算子库和生态开发者，突破英伟达 CUDA 现有生态的桎梏，让更多的国产模型“回家”，那么对其商业帝国将产生难以估量的冲击，甚至有可能成为中美科技博弈的关键胜负手。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;KernelCAT 团队在让国产模型“迁移回家”的场景下做了大量尝试：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以 DeepSeek-OCR-2 模型在华为昇腾 910B2 NPU 上的部署为例，让我们看看 KernelCAT 是如何重塑工作范式的：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对抗“版本地狱”：KernelCAT 对任务目标和限制条件有着深度理解，基于 DeepSeek-OCR-2 官方的 CUDA 实现，通过精准的依赖识别和补丁注入，解决了 vLLM、torch 和 torch_npu 的各个依赖库间版本互锁的三角矛盾，硬生生从零搭建起了一套稳定的生产环境，结合基础 Docker 镜像即可实现模型的开箱即用。准确修补：它敏锐地识别出原版 vLLM 的 MOE 层依赖 CUDA 专有的操作和 vllm-ascend 提供的 Ascend 原生 MOE 实现，并果断通过插件包进行调用替换，让模型在国产芯片上&quot;说上了母语&quot;。实现 35 倍加速：在引入 vllm-ascend 原生 MOE 实现补丁后，vLLM 在高并发下的吞吐量飙升至 550.45toks/s，相比 Transformers 方案实现了惊人的 35 倍加速，且在继续优化中。无需人工大量介入：在这种复杂任务目标下，KernelCAT 可以自己规划和完成任务，无需研发提供大量提示词指导模型工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这意味着，原本需要顶尖工程师团队花费数周才能完成进行的适配工作，现在可以缩短至小时级（包含模型下载、环境构建的时间）；同时让国产芯片从“能跑”到“飞起”，实现 35 倍的加速。KernelCAT 让国产芯片不再是被“封印”的算力废铁，而是可以通过深度工程优化，承载顶级多模态模型推理任务的性能引擎。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“天下苦 CUDA 久矣”——这句话曾是行业的无奈，但 KernelCAT 的出现，似乎让国产 AI 产业看到了一种新的可能。它不只是国内团队在 AI Agent 技术上的突破，更是一次对算力主权的郑重宣示：我们不再满足于在别人的地基上盖楼，而是要打好属于自己的 AI“地基”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://kernelcat.cn/&quot;&gt;KernelCAT 限时免费内测&lt;/a&gt;&quot;中，点击链接，马上体验~&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/wechat/images/14/140a6c0e97d8e4f35ef00ee8f4f9f40e.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><link>https://www.infoq.cn/article/JAmVx35sxdz0ubB7l0Ua</link><guid isPermaLink="false">https://www.infoq.cn/article/JAmVx35sxdz0ubB7l0Ua</guid><pubDate>Fri, 30 Jan 2026 09:46:03 GMT</pubDate><author>InfoQ</author><category>芯片&amp;算力</category></item><item><title>效率狂飙数倍后：Coding Agent已然成熟，但开放世界仍是“无人区”</title><description>&lt;p&gt;如果说 2024 年是属于大模型的“奇迹之年”，那么刚刚过去的 2025 年，则可以被定义为 Agent（智能体）的“工程落地元年”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在技术圈的语境里，大模型正经历从“被动问答”到“主动干活”的范式转移。过去没有 Agent 的时候，大模型是在被动地回答问题；Agent 诞生后，它变成了主动执行。这不仅仅是业务模式的变化，更是从聊天程序到生产组件的根本性变革。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但这种根本性的变革却不是一蹴而就的，而是由多个重要的、里程碑式的“协议”和框架强力驱动的。这一点与早期互联网协议定义推动 Web 应用爆发式增长的逻辑类似——标准化不是为了漂亮的规范，是要真正去解决跨系统、跨场景、跨团队协作的实际工程痛点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;2025 年，两大协议推动了 Agent 应用的爆发&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;阿里云容器计算服务 ACS Agent Sandbox 技术负责人黄涛在最近的一次深度对谈中将其归结为三个关键事件：MCP 协议的爆火、A2A 协议的发布，以及多智能体协同的工程化实现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先是 Anthropic 发布的 MCP（Model Context Protocol，模型上下文协议），旨在定义 AI 模型如何访问外部工具、数据库和服务的标准化方式。与过去每个模型厂商根据自有接口定制不同，MCP 提供了类似 “USB-C 接口” 的统一协议，使得智能体能跨平台访问外部能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;例如，MCP 能够让智能体通过统一的协议访问数据库、库存系统、工作流 API 等，而不需要针对每种服务和接口写特定的适配代码。 这种标准化的好处，在企业级应用场景中尤为显著：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;减少集成成本：应用方不再为大量不同的 API 写 glue code。提升可靠性与一致性：统一格式、统一调用流程让错漏减少。加速自动化能力落地：智能体能快速理解系统数据并据此执行任务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;起初，这看起来只是一个单纯的技术协议，但在刚刚过去的一整年，它彻底引爆了应用层。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以阿里集团内部为例，为了加速 AI 在电商领域的渗透，阿里孵化出了名为“TMCP”的电商 MCP 网关平台。大量业务方通过编写 MCP Server，将复杂的供应链、库存数据、用户信息等通过标准化协议“喂”给 Agent。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“MCP 解决的是 Agent 看世界、调工具的‘语言统一’问题。”黄涛解释道。以前 Agent 调用工具需要针对每个接口做定制，现在有了标准网关，Agent 可以更快速地理解客户需求，从一个只会聊天的程序，变成真正能调度阿里复杂业务逻辑的“超级组件”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，另一款协议也值得重点关注。Agent-to-Agent（A2A）是由谷歌发布的，其核心目标是定义智能体间的“通用语言”和协作规范，使不同背景、不同厂商或不同开发框架下的智能体，可以像微服务一样，通过标准化方式互相发现、协商任务、交换状态、协调工作流。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这类似于 Web 发展的历史中 HTTP、REST API 为服务间通信提供标准一样——如果没有可互操作的通讯协议，大规模协作系统无法自然形成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在过去，不同功能的 Agent 之间想要对话，往往需要开发者编写极其复杂的“粘合代码”。而 A2A 标准的出现，意味着不同背景、不同厂商的 Agent 可以像人类员工一样，通过一套标准的交互准则进行协作。&lt;/p&gt;&lt;p&gt;协议能力上看，MCP 与 A2A 都可以用于描述智能体之间的交互，但二者的设计侧重点存在差异。MCP 更强调通用的调用与连接能力，统一智能体与外部工具、系统乃至其他智能体的交互方式；相比之下，A2A 在设计上更聚焦于多智能体场景本身，试图为智能体之间的协作、状态同步与交互模式提供更直接的抽象支持。因此，在早期多 Agent 系统实践中，即便采用了 MCP 这类通用协议，智能体之间的协调逻辑仍常常依赖开发者手工实现，难以随着系统规模的增长而自然演进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与此同时，Manus 等框架提出的多智能体协同概念，不仅停留在交互层，更深入到了底层的基座能力。比如安全沙箱（Sandbox）技术的引入，解决了 Agent 在执行代码或处理敏感数据时的隔离问题，让“协作”不再是裸奔。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;繁荣背后的工程陷阱：多 Agent 协作的“收敛性”困局&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管应用层呈现爆发趋势，但当 Agent 真正走进企业级生产环境时，工程性挑战接踵而至。最让开发者头疼的，莫过于多 Agent 协作中的“低效”与“幻觉”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;OpenAI CEO 奥特曼曾描绘过一个超级个体带领一堆 Agent 协作的未来。但在实际操作中，守辰发现了一个尴尬的现实：Agent 之间会产生大量“无效沟通”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“多个 Agent 协作时，经常会出现不聚焦的情况，聊着聊着就聊开了。”阿里云智能容器服务高级专家， OpenKruise Agents 项目发起人张振举例说，有些框架下，Agent 之间会互相委派任务，甚至出现死循环。这种“社交式发散”直接导致了 Token 消耗的激增，但最终得到的推理效果却可能不如一个定义明确的单 Agent。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种成本不仅仅是金钱上的，更是算力资源的浪费。对于企业而言，如何量化 Agent 之间的协作模式，识别并固化有效的沟通路径，避免像人类会议一样的“低效扯皮”，是目前的重难点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另一个挑战在于 Agent 的“自制能力”尚浅。在传统的 BPM（业务流程管理）或 RPA（机器人流程自动化）领域，追求的是强约束、强工程化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前的 Agent 虽然有灵性，但离完全自制还有很大差距。黄涛认为，现阶段 Agent 与 BPM 的关系并非“替代”，而是“融合”。“我们要给 Agent 定义清晰的边界和子系统，明确它的输入、输出和约束，而不是把它当作一个泛化的、人格化的机器人。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在阿里的实践中，开发者尝试在现有的工具流中加入 Agent 节点，让它处理那些“不那么确定”的子任务，而将确定性的逻辑依然留给脚本或流程引擎。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;黄涛的这一观点，为 Agent 当前的发展阶段进行了精准锚定。它摒弃了不切实际的科幻幻想，转而拥抱一种务实、可工程化的演进路径：Agent 并非一个从天而降、全知全能的“取代者”，而是一个需要被精心设计和集成到现有生产体系中的“增强组件”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种“融合”思维，决定了 Agent 价值的兑现方式——它必须深入具体业务的血肉之中，在解决真实痛点、优化既有流程的过程中证明自己。那么，Agent 究竟在哪些场景里产生了真实价值？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;业内普遍认为，最先被 Agent 攻陷的堡垒是编程和运维。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;AI Coding 是目前 Agent 落地最成熟、收益最可观的领域。黄涛分享了自己的体感：“以前写一段代码需要一个小时，现在 Agent 一分钟生成，我再改个十来分钟，效率提升是巨大的。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更显著的变化发生在自动化运维。2024 年的运维 AI 更多是基于 RAG 查手册，而 2025 年的 Agent 则学会了“模仿工程师经验”。当系统报错时，Agent 会自动执行一系列命令去定位问题，甚至能感知真实的运行环境并做出反馈。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;张振对 2026 年最期待的突破点是“开放世界训练”。随着 Agent 被装进手机（如字节跳动与中兴的合作）或机器人（如宇树机器人），它面临的是未知的、非实验室的环境。一个典型的挑战是：Agent 操作某个 App 时被封禁了，它该怎么办？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“让 AI 知道自己不知道，是走向真智能的关键一步。”张振提到。阿里云正在通过发布像 OpenKruise Agents 这样的基础设施，提供检查点（Checkpoint）和克隆功能，来加速这种在开放世界中的训练效率。值得一提的是，OpenKruise Agents 是阿里云容器计算服务 ACS 的 Agent Sandbox（ACS Agent Sandbox）逐步开源的能力之一。与 OpenKruise Agents 不同，ACS Agent Sandbox 面向企业级 AI Agent 应用规模化落地，内存级休眠唤醒与 checkpoint 克隆能力 ，支持结合云端弹性调度与微虚拟化隔离，以缩短沙箱启动与恢复时间，提升并行探索效率以及降低训练成本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Agent 的终极形态：超级自动化还是数字员工？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从攻克编程与运维的确定性堡垒，到勇敢迈向充满未知的开放世界训练，Agent 的能力边界正在实践中被不断拓展和重新定义。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种从“专用工具”到“适应环境”的演进路径，自然引发了更深层次的思考：Agent 进化的终点究竟在何处？是成为无所不能的超级自动化智能，还是先成为我们身边协同工作的可靠伙伴？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关于 Agent 的终极形态，黄涛和张振两位专家给出了略有分歧但互补的视角。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;黄涛的视角更偏向“高度自制的智能体”：他认为 Agent 最终会演化成在家庭助理、工厂、无人驾驶等场景中完全自主运行的实体。它能完美感知环境差异，自主决策，彻底解放人类。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而张振的视角则更务实，倾向于“数字员工”：他认为短期内，AI Agent 会以数字员工的身份在企业中入职。“员工”这个角色方便企业进行 KPI 评估，也方便人类与之协作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管愿景不同，但共识已成：Agent 将不再是特定领域的应用，而是一种像数据库、中间件一样的“新兴基础设施”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一年，我们经历了对 Agent 能力的盲目崇拜，也正在经历对其工程化落地的痛苦磨合。当 MCP 协议把业务的大门敲开，当沙箱技术把安全的篱笆扎紧，当开放世界训练让 AI 开始学会“思考”，Agent 就不再是 PPT 上的概念，而是真正开始改变生产力逻辑的底层变量。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;正如张振所强调的那样，AI 可能无法立即成为那个“超级智能体”，但它会以无数个“数字员工”的身份，渗透进代码的每一行、运维的每一次报警、以及每一个复杂的商业决策中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这才是 Agent 时代的真实叙事：不在于取代，而在于进化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;采访嘉宾简介：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;黄涛 ，阿里云容器计算服务 ACS 技术负责人张振，阿里云智能容器服务高级专家， OpenKruise Agents 项目发起人&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><link>https://www.infoq.cn/article/0gUgQyIFDDrgJaXlESUg</link><guid isPermaLink="false">https://www.infoq.cn/article/0gUgQyIFDDrgJaXlESUg</guid><pubDate>Fri, 30 Jan 2026 08:59:12 GMT</pubDate><author>李冬梅</author><category>生成式 AI</category></item><item><title>OCR竞争加剧！百度开源新一代SOTA OCR模型，性能超越DeepSeek-OCR2？</title><description>&lt;p&gt;&lt;/p&gt;&lt;p&gt;1月29日，百度正式发布并开源新一代文档解析模型PaddleOCR-VL-1.5。该模型以仅0.9B参数的轻量架构，在全球权威文档解析评测榜单OmniDocBench V1.5中取得全球综合性能第一成绩，整体精度达到94.5%，超过Gemini-3-Pro、DeepSeek-OCR2、Qwen3-VL-235B-A22B、GPT-5.2等模型。&lt;/p&gt;&lt;p&gt;﻿&lt;/p&gt;&lt;p&gt;值得关注的是，PaddleOCR-VL-1.5 全球首次实现OCR模型的“异形框定位”能力，使机器能够精准识别倾斜、弯折、拍照畸变等非规则文档形态，首次让“歪文档”实现稳定、可规模化解析。该技术解决了传统OCR模型在移动拍照、扫描件变形、复杂光照等真实场景中因文档形变导致的识别失败问题，可广泛应用于金融票据处理、档案数字化、政务文档流转等场景。&lt;/p&gt;&lt;p&gt;﻿&lt;/p&gt;&lt;p&gt;PaddleOCR-VL-1.5 基于文心大模型进行开发，在 OmniDocBench V1.5多个关键指标上取得领先表现。其中，表格结构理解（92.8 分）和阅读顺序预测（95.8 分）两项核心指标上均位列第一，分别领先 Gemini-3-Pro、DeepSeek-OCR 等主流模型 2–5 分不等。在文档阅读顺序预测任务中，其版面逻辑解析错误率仅为同类其他模型约一半。这表明，PaddleOCR-VL-1.5 在复杂文档结构还原与版面逻辑理解方面具备更高稳定性，在合同、财报等高复杂度业务场景中拥有更高可用性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.infoq.cn/resource/image/9d/77/9dfbbc9e3fc80bbba7174cdbe6fe7177.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在线使用/API：&lt;a href=&quot;https://www.paddleocr.com/&quot;&gt;https://www.paddleocr.com&lt;/a&gt;&quot;﻿&lt;/p&gt;&lt;p&gt;开源项目地址：&lt;a href=&quot;https://github.com/PaddlePaddle/PaddleOCR&quot;&gt;https://github.com/PaddlePaddle/PaddleOCR&lt;/a&gt;&quot;﻿&lt;/p&gt;&lt;p&gt;模型下载地址：&lt;a href=&quot;https://huggingface.co/PaddlePaddle/PaddleOCR-VL-1.5&quot;&gt;https://huggingface.co/PaddlePaddle/PaddleOCR-VL-1.5&lt;/a&gt;&quot;﻿&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;2025年10月16日，百度首次发布并开源 PaddleOCR-VL模型，在 OmniDocBench V1.5 榜单中取得全球SOTA成绩，并连续五天登顶 HuggingFace全球模型总趋势榜与ModelScope全球模型总趋势榜双榜第一。&lt;/p&gt;&lt;p&gt;﻿&lt;/p&gt;&lt;p&gt;相比于上代，在功能层面，PaddleOCR-VL-1.5 进一步集成印章识别、文本检测与识别等任务能力，关键指标持续领跑；同时针对特殊场景与多语种识别进行系统优化，在生僻字、古籍文献、多语种表格、下划线与复选框等复杂结构识别方面显著提升，并新增对藏语、孟加拉语等语种的支持。模型还支持跨页表格自动合并与跨页段落标题识别，有效解决长文档解析中的结构断裂问题。&lt;/p&gt;&lt;p&gt;﻿&lt;/p&gt;&lt;p&gt;近半年来，全球主流模型厂商密集布局OCR 领域。1月27日，深度求索发布新一代 OCR 模型 DeepSeek-OCR-2，引入“因果流查询”机制，并将语言模型融入视觉编码，在OmniDocBench V1.5中实现91.09%精度。与此同时，Mistral AI、字节跳动、腾讯等企业也相继推出新一代 OCR 模型，行业竞争持续加剧。&lt;/p&gt;&lt;p&gt;·&lt;/p&gt;</description><link>https://www.infoq.cn/article/US8DFAjTKWuEUkRBEFSj</link><guid isPermaLink="false">https://www.infoq.cn/article/US8DFAjTKWuEUkRBEFSj</guid><pubDate>Fri, 30 Jan 2026 08:34:01 GMT</pubDate><author>褚杏娟</author><category>AI&amp;大模型</category></item><item><title>商汤开源SenseNova-MARS，突破多模态搜索推理天花板</title><description>&lt;p&gt;今天，商汤正式开源多模态自主推理模型：SenseNova-MARS（8B/32B 双版本）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS，是首个支持动态视觉推理和图文搜索深度融合的Agentic VLM（ Vision-Language Model，视觉-语言模型）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所谓Agentic VLM，就是既能看图、又能像Agent一样行动的多模态模型。在工程上，Agentic VLM通常是“一个核心模型+一层轻量控制逻辑”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;和很多Agentic VLM主要依赖外部框架来“指挥流程”不同，SenseNova-MARS把部分记忆判断能力，放进了模型自己的思考过程里——而且把“视觉细节+搜索结果”，当作推理过程中的持续变量，而不是把这些信息当作一次性输入或外部状态被简单传递。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这样做的好处在哪？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;简单来说，就是模型的推理不再是线性的，而是带反馈的闭环过程。可以显著降低错误累积，并提升复杂任务的稳定性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;来看看更直观的结果：在多模态搜索与推理这一组核心测试中，SenseNova-MARS 拿到了69.74分，超过了Gemini-3-Pro（69.06 分）&amp;nbsp;和&amp;nbsp;GPT-5.2（67.64 分）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d5/d59e3e801fd91e41cf2e0c83792b9c75.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;再看细项，在MMSearch、HR-MMSearch、FVQA、InfoSeek、SimpleVQA、LiveVQA等基准测试中，SenseNova-MARS取得开源模型中的SOTA 成绩，还超越Gemini-3.0-Pro、GPT-5.2等顶级闭源模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更多细节可见技术报告（https://arxiv.org/abs/2512.24330）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;全能冠军，自主解决复杂问题&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在MMSearch 榜单（图文搜索核心评测）中，模型以 74.27 分登顶，超越GPT-5.2（66.08 分）；HR-MMSearch（高清细节搜索评测）中 54.43 分领先，显著拉开与闭源模型的差距。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ee/ee360ad6b9e7a1c18c12111f17be378e.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;HR-MMSearch的测试题目堪称“AI界的奥林匹克”：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;采用305张2025年最新的4K超高清图片，确保AI无法依赖旧知识“作弊”；所有问题都针对图片中占比不到5%的细节，比如小标志、小字、微小物体，必须用图像裁剪工具才能看清；覆盖体育、娱乐文化、科学技术、商业金融、游戏、学术研究、地理旅行等八大领域，60%的问题都需要至少使用三种工具才能解答。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;简单说，无论是需要“查遍全网”的知识密集型任务，还是需要“火眼金睛”的细粒度视觉分析，它都是当前的“全能冠军”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/53/53574430ae73cb193eb1344d4827f15f.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;用组合拳，解决真实场景问题&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS还能实实在在落地到我们生活和工作的场景，解决需要“多步骤推理+多工具协作”的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;普通AI的工具调用，要么只能搜文字，要么只能看图片，遇到需要“先放大细节、再识别物体、最后查背景”的复杂任务就束手无策。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2e/2e721ddf42290eb3d1b494efef9c4d06.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;面对识别赛车服微小 logo + 查询公司成立年份 + 匹配车手出生年月 + 计算差值’的复杂任务，SenseNova-MARS 可自主调用图像裁剪、文本 / 图像搜索工具，无需人工干预完成闭环解答。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/1b/1bce7ce95d3d9aaa60d3d464daa9a2a6.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS能从产品和行业峰会的照片中，识别企业的标志，快速搜集产品、企业的信息，以及时间、数量、参数等细节要素，辅助分析行业情况和格局。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f2/f26dbef3bdeb01be2048393ea5d3d1b3.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS能从赛事照片中识别画面中的logo、人物等信息，追溯比赛或人员背景信息，帮助快速补充重要细节。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/51/5160df7753308658f84b55092d602833.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS甚至能够轻松处理，这类超长步骤的多模态推理，和超过三种工具调用，自动裁剪分析细节、搜索相关研究数据，快速验证假设，得出关键判断。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;拥有这种“自主思考+多工具协作”的能力，SenseNova-MARS能够自动解决“细节识别 + 信息检索 + 逻辑推理”复杂任务，帮助实现工作效率提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;图像裁剪：能精准聚焦图片上的微小细节，哪怕是占比不到5%的细节——比如赛车手衣服上的微小logo、赛事照片里观众席的标语，都可通过裁剪放大清晰分析。&lt;/p&gt;&lt;p&gt;图像搜索：能在看到物体、人物或场景，的瞬间自动匹配相关信息——比如识别出赛车手的身份，或是某款冷门设备的型号。&lt;/p&gt;&lt;p&gt;文本搜索：能快速抓取精准信息——无论是公司成立年份、人物出生年月，还是最新的行业数据，都能秒级获取。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/53/53574430ae73cb193eb1344d4827f15f.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;从练中学，形成“经验”和“直觉”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SenseNova-MARS采用了“因材施教”的训练方法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一阶段：打基础。&lt;/p&gt;&lt;p&gt;针对跨模态多跳搜索推理训练数据稀缺的痛点，创新性的提出了基于多模智能体的自动化数据合成引擎，采用细粒度视觉锚点+ 多跳深度关联检索的机制，动态挖掘并关联跨网页实体的逻辑，自动化构建高复杂度的多跳推理链路，同时引入闭环自洽性校验来去除幻觉数据，构造出具备严密逻辑链条与高知识密度的多跳搜索问答数据。用精心筛选的“高难度案例”做教材，每个案例都标注了“该用什么工具、步骤是什么”，让AI先学会基本的“破案逻辑”。这些案例都是从海量数据中挑出的“硬骨头”，确保AI一开始就接触真实复杂场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二阶段：练实战。采用“强化学习”——就像侦探在一次次破案中积累经验，AI每做对一次决策（比如选对工具、步骤合理）就会获得奖励，做错了就调整策略。为了避免AI“学偏”，研究团队还加了个“稳定器”——BN-GSPO算法，让它在处理简单题和复杂题时都能保持稳定进步，不会出现“偏科”。 这种基于双阶段归一化的优雅机制有效平滑了动态工具调用返回分布多样性带来的优化波动并确保了学习信号分布的一致性，从而成功解决了跨模态多步多工具智能体训练过程中的收敛性难题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;经过这样的训练，AI不仅学会了用工具，更培养&quot;工具使用直觉&quot;——知道在什么情况下应该使用哪些工具，以及如何将不同工具的结果有机结合起来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;商汤日日新SenseNova-MARS模型、代码、数据集全开源，支持 Hugging Face 直接下载。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Github 仓库：&lt;/p&gt;&lt;p&gt;https://github.com/OpenSenseNova/SenseNova-MARS&lt;/p&gt;&lt;p&gt;模型仓库：&lt;/p&gt;&lt;p&gt;32B：&lt;/p&gt;&lt;p&gt;https://huggingface.co/sensenova/SenseNova-MARS-32B&lt;/p&gt;&lt;p&gt;8B：&lt;/p&gt;&lt;p&gt;https://huggingface.co/sensenova/SenseNova-MARS-8B&lt;/p&gt;</description><link>https://www.infoq.cn/article/3x5oE24DW1X5eFYeMGTE</link><guid isPermaLink="false">https://www.infoq.cn/article/3x5oE24DW1X5eFYeMGTE</guid><pubDate>Fri, 30 Jan 2026 08:08:48 GMT</pubDate><author>木子</author><category>AI 工程化</category></item><item><title>苹果 Siri 压力大了？Google 甩出 FunctionGemma 杀手锏，手机本地也能流畅调 API</title><description>&lt;p&gt;Google 正式发布了&amp;nbsp;&lt;a href=&quot;https://blog.google/innovation-and-ai/technology/developers-tools/functiongemma/&quot;&gt;FunctionGemma&lt;/a&gt;&quot;，这是其 Gemma 3 270M 模型的一个全新轻量化版本。该模型经过专门微调，能够将自然语言指令精准转化为结构化的函数和 API 调用，从而让 AI 代理超越“空谈”，具备真正的执行力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在&amp;nbsp;&lt;a href=&quot;https://developers.googleblog.com/en/introducing-gemma-3-270m/&quot;&gt;Gemma 3 270M&lt;/a&gt;&quot;&amp;nbsp;发布数月后，为了响应开发者日益增长的需求，Google 赋予了该模型原生的函数调用（Function Calling）能力，使其进化为 FunctionGemma。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本地化运行赋予了该模型双重身份：它既可以作为一个独立的代理，处理私密且离线的任务；也可以充当“智能流量调度员”，将更复杂的请求路由至更大规模的远程模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;这一特性在端侧（On-device）应用中尤为引人注目。AI Agent 可以借此实现从设置提醒到切换系统设置等一系列复杂的多步工作流自动化。为了在边缘计算场景中实现这一目标，模型必须足够轻量以支持本地运行，同时又必须具备极高的专业化程度以保证可靠性。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Google 解释称，FunctionGemma 的初衷并非用于零样本提示（Zero-shot prompting），而是旨在让开发者进行深度定制，从而构建出快速、私密且能将自然语言转化为可执行 API 操作的端侧代理。这种方法是模型达到生产级性能的关键。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;在 Google 的“移动操作（Mobile Actions）”测试评估中，微调技术显著提升了模型的可靠性，将其准确率从 58% 的基准线大幅拉升至 85%。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在硬件适配方面，该模型专为手机和 NVIDIA Jetson Nano 等资源受限的设备设计。它利用 Gemma 家族的 256k 词表，能够高效地对 JSON 数据和多语言输入进行分词处理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;FunctionGemma 支持 Google 所称的“统一行动与对话”模式。这意味着模型既能生成用于调用工具的结构化代码或函数，又能无缝切换回自然语言，向用户解释执行结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Google 同时指出，FunctionGemma 拥有广泛的生态系统支持。开发者可以使用 Hugging Face Transformers、Unsloth、Keras 或 NVIDIA NeMo 等框架进行微调，并通过 LiteRT-LM、vLLM、MLX、Llama.cpp、Ollama、Vertex AI 或 LM Studio 等平台进行部署。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对开发者，Google 明确列出了 FunctionGemma 的最佳适用场景，包括：拥有明确的 API 接口、愿意进行模型微调、优先考虑本地化部署，或正在构建结合端侧与远程任务的复杂系统。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了展示模型的实战能力，Google 发布了多个演示项目，包括 Mobile Actions、TinyGarden 和 Physics Playground。这些演示均可通过 Play 商店中的&amp;nbsp;&lt;a href=&quot;https://play.google.com/store/apps/details?id=com.google.ai.edge.gallery&quot;&gt;Google AI Edge Gallery 应用&lt;/a&gt;&quot;进行体验：&lt;/p&gt;&lt;p&gt;Mobile Actions：解析诸如“为明天的午餐创建一个日历行程”、“将 John 添加到联系人”或“打开手电筒”等自然语言指令，并将其映射到相应的操作系统级工具调用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;TinyGarden：一款语音控制游戏。玩家给出“在顶排种下向日葵并浇水”等指令，模型会将其分解为带有坐标目标的 plantCrop 和 waterCrop 等具体函数调用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Physics Playground：一个交互式物理益智演示。它使用自然语言指令控制游戏内的模拟动作，并利用 Transformer.js 展示了客户端 JavaScript 的集成能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，FunctionGemma 已在&amp;nbsp;&lt;a href=&quot;https://huggingface.co/google/functiongemma-270m-it&quot;&gt;Hugging Face&lt;/a&gt;&quot;&amp;nbsp;和&amp;nbsp;&lt;a href=&quot;https://www.kaggle.com/models/google/functiongemma&quot;&gt;Kaggle&lt;/a&gt;&quot;&amp;nbsp;上线。此外，Google 还提供了&amp;nbsp;&lt;a href=&quot;https://github.com/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb&quot;&gt;Colab 笔记本&lt;/a&gt;&quot;和&amp;nbsp;&lt;a href=&quot;https://huggingface.co/datasets/google/mobile-actions&quot;&gt;mobile-actions 数据集&lt;/a&gt;&quot;，以帮助开发者更轻松地对模型进行专业化训练。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/functiongemma-edge-function-call/&quot;&gt;https://www.infoq.com/news/2026/01/functiongemma-edge-function-call/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/QRiKGWvWxwUh7wAwODjK</link><guid isPermaLink="false">https://www.infoq.cn/article/QRiKGWvWxwUh7wAwODjK</guid><pubDate>Fri, 30 Jan 2026 08:00:00 GMT</pubDate><author>Sergio De Simone</author><category>Google</category><category>AI&amp;大模型</category></item><item><title>凌晨三点写代码、10个 Agent 同时跑！ClawdBot 创始人自曝 AI 上瘾史：Claude Code 入坑，Codex 成主力</title><description>&lt;p&gt;&lt;/p&gt;&lt;p&gt;Clawdbot（现名：Moltbot）火了到国内，社交平台上到处都是部署教学、使用教学和使用展示。国内的腾讯云、阿里云等也相继宣布上线 Clawdbot 云端极简部署及全套云服务，钉钉也在 Github 上开源了 Moltbot 接入方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;项目背后的创始人 Peter Steinberger 也红极一时，他的构建方式成为很多人的学习对象。Peter之前就是一位非常出色的开发者，打造了一个被用在超过十亿台设备上的 PDF 框架。后来他经历了严重的职业倦怠，卖掉股份，整整三年从科技圈消失。今年，他回来了，而他现在的构建方式、正在做的事情，已经和传统软件开发完全不同。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter 近期在“The Pragmatic Engineer”节目中，用近两个小时的时间分享了他的开发经历。他解释了，为什么他现在发布的代码，大部分自己都不再逐行阅读，而这其实并没什么大不了；他具体是如何打造了 ClawdBot 这个看起来就像 Siri 未来版本的个人助手的；他如何利用“闭环原则”，高效进行 AI 编程；为什么代码评审已经过时，PR 应该改名叫 Prompt Request等，他还分享了很多关于软件工程工作流在未来几年可能发生的变化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter 可以称得上是“AI 重塑开发方式”的最佳实践者之一。我们整理翻译了这期干货满满的对话，并在不改变原意基础上进行了删减，以飨读者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;怎么入行的？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这次终于线下见到你了，太棒了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是啊，差点还搞砸了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：怎么回事？是忘了时间吗？你经常这样吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：其实不太常见。只是最近这个时间点比较特殊，因为我最近的项目 ClawdBot 突然火了。说实话，有点睡不够了。但这种感觉也很有意思，我从来没经历过一个社区在这么短时间内爆发。真的非常好玩。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：在聊 ClawdBot 之前，我们先把时间拉回去。你做的 PSPDFKit，据说被用在超过十亿台设备上，基本上你看到一个 PDF 被渲染，很可能背后就是它。那在更早之前，你是怎么进入技术行业的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：天哪，这得从很早说起了。我来自奥地利一个小地方，一直比较内向，经常被欺负。那时候，夏天总会有客人来家里，其中有个电脑迷，我迷上了他的机器，天天盯着这台机器研究，最后求妈妈给我买了一台。从那以后，我就彻底陷进去了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那时候你还在读中学？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：差不多吧，大概十四岁。我最早做的事情之一，是从学校“顺”了一张老 DOS 游戏的软盘，然后自己写了个拷贝保护，好拿去卖。加载一次要两分钟，但我当时觉得这事特别酷。当然也打了很多游戏，不过对我来说，做东西本身就像在玩游戏。说实话，现在做事带来的成就感，比通关游戏还爽。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一开始我看的是类似Windows的bash脚本，然后做网站，写一点 JavaScript，虽然完全不知道自己在干嘛。真正系统性地学“怎么构建东西”，是上大学之后。我从没见过我父亲，家里也很穷，所以我一直要打工，学费生活费都得自己赚。别人放假的时候，我就在公司全职上班。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我第一份正式工作在维也纳，本来只打算干一个月，结果他们留了我六个月，后来我在那家公司工作了大概五年。第一天他们给了我一本厚厚的书，上面写着“Microsoft MFC”，到现在我做梦还会被吓醒。我当时心想，这也太糟了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来我干脆悄悄用 .NET，也没跟他们说。过了几个月我才摊牌，说我顺便做了点“技术栈现代化”。反正木已成舟，他们居然也一直留着我，大概因为事情确实做成了。我实际上还挺喜欢.NET 2.0的泛型，不过应用启动慢得要命，第一次跑基本要等很久，老 Windows 用户应该都懂。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那你后来是怎么接触到 iOS，又是怎么想到做PSPDFKit 的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：那是后面的事了。上大学时，有个朋友给我看了 iPhone。我就摸了一分钟，立刻决定要弄一台。那一刻真的像被雷劈了一样，完全不一样，完全是另一个层级的体验。但当时我其实还没想过要给它做应用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那大概是2009、2010年左右？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：差不多。后来有一次，我在地铁上用一个交友网站，用的是 iPhone OS 2。我打了一大段很走心的消息，刚点发送后车进隧道了，JavaScript禁用了发送按钮，然后直接报错。那时候没有复制粘贴、没有截图、页面还不能滚动，那段话就这么没了。我当时气炸了，觉得这简直不可接受。回到家我就把那个网站黑了，用正则去解析 HTML。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在看当然完全不该这么干，后来我硬做了一个 App。我用的是 iPhone OS 3 的 Beta 版，Core Data 也是 Beta，还用改过的 GCC，把 blocks 编译器移植进来。各种 Beta 技术一锅炖，我自己其实也不知道在干嘛，折腾了很久才跑起来。我给那家公司写信说我做了个 App，问他们怎么看，没人理我，我就直接丢到 App Store上架了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这就是那个交友 App 的客户端？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，本质上就是把 HTML 当 API 用，纯解析页面。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：现在看挺野的，但在当年确实没人这么干。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我定价五美元，第一个月就赚了一万美元。当时我完全不知道流程有多复杂，Apple 的系统也很原始。我甚至把收款账户填成了我爷爷的。有一天我爷爷打电话问我，说怎么 Apple 给他打了一大笔钱，我跟他说“这是我的，你千万别动”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来有一次我在夜店里，看到有人在用我的 App，我特别骄傲，差点冲过去跟他说这是我做的，最后还是忍住了。没多久，我就跟工作了五年的公司说，我要全力做这个项目。老板当面嘲笑我，说这是个一时的风口，肯定不长久。那一刻我心里就憋了一口气：总有一天，我要做一家比你们值钱的公司。结果这花了我八年的时间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我有点成瘾性格，一旦投入就停不下来。我疯狂打磨这个 App，高速学习，也是那段时间我开始用 Twitter，那些对我职业发展影响巨大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来有一天凌晨三点，我在派对上喝得有点多，然后接到了一个电话，对方说他是 Apple 的 John，说我的应用有问题，有人举报不当图片。电话挂了，我的 App 也就此下架。我刚辞了工作，心态直接炸裂，开始接零散的活儿。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在旧金山的一家酒吧里，我被介绍为“奥地利最好的 iOS 开发者之一”。就这样，我拿到了美国的工作机会，搬过去待了一阵子。后来去了 Nokia Developer Days，那真是史前时代了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在那里，有人找我，说他们在东欧做了一个杂志阅读 App，经常崩溃。那会儿 iPad 刚出来，Steve Jobs 说它是出版业的救世主，大家都在做杂志 App。我一听觉得这是个不错的短期项目，就接了。我一打开代码，整个人都懵了。那是我见过最糟糕的 iOS 代码，整个项目只有一个文件，几千行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：还是 Objective-C？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，是 Objective-C，而且他们把 Windows 当成 Tab 来用。我都不知道这能行。我很惊讶这居然能用，但感觉像个纸牌屋。我试着“外科手术式”地修补问题，但基本上是动一处、坏一片。最后我好不容易把它稳住了，就跟他们说，“这太疯狂了，我要重写”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他们原本预计要半年，我说我一个月就能搞定，最后花了两个月，也不算差太远。接下来我就一直在解决各种 PDF 相关的技术问题。这个领域谈不上多性感，但每个领域里都能找到真正有挑战的点。比如一个 C 语言调用渲染PDF可能要30MB，但整个系统只有64MB，如果你不够小心、不够聪明，系统随时就把你干掉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我那段时间完全沉迷在“把它做到极致”这件事上，比如屏幕旋转时页面的动画效果，这种细节我会反复打磨，花了远超合理的时间。所以原本一个月的活，最后干了两个月，但结果是好的。之后我又跟他们合作了一段时间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来有个朋友给我发消息，说他在做一个杂志应用，PDF 那块特别难。我跟他说，我刚好做过，对方就问我能不能把代码给他，我说可以。先把那套杂志 App 里和 PDF 有关的部分抽出来，确认对方也没意见。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;然后我突然想到，既然有人需要，为什么不试着卖给更多人？我用一个 WordPress 模板，硬改成能跑在 GitHub Pages 上。然后用fastlane流程最后得到一个Dropbox链接，里面有源代码。当天晚上我就发了条推文。一周之内，有三个人买了，大概两百美元。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在当时对我来说，这已经很不可思议了。不只是有人付钱，还有十封邮件在抱怨，说他们也想买，但这个产品还没有他们想要的功能。比如有人问，为什么不能选中文本？几个月后我才真正意识到，这功能到底有多难。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：PDF 里的文本选择。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，尤其是这个。你知道那句话吗：公司是由年轻人建立的，因为他们不知道有多难。我当时完全没概念，后来才发现这简直是疯了一样复杂。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;直到现在，前几周还有人给我写邮件，说他们在做 PDF 相关的事情，想找我帮忙。我基本都会回一句：不好意思，我已经把这辈子该懂的 PDF 知识都学完了，远远超过一个正常人该承受的量，祝你好运。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不过当时，这个项目真的起飞了。我一边等签证，一边继续维护。买的人越来越多。那是夏天，我躺在湖边晒太阳，邮箱里突然又进来一封邮件，说又有人买了，六百美元、八百美元。随着功能变多，我不断涨价。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;等我真的去旧金山那家公司上班时，这个项目赚的钱，已经超过我在那里拿的工资了。但我那时的想法还是：我得去那家公司看看，于是还是去了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：也就是说你搬到了 San Francisco。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，而且很有意思的是，那家公司后来也让我用自己的框架帮他们做东西。创业公司当然不可能只干八小时，我的本职工作很忙，个人项目也一样，睡的自然越来越少。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;三个月后，我的经理 Sabine 把我叫过去，问我一句话：“Peter，你还好吗？”公司给了我一个选择：要么继续在这家公司工作，把个人项目停掉；要么反过来。他给我一周时间决定，而且因为签证问题，如果不留下，就得离境。这个决定其实一点都不难。我很清楚，我想做自己的事情。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那时候你已经看出来了，这是一个真正的生意，至少能给你带来和美国工作差不多的收入。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我从来不是被钱驱动的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那你真正的驱动力是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我想做那种让别人觉得“太棒了”的东西。我特别迷恋细节，迷恋那些小小的惊喜感。并不是因为这个领域没有竞争，相反，竞争很多。但我心里一直憋着一股劲：我要做一个像 Apple 自己会做出来的产品，充满关怀、打磨、克制，还有那些行业里很多人已经不在乎的细节。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以哪怕有竞争对手功能更多、做得更早，我的产品依然更成功。因为开发者试过之后，都会觉得我的用起来最好。我一直觉得，产品的“感觉”比功能列表重要得多。我们为什么买 Apple？不是因为它功能最多，而是因为它用起来就是更舒服。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;从卖组件到创建公司&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那你是怎么从“一个人在卖 PDF 组件”，走到开始招人的？你什么时候意识到这件事可以做得更大？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我回到维也纳之后，决定彻底 all in，开始和一些自由职业者合作。说实话，我招人其实招得太晚了，完全可以更早迈出这一步，但这一步真的很难。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从那时起，这个产品开始有了自己的生命。我职业生涯里差不多有13年都在打磨这个名字奇怪的产品。名字我一直没改，当初想名字只花了几分钟，就叫 PSPDFKit。后来改过一次，但说实话，要不是不得不改，我可能还是不会动。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：名字确实有点绕，但非常独特。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：如果你写 Objective-C，你就会觉得这个名字很合理，因为它本质上就是个命名空间。我的营销策略也一直很简单：我只关心开发者。虽然最终拍板的是管理层，但只要我能说服公司里的工程师，他们就会替我去内部推广、游说。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们从来不做冷邮件，也不搞侵略式销售。所有客户都是自然找上门的。我们只做三件事：把产品做好、写真正有价值的技术博客，以及参加大量开发者大会。对我来说，最重要的是让大家明白，这个产品背后的人是真的懂技术、也真的热爱这件事。而这一点，会直接体现在产品里。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：PSPDFKit 底层用的是什么技术？最早是 Objective-C 吗？后来转成 Swift？有没有用到 C 之类的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：一开始确实是 Objective-C，后来逐步覆盖到所有平台。真正一次大的转折，是我们把 Apple 自带的渲染器换掉了，那个东西当时问题很多，之后改成了一个大型的 C++ 渲染器，后来所有平台基本都共用这一套核心。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们在 Web 这块也做得非常早，是最早一批跑在 WebAssembly 上的 PDF 框架之一。当时我做了一件现在看来还挺聪明的事：在一切刚开始的时候，我们做了一个性能基准测试。后来这个 benchmark 被 Google、Microsoft、Apple 等公司拿去用，成了他们内部的参考指标之一。结果就是，这些大公司为了跑得比我们快，反过来不断把他们的渲染器优化得更快，而测试用的内容，其实就是我们自己的渲染场景。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;创业后，分享公司的“核心秘密”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：厉害。随着公司规模变大，我对 PSPDFKit 的一个深刻印象是，你们写了大量博客。记得有一篇文章，讲的是团队怎么运作：每个功能都要从 proposal 开始，因为 API 很大、用户很多，所以你们非常保守；还有类似 Boy Scout Rule 那样的重构原则。团队从十几个人发展到几十个人，这种文化是怎么建立起来的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我卖股份的时候，公司大概七十人，现在已经接近两百人了。一开始我就很清楚，在维也纳不可能招到我需要的所有人，所以我们从一开始就是 remote first，后来又变成了一种混合模式，反而更复杂。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;很多东西都是边走边学。我从来没有“我要当 CEO”的执念，我一直在写代码，我会找合适的人来帮我做公司的其他部分。业务我能做，也做得还可以，但我真的不喜欢那种企业销售电话，你得去琢磨一个“魔法数字”，看对方可能愿意付多少钱。这就是企业销售，真的很折磨。但说到底，这种模式可能是唯一行得通的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你是说企业销售本身？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：很多开发者去厂商官网，看不到价格，只看到“联系我们”或者“预约演示”，都会很不爽。为什么一定要这样？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：原因很简单，我们会看你的公司情况，然后大概判断你能接受的价格，再定一个数。听起来确实很糟糕，但当你的产品没办法简单拆成一个统一定价时，这是现实。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一个自由职业者，和一家财富五百强公司，用法完全不同，获得的价值也完全不同。如果统一收费，要么把小客户挡在门外，要么让大客户觉得价格可疑。价格定低了，大公司采购流程都走不起来；定高了，小团队直接流失。所以这个过程看起来不公平，但在某些产品上，反而是最公平的方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;软件大致可以分成四个象限：容易或困难，有趣或无聊。我们处在“又难又无聊”的那一块。&lt;/p&gt;&lt;p&gt;如果只构建每个开发者都想构建的东西，卖起来一定很难。卖给开发者本来就难，如果一个东西既简单又有趣，那基本没戏。但如果是那种“我真不想碰，而且还特别难”的，反而是个好位置。我找到了这样一个细分领域，里面有无限多复杂问题可以解决。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那解析 PDF 到底难在哪？有规范啊，我是工程师，照着规范做不就行了？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：举个最简单的例子。PDF 里有链接，比如目录，点一下跳到某一页。我一开始的假设是，可能有一两百个链接。我就按这个规模设计了整个数据模型。后来来了一个付费很高的客户，说他们的 PDF 打开要四分钟，我一看是一份五万页的文本圣经，每一页上有上百个链接。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那就是五十万个链接。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，我的模型直接爆炸了。假设差了三个数量级。但这时候你已经是一个成熟产品了，还有稳定的 API。你要怎么彻底重构内部，又不破坏所有用户？所有东西都得改成 lazy loading。以前加载100个对象没问题，现在不行了。我花了整整两个月重写内部结构，同时还要保证对外 API 看起来还是“简单的”。用户不需要知道哪些是立即加载的、哪些是延迟加载的，引用关系也必须保持一致。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这些引用必须还能连得上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。我其实非常喜欢做支持，这也是公司能成功的重要原因之一。如果你提一个工单，结果 CEO 直接回你，还帮你解决问题，那感觉是完全不一样的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我一直有个策略：支持一定要快。五分钟内回，和两天后回，体验差别巨大。这个问题就是其中一个例子，我花了两个月把它彻底解决，最后跑得非常顺，那种满足感真的很强。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那时候你自己还写很多代码，对吧？虽然团队已经很大了，但你仍然会深入细节。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：当然。我有一支非常棒的团队，有些模块我参与得更多。移动端一直是我最上心的部分，但我也会深度参与技术、市场和业务。业务上我有 Jonathan 帮忙，市场和销售也有很优秀的人。其实，持续写博客、写你是怎么解决这些复杂问题的，会帮你吸引同样想解决复杂问题的人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这是我对 PSPDFKit 最深的印象之一。你们的博客不只是营销，而是真的好看。说实话，我并不做 PDF，但如果要说起 PDF 框架，第一个想到的就是 PSPDFKit，因为只有你们会写这么有意思的技术文章。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你现在回头看，会不会也觉得奇怪，为什么更多公司不这么做？还是说，这本来就需要创始人本身是个喜欢写、喜欢拆解问题的工程师？你当时写这些文章，是出于“这对公司有用”，还是单纯因为你自己想把解决过的难题记录下来？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我喜欢分享，也喜欢启发别人。有时候团队内部也会纠结，要不要写这些内容，毕竟算是一些“秘密武器”，但我从来没太在意这些声音。还有一点很重要：写下来本身，就是加深理解。你觉得自己懂了，但当你要教别人时，才会发现自己是否真的懂。所以对我来说，这也是一种复盘和保存。我解决了一个很难的问题就想把它留下来，顺便帮到别人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，我也享受关注。但更重要的是，有时候我自己过一年再回头看这些文章，会发现这就是公司最好的文档，是我自己的“技术笔记本”。它在很多方面都很有用。很多大公司流程太重，而且不少开发者本身不喜欢写东西，所以我后来干脆规定，每个月给所有人一整天，只干一件事：写一篇博客。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那天不用干别的活，只写。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，就写。一天的时间其实已经很多了，现在我写一篇文章也就几个小时。我不想过多谈论公司增长阶段，但我觉得公司最有意思的阶段，是刚开始以及快速成长的阶段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来人多了，流程多了，更像是在“养护花园”，而不是疯狂 hack。事情变得更迭代化，也没那么刺激了。人一多，内部摩擦、情绪问题也多，这些我并不享受。那段时间我真的被烧干了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;“停更”，赋闲&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你觉得是什么让你最终人力交瘁的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我只是工作太猛了，几乎每个周末都在工作，还要处理大量管理事务。CEO 本质上就是“兜底的人”，凡是别人没处理好、处理不了、或者搞砸的，最后都得你来收拾。而且很孤独，你不能随便讲很多事情。哪怕公司已经很开放了，你也不能一直表达负面情绪，就算真的发生了很糟糕的事，你也得扛着。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我记得有个周末，合伙人凌晨给我打电话，说一家大型飞机制造公司，因为我们的软件崩了，飞机停飞了。那是个非常“刺激”的周末，最后我拆了他们的应用，证明是他们外包代码乱改，触发了授权回退逻辑。但那种时刻，你会觉得公司随时可能完蛋，而这种压力只是所有压力中的一部分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些事情你能撑一阵子。但我也相信，burnout 不完全是因为工作太多，更是因为你开始不再真正相信自己在做的事情，或者内部冲突太多。我们当时在管理团队里争论也很多，我还犯了一个错误，以为公司应该用一种过度民主的方式来管理。这些都消耗了我。但即便如此，我一点都不后悔这段经历。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：从外人的角度看，你卖掉了股份，赚到足够多的钱，按理说已经不用再工作了。很多刚起步、或者未来想创业的人，都会觉得这简直是终极梦想。既然已经“通关”，是不是就该停下来、享受生活了？现实是，大多数人走不到那一步。但一旦走到了，好像任务就完成了，就像攀岩爬到顶，敲响铃铛，游戏结束。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：外界看，你博客更新停了好几年。那段时间你在做什么？又学到了什么？也就是在你回归到现在之前，那几年到底发生了什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我真的花了很长时间让自己“降压”，去填补那些我以为错过的人生体验，花了不少钱。有几个月，我甚至连电脑都没开过。那段时间，我完全没有“接下来该干嘛”的感觉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;说实话，那种状态挺违和的，你这么早就“退休”，或者说有一个好到不需要再工作的退出，这件事本身就会把人搞懵。那几年对我来说，其实挺难熬的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来有一天，大概在四月，我突然想起一个很多年前只是当副业做过的项目，我心想还是想把它继续做完吧。于是，三年多之后，我重新坐回电脑前，开始写代码。那个项目是个 Twitter 分析工具，用 Swift 和 SwiftUI 写的。其实当年我就知道，这东西如果做成 Web 会好很多。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：所以这是一个你一直放在心里的老想法？跟 Twitter 有关的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，算是分析工具。最开始只是我自己想用，因为市面上根本没有。三年后再看，还是没有。现在勉强算有点类似的，但我中途也被别的事带跑了。我当时想用 Web 技术重写，但说实话，在公司里我从来没碰过那一块。那一整套技术栈一直是 Martin 在负责，他很厉害，所以我完全不用操心。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：所以你其实一直没怎么亲手下场？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。等我再回来自己做的时候，我才发现，“哇，这一层真的很深”，而且这其实是个陷阱：你在某一套技术上越熟练，跳到另一套时就越痛苦。不是做不到，是太折磨人了。我在 Apple 那套技术里，闭着眼都能写代码；可一换栈，连最基础的东西都要去 Google，一下子就感觉自己又成了新手。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：而且经验越多，越讨厌这种感觉。效率下降，明明知道自己本可以更快。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。所以我回来的时候就在想：那 AI 到底是什么？CI、AI 那些大家都在吐槽的东西，到底值不值得看一眼？老实说，我某种程度上反而要感谢那三年几乎没碰电脑的日子，因为你们那时候已经把 AI 看过一轮了，知道它当时有多烂。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;回归即上手Claude Code，“上瘾了”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：对，你错过了 GitHub Copilot 的早期测试版，那种“高级自动补全”的阶段。后来有了 GPT-3.5，再到 GPT-4，才是真正的飞跃。所以你回来之后，第一个用的是什么工具？你等于是直接跳过了两年开发者一边用、一边嫌弃 AI 的阶段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是 Claude Code。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你一上来就用它？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。我记得它刚发布不久，之前就有 Beta。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：也就是说，你休息了一段时间回来，直接打开 Claude Code，前面的演进全都没经历。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：没错。我记得我拿了一个以前写得很乱的副项目，又用我自己做的一个浏览器插件，把整个 GitHub 仓库转成一个 1.3MB 的 Markdown 文件。我把它丢进 Google AI Studio，用 Gemini 之类的模型，敲了一句：“给我写一份 spec。”它直接生成了四百多行代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我再把这份 spec 拖回 Claude Code，说一句“照这个做”，然后我去干别的事了。等我回来，它告诉我：“已经百分之百可以用于生产环境了。”我一跑，直接崩了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来我又给它接了 MCP，让它能用浏览器，我记得 MCP 当时已经有了。它又跑了几个小时，最后居然做出了一个 Twitter 登录页，还能跑点流程。说实话，效果不算好，但它真的“做出了点东西”。那一刻对我来说，简直是被震住了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那是在去年四月、五月左右，对吧？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。已经好到让我看清方向了。我立刻意识到：这就是未来。从那之后，有好几个月我都睡不好觉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我记得有一次我凌晨五点在 Twitter 上给你发私信，你马上就回了。我还问你怎么这么早，你说这是常态，你基本都没睡。我问你在干嘛，你说一直在用 Claude，特别上瘾。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：真的，就跟赌场一个道理，它就是我的小老虎机。你敲下一个 prompt，要么啥也没发生，要么一坨垃圾，要么突然给你个让人头皮发麻的结果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：而且你是一个经验非常丰富的开发者，对你来说，被“震撼”并不容易。你见过好代码、烂代码，心里是有一个标准的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：所以才好笑。我以前在公司时，花了大量的时间在所谓“抠细节”上。现在回头看，我都会想：我当时在干嘛？客户根本感知不到这些。当然，代码要可靠、要快、要安全，这些是底线。但我当年真的抠太多了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：但另一方面，你刚才也说过，大家之所以喜欢 PSPDFKit，正是因为它打磨得最好、最稳定。你不觉得那种“抠细节”其实是在控制技术债吗？某种程度上，正是这种偏执才让产品性能和质量都站得住。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是的，这么说也没错。到现在我也还是这样。我上一篇博客，其实就是在“忏悔”，我承认我开始在主分支上直接提交 AI 写的代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，我其实还是花了大量时间在做结构重构。就拿最近来说，我特别想把一个 PR 合进去，那是一条接近一万五千行的改动链。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在一个项目里，我把所有东西都迁移到了插件化架构，这件事让我非常兴奋。我真的很在意整体结构。但我没有把每一行代码都读一遍，因为很多代码说白了就是枯燥的“管道工程”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;你看，大多数应用本质上都差不多：数据从 API 进来，是一种形态；你解析、封装，变成另一种形态；存进数据库，又是一种形态；再读出来，又变一次；最后变成 HTML 或别的形式，你在页面里输入，它又变了。大部分软件，其实就是在应用里不断“揉捏”数据，我们本质上就是高级的数据搬运工，而真正难的部分，如Postgres 这种东西三十年前就被一群天才解决了。这就是现实。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，总会有一些有意思的地方，但我真的不需要关心每个按钮怎么对齐、每个 Tailwind class 怎么写。有些细节很无聊，有些细节很有趣，但整体来说，更重要的是系统架构，而不是逐行读代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;日常如何用AI 编程工具工作？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那我们跳到现在。你现在用 Claude 相关工具写代码时，日常工作流是怎样的？你用终端吗？几个终端？都用哪些工具？你刚才说你不太做逐行代码审查，但又一直在想做架构。如果你要跟一个即将加入团队的开发者解释，你的一天大概是什么样的，会怎么说？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：这个过程挺有意思的。稍微回顾一下，一开始是 Claude Code，然后我就彻底上头了。接着有一段时间我用 Cursor，又试了 Gemini 2.5，后来又用了 Opus 4。我还把不少朋友也拉进来了，比如我在越南认识的 Armin 和 Mario，他们都是被我“传染”的。我当时状态真的很上头，搞得他们也开始试，然后大家一起凌晨五点不睡觉。我把这群人戏称为“黑眼圈俱乐部”。这也是为什么我后来在伦敦搞了一个 meetup，名字就叫 Claude Code Anonymous。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;真正把我震住的，是一个认知上的变化：我突然意识到，我现在几乎什么都能做了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以前做副业要慎重挑选，因为写软件真的很难。现在也不轻松，但那种“摩擦”感变了。过去是“我在这个技术栈里很强，在那个栈里很菜”，现在我会想：算了，直接上 Go 吧。我完全不懂 Go，但我有系统层面的理解。一旦你有了这种理解，就会慢慢形成一种感觉，知道什么是对的、什么是错的。这本身就是一种技能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我记得有人发推说，写代码时你能“感觉到摩擦”，而正是这种“摩擦”帮你做出好的架构。我现在 prompt 的时候也有同样的感觉：我能看到代码刷刷地生成、能感知它花了多久、能感觉到模型是不是在“顶你”，也能判断生成的东西是乱的，还是有章法的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我在发出 prompt 的那一刻，心里其实已经有个预期：这事大概要多久。如果明显比预期慢，我立刻就知道有问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你等于是在“感觉”模型的状态，对吧？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，我觉得这是一种共生关系。我在学着更好地“跟它说话”，甚至可以说是一种新的、半死不活的语言。同时，我用这些工具的能力在提升，模型本身也在进化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从四月到现在，我觉得真正的拐点是在夏天：那时它已经强到，你几乎可以不手写代码，就把软件做出来。但真正让我彻底服气的，其实是 GPT-5.2。我觉得它被严重低估了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我其实不太理解，为什么还有那么多人主要用 Claude Code。当然，我能理解那是一种不同的工作方式。但我现在用的这一套强得离谱，几乎每一个 prompt都能给我想要的结果。这在 Claude 上是很难想象的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我最近的一个项目常常在Codex 上同时跑五到十个 agent。如果你是典型的 Claude Code 用户，你得忘掉不少“为了哄它出好结果”的小技巧。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我也见过 Claude Code 团队，他们确实开创了一个新类别。Claude Code 是一个定义品类的产品，用来做通用电脑工作非常棒、用来写代码也很好，我现在几乎每天还在用。但一旦进入复杂应用的代码编写，Codex 就强太多了。Claude Code 往往只读三四个文件，就自信满满开始写代码，你得不断拉着它，让它多读、多看，理解整个代码库，才能把新功能编进去。Codex 则会安静地读文件，可能读十分钟。如果你只用一个终端，这体验确实会让人崩溃，我完全理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但我更喜欢那种，你不用事无巨细地告诉它该怎么做，我和模型更像是在对话。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我会说：“我们一起看看这个结构，有哪些可能性？你有没有考虑过这个功能？”因为每一次 session，对模型来说都是从零开始理解你的产品，你有时候只需要给它一点点提示，让它往不同的方向探索。我不需要什么Plan模式，只是一直聊，直到我说“那就这么建吧”，它才会真的开始动手。当然，它们都挺“容易被触发”的，但只要我说的是“讨论”“给我选项”，它就不会直接写代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：所以你大量的 prompting，其实是在和 agent 一起做规划？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。比如我会提醒它“我们需要文档，那放在哪里合适？”它可能会建议“这应该单独成一页。”系统设计是我在做的，因为我对产品整体形态有清晰的理解。我不需要逐行理解代码，那是 Codex 在做的事，但架构师是我。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这听起来有点像很久以前的一种模式：有一个“Architect”，以前也是开发者，但不再亲手写代码，而是负责系统蓝图，下面有一群工程师实现。这种模式在很多现代公司已经不流行了，大家更偏向资深工程师一起协作。不过在一些银行之类的地方，还是能看到这种“大写的 Architect”。问题是，这种模式往往很让人讨厌：设计的人不用值班，不直接为结果负责，最后在现实里容易失效。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而你现在的状态，倒像是你是 architect，但手下是一群 agent。区别在于，你依然是独立贡献者，代码是你的、责任也是你的。如果你推了个 bug 把 ClawdBot 搞挂了，就像最近那次，你是要负责的。以前在公司里，architect 往往被流程和人层层保护，不太需要直接面对结果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我其实不太喜欢“architect”这个词，我更愿意叫自己 builder。我发现，能不能把 AI 用好，人群之间差异非常明显。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;像我关心的是结果、是产品，我很在意它的感觉、体验。我关心结构层面的骨架，但不会抠那些小细节。而另一类人，特别喜欢写硬核代码、研究算法，他们不太喜欢产品、市场这些东西。他们更享受解决“难问题”。而偏偏，这正是 AI 最擅长的部分，所以这类人往往会抗拒 AI，或者感到非常失落。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;很多时候，我只是给模型一点提示，但老实说，我去年在软件架构和系统设计上学到的东西，比过去五年加起来都多。这些模型里装着海量知识，一切都只差一个“问对的问题”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;像我那个 Twitter 项目到现在还没完成，我也很希望能回去继续做。所有东西一度都曾跑得很好，但用着用着就开始卡、变得奇怪，然后又莫名其妙恢复。这类问题特别难 debug，因为很难复现。基本就是：你用得越多，它就越慢。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来我发现，是 Postgres 里有一些在特定 insert 时触发的逻辑把数据库拖得很忙。模型看不到这一层，因为抽象太远了。问题出在一个文件里的一个函数，名字也不明显。我一直没问对问题，直到我问了一句：“这里有没有副作用？”才把它挖出来，然后改掉了。所以说，一切真的都只差在能否问一个对的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：但前提是，你得有足够的知识和经验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，这正是关键。那些对内部实现执念很深、又不太在乎“能不能先做出来”的人，往往会抗拒 AI；而那些更兴奋于“把东西做出来”的人，反而进展飞快。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有一点对我帮助很大：以前我开公司带团队，可以盯着每个人的代码，要求他们写成我想要的样子。但很多没管过人的开发者，没有学会放手，接受“这段代码不是我理想中的样子，但它能让我更接近目标”。不完美的地方，永远可以之后再改。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我非常相信“迭代式改进”。当年在公司里，我就是花了很长时间学会一点点放手。所以，当我开始用 Claude Code 的时候，感觉就像我手下有了一群工程师：有时候很不完美，有时候甚至有点蠢，但偶尔又异常聪明。我需要引导他们，一起朝着一个目标前进。某种程度上，这感觉就像又当了一次老板。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;高效率的秘诀&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：挺有意思的一点是，在之前，你用一种非常传统的方式做了十几年的软件，甚至不止十几年。你不仅把产品打磨得很扎实，也非常擅长带团队、设立高标准，对“工程本身”这件事非常在意。而现在，你用 agent、用 AI 写代码有一年左右的时间了。对比这两种阶段，你觉得真正改变了什么？又有哪些东西，其实并没有变？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我不太喜欢“vibe coding”这个说法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那你更愿意怎么称呼？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：现在大家基本都这么叫了吧。我自己对外会说，我做的是“Agentic Engineering”。现在我往往是凌晨三点开始写代码。那些枯燥、机械的编码工作基本都被自动化掉了，我的速度快了很多，但与此同时，我需要思考的事情也多得多。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我依然能进入那种心流状态，感觉和以前几乎一样，但精神消耗其实更大，因为我不是在管理一个工程师，而是同时管五个、十个 agent。我在不同模块之间来回切换：这边是一个子系统，那边是一个功能点，我心里大概知道这个功能交给 Codex 可能要跑四十分钟到一个小时，那我就先把方案想清楚再丢给它去做，然后我转头去做别的事。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这个在跑、那个也在跑，我要过一会儿回来看看这个、再切到另一个，脑子里一直在做上下文切换。我其实挺不喜欢这种状态的，也觉得这是一个过渡期的问题。将来模型和系统更快之后，我可能就不用并行这么多。但为了保持 flow，我现在必须高度并行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通常会有一个主项目占据我的主要注意力，旁边还有几个“卫星项目”，可能我只花五分钟交代一下、它跑半小时，我回来看看结果就行，对脑力占用不算大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：听你这么说，我想到两种画面。一种是那种经营类游戏，要管厨房里的员工，看着一道道菜出炉，你得不停切换。另一种是看国际象棋大师同时下二十盘棋，他们走到一块棋盘前看一眼，立刻做决定。有的棋要想久一点，有的扫一眼就走。你就像在不断扩展自己的“并行带宽”，只要你还能顺畅地切换。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：区别在于，用 Claude Code 的时候，你确实得换一种工作方式。它很快，但第一版产出经常是跑不通的。比如它写了点东西但你忘了同步改另外三个地方的话，程序就崩了。真正高效的秘诀在于：你必须把闭环做完整，让 agent 能自己 debug、自己测试。这是最大的秘密，也正是我后来效率暴涨的原因。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但老实说，在 Claude Code 那一套下，很多时候你还是得回去修修补补，迭代次数也不少，所以总体并不一定快多少，只是更“互动”。现在用 Codex，几乎一次就对。我的基本策略永远是：做一个功能，一定让它写测试，确保能跑起来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：至少要能跑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。哪怕是写一个 Mac 应用也是一样。就像我前两天在 debug 一个问题：同样的 TypeScript 代码，在 CLI 里能找到远程网关，但在 Mac app 里不行。Mac app 的 debug 特别烦，你得编译、启动、点来点去才知道不对。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以我干脆说：“你给我做一个 CLI 调试工具，走完全相同的代码路径，我可以直接调用。”然后就让它自己跑、自己改。它跑了一个小时，最后告诉我这是一个 race condition 和一个配置错误。听起来也很合理。我不需要亲眼看它怎么写代码，只要闭环跑通了就行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你其实是因为搭好了验证闭环，所以你信任它。这和在大公司里做项目有点像，所有测试都过了，并不代表百分百没问题，但已经是一个很强的信号了，至少有人替你想过、测过。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：即便在我最新的项目里，也照样会有 bug。比如 Antigravity 在工具调用的循环格式上有些奇怪的行为，你得做过滤。我一开始被折腾了很久，后来突然意识到：我为什么不把这事自动化？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;于是我直接跟 Codex 说：“设计一套 live test，起一个 Docker 容器，把整个系统装起来，跑一个完整 loop，用指定文件里的 API key，然后让模型读一张图片，生成一张新图片，再反过来分析结果。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这个过程跑得很慢，但它把我所有 API key 都测了一遍，从 Anthropic 到 OpenAI 再到 GLM，所有细节问题全修了，因为闭环是完整的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你说的“闭环”，本质上就是让 agent 能验证自己的工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：没错。这也是为什么现在这些模型特别擅长写代码，但写创意内容反而一般，因为代码是可验证的：能编译、能 lint、能跑、能看输出，只要你设计得好，就能形成一个完美的反馈回路。我甚至会把核心逻辑都设计成可以用 CLI 跑，因为浏览器那一套循环太慢了，你要的是快速反馈。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：所以有些东西其实没怎么变：比如后端、业务逻辑这种，本来就更容易验证。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：反而有个挺反直觉的点：用这种方式写代码，会让你变成一个更好的工程师。因为你必须把架构想清楚，才能更容易验证，而验证正是把事情做对的关键。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这其实和 AI 之前是一样的。做复杂系统的人，一开始就会想怎么让它可测试、接口怎么设计、要不要 mock、要不要端到端测试。这些都是非常困难、而且一旦做了就很难改的决策。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：软件还是软件。我现在可以很坦然地说，我不再亲手写代码了，但我写的代码质量比以前更好。而以前我已经写得很好了。在公司那会儿，测试常常很痛苦，各种边界条件、分支爆炸。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：除了像 Anders 这种我非常尊敬坚持 test-first 的人，大多数开发者其实都不爱写测试。我自己也是。测试和文档对我来说从来不是一种创作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：现在完全不一样了。我最近一个项目的文档质量是我职业生涯里最好的，但我一行都没写。我只是跟模型讲清楚设计权衡：为什么这么做，然后让它写给新手看的部分，再在后面加上更技术化的细节，效果好得惊人。测试也是一样。每做一个功能，我就会自然地问：这个怎么测？如果换一种结构，是不是更好测？因为我脑子里始终只有一件事：怎么把闭环关上。模型必须能自己验证结果，这会反过来逼我做出更好的架构。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;为什么开发者AI编程玩不溜？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那你觉得，为什么还有很多经验丰富的开发者，对 AI 这套东西依然很抗拒？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：前阵子我看到一篇博文，作者是我非常尊敬的人。他测试了好几个模型，其中甚至包括一些本来就不适合写代码的模型。他的做法听起来像是随便写个 prompt，在网页上点发送，拿结果就跑，甚至都不编译，结果当然很失望。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但问题是：你觉得自己第一次写代码就能没 bug 吗？这些模型，本质上是人类知识的幽灵。它们不可能一次就对，所以你必须有反馈闭环。你也不能只发一个 prompt，而是要开始一段对话。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他还抱怨模型用了旧 API。但你没告诉它 macOS 版本，它当然会默认用老 API。模型训练的数据里，旧数据本来就比新数据多。你越理解这些“小怪兽”是怎么思考的，你的 prompting 就越好。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但他可能只玩了一天，就下结论说这东西不行。这就好比你会弹吉他，我把你放到钢琴前，你随便敲两下说“这不行，我还是回去弹吉他吧”。这是另一种构建方式，另一种思维方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;你不知道我凌晨三点对着 Claude Code 吼过多少次。后来我慢慢搞明白了：它真的就是严格按我说的话在做事。甚至有时候你可以直接问它：你为什么这么理解？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在最近一个项目里，我感觉自己更像一个“人肉合并按钮”。社区很活跃，我几乎一直在 review PR。一开始它经常只 cherry-pick 一部分就关 PR，我被气得不行。后来我问它为什么，它会说：因为你之前这么说过，我就这么理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;慢慢地，我学会了这门“机器语言”，调整我的表达，现在它几乎每次都能给我想要的结果。这和任何技能一样，是可以练出来的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这和 Simon Willison 说的也很像：用得越久，越能意识到自己还能做得更好。那我们来做个更极端的假设。你现在做的ClawdBot 很火、用户很多，但还不是像 PSPDFKit 那样直接承载大量收入的业务。如果今天 PSPDFKit 从世界上消失了，你要从零重建它，手上有现在这些 agent，你会怎么做？你会把什么交给 AI？什么一定要自己把控？团队结构会变成什么样？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：今天的话，我大概用三成的人就能跑起一家公司。但前提是，这些人必须非常资深，既懂系统又敢于放手，知道哪些地方重要，哪些地方可以“vibe”一下。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一点我在 AI 圈里其实不太常见。Twitter 上太多声音很大、但明显不知道自己在干什么的人，还有很多我觉得挺荒唐的概念。比如某些用来绕 Opus 限制的复杂流程，Codex 根本用不着。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;软件开发很少是那种“列一个超长任务清单，然后全部自动执行”的问题。我看到很多人搭了一整套复杂的编排系统：自动建 ticket、agent 处理 tickets、agent 互相发邮件，最后搞出一团复杂系统。图什么？这本质上就是瀑布模型，我们早就知道它不好用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对我来说，开发必须从一个模糊的想法开始。我甚至会故意少给 prompt，让 agent 先做点“不太对”的东西，因为可能八成都是垃圾，但那剩下的两成会给我新的启发，然后我不断迭代、塑形。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我得点它、用它、感受它。好软件需要“品味”，而这是 AI 现在最欠缺的部分。但好处是，现在做一个功能太容易了，不行就扔掉，或者重新 prompt。我的构建方式几乎总是向前的，很少回滚。就像雕塑一样：你拿着一块石头，一点点敲，慢慢地，形状就从大理石里浮现出来了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：回过头看软件工程的变化，好像有一个很明显的转折点。过去没有 AI、没有这些agent的时候，前期规划非常重要。你觉得现在这种变化，是因为写代码本身的成本大幅下降了吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我现在还是会做规划，但投入的精力没以前那么多了。因为现在试错太便宜了，你可以直接做出来看看效果，再判断“这个形态行不行”“是不是需要微调”，甚至“干脆完全换一条路”。相比过去，这一切的成本低到一个程度，让整个过程变得更像是在玩。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：对，就像以前哪怕是交给一个刚毕业的新人或者实习生，一件事也得花一两天。现在不是一天两天，而是分钟级。就算是比较长的任务，最多也就是十几二十分钟。而且你还不是干等着，一个任务在跑，另外几个也在并行跑，所以试错本身几乎不算浪费。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是的。最早我在 Claude 里其实假设只有一个 agent，后来变成多个；一开始假设只有一个 provider，比如 WhatsApp，后来又变成支持多个。这种改动，如果是我自己手写代码，简直是灾难，要把逻辑贯穿整个系统重新织（weaving）一遍。但 Codex 花了大概几个小时就搞定了，这要是我自己来至少得两周。所以以前那种“前期一定要一次想对”的心态是现实所迫，现在我知道，很多东西是可以改的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这也让技术债的处理变得轻松很多。你可以一边做，一边重新理解项目本身，一边调整你的思路。所以我其实不太相信那种“按 spec 写完，机器跑完就结束”的模式。你在真正开始构建之前，根本不可能完全知道自己要做什么。很多关键认知，都是在构建过程中才出现的，它们又会反过来影响系统最终的形态。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对我来说，这更像一个循环，你不是直线爬山而是绕着走，有时候还会偏离一下路径，但最终还是会到达山顶。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;ClawdBot 来了&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我们换个话题。你已经连续几个月几乎不间断地在做 ClawdBot。其实有一个想法很早就把你拉回来了，对吧？你一直想做一个“超个人化”的助理。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，而且不是那种每天早上给你发“早安，这是你今天三件待办事项”的助理。&lt;/p&gt;&lt;p&gt;我想要的是一个真正理解我的东西，比如我见了一个朋友回家后它会问我：“刚刚那次见面感觉怎么样？”或者有一天提醒我：“你已经三周没给 Thomas 发消息了，我注意到他最近在城里，要不要打个招呼？”又或者它会发现某些模式，比如“你每次提到这个人语气都会变，为什么？”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;那是一种极度个人化的东西，几乎是反 CRM 的存在，有点像电影《Her》，但这确实是技术发展的方向。模型对文本的理解能力非常强，上下文越大它们看到的模式就越多。即便它们本质上只是矩阵计算、没有灵魂，但很多时候给人的感觉已经完全不一样了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当时我甚至为这个想法注册了一家公司，叫 Amantus Machina，意思是“有爱的机器”。但去年夏天我真正深入做的时候，发现模型还差一点。能跑起来也有一些惊喜，但整体上还站在我需求的边缘之外。不过这反而让我很兴奋，因为 AI 的进展太快了，我很清楚这个想法可以晚点再回来做。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有一个判断是，我相信所有大型公司都在做个人助理。未来每个人都会有一个“最懂你的朋友”，它是台机器，了解你的一切、可以替你做事、能主动提醒你。当然，这会非常消耗算力，但凡是负担得起的人，都会想要一个。然后随着系统效率提高、芯片进步，这种能力一定会逐步下沉。这几乎是确定的趋势，而且现在已经能看到一些雏形了，比如 OpenAI 推出的一些偏生产力的功能。但现在算力还不够，把这种东西真正作为产品推出来非常难。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而且还有一个问题是，我其实更希望它跑在我自己的电脑上，数据真正属于我自己。把邮件、日历、约会软件全部交给 OpenAI 或 Anthropic，说实话，挺吓人的，很多人已经在把这些模型当作心理咨询师用了，而且效果出奇地好。它非常会倾听，能理解你的困扰，只要不是某些明显差劲的版本，它真的能提出很有洞察力的问题，哪怕只是帮你复述和反思，你都会感觉被理解了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以我一直有这个助理的想法，只是当时技术还没到位。与此同时，我也做了很多别的有趣的东西。在职业里绕一点“vibe 的弯路”，不断给自己造工具，优化自己的工作流，这几乎是成为一个真正工程师的必经阶段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但“超个人化 agent”这个念头一直没消失。最近几个月，我终于开始认真把它做出来。一开始它的规模其实很小，我甚至叫它 WhatsApp Relay，本意只是通过 WhatsApp 触发我电脑上的一些操作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来我去摩洛哥给朋友过生日，一整天都在外面，就一直用 WhatsApp 跟这个 agent 聊天。它帮我指路、开玩笑，还能用我的身份给其他朋友发消息。那一刻我真的被震住了。最早的实现非常粗糙，我甚至没用正式的方式传图片，只是丢了个字符串，让它自己用工具去读。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有一次我随手发了一条语音，其实我根本没实现语音功能。结果过了半分钟，它居然回了我一条语音。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我问它怎么做到的，它说：你发了一个文件，我看了 headers，发现是 Ogg 格式，就用 ffmpeg 转了一下；然后我找你电脑上的语音识别工具，没装，但我发现了一个 OpenAI 的 endpoint，于是用 curl 调了接口。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;那一刻我真的觉得不可思议。这就是 Opus 的能力，它太“能自己想办法”了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我开始彻底上瘾。我让它叫我起床，它跑在伦敦的 Mac Studio 上，通过 SSH 连到我在摩洛哥的 MacBook，帮我开音乐，因为我没回应就一直把音量调大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我还加了一个 heartbeat。这简直疯了，你每隔几分钟就给一个模型发“想点酷的事情，给我点惊喜”的 prompt，这可能是史上最贵的闹钟，但它真的“懂”了。我那段时间脚受了伤需要很早起床，却一直没回应，它的推理过程非常清楚：“Peter 没回复，他必须起床，不能再睡了。”我把这个东西给朋友们看，所有人都被吸引住了，觉得这太神奇了。我自己也一样。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来我发到 Twitter 上，反而反响很冷，因为很多人完全看不懂这是什么。我感觉，这可能是一种全新的产品类别，大家还没有形成认知。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这有点像你当年第一次接触 iPhone 的经历。广告、电视、各种宣传你都看过了，但真正的变化，其实还是在你亲手用上它之后。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，必须得用。我真正全力投入也就是最近这几个月，一开始它还叫 VA Relay，后来我自己都觉得这个名字不对劲了，因为功能早就不止这些了，已经接了 Telegram，还有一堆别的东西，再叫 Relay 完全不贴切。所以我给它改了个名字，叫 ClawdBot。算是个内部玩笑，我很喜欢《Doctor Who》，而且这个名字域名更好，也更能解释这个产品是什么。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，我也在悄悄搭建我的“军队”。要让这套东西真正跑起来，核心原则就是：一切都得是 CLI。所以我写了大量 CLI 控制 Google、床、灯、音乐，所有东西都变成命令行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;为什么是 CLI，不是 MCP&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那为什么是 CLI？为什么不是 MCP？你怎么看 MCP 这套东西？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：说实话，MCP 更像是一根拐杖。它最大的正面价值是逼着公司去开放更多 API。但整个设计思路本身是有问题的：你得在会话一开始，就把所有工具、所有函数、所有说明一次性塞进上下文，然后模型还得精确地构造一大坨调用参数，再接收一大坨返回。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;问题是，模型其实特别擅长用 bash。举个例子，你要一个天气服务，模型先问“有哪些城市”，接口一次性给你几百个城市；模型没法过滤，只能全吃进去。然后你再问“给我 London 的天气”，返回温度、风速、降雨、几十个你根本不关心的字段，最后上下文里全是垃圾信息。但如果是 CLI，模型可以直接用 jq，只拿它真正需要的那一小部分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：听起来问题并不是 MCP 本身，而是所有东西都必须提前塞进上下文。如果能按需发现、按需调用，理论上是能解决的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：现在大家确实在往这个方向做，但还有一个根本问题：你没法“链式组合”。&lt;/p&gt;&lt;p&gt;我不能写一个脚本说：“找出所有温度超过二十五度的城市，再过滤字段，再把结果打包成一个命令。”因为 MCP 本质上都是孤立的工具，没法脚本化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：但这听起来更像是时间问题。就像现在我们做一个天气应用，本来就要选 API、比较价格、覆盖范围，然后再把不同 API 的结果串起来。这套事情在没有 AI 的年代已经解决过了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是的，AI 时代迟早也会解决。只是形式还没定。我自己干脆写了个小工具，叫 Porter，用 TypeScript，把 MCP 转成 CLI，直接打包用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：所以你的结论是至少现在，CLI 的效率更高？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。ClawdBot 里我其实根本没直接支持 MCP，但通过 Porter，几乎可以用任何 MCP。你甚至可以在手机上说：“用 Vercel 的 MCP 做这个事情。”它会自己去网站找 MCP、加载、按需使用。而现在很多 MCP 方案，甚至还得重启 Claude Code，用户体验非常糟，所以我就一路把自动化堆起来，工作量非常大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Taylor 前几天还做了个视频，说“这个人疯了”，因为现在支持的东西已经多到离谱。但我自己在用 agent 的过程中只会不断冒出一个念头：我还想让它多做一点。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;前段时间我干了一件“非常不理智”的事：我建了一个 Discord，把我的 agent 加了进去。有人给项目贡献了 Discord 支持，我当时其实很犹豫要不要合并，但最后还是合并了。结果就是我把一个拥有我电脑完整读写权限的 agent，扔进了一个公开的 Discord。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;把复杂度隐藏到让人觉得“理所当然”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：听起来完全不像是个好主意。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，简直疯狂。但后来有人进来，看到我用它检查摄像头、做家庭自动化、帮我放音乐。我在厨房里，跟它说“看我的屏幕”，它就真的看到了。因为它有完整权限，可以点终端、替我打字、执行命令。你甚至可以对它说“做这个做那个”，它就照着屏幕操作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我现在还在优化，理想状态当然是纯文本流，但现在这种方式已经能跑了，而且是后台默默在跑。任何体验过几分钟的人都会上瘾，项目的 star 数一周内从一百涨到三千多，我已经合并了500多个 PR。所以，我现在感觉自己就是个人肉 merge 按钮，整个人状态都有点散。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但这正是它的美妙之处：技术本身消失了。你只是拿着手机，像跟一个朋友聊天。这个“朋友”无所不能：能访问你的邮件、日历、文件，能给你搭网站、能做行政工作、能爬网页、能给朋友打电话，甚至能帮你打电话给商家订位。我正准备合并通话功能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;你完全不用关心算力、上下文、子 agent。它们在后台疯狂运转，只为了让你觉得“一切都很简单”。我还有一套记忆系统，当然不完美，但已经足够让人觉得像是魔法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在我走在路上，看到一个活动，随手给 Claude 发张照片。它不仅能告诉我这个活动的评价，还会检查我日历有没有冲突、朋友有没有提过。因为它掌握了大量上下文，给出的回答，已经完全不是那种“各自待在小盒子里的工具”能比的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：听起来你已经做出了 Apple 想让 Siri 成为、却始终没做到的东西。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：老实说，我可能是 Anthropic 最好的销售。我都不知道有多少人因为 ClawdBot 去买了200美元的订阅，有些人甚至多开了一个账号。不是因为模型“浪费 token”，而是大家太爱用了，用得太频繁。而且由于复杂性被完全隐藏，他们根本感觉不到后台有多少子 agent 在忙。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;真正难的地方在工程上：如何把复杂度隐藏到让人觉得“理所当然”。这才是魔法的来源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：但这也很有意思。你在架构上投入了这么多思考。现在这个项目已经跑了几个月，也确实爆了。在你脑子里，你是不是很清楚 ClawdBot 的结构？哪些地方该改、哪些地方要重构？你会不会开始担心内存、token、效率这些问题？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：Token 更多是 prompt 和 memory 结构的问题。说到底，这就是 TypeScript 在搬 JSON。大模型给我文本，我存盘；我再把文本发到 WhatsApp、Slack、Discord、Signal、iMessage，还有更多渠道在接入。现在结构确实有点乱，但本质上只是文本在不同形态间流动。有多 provider、多 agent、有 agent loop、有配置、有大量 plumbing，但没有哪一块是真的“难”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：更多是碎片化的复杂，对吧？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。真正的难点是：怎么让它“看起来像魔法”。我花了大量时间在安装和引导体验上。你只需要敲一行命令，我会检查你有没有 Homebrew、有没有 Node，自动安装依赖，兼容老版本；然后引导你选模型，能自动识别你已经装了什么，基本就是一路按回车。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;接着你填个手机号，WhatsApp 就能直接用。我会问你要不要“给它起名字”，然后终端里会弹出一个 TUI，让你完成这一步。我还加了一个 bootstrap 阶段：模型一开始不会假装自己“有灵魂”，而是通过一轮对话慢慢理解你；然后它会把 bootstrap 文件删掉，生成 user.md、soul.md、identity 文件，记录你的偏好、价值观、内部玩笑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些文件不是静态的，它们会随着你们的互动不断演化。等这一切结束，你只是用 WhatsApp 跟它聊天，但你已经不再觉得自己是在跟“GPT 某个版本”说话，而是在跟一个真正的“朋友”交流。配置不需要你手改，因为 agent 能改自己。你甚至可以对它说“更新一下自己”，它就会拉最新版本、更新完再回来告诉你。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这就是我说的魔法：当复杂度被隐藏到极致，体验才会真的发生变化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这听起来其实很像你当年做 PSPDFKit 的思路，对吧？你把 PDF 那套复杂性完全“融”掉了，用户只需要直接用，旋转、编辑，一切都很自然地发生。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，甚至在当年的 API 层面就是这么想的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;你的工作流程，公司能套用吗&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我们把话题拉回到软件工程本身。你现在做的已经是一个真实在跑的产品了，是生产软件，大家在用，你也在不断 merge PR。回头看 PSPDFKit 那样的公司，几十人、上百人的团队在维护成熟系统。基于你现在构建 ClawdBot 的方式、你用的这些工具，你觉得大型公司的软件工程方式会发生什么变化？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我明显感受到一个割裂：像你这样的个人，AI 对生产力的提升是巨大的，你完全掌控；但在团队或公司层面，尤其是有大量历史代码的情况下，一切就慢很多。不是说他们不用 AI，而是感觉两个世界之间有一道鸿沟。你当过 CEO，你怎么看？这是结构性问题，还是只是时间问题，就像每一代新技术，先被一小撮人玩明白？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我觉得，大多数公司要高效采用 AI，会非常非常难，因为这不仅是工具问题，而是要求你重新定义“公司是怎么运作的”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;你想想，在 Google 这种地方，你要么是工程师，要么是经理；你想顺手决定一下 UI 什么样？对不起，不行。要么你写代码，要么你做设计，角色边界非常清楚。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在这个新世界里，你需要的是有完整产品视角的人，能把事情从头做到尾。这样的人数量会少得多，但要求极高：高自主性、高能力。极端一点说，公司规模可能只需要现在的三成。这听起来就很吓人了，经济上也一定会带来巨大的冲击，很多人会发现自己在这个新世界里找不到位置。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以我一点都不意外，现有的大公司用不好 AI。他们当然也在用，但只是“用到一点”。要真正发挥作用，你得先来一次大重构，不只是代码层面的，也是组织层面的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我现在设计代码库，已经不是为了“对我来说顺不顺手”，而是为了“对 agent 来说顺不顺手”。我优化的是模型摩擦最小、跑得最快的路径，而不一定是我个人最偏好的写法。因为最终是它在跟代码打交道，不是我。我负责的是整体结构和架构，这部分我还是按自己的方式来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在所有东西都要“可被解析”。PR 在我眼里，越来越像是 Prompt Request。有人提了一个 PR，我很少直接在那个 PR 上改。我会先说声谢谢，理解这个功能想干嘛，然后拉着 agent 从这个 PR 出发，把功能按我理解的方式重新设计一遍。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;代码可能会复用一点，但更多是把“目标”传达清楚。有些 PR 在定位 bug 时确实很有帮助，但说实话，现在很多 PR 的整体代码质量在下降，因为大家在疯狂 Vibe Coding。可真正要把功能做对，还是得对整体设计有深刻理解，否则你连怎么引导 agent 都不知道，结果自然就会很糟。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：对，没有一个完整的反馈闭环，质量肯定会出问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是的，对我来说，这种方式效率极高。我记得在 PSPDFKit 的时候，一个 PR 可能要做一周，评论、来回切换上下文、等 CI 四十分钟……现在不一样了。我把代码丢给模型，它会主动提醒我“这个地方可能会影响到别的模块”。我自己也会有判断，然后我们一起把它“重塑”成符合我愿景的形态，再把代码织进去。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;说实话，我现在写代码用的动词都变了，“把代码织进现有结构里”，有时候甚至要先改结构，才能让它装得进去。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那如果你现在招一两个人，变成一个小团队，你觉得代码评审、CI、CD 这些东西会怎么变化？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我其实没那么在意 CI 了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你以前在 PSPDFKit 可是非常在意这些的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：以前是，现在测试本身我还是在意的，但我用的是本地 CI。我现在有点“异端”了。&lt;/p&gt;&lt;p&gt;agent 会跑测试，我不想每次推个后端 API，都等十分钟 CI。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：但你已经在 agent 那里等了不少时间了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：只要本地测试过了，我就 merge。偶尔 main 会出点小问题，但通常很接近正确状态。&lt;/p&gt;&lt;p&gt;我现在管完整流程叫 “gate”。full gate 就是 lint、build、全测试跑一遍。它就像一道门，代码出去之前必须过这关。我甚至开始用 agent 的语言了：“提交之前，跑一下 full gate。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那如果多一个人一起做，你可能也不会做传统的 code review 了？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我们不会讨论具体代码，而是讨论架构、讨论大的决策、讨论风格。比如最近有个 PR 加了语音通话功能，现在我可以直接对 ClawdBot 说：“帮我给这家餐厅打电话，订两个位置。”这功能很酷，但它是一个很大的模块，影响面很广。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我当时就有点犹豫：这是不是开始变成臃肿软件了？然后我又回到老套路：把它做成一个 CLI。我之前有个没做完的项目正好相关，于是我打开 Codex，说：“你看看这个 PR，再看看那个项目，能不能把这个功能织进去？”对，我又用了“织”这个词。对我来说，这已经成了一种工作方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：就这么继续往前推了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对，就这么继续。我们能不能把这个功能织进 CLI 里？利弊分别是什么？然后他们会跟我说可以这样做、那样做，也会给我很坦诚的意见。听下来我会觉得，这个功能其实是适合放进项目里的，而且确实能带来一些如果做成外置 CLI 就拿不到的好处。但我心里还是会有警惕：我不喜欢臃肿，这会不会开始变成 bloatware？那能不能搞一个插件式架构？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有一个用 AI 的“隐藏技巧”是：多引用别的产品。我经常直接跟 agent 说，你去看这个文件夹，我当初在那儿已经把问题解决过了；或者去看那个地方，之前的思路都在那里。这样它就能直接理解我当时是怎么想的，我也不用重新解释一遍。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;因为如果我再解释一次，很可能反而会引入偏差，没法完全表达我脑子里的原始想法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有个人叫 Shitty Coding Agent的项目，名字虽然这么叫，其实一点也不 shitty。他里面有一套插件架构，可以通过 Git 加载代码，而且全是 TypeScript。我就跟 agent 说，“你去看看这个文件夹、那个文件夹。”结果它受到启发，直接给我设计出了一套非常炸裂的插件架构。所以本质上还是一种直觉驱动的过程。我昨晚基本上就是在干这个。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：听起来，你的整个工作流已经和传统方式完全不一样了。PR 在你这里的角色变了，CI 也不一样了，测试还在，但更重要的是反馈回路。你用的是“织代码”，而不是“写代码”，讨论的是架构和品味。这对我来说是一个非常大的转变。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;那我们假设接下来你要招一两个、三个工程师，把这个项目变成一个真正的团队，甚至一个业务,你会看重什么样的能力？如果现在有一个资深工程师，你会被什么样的品质吸引？你会期待他们做过什么项目，或者具备什么特质，才能适应、或者快速学会这种工作方式？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我会找那种活跃在 GitHub 上、做开源的人。更重要的是，我要感觉到他们“爱玩这个游戏”。在这个新世界里，学习方式就是不断尝试，它真的很像一个游戏：你越玩越熟练，就像学乐器一样，得一直练。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我现在能做到这么快、这么高效，连我自己都觉得有点不可思议。前几天我一天之内提交了600多个 commits，简直疯狂。但它是能跑的，不是那种“看起来很糟”的代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：对，这背后是大量的技能积累。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是的，但真的很累，你必须去玩这些技术、去学习。一开始一定会很挫败，就像你第一次去健身房又累又痛，但很快你就会变强，你会感觉到工作流在加速，能明显看到进步，然后你就慢慢上瘾了。所以，一边玩，一边拼命干。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你现在投入的时间，明显比以前多了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我从来没像现在这么拼过。就算当年我有公司，也没这么拼。不是因为我必须这么做，而是因为这件事太上瘾、太好玩了。再加上现在正好有势能，有一群人在推着我往前走。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;年轻人的建议&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：是不是也因为你商业嗅觉很好？你能看出来什么时候有机会、什么时候窗口期打开了。&lt;/p&gt;&lt;p&gt;你刚才提到，现在“公开做事”这件事本身就很新颖。你也说，就算你现在想招人，其实也很难，因为真正公开、高频使用这些工具的人并不多。但可能两三年后，大家都会这么做，这个优势也就没了。还有一群人很焦虑的，是应届生、没什么经验的新人。毕竟你是在成为资深工程师之后，AI 才出现的，你有大量积累可以借力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果你把自己放回到那个阶段，基于你现在知道的一切，你会建议他们去做什么？是打好软件工程基本功，还是直接拥抱 agent，还是两者结合？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我会建议他们保持无限的好奇心。毫无疑问，进入这个市场一定会更难，你必须通过不断做东西来积累经验。我不觉得一定要写很多代码，但你得去接触复杂的开源项目，去读、去理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;你现在有一台无限耐心的机器，可以把任何东西给你讲清楚，你可以不停地问：为什么要这么设计？为什么当初要这么做？慢慢建立起系统级理解。但这一切都依赖真实的好奇心，而我不觉得现在的大学真的很擅长教这个。通常，这种能力都是在痛苦中学会的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对新人来说不会轻松，但他们也有一个优势：他们没有被“旧经验”污染。就像小孩子一样，他们会用 agent 做出我们根本想不到的事情，因为他们不知道“这事不该这么做”。而等他们这么做的时候，往往已经能跑通了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：而且他们身边的朋友也都在用这些工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：对。前几天我有个小的菜单栏应用，用来统计 Cursor、Claude Code 这些成本，跑得有点慢。我本能反应是：好，打开 Instruments，开始点。结果他们直接在终端里把 profiling 全做了，连 Instruments 都不用开，就直接给我提了优化方案，还顺带把性能搞快了。我完全被震住了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我觉得我们可能低估了进入这个行业的年轻人的能力和资源整合水平。很多伟大的公司创始人都非常年轻，当时经验也不多，但热情极强。对我来说，最冲击的还是你提到的这些变化：不再依赖 PR，不做传统 code review。这些东西陪伴了你十五年以上，也是 PSPDFKit 成功的重要基石。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：是的，现在需要一整套新东西。哪怕现在有人给我提 PR，我更关心的其实是 prompt，而不是代码。我会让大家把 prompt 也一起提交，有些人会这么做。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我读 prompt 的时间，比读代码还多。因为那是更高信号的信息：你是怎么得到这个结果的？你问了什么问题？中间做了多少引导？这比最终代码本身更能帮我判断质量。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果有人想要一个新功能，我甚至直接要一个“Prompt Request”。你把需求写清楚，我就能把 issue 指给 agent，让它直接去做。真正的工作，其实是在想清楚系统应该怎么运作、细节是什么。如果别人已经帮我把这些想清楚了，我基本可以直接说一句“build”，然后它就能跑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;相反，如果有人只提了一个很小的修复 PR，我反而会请他们别这么做，因为我花在 review 上的时间，可能是我直接在 Codex 里敲一句“fix”再等几分钟的十倍。现在我们已经可以有一行命令就启动。但在最近两周项目开始真正有热度之后，我干脆让大家直接用 agent 指向仓库来做配置。所以我们没有传统意义上的 Onboarding，而是 Claude Code 驱动的 Onboarding。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我的 agent 会自己 clone 仓库、读文档、写配置、帮用户把环境全搭好，甚至设置 Launch Agent，全程不需要人工步骤。这在以前完全不可想象，但现在不是优先级问题了，因为 agent 可以替你做这些事。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而且这个产品本身就是 agent 构建的，所以它的结构、命名方式，完全符合 agent 的“直觉”。模型权重里本身就编码了某些对命名和结构的偏好，它在这个项目里导航起来非常顺。所以我没有把太多精力放在 Onboarding 上。以后我当然也想做成很魔法的体验，但当下更重要的是信息传得通、系统别炸。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;小彩蛋&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：好，那我们用几个快问快答收尾。第一个：有没有一个你会推荐的工具？不是 CLI，也不是 IDE，可以是实体设备。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：我买过很多小玩意，大多数都挺一般。但有一个不贵、看起来也挺糙的东西，给了我几乎无限的快乐。它是一个用 Android 跑的电子相框，可以上传照片。它有一个邮箱，朋友可以直接给它发照片，之后就会自动显示。我家里放了好几个。技术上说，它很糟糕，动画也很简陋，但它就是不停地给我展示生活中那些快乐的瞬间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;它大概两百美元，但说实话它给我的满足感，比我新买的 iPhone 还大。我买了 iPhone 17，到现在都还没拆封，因为我一想到要换卡、迁移数据就觉得太麻烦，完全没有“非换不可”的理由。但这个小相框，真的让我很开心。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那在科技之外，有什么事情能让你充电、让你远离屏幕？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Peter：健身房，最好是和教练一起，把手机锁在柜子里。那一个小时里，我完全活在当下，没有通知，没有冲动去摸手机。有时候我甚至出门散步，把手机直接留在家里。一开始会非常恐慌，好像手机已经变成身体的一部分了，但这种感觉反而让我觉得特别爽。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=8lF7HmQ_RgY&quot;&gt;https://www.youtube.com/watch?v=8lF7HmQ_RgY&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/XW07axk5vWGgzz4bFqol</link><guid isPermaLink="false">https://www.infoq.cn/article/XW07axk5vWGgzz4bFqol</guid><pubDate>Fri, 30 Jan 2026 07:30:53 GMT</pubDate><author>褚杏娟</author><category>AI&amp;大模型</category></item><item><title>就差两个字符！亚马逊云科技自家 GitHub 仓库险被攻破，供应链安全亮红灯</title><description>&lt;p&gt;亚马逊云科技近日发布了一则安全公告，确认其部分由亚马逊云科技管理的热门开源 GitHub 仓库存在配置问题。该高危漏洞被命名为 CodeBreach，可能导致恶意代码被引入仓库，甚至使依赖 AWS CodeBuild 的仓库遭到接管。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Wiz Security 的研究团队发现，一部分仓库在为 AWS CodeBuild&amp;nbsp;&lt;a href=&quot;https://www.wiz.io/blog/wiz-research-codebreach-vulnerability-aws-codebuild&quot;&gt;配置 Webhook 过滤规则&lt;/a&gt;&quot;时，使用了正则表达式来限制可信的触发者 ID，但这些过滤规则并不充分，导致攻击者可以利用可预测获取的 actor ID 获得管理员权限。此次受影响、并对 AWS Console 供应链构成风险的仓库共有四个，分别是：AWS SDK for JavaScript v3、通用加密库&amp;nbsp;&lt;a href=&quot;https://github.com/aws/aws-lc&quot;&gt;aws-lc&lt;/a&gt;&quot;、&lt;a href=&quot;https://github.com/corretto/amazon-corretto-crypto-provider&quot;&gt;amazon-corretto-crypto-provider&lt;/a&gt;&quot;，以及&amp;nbsp;&lt;a href=&quot;https://github.com/awslabs/open-data-registry&quot;&gt;awslabs/open-data-registry&lt;/a&gt;&quot;（一个可通过 AWS 资源访问的公开数据集仓库）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Wiz 的漏洞研究员&amp;nbsp;&lt;a href=&quot;https://www.linkedin.com/in/yuval-avrahami-25139416b/&quot;&gt;Yuval Avrahami&lt;/a&gt;&quot;&amp;nbsp;与 Wiz 漏洞研究负责人&amp;nbsp;&lt;a href=&quot;https://www.linkedin.com/in/nir-ohfeld-b534b010a/&quot;&gt;Nir Ohfeld&lt;/a&gt;&quot;&amp;nbsp;解释称：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;该漏洞源于仓库中 AWS CodeBuild CI 流水线在处理构建触发条件时存在一个极其细微的缺陷。正则表达式过滤规则中仅仅缺失了两个字符，就足以让未认证的攻击者进入构建环境，并泄露高权限凭据。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体而言，用于校验哪些 GitHub 用户可以触发构建的 ACTOR_ID 过滤规则，缺少了起始符号（^）和结束符号（$），这使得任何只要在用户 ID 中“包含”受信任 ID 作为子串的用户，都可以绕过限制。由于 GitHub 用户 ID 是按顺序分配的，研究人员通过创建自动化的 GitHub App，从构建缓存中捕获凭据，最终获得了受影响仓库的完整管理员权限。鉴于 AWS SDK for JavaScript 被打包进 AWS Console，一旦攻击成功，可能会危及无数 AWS 账户所依赖的控制台供应链。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;亚马逊云科技在确认漏洞存在并感谢 Wiz Security 研究团队发现该问题的同时表示，其他由亚马逊云科技 管理的开源仓库并不存在类似的错误配置。受影响仓库中的问题在首次披露后的 48 小时内即已完成修复。Avrahami 与 Ohfeld 进一步指出：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;这一问题延续了近年来多起供应链攻击中常见的模式，例如 Nx S1ngularity 事件：细微的 CI/CD 配置错误，却可能引发影响巨大的攻击。就在去年 7 月，一名威胁行为者还曾滥用类似的 CodeBuild 问题，对 Amazon Q VS Code 扩展的用户发起供应链攻击。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着此类攻击日益频繁，Wiz 呼吁各组织进一步加固自身的 CI/CD 流水线，确保所有基于 ACTOR_ID 的访问控制都经过严格限定与正确配置，仅允许白名单中的身份触发构建。Reddit 用户 hashkent&amp;nbsp;&lt;a href=&quot;https://www.reddit.com/r/aws/comments/1qeh9wh/codebreach_supply_chain_vuln_aws_codebuild/&quot;&gt;评论&lt;/a&gt;&quot;道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;现在感觉要保护源代码变得越来越难了，外面的世界真的有点吓人。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一事件以及近期的其他攻击，再次凸显了一个重要原则：绝不能让不受信任的贡献触发具有高权限的 CI/CD 流水线。The Duckbill Group 首席云经济学家 Corey Quinn 也&lt;a href=&quot;https://www.lastweekinaws.com/newsletter/&quot;&gt;评论&lt;/a&gt;&quot;称：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;这是过去一年里第二起重大的 CodeBuild 安全失误了。那边是不是“水土有问题”？友情提示：如果连亚马逊云科技都没能把自家安全配置好，你可能更应该好好检查一下自己的。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;据披露，CodeBreach 漏洞最早由 Wiz 于 8 月 25 日向亚马逊云科技报告。亚马逊云科技随后在 8 月 27 日为存在问题的 actor ID 过滤规则补齐了锚点，并吊销了 aws-sdk-js-automation 的个人访问令牌。9 月，亚马逊云科技 还进一步加固了安全措施，以防止非特权构建通过内存转储方式访问项目凭据。不过，该事件直到 1 月 15 日才正式对外公开。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/aws-github-vulnerability/&quot;&gt;https://www.infoq.com/news/2026/01/aws-github-vulnerability/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/Uo24zvaQqEsDyK752BYQ</link><guid isPermaLink="false">https://www.infoq.cn/article/Uo24zvaQqEsDyK752BYQ</guid><pubDate>Fri, 30 Jan 2026 06:00:00 GMT</pubDate><author>Renato Losio</author><category>亚马逊云科技</category><category>云安全</category></item><item><title>如何破解大模型生产级部署「最后一公里难题」？</title><description>&lt;p&gt;破局大模型落地最后一公里：AI Serving Stack荣膺2025中国技术力量年度卓越奖 #2025年度中国技术力量卓越奖&lt;/p&gt;
</description><link>https://www.infoq.cn/article/CDqEUTowOKzrfddKqqbK</link><guid isPermaLink="false">https://www.infoq.cn/article/CDqEUTowOKzrfddKqqbK</guid><pubDate>Fri, 30 Jan 2026 04:00:00 GMT</pubDate><author>郭佳浠</author><category>AI&amp;大模型</category></item><item><title>DoorDash通过多臂老虎机增强A/B测试</title><description>&lt;p&gt;DoorDash工程师Caixia Huang和Alex Weinstein说，尽管实验至关重要，但传统A/B测试可能过于缓慢且成本高昂。为了消除这些限制，他们&lt;a href=&quot;https://careersatdoordash.com/blog/experimentation-at-doordash-with-a-multi-armed-bandit-platform/&quot;&gt;采用了“多臂老虎机”（MAB）方法来优化实验&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他们的实验目标是，最小化因向用户子集提供效果较差的功能变体而造成的机遇成本或遗憾。传统A/B测试依赖于固定的流量分割和预先确定的样本大小，并且在整个实验过程中保持不变。这样做的结果是，即使早期出现了明显的优胜版本，实验也会继续进行，直到达到预定的停止条件。更糟糕的是，随着同时进行的实验增多，机会成本会不断累积，而鼓励团队按顺序开展实验以减少遗憾则会显著减慢迭代速度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;多臂老虎机方法提供了一种基于性能自适应分配流量的方法，可以在加速学习的同时减少浪费。其基本工作原理是：它反复在多个选项（仅部分属性已知）中做选择，并随着实验进行收集到更多证据时细化这些选项：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;就我们的目的来说，这种策略根据实验期间收集的持续反馈将实验流量分配给表现更好的功能变体。其核心思想是：自动化的多臂老虎机（MAB）代理会不断地从一组动作池（即多个操作选项）中做选择，从而最大化预设的奖励值，同时在后续迭代中通过用户反馈不断学习优化策略。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种策略实现了探索（即了解所有候选选项）和利用（即优先考虑最佳表现选项）之间的平衡，直到实验收敛到最佳选项。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;按照Huang和Weinstein的说法，MAB有助于降低实验成本，方便快速评估许多不同的想法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;DoorDash的MAB方法核心是汤普森采样，这是一种贝叶斯算法，以其卓越的性能和对延迟反馈的鲁棒性而闻名。简而言之，该算法通过从后验奖励分布（即决策周期结束后）采样来决定资源分配，并在新数据涌入时更新奖励预期以准备下个决策周期。在每个决策周期中，预期奖励将被用于确定选项分配方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;DoorDash工程师表示，采用MAB方法并非没有挑战。特别是，对奖励函数中未包含的指标进行推断变得更加困难，而这反过来又在鼓励团队选择更复杂的奖励指标，以便捕捉尽可能多的洞察。相比之下，传统A/B测试允许在实验结束后对任何指标进行事后分析。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，由于MAB会更积极地调整分配，所以它可能会导致用户在多次与同一功能进行交互时产生不一致的用户体验。DoorDash计划通过采用上下文老虎机、利用贝叶斯优化和实施粘性用户分配来解决这些限制，增强整体用户体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;多臂老虎机的概念来自概率论和机器学习。它使用老虎机的类比描述了这样一个问题：一个赌徒面对多个老虎机，必须决定玩哪个，多久玩一次，以什么顺序玩，以及何时尝试另一台机器。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/multi-armed-bandits-doordash/&quot;&gt;https://www.infoq.com/news/2026/01/multi-armed-bandits-doordash/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/X7i8hMBrPd7hKvgkwKaC</link><guid isPermaLink="false">https://www.infoq.cn/article/X7i8hMBrPd7hKvgkwKaC</guid><pubDate>Fri, 30 Jan 2026 03:06:22 GMT</pubDate><author>Sergio De Simone</author><category>可观测</category></item><item><title>Ramp构建的内部编码代理支撑着30%的工程拉取请求</title><description>&lt;p&gt;Ramp&lt;a href=&quot;https://builders.ramp.com/post/why-we-built-our-background-agent&quot;&gt;分享&lt;/a&gt;&quot;了Inspect的架构。在公司前后端存储库的合并拉取请求中，这个内部编码代理的采用率迅速达到了约30%。这家金融科技公司分享了一份详细的技术规范，解释他们如何创建了一个系统，使AI代理能够像人类工程师一样访问开发环境。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Inspect的真正创新之处在于，它让编码代理能够完全访问Ramp的所有工程工具。与只让代理编写基本代码不同，Ramp的系统在Modal的沙盒虚拟机中运行，能与数据库、CI/CD管道、监控工具（如Sentry和Datadog）、功能标志以及Slack和GitHub等沟通平台无缝衔接。该代理可以编写代码，并通过工程师每天使用的测试和验证流程来确保代码可以正常运行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ramp的工程团队表示，这种验证循环标志着对旧式代码生成工具的重大变革。该代理可以运行测试，检查监控仪表板，查询数据库进行验证，并参与代码审查。这有助于弥补影响许多AI编码助手的验证不足问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ramp选择基于Modal的基础设施进行构建，这对Inspect的性能特征至关重要。该平台能近乎即时地启动会话，并支持无限并发会话。这使得多名工程师可以同时使用独立的代理实例而不会导致资源争用。Modal的沙箱隔离功能与文件系统快照机制确保了代码执行的安全性，并且支持快速迭代。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该架构使用Cloudflare Durable Objects进行状态管理。在交互过程中，这可以保持对话上下文和开发会话状态稳定。这种有状态的设计有助于代理跟踪它们的工作，就像人类工程师在开发时记住代码库一样。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ramp实现了多个客户端接口，使Inspect能够从不同的工作流程中访问。工程师可以使用许多工具与代理互动：用于快速聊天的Slack机器人，用于详细任务的Web界面，以及用于编辑可视化React组件的Chrome扩展。这种多模态方法表明，不同的任务需要不同的交互模式才能发挥最佳的效果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该系统支持团队成员之间协同工作。他们能够同时观察并引导智能代理的操作。这一功能解决了人们对自主编程工具的普遍担忧。它既能确保有效的人工监督，又能让团队受益于自动化带来的效率提升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ramp明确主张构建而不是购买现成的编码代理解决方案。其工程团队相信，与商业产品相比，自主工具可以实现更强大的集成。这主要是因为内部工具可以与外部供应商无法触及的专有系统、数据库和工作流程深度连接。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该公司承认，这种方法需要大量的工程投资。Ramp分享了详细的实施规范，希望能够给他人带来一些启发。其中包括执行环境、代理集成模式、状态管理和客户端实现的细节。这显示了Ramp的自信，即竞争优势来自于执行，而不是隐藏架构细节。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最引人注目的也许是Inspect的部署，Ramp并没有强制推广。合并拉取请求占比30%是工程师自主选择采用代理的结果。他们发现，它在质量、速度或便利性方面均可媲美手动编码。持续增长的趋势表明，人们越来越了解该系统的能力与局限性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其团队还指出，Inspect简化了代码贡献工作。它为非工程师提供了与专业开发人员相同的工具访问权限。也就是说，该代理可能允许产品经理、设计师和其他人直接添加代码。这可能会改变跨职能团队的合作方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ramp的工程团队知道，会话速度和质量仍然主要取决于模型的智能程度。即使有最好的工具和设置，编码代理也会受限于当今的语言模型。这些模型仍然会犯错误，会产生幻觉，难以进行复杂的推理，并且需要人类监督。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该公司知道，他们的构建而非购买的建议可能不适用于每个组织。要实现类似的系统，需要强大的AI基础设施技能和工程资源。规模比较小的团队或有些组织可能没有那么多资源，或者认为不值得投入那么多资源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;随着编码代理的不断演进，Ramp的技术规范和采用指标提供了清晰的数据支撑。这有助于企业评估自身的自动化战略。研究表明，在具备适当环境、工具和验证机制的前提下，AI编码代理能够大规模地提升工程生产力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/ramp-coding-agent-platform/&quot;&gt;https://www.infoq.com/news/2026/01/ramp-coding-agent-platform/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/gf8Vj1s4sAA0svzVYke3</link><guid isPermaLink="false">https://www.infoq.cn/article/gf8Vj1s4sAA0svzVYke3</guid><pubDate>Fri, 30 Jan 2026 03:00:49 GMT</pubDate><author>作者：Claudio Masolo</author><category>软件工程</category></item><item><title>谷歌通用商务协议（UCP）赋能智能代理购物</title><description>&lt;p&gt;谷歌推出了&lt;a href=&quot;https://developers.googleblog.com/under-the-hood-universal-commerce-protocol-ucp/&quot;&gt;通用商务协议&lt;/a&gt;&quot;（UCP），这是一个旨在提升AI驱动平台商业体验的开源标准。UCP为智能购物提供了一种通用语言，可以实现消费者、企业与支付服务商之间的无缝交互。该协议既能与现有的零售基础设施集成，又能通过智能支付协议（&lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/announcing-agents-to-payments-ap2-protocol&quot;&gt;AP2&lt;/a&gt;&quot;）保障支付安全，并通过API及Agent-to-Agent通信（&lt;a href=&quot;https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/&quot;&gt;A2A&lt;/a&gt;&quot;）为企业提供了灵活的连接方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;UCP是与Shopify、Etsy、Wayfair、Target和沃尔玛等主要的行业参与者合作开发的，并得到了全球20多个合作伙伴的支持。该协议旨在服务于整个商业生态系统：商家可以控制自己的产品和结账流程，AI平台可以快速上线商家，开发者可以基于中立的开放标准进行构建，支付提供商获得互操作性，消费者享受流畅的购物体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该协议解决了当今商业基础设施面临的一个主要挑战：N乘以N的集成问题。传统系统需要为每个平台或销售渠道建立单独的连接，这可能会减慢智能代理购物体验的推广速度。UCP提供了一个安全层，标准化了从产品发现到结账和订单管理的整个商业工作流程。它允许代理动态发现商家能力和可用的支付选项，支持多种通信方法（包括API、Agent2Agent和MCP），而且，为了与广泛的支付提供商合作，实现了支付工具与处理程序的分离。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;实际上，UCP允许智能代理通过标准化请求访问商家的服务、启动结账流程并应用折扣。谷歌的参考实现通过搜索功能的AI模式和Gemini等AI界面展示了这一功能，支持使用谷歌钱包或其他兼容的支付方式完成购买。企业可通过商家中心账户访问库存信息，不用单独集成每个平台即可让智能代理访问他们的产品。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在LinkedIn上，首席创新官兼AI大使Andy Reid提出了一个&lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:7417105773681614848?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7417105773681614848%2C7418624068054052864%29&amp;amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287418624068054052864%2Curn%3Ali%3Aactivity%3A7417105773681614848%29&quot;&gt;问题&lt;/a&gt;&quot;，探讨这对小品牌的潜在影响：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;如果UCP允许Gemini将整个购物旅程压缩成一个“支付”按钮，这是否加速了向“默认经济”的转变？在这种经济模式下，每一项交易只有一个品牌作为最终答案出现。如果协议倾向于最相关“默认选项”而不是提供多种选择的市场环境，小品牌该如何生存？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌AI负责人James Massey&lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:7417105773681614848?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7417105773681614848%2C7418624068054052864%29&amp;amp;replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7417105773681614848%2C7418679761016619008%29&amp;amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287418624068054052864%2Curn%3Ali%3Aactivity%3A7417105773681614848%29&amp;amp;dashReplyUrn=urn%3Ali%3Afsd_comment%3A%287418679761016619008%2Curn%3Ali%3Aactivity%3A7417105773681614848%29&quot;&gt;回应&lt;/a&gt;&quot;道：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Andy Reid，这个角度很有趣。我认为，尽管“支付”按钮简化了最后一步，但UCP是作为一个开放标准而不是封闭市场来设计的。在我看来，这实际上可能对小品牌更有利。使用UCP让自己成为AI代理的“可发现”对象，可以帮他们节省传统搜索所需的巨额广告预算，如果他们的产品是最相关的，无论品牌大小，协议都允许Gemini将它们作为主要选项呈现。实际上，这和数据质量有关。不过，我认为需要过段时间才能看到结果！&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;UCP的开放架构使开发者能够探究付款、折扣和订单管理等功能，使用基于Python的SDK进行快速实现。谷歌及其合作伙伴旨在通过共享的代理商务标准简化集成并增强消费者和商家的购物体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通用商务协议已作为开源规范发布于GitHub平台。该项目鼓励人们通过提交拉取请求和参与讨论来为社区做贡献。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/google-ucp/&quot;&gt;https://www.infoq.com/news/2026/01/google-ucp/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/48dPcqMKE6lcxtp9OLH6</link><guid isPermaLink="false">https://www.infoq.cn/article/48dPcqMKE6lcxtp9OLH6</guid><pubDate>Fri, 30 Jan 2026 02:58:14 GMT</pubDate><author>作者：Robert Krzaczyński</author><category>Google</category><category>云计算</category></item><item><title>Rust 重写代码格式化器，Oxfmt 宣称比 Prettier 快 30 倍，前端工具链要“统一口径”了？</title><description>&lt;p&gt;&lt;a href=&quot;https://voidzero.dev/&quot;&gt;VoidZero&lt;/a&gt;&quot;&amp;nbsp;近日宣布推出&amp;nbsp;&lt;a href=&quot;https://voidzero.dev/posts/announcing-oxfmt-alpha&quot;&gt;Oxfmt&lt;/a&gt;&quot;&amp;nbsp;的 Alpha 版本。这是一款基于&amp;nbsp;&lt;a href=&quot;https://rust-lang.org/&quot;&gt;Rust&lt;/a&gt;&quot;&amp;nbsp;实现的代码格式化工具，面向 JavaScript 与 TypeScript 项目，目标是在大幅提升性能的同时，保持与 Prettier 输出结果的高度一致。作为 VoidZero 更大规模 Oxc 工具链计划的一部分，Oxfmt 在官方测试中展现出比 Prettier 快 30 倍以上的格式化速度，同时与&amp;nbsp;&lt;a href=&quot;https://prettier.io/&quot;&gt;Prettier&lt;/a&gt;&quot;&amp;nbsp;的兼容度超过 95%。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Oxfmt 试图解决 JavaScript 生态中一个长期存在的矛盾：性能与习惯之间的冲突。一方面，Rust 工具链在性能上优势明显；另一方面，Prettier 已成为事实上的格式化标准。Oxfmt 将两者结合，既利用 Rust 带来的性能提升，又严格对齐 Prettier 的格式化风格，使其可以作为 Prettier 的“即插即用”替代方案，开发者迁移时几乎不需要承受格式差异带来的成本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Oxfmt 的开发动机，部分来自 VoidZero 在 2025 年初发布&amp;nbsp;&lt;a href=&quot;https://oxc.rs/docs/guide/usage/linter.html&quot;&gt;Oxlint&lt;/a&gt;&quot;&amp;nbsp;之后收到的大量用户反馈。根据官方公告，用户反复提出对“样式类能力”的需求，例如 import 排序。VoidZero 团队对此采取了明确的工具边界划分：Lint 工具负责逻辑问题，Formatter 只关注代码风格。通过同时提供 Oxlint 与 Oxfmt，团队希望减少配置复杂度，并避免在多个工具之间反复关闭重叠规则。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在性能方面，官方&lt;a href=&quot;https://github.com/oxc-project/bench-formatter&quot;&gt;基准测试&lt;/a&gt;&quot;显示：在无缓存的首次运行中，Oxfmt 的速度约为 Biome 的 3 倍、Prettier 的 30 倍。Oxfmt 构建在 Oxc 编译器栈之上，刻意规避了现有格式化工具中常见的架构瓶颈，因此在大型代码库和 CI 场景下表现尤为突出。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从 Prettier 迁移到 Oxfmt 对多数项目来说相当简单。开发者只需将现有的 .prettierrc 配置文件重命名，即可直接使用 Oxfmt。当前版本已支持包括 singleQuote、printWidth 在内的多项主流 Prettier 配置，&lt;a href=&quot;https://oxc.rs/docs/guide/usage/formatter&quot;&gt;完整列表&lt;/a&gt;&quot;可在官方文档中查阅。虽然 Oxfmt 目前通过了约 95% 的 Prettier JavaScript 和 TypeScript 测试用例，但 VoidZero 也在持续向 Prettier 提交 Bug 报告和 Pull Request，以进一步缩小两者之间的差异。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;开发者 Ryan Leichty 在 X（原 Twitter）上回应作者&lt;a href=&quot;https://x.com/ryanleichty/status/1979971666127032701&quot;&gt;相关帖子&lt;/a&gt;&quot;时表示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我们已经切到 oxlint 了，oxfmt 真的等不及了。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;参数状态管理工具&amp;nbsp;&lt;a href=&quot;https://x.com/nuqs47ng&quot;&gt;nuqs&lt;/a&gt;&quot;&amp;nbsp;的官方账号，则在评论 Oxfmt 新增 Tailwind CSS 支持时写道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;对 Biome 来说，直接被秒。很期待用 oxfmt 替换 Prettier（顺便也可能把 oxlint 一起试了）。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 Reddit 上，也有用户围绕 Oxfmt 与 Biome 的性能差异&lt;a href=&quot;https://www.reddit.com/r/javascript/comments/1pbid6b/first_alpha_of_oxfmt_the_rustbased/&quot;&gt;提出疑问&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;不错啊，但有点好奇，他们是怎么做到比同样是 Rust 的 Biome 快这么多的？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对此，有人回应称，关键区别在于两者的架构设计：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;架构完全不一样，而且对性能这件事是真的“较真到偏执”。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从更广泛的工具生态来看，Oxfmt 与&amp;nbsp;&lt;a href=&quot;https://biomejs.dev/&quot;&gt;Biome&lt;/a&gt;&quot;、Prettier 一同构成了 JavaScript 和 TypeScript 领域的主要格式化工具选择。Prettier 仍然是采用最广泛的事实标准；Biome 则通过将 lint 与 format 合并到单一工具中逐渐获得关注。Oxfmt 的差异化路径在于：在保持 Prettier 兼容性的前提下，提供超越两者的性能表现。与 Biome 类似，Oxfmt 也构建在 biome_formatter 的一个分支之上，VoidZero 在公告中特别致谢了 Biome 与 Rome 团队的基础性贡献。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;展望即将到来的 Beta 版本，VoidZero 正在推进多项实验性能力的稳定化工作，包括内置 import 排序、CSS-in-JS 的嵌入式语言格式化等功能。同时，团队也在研究为 Vue、Svelte、Astro 等主流框架提供插件支持。开发者可以通过项目的&amp;nbsp;&lt;a href=&quot;https://github.com/oxc-project/oxc/discussions&quot;&gt;GitHub Discussions&lt;/a&gt;&quot;&amp;nbsp;提交问题和反馈，或加入官方&amp;nbsp;&lt;a href=&quot;https://discord.gg/9uXCAwqQZW&quot;&gt;Discord 社区&lt;/a&gt;&quot;参与讨论。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/oxfmt-rust-prettier/&quot;&gt;https://www.infoq.com/news/2026/01/oxfmt-rust-prettier/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/sDC0oXfPeGcqk1CokzsU</link><guid isPermaLink="false">https://www.infoq.cn/article/sDC0oXfPeGcqk1CokzsU</guid><pubDate>Fri, 30 Jan 2026 02:00:00 GMT</pubDate><author>作者：Daniel Curtis</author><category>大前端</category></item><item><title>一项 20 年前的 Oracle 排序算法专利到期，开源数据库集体受益</title><description>&lt;p&gt;近日，一篇文章披露，Oracle 公司一项关于高速排序方法的&lt;a href=&quot;https://smalldatum.blogspot.com/2026/01/common-prefix-skipping-adaptive-sort.html&quot;&gt;专利已经到期&lt;/a&gt;&quot;，这意味着开源数据库可以自由使用这一算法。该排序算法的发明者&amp;nbsp;&lt;a href=&quot;https://www.linkedin.com/in/mdcallag&quot;&gt;Mark Callaghan&lt;/a&gt;&quot;&amp;nbsp;指出，这种诞生于 20 年前的技术，能够显著加速对相似数据的排序过程，有望让数据库系统在性能和效率上实现进一步提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这项编号为&amp;nbsp;&lt;a href=&quot;https://patents.google.com/patent/US7680791B2&quot;&gt;US7680791B2&lt;/a&gt;&quot;&amp;nbsp;的专利于 2010 年授予 Oracle Corporation，描述了一种利用“公共前缀字节”进行数据排序的方法。Callaghan 建议将这一排序算法称为 “Orasort”。该方法的核心目标，是解决排序过程中反复比较相似键值前缀所带来的效率问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体而言，该算法融合了多种技术手段，包括：在比较键值时跳过公共前缀、在快速排序（quicksort）与基数排序（radix sort）之间自适应切换、缓存键值子串以减少缓存未命中，以及在排序尚未完全结束时提前输出部分结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;由于排序过程中数据会被拆分为更小的分组，组内键值往往共享更长的前缀。该算法会记录这些共享部分，在比较时直接跳过它们；在合适的情况下切换到更高效的排序方式；并预先加载下一步所需的字节，从而减少无效计算、提升整体性能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Callaghan 曾先后任职于 Oracle、Google 和 Facebook，是资深数据库专家。他回顾了这一专利的诞生过程，并解释了其当下重新受到关注的原因：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我是在 Oracle 工作期间发明了这个算法，它最终被集成进 10gR2 版本中，官方宣称相比 Oracle 之前使用的排序算法，性能提升约 5 倍。我一直希望有一天能看到它的开源实现。这项专利对算法的描述非常清晰，比大多数专利都更容易阅读。值得庆幸的是，负责知识产权的律师充分利用了我当时撰写的功能和设计文档。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一消息迅速引发社区关注，开发者开始讨论如何将该算法引入并优化 MySQL、PostgreSQL 等数据库系统。Flooid.in 的 CTO、ScaleArc 前创始人 Varun Singh 表示：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;细节完整到这种程度，你甚至可以把它和专利文档一起丢进一个 AI agent 里，直接开始实现。Mark 太厉害了。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在另一条讨论中，Google 的数据库工程师 Hannu Krosing 尝试借助 Gemini，分别使用 Python、C 和 C++ 对该算法进行了实现。文章指出，Oracle 内存排序算法在当年实现了约 5 倍于旧方案的性能提升，甚至因此收到了 Oracle 创始人 Larry Ellison 的致谢邮件。Callaghan 回忆道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;当我把它集成进 Oracle DBMS 后，就能直接与旧排序算法对比。新算法通常快了大约 5 倍。后来我又把它和 SyncSort 做了比较。我不记得他们是否有 DeWitt Clause（限制公开对比结果的条款），所以不便透露具体数据，但可以说，Oracle 的新排序算法在对比中表现非常出色。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对此，Charles Thayer 评论道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;我以前从没认真考虑过，一个排序算法在什么时候可以输出第一个结果，以尽早开始响应流、降低延迟。（快速排序在这方面应该相对有优势。）这项工作很有意思。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;截至目前，Oracle 共持有超过 52,000 项专利，其中仍包含大量与数据库技术相关的专利，例如自管理数据库架构、数据库性能优化方法等，涵盖自动调优、高效数据存储等数据库管理的多个关键领域。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/oracle-patent-sorting-databases/&quot;&gt;https://www.infoq.com/news/2026/01/oracle-patent-sorting-databases/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/cMYZm5ujJag5Y2SPxTG2</link><guid isPermaLink="false">https://www.infoq.cn/article/cMYZm5ujJag5Y2SPxTG2</guid><pubDate>Fri, 30 Jan 2026 00:00:00 GMT</pubDate><author>Renato Losio</author><category>数据库</category></item><item><title>世界模型混战，蚂蚁炸出开源牌</title><description>&lt;p&gt;作者｜陈姚戈&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;世界模型领域迎来了一个重要开源模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;今天，蚂蚁集团旗下的具身智能公司“蚂蚁灵波”，正式发布并开源其通用世界模型LingBot-World。与许多闭源方案不同，蚂蚁灵波选择全面开源代码和模型权重，而且不绑定任何特定硬件或平台。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;去年DeepMind发布的Genie&amp;nbsp;3，让人们看到了世界模型能够根据文本或图像提示，实时生成一个可探索的动态虚拟世界。LingBot-World沿袭了这条路线，并在交互能力、高动态稳定性、长时序连贯性以及物理一致性等维度取得了突破。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更令人惊喜的是，LingBot-World呈现出从“生成”到“模拟”的跨越。随着模型规模的扩大，灵波团队观察到，LingBot-World开始表现出远超普通视频生成的复杂行为，涌现出对空间关系、时间连续性和物理规律的理解。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;可以看到，鸭子腿部蹬水的动作、水面对扰动的响应、以及鸭子身体与水之间的相互作用都比较符合物理规律。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这显示出模型不仅记住了视觉表象，还在某种程度上理解了流体力学等基础物理机制。同时，水面对扰动的反应，显示出模型对因果关系的理解。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;用户切换视角后再回来时，环境中的智能体（比如这只猫）仍能保持持久记忆。智能体即使没有被观察到，也能持续行动。这确保了当视角回归时，世界状态会自然推进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当环境中智能体（这只猫）碰到沙发后，没有穿透沙发，反而向空地走去。可以看到，LingBot-World遵循了空间的逻辑，让智能体运动具有物理的合理性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是一个长达9分20秒的视频，没有经过任何剪辑和拼贴。视频为用户第一视角，从一座破旧的古希腊神庙出发，沿城市小径前行，经过一座新古典主义建筑，再向左进入一片复原的古希腊建筑群。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在近十分钟内，画面保持了较为稳定的物理状态和视觉质量，这在目前的视频生成模型和世界模型中都比较罕见。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过，在视频最后几分钟，建筑之间的位置关系似乎被模型遗忘了。在7:00，新古典主义建筑和复原式古希腊建筑群是连接在一起的；但7:31，从复原式古希腊建筑群望向新古典主义建筑时，新古典主义建筑消失了。8:30回到新古典主义建筑时，它成为了一栋孤立的房子。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管存在这些细节瑕疵，LingBot-World&amp;nbsp;的进步依然显著——单次生成接近10分钟的连贯视频，很可能刷新了当前视频/世界模型的长度纪录。作为对比，Veo&amp;nbsp;3&amp;nbsp;和&amp;nbsp;Sora&amp;nbsp;2&amp;nbsp;的单次生成上限分别为8秒和25秒，Runway&amp;nbsp;Gen-3&amp;nbsp;Alpha&amp;nbsp;为40秒，Kling&amp;nbsp;最长支持2分钟。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与其他交互世界模型相比，LingBot-World在开源、提供720p分辨率的情况下，还保证了高动态程度和长生成跨度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/28/282a90e7af1f10973a9978f4f3ff0c6b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在VBench测试中，LingBot-World全面领先于Yume-1.5和HY&amp;nbsp;World-1.5等先进开源模型，证明了自己不仅是一个视频生成器，更是一个强大的交互式模拟器。通过接收用户输入的动作指令，它能够生成高度动态且物理一致的视觉反馈，保持在高动态度下的整体一致性，使视频内容在长时间段内始终与最初的提示保持一致。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/8a/8a4d518073a166cd7b25a615d22b7c76.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在看到大语言模型的局限后，世界模型成为火热赛道。Google、李飞飞、Yann&amp;nbsp;LeCun以及众多科学家纷纷指出，LLM无法很好地理解物理世界、因果关系，而“世界模型”是AI走向真实物理世界深度理解的一个解。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;至于“世界模型”究竟该长什么样，行业至今尚无统一标准。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;李飞飞的Marble正专注理解空间关系；英伟达把世界模型细分为预测模型、风格迁移模型、推理模型；DeepMind团队的Genie&amp;nbsp;3，则试图在同一个模型中，实现端到端的实时渲染。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;路线的分歧，也反应了行业需求的多样性，以及寻找解决方案的困难——无论是智能驾驶、具身智能，还是游戏，都在寻找各自需要的智能方案，以及合适的开发范式和入口。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;蚂蚁灵波的世界模型方案更接近Genie&amp;nbsp;3，旨在成为一个通用模型，为Agent、具身智能、游戏、仿真等领域提供理解世界物理规律的基础设施平台。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过开源其训练方法、模型权重等内容，蚂蚁灵波不仅展示了其在具身智能领域的战略布局，也为行业提供了探索世界模型更多可能性的契机，帮助降低验证世界模型的门槛。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一周，蚂蚁灵波对外集中发布和开源模型研究成果，相继发布并开源空间感知模型LingBot-Depth、具身大模型LingBot-VLA。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如今，随着LingBot-World的发布，蚂蚁灵波正从幕后走向台前。蚂蚁灵波的目标是打造一个开放、通用的智能基座，与越来越多行业和厂商共建生态。这一次，它用开源的方式，向世界抛出了自己的世界模型范式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;构建世界模型的梦想和努力&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在深入探讨蚂蚁团队通用世界模型的细节之前，我们需要花点时间，回顾一下1990年世界模型的开始。这将帮助我们更清楚地理解过去30多年中“世界模型”研究的变与不变、当前世界模型技术路线之争的焦点，从而更好地理解蚂蚁是在怎样的方向和基础上努力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;世界模型40年，变与不变&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1990年，强化学习领域奠基人、2024图灵奖获得者Richard&amp;nbsp;S.&amp;nbsp;Sutton&amp;nbsp;在人类认知学习过程的启发下，在论文《Dyna,&amp;nbsp;an&amp;nbsp;Integrated&amp;nbsp;Architecture&amp;nbsp;for&amp;nbsp;Learning,&amp;nbsp;Planning,&amp;nbsp;and&amp;nbsp;Reacting》中提出了一个开创性架构：智能体不应只靠真实世界试错学习，而应构建一个内部世界模型，在“脑海”中模拟动作后果，低成本地进行规划与策略优化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a8/a807cbddb837a572be625ae5eb02f6bd.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;图片来自Dyna论文。&lt;/p&gt;&lt;p&gt;图片呈现的是Dyna框架的核心逻辑，智能体的目标是最大化其在时间维度上累积获得的总奖励。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在&amp;nbsp;Dyna&amp;nbsp;框架中，世界模型也被称为动作模型，它被视为一个“黑盒子”，输入当前的情境和动作，输出对下一个情境和即时奖励的预测。模型的作用是模拟现实世界，Agent&amp;nbsp;通过与现实世界的持续互动产生经验，并利用这些经验通过监督学习方法来改进模型，使其更接近真实的物理规律。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在2026年回顾这篇36年前的论文，会发现这份古早的研究为理解当下复杂的技术路线之争提供了共同的根基——&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对世界模型的探究，起源于对人类、机器，以及更广泛的智能体如何学习和行动的好奇。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而“世界模型”作为一种方法，提出的解决方案是在模拟出的世界中，让智能体学习、行动、获得反馈和迭代。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Dyna这篇论文的核心理念，成为了今天世界模型的研究的底层思路。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不管是NVIDIA&amp;nbsp;Cosmos、World&amp;nbsp;labs、Google&amp;nbsp;Genie，还是LingBot-World，都沿袭了Dyna的核心理念：世界模型是为智能体提供“模拟经验”的内部环境，使得智能体可以在一个虚拟的环境中进行规划和策略训练。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在不同方向的探索中，我们可以得到的共识是：世界模型从多样化的输入数据中学习对真实世界环境的内部表征，包括物理规律、空间动态和因果关系等。这些表征帮助模型预测未来状态，模拟动作序列，并支持复杂的规划与决策，而不需要反复进行真实世界的实验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;36&amp;nbsp;年过去，我们正站在大语言模型的阴影和语境中讨论世界模型。LLM在理解真实物理世界、及模拟/预测未来后果等方面的局限，正加速科研和商业领域对世界模型的探索。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在2025年的一次访谈中，Dyna的创作者&amp;nbsp;Richard&amp;nbsp;S.&amp;nbsp;Sutton强调，LLM已经走到了瓶颈。他指出，LLM的核心缺陷在于，它们仅仅是在模仿人类行为，而无法理解世界、预测现实世界中的未来事件。他提倡放弃基于LLM的路径，转而开发基于强化学习、拥有世界转换模型（Transition&amp;nbsp;model&amp;nbsp;of&amp;nbsp;the&amp;nbsp;world）。这种世界模型不仅能学习奖励，还能从所有感官信息中获取环境的丰富理解，最终能够预测“如果做某事，后果将是什么”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大语言模型在理解真实物理世界的不足，以及模拟/预测未来后果的不足，让一批科学家转向，在世界模型中寻找解法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;李飞飞认为&amp;nbsp;LLM&amp;nbsp;缺乏对物理世界的感知，提出“空间智能”（Spatial&amp;nbsp;Intelligence）是&amp;nbsp;AI&amp;nbsp;的下一个北极星，AI&amp;nbsp;需要理解三维空间、几何、物理规则以及因果关系，才能从“理解文本”迈向“理解并作用于物理世界”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Yann&amp;nbsp;LeCun则批评&amp;nbsp;LLM&amp;nbsp;依赖文本概率预测，感知学习世界的方式背道而驰。为此，他推广&amp;nbsp;JEPA（联合嵌入预测架构），并成立&amp;nbsp;AMI&amp;nbsp;Labs，通过世界模型的路径实现AGI，探索如何让AI&amp;nbsp;系统具备理解物理世界、持久记忆、逻辑推理以及复杂任务规划能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;DeepMind联合创始人兼CEO&amp;nbsp;Demis&amp;nbsp;Hassabis&amp;nbsp;在今年1月的对谈节目中强调，目前的&amp;nbsp;AI&amp;nbsp;系统还不能理解物理世界、因果关系、行为如何影响结果，而精确的世界模型是实现科学发现或理论创新的关键。他表示，Genie这样的模型还只是“胚胎期世界模型”，Genie体现出的，生成关于世界的内容的能力，某种程度上体现了模型理解了世界的知识。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Google&amp;nbsp;AI团队深度押注了世界模型的发展，并认为它会在2026年赢得重大发展。Hassabis在谈及2026年的突破和期待时提到，“最令我兴奋的，莫过于进一步推动‘世界模型’的发展，提升其运行效率，从而使其能够真正被用于我们通用模型中的‘规划’环节。”这可能意味着，未来世界模型将融入Gemini这样的基础模型中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;世界模型的路线分歧&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在探索AGI的道路时，蚂蚁集团也看到了世界模型的潜力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;作为蚂蚁集团旗下的具身智能企业，蚂蚁灵波的定位是“智能基座公司”，致力于打造一个能够理解世界、物理规律以及时空演化的AI系统。而世界模型正是实现这一目标的重要方式之一。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管各方都将世界模型视为未来的关键技术，然而不同公司选择的路径却各不相同。总体上，这些路径可以分为生成式和非生成式两类，两种路径的核心区别在于预测空间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;NVIDIA&amp;nbsp;Cosmos、DeepMind&amp;nbsp;Genie和World&amp;nbsp;Labs都是生成式路径的代表。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Cosmos和Genie主要使用由像素构成的观测空间，利用大规模高维视觉数据训练，通过特定的时空架构设计，让模型产生对三维物理世界的理解。Genie&amp;nbsp;3官网中特别提到“Genie&amp;nbsp;3&amp;nbsp;的一致性是一种涌现能力……Genie&amp;nbsp;3&amp;nbsp;生成的世界更为动态和丰富，因为它们是基于世界描述和用户动作逐帧创建的。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;World&amp;nbsp;Labs则另辟蹊径，将预测空间设定为在3D空间中带有位姿的帧，通过查询待生成帧的位姿来生成新图像。其发布的RTFM模型表明：“模型对世界的记忆（存储在各个帧中）具备了空间结构；它将带有位姿信息的帧视作一种‘空间存储’，这赋予了模型一种弱先验——即所建模的世界是三维欧几里得空间，而无需强迫模型显式预测该世界中的物体几何结构。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;非生成路径的代表是Yann&amp;nbsp;LeCun的联合嵌入预测架构（Joint&amp;nbsp;Embedding&amp;nbsp;Predictive&amp;nbsp;Architecture,&amp;nbsp;JEPA）。JEPA&amp;nbsp;通过编码器将输入转化为潜空间（Latent&amp;nbsp;Space），并在该空间内预测未来抽象表征（Embeddings），从而无需进行像素级的重建。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;蚂蚁灵波的LingBot-World&amp;nbsp;选择了类似Genie的路径，试图在此基础上解决从视频生成到世界模拟之间的技术障碍。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;拆解&amp;nbsp;LingBot-World&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在前文的案例和分析中，我们看到蚂蚁灵波的&amp;nbsp;LingBot-World沿袭了Gienie的生成式路线，同时在交互能力、高动态稳定性、长时序连贯性以及物理一致性上表现惊艳。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在此基础上，蚂蚁灵波选择开源代码和模型权重，并在论文中完整披露了从数据采集到训练部署的全链路设计，鼓励社区测试、使用和复现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;即使是在近10&amp;nbsp;分钟的超长视频中、或是快速运动下，画面中的物体依然保持了较为稳定的几何物理特性，没有出现视频生成模型常见的崩坏。这种稳定性，源于其独特的数据引擎和模型架构设计。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;数据引擎&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;许多从视频生成模型切入世界模型研发的团队，很快会撞到数据瓶颈。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;互联网上浩如烟海的短视频大多是“被动”记录，缺乏因果链条。对于世界模型而言，它需要理解的是动作和后果之间的关系。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比如：“按下&amp;nbsp;W&amp;nbsp;键向前走，门是否会打开？”“绕到建筑背面，窗户是否依然存在？”这类智能体动作与环境反馈之间的因果闭环，在普通视频中几乎不存在，在真实世界中规模化采集的成本也很高。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了构建“动作-反馈”的闭环，LingBot-World&amp;nbsp;打造了从采集、处理到标注的流程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LingBot-World的数据包含通用视频、游戏数据和合成渲染数据，以确保训练语料的丰富性、高质量和交互性。为游戏数据，灵波团队还开发了专门的平台，捕获&amp;nbsp;RGB&amp;nbsp;帧并严格对齐用户的输入和相机参数。合成数据由&amp;nbsp;Unreal&amp;nbsp;Engine&amp;nbsp;生成，带有精确相机数据和自定义轨迹。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/97/97fcf2abdd59e576054679e2bc9125e4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;LingBot-World&amp;nbsp;数据处理和标注流程&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在数据处理层面，灵波团队首先对原始视频进行质量筛选与切分，生成结构清晰的视频片段；然后借助VLM视频的视觉质量、场景类型和视角等，结合几何标注提供必要的3D结构先验，产出元数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在此基础上，团队引入三种不同粒度的描述标注，涵盖视频全过程的宏观描述、去除了动作和相机数据的静态描写，以及带有时间标注的描述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;模型构建和训练&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LingBot-World&amp;nbsp;将世界模型定义为一个条件生成过程，模拟由智能体动作驱动的视觉状态演化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从模型构建和训练过程，我们可以看到，LingBot-World&amp;nbsp;是从“视频生成模型”起步，通过不同阶段训练，让模型从“生成”走向“模拟”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从目标函数上看，这种模拟本质上是一种概率预测。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LingBot-World&amp;nbsp;的目标函数明确表达了这一思想：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;即在最大化给定历史帧&amp;nbsp;()&amp;nbsp;和动作序列&amp;nbsp;()&amp;nbsp;的条件下，预测下一帧状态&amp;nbsp;()&amp;nbsp;的似然概率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;简单来说，就是让模型学会根据过去看到的画面和执行过的动作，尽可能准确地预测下一帧画面。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了避免直接从零训练导致的计算开销和模式崩塌，LingBot-World采取了分阶段的训练策略。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;预训练负责建立稳健的通用视频先验，确保高保真开放域生成；中训练注入世界知识和动作可控性，使模型能够模拟具有一致交互逻辑的长期坚持动态；后训练使架构适应实时交互，采用因果注意力和少步蒸馏以实现低延迟和严格因果性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/06/06c308590e1819dc8efa59b49ac3b639.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;LingBot-World&amp;nbsp;模型训练流程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;从“生成视频”到“模拟世界”，LingBot-World带来的可能性&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LingBot-World&amp;nbsp;的意义绝不仅在于生成一段精美的视频，而在于它提供了一个高保真的物理交互沙盒，成为具身智能、自动驾驶与虚拟现实等下游任务的通用基础设施。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LingBot-World&amp;nbsp;最直观的突破在于它赋予了通过自然语言控制模拟过程。例如，通过输入“冬季”或“夜晚”，模型会渲染出城堡结冰或夜晚灯光变化的物理效果，同时支持向“像素风”或“蒸汽朋克”等风格的切换。还可以在具体场景中精确注入特定物体。例如，在城堡上空触发烟花，或在喷泉中生成鱼和鸟。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在环境中生成烟花效果&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;改变环境整体风格&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在自动驾驶训练中，这种能力极具价值。算法团队可以人为制造“鬼探头”、极端天气或突发交通冲突，构建出严苛的因果推理环境，从而低成本地解决智驾中的长尾问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;深层物理特性的稳定性，则为这种模拟提供了实际应用的底座。得益于模型展现的长程记忆，生成的视频序列具备了较高的&amp;nbsp;3D&amp;nbsp;一致性，这使得视觉信息可以直接转化为场景点云，从而服务于&amp;nbsp;3D&amp;nbsp;重建或高精度仿真任务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;LingBot-World具有很好的3D一致性。可以看到，视角变化的情况下，房间结构和物理性状仍然保持稳定。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种稳定性试图触及具身智能训练中的一个核心痛点：机器人的导航或复杂操作往往涉及跨越长时序的决策序列。LingBot-World&amp;nbsp;展现的&amp;nbsp;10&amp;nbsp;分钟级别生成能力，在理论上为多步骤任务提供了更稳定的物理一致性。如果这种长程模拟能有效控制累积误差，将有助于机器人在虚拟环境中进行高频次、深度、低成本试错。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在此基础上，LingBot-World&amp;nbsp;与&amp;nbsp;LingBot-VLA（视觉-语言-动作模型）的结合，勾勒出了一种具身大脑的闭环方案。在这种设定下，世界模型充当了机器人的“内部模拟器”：在&amp;nbsp;VLA&amp;nbsp;模型输出最终指令前，系统可以在虚拟空间中先行演练不同的动作轨迹，评估其物理后果，从而筛选出更符合物理规律且具备安全性的执行路径。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;令人惊喜的是，利用训练LingBot-World的数据，蚂蚁灵波团队还微调出了动作智能体。智能体可以被置于&amp;nbsp;LingBot-World&amp;nbsp;打造的环境中，Agent&amp;nbsp;的动作改变会实时重塑环境状态，而环境的演变则反过来决定Agent的下一步决策。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;灵波团队利用LingBot-World相同数据训练处的自主智能体，能在生成的世界中自主规划并执行动作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种互动揭示了世界模型在“模拟沙盒”之外的另一种可能——它不仅能理解环境对智能体变化的响应，也具备预测智能体动作流的能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这意味着，世界模型未来或许不仅仅是训练智能体的工具，也有可能成为驱动智能体（包括机器人）的底座。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;项目官网：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://technology.robbyant.com/lingbot-world&quot;&gt;https://technology.robbyant.com/lingbot-world&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;论文连接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2601.20540&quot;&gt;https://arxiv.org/abs/2601.20540&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;代码和模型权重下载:&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/robbyant/lingbot-world&quot;&gt;https://github.com/robbyant/lingbot-world&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://huggingface.co/robbyant/lingbot-world&quot;&gt;https://huggingface.co/robbyant/lingbot-world&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.modelscope.cn/models/Robbyant/lingbot-world-base-cam&quot;&gt;https://www.modelscope.cn/models/Robbyant/lingbot-world-base-cam&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/hmKcZ2hdjDk3SspgikfV</link><guid isPermaLink="false">https://www.infoq.cn/article/hmKcZ2hdjDk3SspgikfV</guid><pubDate>Thu, 29 Jan 2026 11:59:46 GMT</pubDate><author>陈姚戈</author><category>AI&amp;大模型</category></item><item><title>如何大规模构建、部署和管理智能体</title><description>&lt;p&gt;生成式 AI 的投资回报远超预期？Snowflake 调研全球 1900 位企业与 IT 专业人士后发现平均 ROI 高达 41%！&lt;a href=&quot;https://www.infoq.cn/minibook/aja6h8SVCM1Smvggyvvu?utm_source=snowflakecn&amp;amp;utm_medium=snowflakecn&amp;amp;utm_campaign=snowflakecn&amp;amp;utm_content=snowflakecn&quot;&gt;点击下载&lt;/a&gt;&quot;完整报告&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着大语言模型能力的成熟，围绕 AI 智能体的讨论正在迅速升温。构建一个能够执行任务、调用工具的 Agent，已经不再是少数团队的专属能力。但在这场技术热潮之下，一个更现实的问题逐渐浮出水面：当智能体不再停留在演示环境，而是被放入真实业务系统中运行时，会发生什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;CrewAI 创始人兼 CEO Joao Moura 以实践者的视角，在 BUILD 2025 大会上系统梳理了 AI 智能体从概念、原型走向生产环境过程中，所面临的一系列关键问题。这场分享的核心，并不在于“如何快速做出一个 Agent”，而在于如何让 Agent 在复杂系统中长期、稳定地工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;从“会生成”到“会决策”：重新理解智能体的能力边界&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在分享中，Joao 首先回到一个基础问题：什么才是 AI 智能体真正的能力来源。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;他指出，很多人已经非常熟悉大语言模型在内容生成上的表现，例如生成文本、改写表达、调整语气。这些能力本质上仍然是“输出导向”的，模型根据输入，生成一段结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而智能体的出现，源于另一类能力的被系统性使用：决策能力。当模型不仅要给出答案，还需要在多个选项之间做出判断，并说明为什么选择其中一个时，它开始参与“思考过程”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a5/a5e31ab04b331a193c0acde05d979ea6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在此基础上，当系统为模型提供可调用的工具，并赋予其一个明确目标，模型就不再只是被动响应请求，而是开始围绕目标不断判断下一步行动。这种行动可能包括调用内部系统、获取业务数据、更新状态，甚至触发后续流程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;智能体并不是某种全新的技术形态，而是一个围绕目标进行持续决策与行动的系统。理解这一点，是后续讨论生产化问题的前提。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;真正的分水岭：为什么原型和生产完全是两回事&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在谈到智能体落地时，Joao 明确指出了一个现实情况：从原型到生产，并不是一次线性升级，而是一道本质不同的门槛。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原型阶段，团队关注的往往是“能不能跑起来”；而进入生产环境后，关注点会迅速转向“能不能持续运行”。这时，模型本身反而不再是唯一变量，系统层面的复杂性开始占据主导。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/94/94f0feee4fcd61857bb572dbc119f48f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;智能体一旦被放入真实业务系统，就意味着它将与 ERP、CRM 等核心系统交互，其行为可能直接影响业务流程。在这种情况下，系统是否稳定、决策是否可控、行为是否可预测，都会变成不可回避的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;很多阻碍智能体进入生产的因素，并不来自 AI 本身，而是来自工程、架构和系统集成层面的现实约束。这也是为什么不少 Agent 项目停留在 Demo 阶段，却迟迟无法真正上线的原因。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;决策、工具与执行：Agent 在系统中的运行方式&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一个智能体并不是简单地“调用模型”，而是需要在决策、工具调用和执行之间形成闭环。模型负责判断当前状态下应该采取什么行动，而系统则需要确保这些行动能够被安全、准确地执行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当智能体需要调用外部工具时，问题并不止于“能不能连上接口”，而在于调用是否可控、结果是否可追踪、失败是否可恢复。这些因素，都会直接影响智能体是否具备进入生产环境的条件。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这种结构下，Agent 更像是一个被嵌入到系统中的“决策节点”，而不是一个独立存在的智能模块。它的价值，取决于整个系统是否为它提供了稳定的运行土壤。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;当数量上升：规模化带来的管理问题&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当智能体不再是单点实验，而是开始成批部署时，另一个问题随之出现：如何管理这些 Agent。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;规模化并不意味着简单复制更多实例。随着智能体数量的增加，部署、运行、监控和管理本身会迅速成为新的复杂系统。如果缺乏系统性的设计，智能体越多，整体风险反而越高。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回到整场分享的核心，Joao 传递出的判断其实非常清晰：AI 智能体的真正价值，并不在于是否足够聪明，而在于是否能够被可靠地使用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当讨论从“能不能做”转向“值不值得用”，从原型转向生产，智能体面临的已经不是技术炫技的问题，而是工程与系统成熟度的检验。也正是在这个阶段，智能体才真正开始进入创造长期价值的轨道。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原视频地址：&lt;a href=&quot;https://www.snowflake.com/en/build/americas/agenda/?login=ML&quot;&gt;https://www.snowflake.com/en/build/americas/agenda/?login=ML&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;🔥【活动推荐】2 月 2 日-6 日，&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;Snowflake Discover&lt;/a&gt;&quot; 重磅上线！这是一场免费、线上、可实时互动的技术活动，旨在帮助您全面提升数据与 AI 能力，深入了解如何更高效地管理、整合与分析数据。4 天时间 18 场技术干货分享，由来自亚太地区的一线技术专家亲自分享与讲解～&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/edm/resource/image/85/9a/852e6196c25c9abab4e7a7ee2767159a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;点击报名 Discover&lt;/a&gt;&quot;，更多 Snowflake 精彩活动请关注&lt;a href=&quot;https://www.infoq.cn/space/snowflake&quot;&gt;专区&lt;/a&gt;&quot;。&lt;/p&gt;</description><link>https://www.infoq.cn/article/WYSZ0iMoqpfYfVDiGKdu</link><guid isPermaLink="false">https://www.infoq.cn/article/WYSZ0iMoqpfYfVDiGKdu</guid><pubDate>Thu, 29 Jan 2026 10:26:09 GMT</pubDate><author>王玮</author><category>Snowflake</category><category>大数据</category><category>AI&amp;大模型</category></item><item><title>不要再纠结 LLM 准确率了：从“回答对不对”到“系统是否值得信任”</title><description>&lt;p&gt;生成式 AI 的投资回报远超预期？Snowflake 调研全球 1900 位企业与 IT 专业人士后发现平均 ROI 高达 41%！&lt;a href=&quot;https://www.infoq.cn/minibook/aja6h8SVCM1Smvggyvvu?utm_source=snowflakecn&amp;amp;utm_medium=snowflakecn&amp;amp;utm_campaign=snowflakecn&amp;amp;utm_content=snowflakecn&quot;&gt;点击下载&lt;/a&gt;&quot;完整报告&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;每个人都在努力提高大语言模型的精准度。但真正的挑战并非精度，而是上下文理解能力。在 BUILD 2025 大会上，Hex 合作伙伴工程负责人 Armin Efendic 探讨了为什么传统的方法，如评估套件或合成问题集往往不够有效，以及成功的 AI 系统是如何通过随着时间推移逐步积累上下文来构建的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;由 Snowflake Cortex 提供支持的 Hex，启用了一个新的对话式分析模型，每次交互都让模型变得更聪明。通过 Hex 的 Notebook Agent 与 Threads 功能，业务用户可直接定义核心问题，而数据团队则将这些问题精炼、审计并转化为持久且值得信赖的工作流。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这个模型中，测试用例不再由数据团队闭门设计，而是由业务需求驱动并在数据工作流中自动实施，最终形成一个具有生命力的上下文系统，而非一成不变的提示词或测试集，它能随着组织共同演进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c3/c3f33c248d2dee34e327d20cde14222a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;准确率不是终点&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Armin 开场就把矛头对准了一个常见做法：把业务用户会问的问题合成成一批样例，甚至进一步转成 SQL 查询，然后把这些喂给 LLM，用类似单元测试的方式去衡量它的准确率、稳定性与一致性。他不否认“准确性是顶层关注”，但他强调，把 LLM 当作传统软件组件来做单元测试，本身就是一个不合适的范式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原因在于，当你把业务问题硬转换为一组 SQL，并据此去构建样例与评估集时，你很难覆盖真实业务中不断变化的语义、不断扩张的问题空间，以及不同用户在不同语境下对同一指标的不同问法。更重要的是，即使你做出了一个看似通过率很高的测试集，也依然回答不了企业最在意的那件事：当它在真实环境中生成了一个结论，你如何知道它不是在胡编？你又如何知道它到底做了什么才得到这个结论？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，Armin 把正确性从结果层拉回到系统层：你需要的不是一个靠样例证明自己正确的聊天机器人，而是一套可审计的系统，它能够随着时间变得灵活、可塑，能够让业务用户在使用中不断收敛可回答的问题类型，也能够让系统拥有被“硬化”的路径：哪些能力可以放开，哪些问题必须收紧，哪些定义需要固化，哪些数据应该进入上下文、哪些不应该。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在他看来，真正有效的路线是：从一套能运行、能被观察的系统出发，让系统在使用中暴露问题、沉淀模式，再反过来加固上下文。这种思路听起来不如直接做评估来得爽快，但它更接近企业系统的真实生长方式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;对话式分析如何变成“可审计的系统”&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了把“可审计”讲得具体，Armin 用 Hex 的产品演示展示了对话式分析在真实系统中应该是什么形态。演示从一个非常典型的业务问题开始：假设我是营销经理，我想让系统分析销售机会的“首次触达来源”（first touch source），并做营销归因视角的拆解。这里一个很关键的动作，是他先在系统里配置模型提供方：通过密钥对（key pair）连接到 Snowflake 实例，使用 Snowflake Cortex 内托管的 Claude，并强调这是一个“walled garden”的私有网络环境。这样做的直接意义是：模型驻留在数据所在的环境里，数据可以传递给模型，同时也能让 IT 团队对数据出入边界更放心。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;进入线程后，Hex 并不是立刻吐出一句“结论”，而是在后台进行一系列用户不可见但决定可信度的步骤：它会先围绕可访问的元数据“思考”，查看平台上已有的 Hex 项目、仪表板或资产，判断是否存在可复用的内容；它会拉取来自数据仓库的表描述、列描述等元数据，并强调这些可以自动导入、不需要复杂配置；如果企业已经有 dbt 元数据，也可以进一步带入；随后它形成一个“漏斗式”的收敛过程：从广义元数据到相关表、再到更具体的模型信息与底层数据，最后才开始把 SQL 单元格、可能的 Python 单元格、图表与可视化逐步组织起来，用以回答最初的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这也解释了他在演示里专门强调的一个点：这种模式一开始会“慢”，但这是刻意设计的。因为此时系统面对的是生产数据仓库，它需要把大量上下文带进来，需要推理与迭代，而这类深度思考天然会以时间为代价。换来的收益是：它可以生成更细致、接近数据科学家或嵌入式数据分析师水平的分析过程。Armin 也提到，未来会有更偏“快速、短促回答”的迭代版本，可能更多依赖语义模型，而不是每次都在全量上下文里深挖。但在这个阶段，他们优先解决的是“在没有分析师介入的情况下，业务用户也能得到一份扎实的分析报告”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当线程生成结果后，界面里不仅有图表，还能继续做探索：拖拽维度与度量、查看底层表格数据、检查异常、做更深的切片。这时“可信度焦虑”就会自然出现：这么多信息暴露给业务用户，我怎么知道它没有幻觉？我该不该信这些 SQL？我如何让它更确定？Armin 的回答不是“相信模型”，而是把系统的底座亮出来：在 Hex 里，每一个线程、每一个项目，背后都由笔记本支撑。把线程保存为项目后，你可以在笔记本里看到完整对话以 Markdown 的形式呈现；更重要的是，你能看到它实际运行的 SQL、过滤条件、连接逻辑、图表生成过程，以及它如何一步步构建出整份报告。对于负责准确性与治理的数据团队来说，这种“把对话落到可审计的笔记本”非常关键——它让系统从一开始就具备被审核、被追责、被修正的可能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在此基础上，Armin 进一步展示了一个更现实的协作场景：业务用户提出问题后，不一定要立刻去找数据团队提工单，而是先在对话线程里得到初步洞察；如果需要更深入的分析（比如进一步做季节性拆解），技术用户可以把笔记本智能体（notebook agent）限定在这个项目范围内，和智能体一起继续规划、推理、生成图表，并在生成的“待处理变更”中逐条审核、决定保留哪些结果。分析由此变成一种可协作、可迭代、可沉淀的工作流，而不是一次性、不可解释的问答。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;从一次性对话到可复用资产&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果到这里为止，Hex 展示的是“可观察性”，那么 Armin 在后半段想讲的，是上下文如何变成系统能力，如何从一次性对话沉淀为可复用资产。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;他先展示了一个从笔记本走向应用（app builder）的路径：当某些分析内容需要“持久化”，例如营销与销售负责人希望随时看到季节性分析或关键指标，而不是每次回来重新提问，那么就可以把笔记本中已经生成的图表、文本等资产拖拽到应用构建器里，做成一个仪表板、报告或更像 BI 的交互界面。这里的核心并不是“又做了一个 BI”，而是强调：即便呈现形态变成 BI 风格，背后依然由笔记本驱动，仍然保留 SQL、Python、Snowpark 等灵活性；同时，笔记本与应用这两种范式始终连接，资产是可回溯的。换句话说，展示层可以更友好，但底层逻辑并不会因此变成不可审计的黑箱。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;紧接着他抛出了“连接胶水”的问题：当我们有线程、有笔记本、有应用，如何让它们构成一个一致的策略？答案是语义模型——它是 Armin 所谓“上下文引擎”的关键组成部分。原因也很务实：企业里那些精心构建的报表与仪表板，通常包含大量转化逻辑、业务口径、SQL/Python 查询，这些恰恰是 LLM 最需要、也最容易误解的上下文。如果不能把这些上下文结构化，LLM 的确定性就无从谈起。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在演示里，语义模型有两条路：一是导入已有的 Snowflake semantic view。Hex 可以浏览生产仓库、发现可访问的语义视图，然后快速引入，例如引入一个 B2B sales model，让 enriched metadata 直接在 Hex 中可用。另一条路更贴近多数团队的起点：不是先有语义视图，而是先有一堆被业务反复使用的仪表板项目。Hex 的语义建模工作台里有一个“建模智能体”（modeling agent），它能理解 Hex 的语义建模能力，并且能针对某个具体项目（例如 sales and marketing dashboard）去阅读项目里包含的 SQL 单元格、DataFrame 操作、joins、函数与过滤条件，形成建模计划，做错误预防，推断表关系，把“项目里已经存在的业务逻辑”烘焙进语义模型中。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一段其实回答了一个关键的企业问题：语义模型从哪来？它不一定需要从零凭空设计，它可以从企业已经在用的分析资产中被抽取、被规范、被版本化。建好之后，语义模型还能用一种“拖拽式”的方式被检查：你可以选择维度、度量，查看聚合、查看系统生成的 SQL，在发布之前把模型硬化到你满意的程度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更进一步，Armin 也回应了“供应商锁定”的担忧。他明确表示，Hex 不希望用专有 YAML 把用户锁死，并提到两个方向：其一是和 Snowflake 等一起推动“开放语义交换”（Open Semantic Interchange），一个由约 18 家甚至更多公司组成的联盟，目标是让语义模型信息能在不同系统之间互换，以促进 LLM 采用并避免 vendor lock-in；其二是更近期开启“写回”能力，让在 Hex 中构建的语义模型可以写回到 semantic views 中，保证不同系统间“友好共存”。这些内容在分享里出现得很明确：终点不是锁定格式，而是让用户愿意因为体验与工作流而持续使用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当语义模型准备好后，线程侧的使用方式也随之变化：你可以把对话线程限定为“只使用语义模型”，而不是访问整个生产数据仓库。Armin 强调，这会让系统随着时间更确定：当你不断硬化语义模型、补充上下文，它会越来越稳定、越来越可控。也正因此，他再次回到开场的观点：把精力放在构建上下文系统上，而不是试图用合成样例把原型聊天机器人测到“看起来准确”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;规模化审计与上下文飞轮&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;分享的最后一部分，Armin 把问题推到最现实的规模化挑战上：当系统从一个人试用扩展到五十、一百个用户时，你如何监控它？你如何知道 LLM 系统到底在做什么，业务用户到底拿它解决什么问题？这时，“可审计”就不能停留在某个线程或某个项目，而必须成为一套能覆盖全局的治理能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;他提到 Hex 的“上下文工作室”（context studio），目前处于少数 Alpha 合作伙伴的 Alpha 阶段，但他之所以专门强调它，是因为它承载了上下文系统最关键的一环：理解使用行为，反过来指导上下文如何演进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体来说，你可以看到平台总体使用情况：用户更常用笔记本还是线程？创建了多少语义模型？也可以按对话量看用户分布，查看某个用户使用线程的频次、提问的类型。更重要的是，当你下钻到“问题类型”时，Armin 给出了一个很强的判断：这些真实问题才是你的单元测试。不是你在上线前试图一次性“破坏一切”并用评估集兜住，而是看清业务用户到底在问什么，再回去硬化你需要硬化的上下文与问题类型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;围绕“如何策划上下文”，他在分享里给出了三个层次的抓手。最直接的是规则文件（rules file）：你可以在里面定义 SQL 的数据质量防护、业务定义、偏好的 SQL 风格、杂项信息，以及希望系统使用的可视化方式，并且这些内容可以即时编辑、保存或导出。第二层是“经认可的数据”（endorsed data）：由数据团队或所谓“金层”背书的数据资产，可以在 Hex 的语境下被定义清楚，决定哪些数据可以喂给 LLM。第三层则是更成熟、也最关键的做法：语义项目（semantic projects）。随着审计能力增强，你不仅能看到语义模型被使用的次数，还能观察是否有多个语义模型被同时使用、是否需要在某些场景中合并；你也能判断哪些项目最常被引用，从而决定是否需要对下游数据做更多建模，或者是否需要补充列描述、表描述等元数据来改善上下文质量。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这些细节共同指向同一个结论：上下文不是一次性设计出来的，它是被真实使用不断“磨”出来的。你从稍微宽的范围起步，抽取一两个语义模型，让业务用户用起来；再通过审计看到真实问题与真实路径，回去修规则、补语义、加背书数据、完善元数据。如此循环，系统才会越来越确定、越来越可信。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这场分享最有价值的地方，在于它没有把“可信”简化为一个指标，也没有把“准确率”当作唯一的归宿。Armin 反复强调的其实是另一套思维：企业要的不是一个在评估集上表现漂亮的聊天机器人，而是一套能持续吸收上下文、可审计、可治理的系统。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从线程到笔记本的可观察性，从笔记本到应用的资产化，从项目到语义模型的上下文结构化，再到面向规模化使用的审计与上下文工作室——这些环节被串成一个整体，目的只有一个：让 LLM 在真实业务里变得更确定，并且在需求增长时仍然能保持可控与可信。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原视频地址：&lt;a href=&quot;https://www.snowflake.com/en/build/americas/agenda/?login=ML&quot;&gt;https://www.snowflake.com/en/build/americas/agenda/?login=ML&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;🔥【活动推荐】2 月 2 日-6 日，&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;Snowflake Discover&lt;/a&gt;&quot; 重磅上线！这是一场免费、线上、可实时互动的技术活动，旨在帮助您全面提升数据与 AI 能力，深入了解如何更高效地管理、整合与分析数据。4 天时间 18 场技术干货分享，由来自亚太地区的一线技术专家亲自分享与讲解～&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/edm/resource/image/85/9a/852e6196c25c9abab4e7a7ee2767159a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.snowflake.com/about/webinars/snowflake-discover-apac/?utm_source=InfoQ&amp;amp;utm_medium=Social&amp;amp;utm_campaign=discoverAI-China-InfoQ&quot;&gt;点击报名 Discover&lt;/a&gt;&quot;，更多 Snowflake 精彩活动请关注&lt;a href=&quot;https://www.infoq.cn/space/snowflake&quot;&gt;专区&lt;/a&gt;&quot;。&lt;/p&gt;</description><link>https://www.infoq.cn/article/TZrHpojJxuCmLCP0uRSO</link><guid isPermaLink="false">https://www.infoq.cn/article/TZrHpojJxuCmLCP0uRSO</guid><pubDate>Thu, 29 Jan 2026 09:02:56 GMT</pubDate><author>王玮</author><category>Snowflake</category><category>大数据</category><category>AI&amp;大模型</category></item><item><title>Aspire 13.1带来了MCP集成、CLI增强和Azure部署更新</title><description>&lt;p&gt;&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/&quot;&gt;Aspire 13.1&lt;/a&gt;&quot;作为增量更新发布，它基于Aspire 13引入的多语言平台基础。此次发布专注于通过增强命令行界面、更深入地支持AI辅助开发工作流程、改进仪表板体验以及更清晰的Azure环境部署行为来提高开发者的生产力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据团队报告，此次更新旨在使日常开发任务更可预测、更易于自动化，并与现代AI编码工具更好地对齐。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Aspire 13.1中的一个核心新增功能是通过与模型上下文协议（&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/#-mcp-for-ai-coding-agents&quot;&gt;Model Context Protocol&lt;/a&gt;&quot;，MCP）集成，扩展了对AI编码智能体的支持。一个新的命令允许项目在初始化时支持MCP，使兼容的AI工具能够发现Aspire集成、检查应用程序结构并与运行中的资源交互。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;null&quot;&gt;aspire mcp init&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;连接后，AI智能体可以查询应用程序状态、查看日志并通过暴露的端点检查跟踪。这种集成旨在简化开发过程中AI助手的使用，而无需为每个工具进行自定义设置。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/#%EF%B8%8F-cli-enhancements&quot;&gt;Aspire CLI&lt;/a&gt;&quot;进行了几次更新，旨在减少创建、运行和维护项目时的摩擦。如前所述，项目创建命令现在可以选择通道，并且一旦选择，将全局保持，确保新项目的行为一致。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;CLI还能检测到已经运行的实例，并在启动新运行之前自动停止它们，从而避免常见的冲突。安装脚本现在支持一个选项来跳过修改系统 PATH，这在受控环境中非常有用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此次发布的仪&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/#-dashboard-improvements&quot;&gt;表板更新&lt;/a&gt;&quot;专注于清晰度和可见性。新的参数标签允许直接从资源详情中查看和管理配置值。GenAI可视化器已增强，以更好地显示工具定义、评估和相关日志，并支持预览音频和视频内容。仪表板的几个稳定性问题也得到了解决。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e0/e063e5a2395fca657719db177ab3ec1c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;（GenAI可视化器工具定义，来源：&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/#genai-visualizer-enhancements&quot;&gt;官方Aspire文档&lt;/a&gt;&quot;）&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/#%EF%B8%8F-azure-improvements&quot;&gt;Azure&lt;/a&gt;&quot;改进方面，Aspire 13.1引入了更清晰的命名和更强大的验证。Azure Redis集成已重命名，以更好地匹配底层服务，并且在部署过程中更早地执行额外检查，以便尽早发现配置问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Azure资源现在暴露出标准化的连接属性，这些属性在支持的语言中通用，使得非.NET应用程序能够使用一致的设置进行连接。还增加了对Azure App Service中部署槽的支持和对默认角色分配的更精细控制。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;通过引入通用容器注册表资源，&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/#-container-and-docker-compose&quot;&gt;容器和部署&lt;/a&gt;&quot;工作流得到了改进，允许开发者锁定Azure容器注册表之外的注册表。容器镜像推送现在更加明确和可预测，特别是在部署到Azure容器应用时。Docker Compose支持已得到改进，以增强可移植性并减少并行构建期间的竞争条件。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此次发布还包括针对&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/#-javascript-and-frontend-support&quot;&gt;JavaScript和前端开发的更新&lt;/a&gt;&quot;，例如一个新的起始模板，该模板结合了ASP.NET Core后端和基于Vite的前端，改进了开发中的HTTPS处理，并修复了与包管理器相关的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;证书处理得到了简化，新增了配置HTTPS和在支持的容器中终止TLS的新API。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，Aspire 13.1还稳定了之前预览版中的几个集成，包括Dev Tunnels、端点代理支持和Azure Functions。模板已更新以反映一致的模式，并且广泛的错误修复集提高了跨平台的可靠性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/&quot;&gt;Aspire 13.1&lt;/a&gt;&quot;需要.NET 10 SDK或更高版本。建议从早期版本升级的开发者查看已记录的重大变更，特别是围绕Azure Redis API和重命名的连接属性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于感兴趣的读者，&lt;a href=&quot;https://aspire.dev/whats-new/aspire-13-1/&quot;&gt;完整的发布说明&lt;/a&gt;&quot;和详细文档可在&lt;a href=&quot;https://github.com/dotnet/aspire&quot;&gt;官方Aspire存储库&lt;/a&gt;&quot;和文档渠道中找到。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/dotnet-aspire-13-1-release/&quot;&gt;https://www.infoq.com/news/2026/01/dotnet-aspire-13-1-release/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/7yEzcHRZxLIIVR4zMV4k</link><guid isPermaLink="false">https://www.infoq.cn/article/7yEzcHRZxLIIVR4zMV4k</guid><pubDate>Thu, 29 Jan 2026 09:00:00 GMT</pubDate><author>作者：Almir Vuk</author><category>微软</category><category>云计算</category></item><item><title>LangChain 创始人警告：2026 成为“Agent 工程”分水岭，传统软件公司的生存考验开始了</title><description>&lt;p&gt;过去几十年，软件工程有一个稳定不变的前提：系统的行为写在代码里。工程师读代码，就能推断系统在大多数场景下会怎么运行；测试、调试、上线，也都围绕“确定性”展开。但 Agent 的出现正在动摇这个前提：在 Agent 应用里，决定行为的不再只是代码，还有模型本身——一个在代码之外运行、带着非确定性的黑箱。你无法只靠读代码理解它，只能让它跑起来、看它在真实输入下做了什么，才知道系统“到底在干什么”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在播客中，LangChain 创始人 Harrison Chase 还把最近一波“能连续跑起来”的编程 Agent、Deep Research 等现象视为拐点，并判断这类“长任务 Agent”的落地会在 2025 年末到 2026 年进一步加速。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这也把问题推到了台前：2026 被很多人视为“长任务 Agent 元年”，现有的软件公司还能不能熬过去？就像当年从 on-prem 走向云，并不是所有软件公司都成功转型一样，工程范式一旦变化，就会重新筛选参与者。长任务 Agent 更像“数字员工”——它不是多回合聊天那么简单，而是能在更长时间里持续执行、反复试错、不断自我修正。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这期与红杉资本的对话中，Harrison 抛出了一个判断：构建 Agent，已经不只是把软件开发“加一层 AI”，而是工程范式本身在变。为什么他说“光读代码不够了”？为什么 tracing、评估、记忆这些原本偏“辅助”的东西，突然变成主角？他在对话里给出了非常具体的解释。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而更现实的问题是：如果范式真的在变，那些靠数据、流程、产品形态建立壁垒的传统软件公司，优势还能不能延续？它们手里握着的数据与 API 可能依然是王牌，但能否把这些资产变成 Agent 时代的生产力，取决于一套全新的工程打法。Harrison 的观察与判断，都在下面的完整对话里：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：AI 领域的变化速度快得惊人。当前最受关注的话题，我觉得没有人比你更合适来聊。我们会先谈 长任务 Agent（Long Horizon Agents） 和 Agent Harness（智能体运行框架）。&lt;/p&gt;&lt;p&gt;接着，我们会讨论：构建长任务 Agent 与构建传统软件到底有什么不同，以及你如何看待 LangChain 在整个生态系统中的角色。最后，我想和你聊聊未来。你怎么看红杉资本这篇关于Long Horizon Agents的文章？哪些观点你认同，哪些地方你不太同意？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ac/acbe71eff021a48fa8459ecebfaa8b62.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;“在去年的一篇文章中，我们曾提出：推理模型（reasoning models）是 AI 领域最重要的新前沿。而“长任务 Agent”（long-horizon agents）则在这一范式之上更进一步——它们不只是思考，还能够采取行动，并在时间维度上不断迭代。”&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;来源：&lt;a href=&quot;https://sequoiacap.com/article/2026-this-is-agi/&quot;&gt;https://sequoiacap.com/article/2026-this-is-agi/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：你们这个概念命名得非常好，那篇文章也写得很棒。我整体上是认同的——长任务 Agent 终于开始真正“跑起来”了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一开始对 Agent 的设想，本来就是让一个 LLM 运行在一个循环里，自主决定接下来该做什么。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;AutoGPT 本质上就是这个想法，这也是它当初能迅速走红、抓住那么多人想象力的原因：一个 LLM 在循环中运行，完全自主地决定行动。但当时的问题在于：模型还不够好，围绕模型的 scaffolding（支架）和 harness（框架）也不够成熟。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这几年，模型本身变得更强了；与此同时，我们也逐渐搞清楚了，什么样的 harness 才是“好”的。于是现在，这套东西开始真正奏效了。最明显的例子是在编程领域，Agent 的突破首先发生在那里。之后，这种能力正在向其他领域扩散。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，你仍然需要告诉 Agent 你想让它做什么，它也需要配备合适的工具。但现在，它确实可以持续运行更长的时间，而且表现越来越稳定。所以，用“长时序”来描述这一类 Agent，我觉得非常贴切。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你最喜欢的长任务 Agent 案例有哪些？你觉得它们正在呈现出哪些形态？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：目前最成熟、我自己用得最多的，还是 编程 Agent。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;再往外延一点，我觉得非常优秀的一类是 AI SRE。比如 Traversal（我记得它是一家红杉投资的公司），他们的 AI SRE 可以在更长的时间跨度内运行。再往抽象一点，其实这类 AI SRE 本质上属于“研究型 Agent”。比如：给它一个事故，它会去翻日志、分析上下文、追溯原因。研究任务本身非常适合 Agent，因为它们最终产出的往往是一个“初稿”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Agent 的问题在于：它们还达不到 99% 的可靠性，但它们可以在较长时间内完成大量工作。所以，只要你能把任务框定为：让 Agent 长时间运行，产出一个初步版本，由人来审阅，这在我看来就是目前长任务 Agent 最“杀手级”的应用形态。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;编程就是一个例子：你通常是提交 PR，而不是直接推到生产环境（当然，vibe coding 现在也在不断进步）。AI SRE 也是一样：结果会交给人来 review。报告生成也是如此：你不会直接发给所有用户，而是先看一遍、改一改。我们在金融领域也看到了大量这样的用法，这是一个非常大的研究机会。客服领域同样如此。最早的客服 Agent 主要是做“第一响应”：用户一发消息，马上给出回复，这类用法现在也做得很好。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但现在开始出现新的形态，比如 Klarna&amp;nbsp;这个产品：人类和 AI 协同工作。当第一层自动回复失败后，不是简单地转交给人工，而是让一个长任务 Agent 在后台运行，生成一份完整的事件报告，然后再交给人工客服处理。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这里“agent”这个词在客服语境下会变得有点混乱，但核心逻辑是一致的。总结来说，这些应用的共同点是：先由 Agent 生成一个“初稿”，再由人类接管。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那么，“为什么是现在”？你觉得主要是因为模型本身变得足够强，还是因为人们在 harness 侧做了非常聪明的工程设计？在回答这个问题之前，能不能先帮听众梳理一下：在一个 Agent 系统中，模型、框架和 harness 各自扮演什么角色？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：当然可以。我也顺便把“框架”这个概念一起带进来。一开始，我们把 LangChain 描述为一个 Agent Framework，现在我们又推出了 Deep Agents，我更愿意称它为一个 Agent Harness。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;很多人都会问，这两者有什么区别。模型很简单，就是 LLM：输入 token、输出 token。框架（Framework） 是围绕模型的一层抽象，让你更容易切换模型，封装工具、向量数据库、记忆等组件，本身比较“无偏好”，强调灵活性，更像是基础设施。Harness 则更“有主张”。以 Deep Agents 为例：我们默认就提供一个 规划工具（Planning Tool）；这个工具是直接内建在 harness 里的，带有明确的设计立场：我们认为这是“正确”的做法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们还做了 上下文压缩（Compaction）。长任务 Agent 会运行很久，哪怕上下文窗口已经很大，也终究是有限的，总会有需要压缩的时候。怎么压缩？压缩什么？这是一个正在被大量研究的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，几乎所有 Agent Harness 都会提供文件系统交互能力，不管是直接操作，还是通过 bash。这一点其实很难和模型本身完全分开，因为模型训练数据里已经大量包含了这类操作。&lt;/p&gt;&lt;p&gt;如果回到两年前，我不确定我们是否能预见到：基于文件系统的 harness 会成为最优解之一。那时模型还没被充分训练过这些模式，而现在模型和 harness 是在一起“共同进化”的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以总结来说，这是一个组合效应：模型本身确实在变强，推理模型带来了巨大提升。同时，我们也逐渐摸索出了 compaction、planning、文件系统工具等一整套关键原语。这两者缺一不可。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;设计范式的演进&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我记得在我们第一次对谈时，你把 LangGraph 描述为 Agent 的“认知架构”。现在来看，这是不是也可以理解为 harness 的一种形态？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：是的，这个理解是对的。我们现在的 Deep Agents 是构建在 LangGraph 之上的。可以把它看作是一个非常具体、非常有主张的 LangGraph 实例，更偏向通用目的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;早期我们讨论过“通用架构”和“专用架构”的区别。现在我们观察到一个很有意思的变化：过去需要写进架构里的任务特异性，正在转移到工具和指令里。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;复杂性并没有消失，只是从结构化代码，转移到了自然语言中。因此，prompt 的设计、修改，甚至自动更新，正在成为系统的一部分；而 harness 本身，反而变得更加稳定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：在你看来，harness 工程中最难做对的是什么？你觉得单个公司是否真的有可能在这一层形成显著优势？有没有你特别佩服的团队？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：说实话，目前在 harness 工程上做得最好的，基本都是编程类公司。Claude Code 就是一个非常典型的例子。我认为它能如此受欢迎，很大程度上是因为它的 harness。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：这是否意味着：harness 更适合由模型公司来做，而不是第三方创业公司？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我不确定。比如 Factory、AMP 这些编程公司，也都做出了非常强的 harness。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;确实存在一个现实：harness 往往和模型家族绑定得比较紧密。不一定是某一个具体模型，而是一整个模型体系。Anthropic 的模型会针对某些工具进行微调，OpenAI 则针对另外一些。这和 prompt 类似：不同模型，需要不同的 prompt；同样，不同模型家族，也需要稍微不同的 harness。当然，它们也有很多共性，比如几乎都会使用文件系统。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我自己也没有一个确定答案。但一个很明显的现象是：几乎所有做编程 Agent 的公司，现在都在自研自己的 harness。你去看 Terminal Bench 2 这样的榜单，会发现他们不仅展示模型，还展示 harness。Claude Code 并不总是在榜首。这说明：性能差异并不完全来自模型，而来自对“模型如何在 harness 中工作”的理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：你觉得，排行榜上表现最好的 harness，究竟在哪些地方做得特别好？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：首先是对模型训练偏好的理解。比如 OpenAI 的模型对 Bash 非常熟悉；Anthropic 提供了显式的文件编辑工具。顺着模型的“母语”来设计 harness，本身就能带来性能收益。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其次是 上下文压缩（Compaction）。随着任务时间跨度变长，如何处理上下文窗口溢出，已经成为一个核心问题。这显然也是 harness 的一部分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，还有 skills、子 Agent、MCP 等机制。目前这些能力还没有被系统性地训练进模型中，仍然属于比较新的探索方向。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在我们的 harness 中，一个典型挑战是：主 Agent 如何与子 Agent 高效通信。主模型需要把所有必要信息传递给子 Agent，同时还要明确告诉它：最终只需要返回一个“最终结果”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们见过一些失败案例：子 Agent 做了大量工作，最后却返回一句“请查看我上面的分析”，而主 Agent 根本看不到那些内容，于是完全不知道它在说什么。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以，如何通过 prompt 设计让这些组件协同工作，是 harness 工程中非常重要的一部分。&lt;/p&gt;&lt;p&gt;如果你去看一些公开的 harness prompt，它们往往有几百行之长。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我想从演进角度问一个问题。你一直站在模型“如何落地”的最前沿。如果用一种简化视角来看过去五年的几个关键拐点：ChatGPT 带来了预训练的拐点；o1 带来了推理能力的拐点； 最近，Claude Code + Opus 4.5 带来了长任务 Agent 的拐点。但从你这个“围绕模型做设计”的世界来看，拐点会不会是另一套划分？从认知架构到框架、再到 harness，这中间经历了哪些真正的跃迁？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我大概会把它分成三个阶段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第一阶段：最早期。那时 LangChain 刚刚出现，模型还是“纯文本输入、纯文本输出”，甚至还不是 chat 模型。没有工具调用，没有 reasoning，没有结构化输出。人们主要做的是单一 prompt 或简单 chain。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第二阶段：工具与规划开始进入模型。模型开始支持 tool calling，也尝试学会“思考”和“规划”。虽然还不够强，但已经能做出基本决策。这时，人们大量使用自定义的认知架构，通过显式提问来引导模型行动，但整体仍然依赖大量外部 scaffolding。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第三阶段：长任务 Agent 的真正起飞。大概是在今年 6～7 月，我们看到 Claude Code、Deep Research、Manus 等产品同时爆发。它们在底层使用的是同一个核心算法：让 LLM 在循环中运行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;真正的突破来自于 上下文工程：压缩、子 Agent、技能、记忆——所有这些，都是围绕上下文展开的。这正是我们开始做 Deep Agents 的时间点。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于很多程序员来说，Opus 4.5 可能是一个心理上的分水岭。也可能只是碰巧遇上假期，大家回家开始大量使用 Claude Code，突然意识到：它真的很好用。无论是 2025 年初还是 2025 年末，总之在某个时间点，模型“刚好强到足以支撑这种形态”，于是我们从 scaffolding 迈向了 harness。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Coding Agent 是通用 AI 的终局形态吗&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：接下来会发生什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我也希望我知道答案。这个“让 LLM 在循环中运行、让它自己决定要拉什么上下文进来”的算法，本身极其简单、也极其通用。这正是 Agent 从一开始的核心设想，而我们现在终于走到了“它真的能工作”的阶段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;接下来，可能会有大量围绕上下文工程的技巧出现：有些手动设计的部分可能会消失；比如压缩类的，现在仍然高度依赖 harness 作者的决策。Anthropic 已经在尝试让模型自己决定何时压缩上下文，虽然目前用得还不多。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一个我们非常关注的方向是 记忆（Memory）。从本质上说，记忆也是一种上下文工程，只不过是跨更长时间尺度的上下文。核心算法本身已经非常清晰：运行 LLM 循环。未来的进步，很可能来自更聪明的上下文工程方式，或者让模型自己参与上下文管理。模型当然也会继续变强，越来越擅长长时序任务。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我目前思考最多的一个问题是：我们看到的大多数 harness 都是高度偏向编程任务的。这是长任务 Agent 最先爆发的领域。但即便是在非编程任务中，你也可以认为：写代码本身是一种非常强的、通用的工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我本来想问你：编程智能体（coding agents）到底算不算一个子类别？还是说编程智能体就是智能体本身？换句话说，智能体的工作，本质上是想办法让计算机去做一些有用的事情，而“写代码”本来就是让计算机做有用事情的一种很好的方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我也不确定。但有一点我非常非常坚信：现阶段只要你在做长时序智能体，你就必须给它文件系统的访问能力。因为文件系统在“上下文管理”方面能做的事情太多了。比如我们说 compaction（上下文压缩），一种策略是把内容总结掉，但把完整的消息都放进文件系统里，这样如果智能体后续需要回查，它还能查到。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一种策略是，当你遇到很大的工具调用结果时，不要把全部内容都塞回模型上下文里；你可以把结果放进文件系统，然后让智能体需要的时候再去查。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而这些操作，其实不一定需要真实的文件系统，也不一定要让它真的去写代码。我们有一个概念叫“虚拟文件系统”：它底层可能只是 Postgres 之类的存储，扩展性更强。当然，“真实代码”能做的事情，虚拟文件系统做不了。比如你没法在虚拟文件系统里直接运行代码。所以写脚本在很多场景下确实非常有用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我也认为编程智能体有潜力成为通用智能体，但我不确定这是否意味着“今天的编程智能体”就是通用智能体——如果你能理解我这句话。因为我觉得现在很多编程智能体还是为编程任务做了大量优化的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以“一个通用智能体可能长得像编程智能体”，但反过来，“今天的编程智能体就是通用智能体”，这件事我并不确定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;传统软件面临的挑战&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：那我们能不能转到另一个话题：构建长时序智能体和构建传统软件之间的差异？你能不能先描述一下“1.0 时代”的软件开发栈是什么样的，然后说说现在到底哪里不一样？我记得你在 X 上写过一篇很不错的文章，也许你可以总结一下核心结论。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e1/e1839d7404649a0013d16b7f7d6b4a61.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;来源：&lt;a href=&quot;https://x.com/hwchase17/status/2010044779225329688&quot;&gt;https://x.com/hwchase17/status/2010044779225329688&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我这段时间一直在反复想这个问题：我们经常说“做智能体和做软件是不同的”，而且很多人也同意。但问题是：到底哪里不同？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我觉得很容易、也很偷懒地说“不同”，但“具体不同在哪里”才是关键。下面这些可能听起来很显然，但也许显然是好事，希望它们不太有争议。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当你在做传统软件时，所有逻辑都写在代码里，你能直接在软件代码中看到它。但当你在做智能体时，你的应用如何工作的“逻辑”，并不全部在代码里，其中很大一部分来自模型本身。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这意味着：你不能只看代码，就判断智能体在某个具体场景下会做什么。你必须真的把它跑起来。而我认为，这就是最大的不同：我们引入了这种非确定性系统，它是一个黑箱，它在代码之外。我觉得这就是核心差异。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一个直接后果是：为了弄清楚应用到底在做什么，你不能看代码，你必须看它在真实运行中做了什么。这也是为什么我们做的产品里，最受欢迎的之一是 LangSmith。LangSmith 的一个核心能力是 tracing（追踪/执行轨迹）。为什么 trace 这么受欢迎？因为它能把智能体每一步内部发生的事情都清清楚楚地展示出来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而这跟传统软件里的 trace 又不一样。传统软件里，你的系统在那边跑，它会吐出很多日志和事件；你通常是在出现错误时才去看，而且你不需要“每一步的全部细节”。而且本地开发时，你可能直接打个断点就够了；很多时候日志追踪是上线到生产环境后才会更重度开启。但在智能体里，人们从一开始就会用 trace 来理解“底层到底在发生什么”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而且它在智能体里的影响力，远大于在单一 LLM 应用里的影响力。因为在单一 LLM 应用里，如果模型回答得不好，你知道你的 prompt 是什么，也知道输入上下文是什么（由代码决定），然后你得到一个输出。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在智能体里，它在循环中运行、不断重复。你并不知道第 14 步时上下文里到底有什么，因为前面 13 步可能会把任意东西拉进上下文。所以，“上下文工程（Context Engineering）”真的是一个非常好的词。我真希望这是我发明的。它几乎完美描述了我们在 LangChain 做的一切——只是当时我们并不知道这个术语已经存在。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;trace 的价值就在于：它能直接告诉你此时此刻上下文里到底有什么，这太重要了。那这又意味着什么？这意味着：对传统软件来说，“真相的来源（source of truth）”在代码里。但对智能体来说，真相来源变成了代码与 trace 的组合——而 trace 是你能看到真相的一部分地方。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从技术上说，真相当然也“存在于模型的数百万参数里”，但你基本没法直接对参数做什么。所以现实上，trace 就成了你可以抓住的“事实载体”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;因此，trace 也会成为你开始思考测试的地方。你仍然可以对 harness 的某些部分做单元测试，也可以离线做一些 unit test，但要获得真正的测试用例，你很可能需要用 trace 来构建。而且在智能体里，在线测试（online testing） 可能比传统软件更重要，因为行为不会在离线环境里完整显现出来，只有在真实世界输入驱动下、系统被真正使用时，行为才会“涌现”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们也看到 trace 正在成为团队协作的中心：如果出了问题，不再是“去 GitHub 看代码”，而是“去看那条 trace”。我们在开源项目里也一样。有人说：“Deep Agents 这里跑偏了，发生了什么？”我们的第一反应是：“把 LangSmith trace 发给我们。”如果没有 trace，我们基本没法帮你 debug。过去大家会说“把代码给我看看”，但现在已经转变了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这就是我写在 X 上那篇文章的核心内容，反馈很好。我也还在琢磨怎么把它表达得更精确，但我觉得这一点很关键。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另外一个点我也还在继续想：我觉得构建智能体是一个更偏迭代式的过程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们过去也会这么说，但我以前会有点翻白眼，因为软件开发本来也是迭代式的：你发布、收反馈、不断迭代，这就是软件开发的常态。但我觉得差别在于：在传统软件里，你的迭代是围绕“你希望软件做什么”来进行的。你有一个想法，你发布，你收反馈。比如“这个按钮让人困惑”，或者“用户其实想做 X 而不是 Y”。但你在发布之前，其实你是知道软件会怎么运行的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在智能体里，你在发布之前并不知道它到底会怎么做。你当然有一个预期，但你并不能在发布前真正确定它会做什么。因此，为了让它更准确、让它更“对”、让它能通过某种“概念上的单元测试”，你需要更多轮次的迭代。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这个基础上，我也认为记忆（memory）非常重要。因为记忆就是在从这些交互中学习。如果你的开发过程变得更迭代、更难，那么作为开发者，我为了让系统表现正确，可能需要反复改系统 prompt——这种频率甚至可能比我改代码还高。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这就是记忆进入的地方：如果系统能够以某种方式自己学习，那就能减少开发者必须进行的迭代次数，让构建这类智能体变得更容易。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以，这是我认为“构建智能体确实不同于构建软件”的另一个角度。我也承认，这么说有点老套，所以我一直在逼自己想清楚“到底不同在哪里”，目前我总结出来的就是这两点。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：我也很想追问这一点。现在公开市场上有一个很大的争论：现有的软件公司还能不能熬过去？如果类比当年从本地部署软件（on-prem）转向云（cloud），实际上真正成功转型的公司并不多，因为事实证明，“做云软件”和“做本地软件”确实差异很大。你现在处在“人们如何用 AI 构建产品”的核心地带。你怎么看这件事？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我不是要问公开市场的投资问题，而是想问：这个变化到底有多大？你有没有看到很多人：过去很擅长“旧方法做软件”，现在也能很擅长“新方法做软件”？还是说更像是：你要么在“新方法”里长大，要么就很难真正理解它？你觉得人能跨越这个鸿沟吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我注意到现在有很多年轻创始人，这让我觉得，也许年轻人因为没有太多对“旧软件开发方式”的先入之见，反而可以更快把这些东西学起来、用起来。而且我们确实一再听到一个现象：很多在做 agent engineering 的团队成员，反而是更初级的开发者、更初级的构建者——他们确实没有那些先入之见。我们内部的应用 AI 团队，确实整体更偏年轻一些。我觉得这里面既有“人的因素”，也有“公司的因素”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;先说公司层面：数据依然非常非常非常有价值。如果你从 harness 的角度去看——顺便说一句，我其实不认为长期来看大多数人都会自己去写 harness，因为它比做 framework 难太多了。所以我觉得大家最终会用我们提供的 harness，或者用别人的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那一个 harness 里面有什么？主要就是：prompt、指令，以及它连接的工具。而现有公司在这方面最大的资产之一，是他们已经拥有数据和 API。如果你过去在这块做得不错，那么把这些东西接入到 agent 上，其实会非常容易产生真实价值。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们前阵子和金融行业的人聊，他们就说：数据的价值只会越来越高、越来越高、越来越高。所以如果你是一个传统软件厂商，你手上有这些高价值数据，你应该能够把它暴露给智能体，让智能体去用，从中拿到很大的收益。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过这里还有另一部分：关于“如何使用这些数据”的指令（instructions），这一块可能更偏“新增”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;你作为软件厂商也许一直对“怎么用这些数据”有一些想法，但你并没有把这些想法系统化、固化成可执行的“操作说明”，因为过去这件事更多是由人来完成的——很多智能体现在在做的事情，本来就是人类会做的事情。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;你当然会给人配工具，但你以前不会、或者也很难成功地把它完全自动化。而到了“智能体”这一代，这部分才真正变得可行。所以我觉得这块是新的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们也看到大量需求来自“垂直领域创业公司”。Rogo 就是一个很好的例子：他们团队有人有金融行业经验，把这种行业知识带进了智能体系统里，而这之所以有效，是因为很多智能体的驱动力来自“知识”——但不是那种通用世界知识，而是如何执行特定流程、特定模式的知识。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以问题就变成：做传统软件的人是不是做智能体的合适人选？我觉得我们确实看到很多非常资深的开发者在采用 agentic coding，所以某种程度上这更像是“心态问题”。但确实也可能会呈现出一种“年轻化倾向”。而公司层面，则很大程度取决于它手上的数据资产。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：所以看起来，你认为 trace 是这个新世界里 agent 开发的核心“产物”，LangSmith 在这方面帮助很大。那你觉得还有哪些核心的“产物”——或者说，可能“产物”这个词不对，应该说组件（components）？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：对，组件。我觉得构建软件与构建智能体之间另一个差异是：评估软件时，你可以相当可靠地依赖程序化测试和断言。但智能体做的很多事情，本质上是“人类会做的事情”。因此要评估它，你必须把人的判断引入进来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这也是我们在 LangSmith 里努力解决的问题之一：你已经有了这些 traces，那么你怎么把人类判断带到 traces 上？最直接的方法当然就是：把人引进来。所以我们也看到数据标注类创业公司做得很好。我们在 LangSmith 里有一个概念叫 annotation queues（标注队列），就是把人带进来参与。因此，实际的、真实的人类判断，是其中非常重要的一部分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：这里的“人工标注”的trace，比如，智能体做了这些步骤，这是好还是不好。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：有时候，人会给自然语言反馈：这很好、这很差、这里应该怎么做。有时候，人会直接“纠正它”：把正确步骤完整地写出来。这具体怎么做取决于用例，而且对做 RL 的模型公司，和对做 agent 应用的公司来说，也可能不一样。但核心就是：把人类判断带进来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同时，我们也看到另一条路：尝试为这种人类判断建立一些“代理指标”（proxy）。这就是 LLM-as-a-Judge 这类方法的来源：你可以跑一个 LLM 或其他模型，让它承担某种“类似人类判断”的角色，去给那些本来需要人类判断的东西打分。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们一直在思考的一件事是：怎么让“构建 judge”这件事变得容易。因为 judge 的关键很大一部分在于：它必须和你的人的判断、人类偏好保持一致。如果做不到，那你的 grader（评分器）就很糟糕。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以我们在 LangSmith 里做了一个概念叫 align evals：人类先去标注一些 traces，然后基于这些标注，构建一个 LLM judge，使它在这些样本上被校准（calibrated）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因为关键就在于：你要把人类判断引入进来；如果你要用 proxy 来替代它，那就必须确保这个 proxy 校准得足够好。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;主持人：有意思。我记得我们最开始和你做业务合作的时候，还在邮件里讨论过：LLM-as-a-Judge 到底是否可行。看起来它已经进步很多了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：是的。LM-as-a-Judge 其实有几个不同层面的用法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最常见的一种，是用于 eval：拿一条 trace，直接给它一个分数，比如 1 到 0，或者 0 到 10。这个我认为是可行的，而且很多人确实在做。他们会离线做，也会在线做，因为有些判断并不需要 ground truth（标准答案）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但我觉得另外一个更重要的场景，是你在 coding agents 里也能看到的：coding agent 往往会先工作到某一步，然后遇到错误，触发纠错。它实际上是在“评判自己刚才做的工作”。我们也在 memory 上看到同样的模式：记忆很大一部分就是反思 traces，然后更新某些东西。所以问题是：LLM 能不能去反思 traces——无论是它自己的 trace、以前 session 的 trace，还是别人的 trace？我觉得完全可以。我们在 eval、纠错、记忆里到处都能看到这种模式，本质上其实是一回事。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Eval是 RL 的奖励信号，还是工程反馈机制？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：我明白了。那接下来就很自然会问：你有了所有 traces，也有了 eval。那么这些 eval 到底是什么？它是强化学习的 reward signal？还是一种反馈机制，让工程师去改进 harness、让 agent 工程师去优化 harness？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：因为现在大家都不再手动写太多代码了，大家都在用这些 agent 工具。我们观察到一个很重要的模式：我们有一个 LangSmith MCP，也有 LangSmith fetch（一个 CLI）。因为 coding agents 特别擅长用 CLI。你把这些给智能体，它就能把 traces 拉下来，诊断哪里出了问题，然后把这些 traces 带进代码库里，从而修复它。这是我们正在看到的真实模式，而且我们非常非常非常想支持这种模式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以在这一点上，相比“用 eval 做强化学习奖励信号”，我对“把 eval 当作工程反馈、用于改 harness”的路径更乐观——至少对今天做 agent 应用的公司来说是这样。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：这听起来像是递归自我改进啊。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我觉得是，但还是有一个人类在环。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;回到前面那个点：当它产出“初稿”时效果最好——它改 prompt，然后人类 review，这能让系统保持不跑偏。但我们确实……我们最近发布了 LangSmith Agent Builder，这是一个 no-code 的 agent 构建方式。其中一个很酷的功能就是 memory。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;现在 memory 的工作方式是这样的：当你和 agent 交互时（注意它还不是后台自动跑的那种；它不会自己拉 traces），如果你对它说：“你不该做 X，你应该做 Y”，它就会去改自己的指令——这些指令本质上就是文件——然后直接编辑这些文件。这样未来它就会按新的方式表现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这也是一种“自我改进”的形式。我们确实还想加入另一种机制：比如每天晚上跑一次任务，查看当天所有 traces，更新自己的指令。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：就是那种“做梦”的机制。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：对，“睡眠时间算力（sleep-time compute）”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;记忆与自我改进会成为护城河吗？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：我们再多聊聊未来。你现在最兴奋的是什么？听起来你聊了很多 memory。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：我很看好memory。我觉得让智能体去改善自己，这非常酷，而且在很多场景下也很有用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但也不是所有场景都用得上。比如 ChatGPT 加了 memory 功能，我其实用得不多，我也不觉得它显著增加了我对产品的粘性。我觉得原因之一是：我去 ChatGPT 时，大多数问题都是一次性的。我不太会反复做同一件事：我可能问软件，也可能问吃的、旅行……都很零散。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但在 agent builder 里，你通常是为特定任务构建特定工作流。比如我有一个 email agent。而且我其实……它已经给我发邮件两年了。我之前在 agent builder 之外就有一个 email agent，它带有 memory。后来我们做了 agent builder，我想把它迁移进去，但它没有我之前的那些 memories。即便它的起始 prompt 一样、工具也一样，但因为缺了记忆，它现在的体验就明显差很多。我到现在都还没完全切过去，因为它现在确实不如之前那个好用——说白了，它现在“有点烂”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然，如果我持续和它交互，它会变好，它会不那么烂。但这也恰恰说明：memory 可能会成为真正的护城河（moat）。而且我绝对相信，我们已经到了一个阶段：LLM 可以看 traces，然后改变自己代码里的某些东西。问题在于：怎么把这件事做得安全、并且在用户层面可接受。但我认为，在一些特定场景里（不是所有场景），我们会越来越多看到这种能力。至于 ChatGPT 这种通用聊天产品，我仍然不确定这种形态的 memory 是否有用，至少目前我不确定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：你觉得和长时序智能体一起工作的 UI 会如何演化？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：我觉得大概率需要同步模式（sync）和异步模式（async）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;长时序智能体运行时间可能很长，默认应该是异步管理：如果它要跑一天，你不会一直坐在那里等它结束。你很可能会启动一个、再启动一个、同时跑很多个。所以这里会涉及到异步管理：我觉得像 Linear、Jira、看板，甚至 email，都可以作为 UI 设计的参考——如何去管理一堆异步运行的 agent。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但与此同时，很多时候你又会想切换到同步交流。因为 agent 最后给你返回一份研究报告，你可能需要立刻指出：它这里写错了，你要给反馈。聊天界面在这方面其实已经挺不错的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我唯一想补充的是：现在很多 agent 不仅是在“对话”，它还会去修改文件系统里的文件。所以你必须有一种方式去查看“状态”（state）——也就是它改了什么。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这在编程领域尤其明显：IDE 依然被使用，是因为当你想手动改代码时，你需要看见那个“当前状态”。即便我启动 Claude Code，它跑完后，我有时也会打开来看它到底写了什么代码。所以“能看到状态”这件事很重要。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Anthropic 在 Claude “co-work”（这里指那类协作式工作流）里做了一个很酷的设计：你设置它时要选择一个目录，等于你在告诉它：“这就是你的环境。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这在编程里当然也是常态：你打开 IDE 到某个目录。但我觉得把它明确成一个心智模型很有帮助：这就是你的 workspace（工作区）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个 workspace 也不一定非得是本地目录：它可以是 Google Drive、Notion 页面，或者任何能存储状态的地方。你和 agent 就是在这个状态上协作：你启动它，让多个任务异步跑；然后切到同步模式，在 chat 里和它讨论，但同时你还能看到它正在协作的“状态”。这就是我目前看到的形态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：所以这也就是你说的“agent inbox”的想法：为了进入 sync 模式，agent 需要能联系到你。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：对，没错。我们大概一年前发布过 agent inbox，理念是“ambient agents”：它们在后台跑，必要时来 ping 你。但第一版其实没有 sync 模式：它 ping 你，你回一句，然后你就等它下一次再 ping 你。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但很多时候，我切到邮件去回复它时，我其实只回很短的话，而且我不想再切出去然后干等——我（对方）很重要，所以我更想直接进入一种“同步对话”的模式，跟 agent 把这个问题当场聊完。所以我们后来做了一个关键改动：当你打开 inbox 时，会直接进入 chat，而 chat 是非常同步的。这是一个很大的 unlock（突破点）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我现在认为：只有 async 模式，目前还不太够。也许未来如果 agent 强到你几乎不用纠正它，那么纯异步会更可行。但至少现在，我们看到人们在 async 和 sync 之间来回切换。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人： 你怎么看 code sandboxes（代码沙箱）？是不是每个 agent 最终都会配一个 sandbox？也包括“能用电脑”、能上网用浏览器这种能力？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase： 这是个特别好的问题，我们也一直在想。就目前的经验来看，“写代码/跑代码”这条路明显比“直接操作浏览器”更成熟、更好用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以短期内，如果要在这些能力里挑一个最可能成为标配的，我更看好的是代码执行（code execution）——也就是给 agent 一个能安全运行脚本、验证结果的环境。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另外，文件系统（file system）我几乎是“坚定派”：不管是本地目录、还是背后用数据库实现的“虚拟文件系统”，agent 总得有个地方能存状态、存中间结果、随时回查，这对上下文管理太关键了。比如：&lt;/p&gt;&lt;p&gt;做 compaction（上下文压缩）时，把完整内容丢到文件里，需要再查就去读；工具调用返回特别长时，不塞进上下文，改成写文件、让 agent 自己按需读取。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;至于“coding”（让 agent 真正去写代码），我没那么绝对，但我大概90% 站在“需要”这一边。因为很多长尾任务里，写脚本依然是最通用、最强的手段——你很难找到同等级的替代品。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然也可能出现另一类场景：如果你做的是高度重复、流程固定的事情，未必每次都要写很多代码；但即使这样，文件系统仍然重要，因为重复流程会不断产生上下文和状态，你还是要做上下文工程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;再说浏览器使用（browser use）：从我们目前看到的效果来说，模型还不够稳定。也许可以让 coding agent 通过 CLI 的方式“间接”完成一些浏览器相关任务（算是一种近似解），我确实见过一些挺酷的实现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而所谓 computer use（直接操作电脑界面）则更像是介于两者之间的混合形态，目前还有不少不确定性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以总结一下：我非常喜欢 code sandboxes，我觉得它会成为 agent 能力栈里很关键的一块。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主持人：太棒了。Harrison，真的非常感谢你今天来参加节目。你一直都能在 agent 这条路上看到未来，能和你聊“上下文工程如何演化到今天的 harness 与长时序智能体”，真的特别过瘾。感谢你推动这个未来，也感谢你一直愿意和我们聊这些。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：谢谢邀请。我希望未来还能再来一次，然后证明我今天说的全部都是错的。因为预测未来真的很难。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;https://www.youtube.com/watch?v=vtugjs2chdA&amp;amp;t=1s&lt;/p&gt;</description><link>https://www.infoq.cn/article/2XfMOshHpdVVKjB2hxms</link><guid isPermaLink="false">https://www.infoq.cn/article/2XfMOshHpdVVKjB2hxms</guid><pubDate>Thu, 29 Jan 2026 08:18:49 GMT</pubDate><author>Tina</author><category>生成式 AI</category></item><item><title>Linus 之后的 Linux？内核社区终于写下“接班预案”</title><description>&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/94/945c92e1d75cd68d349118286393a8f5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Linus Torvalds 常开玩笑说自己会“活到永远”。但以防万一，Linux 内核社区现在也准备好了一套交接方案——只是这份方案并没有点名具体的接班人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果 Torvalds 发生意外，或者哪天决定退休，Linux 不再把一切寄托在“到时候再说”。核心内核社区已经正式起草了一份项目连续性计划：一旦顶层维护者出现空缺，应该如何在最坏情况或有序过渡中，选出新的顶层维护者（可能是一人，也可能是多人），确保项目长期稳定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Torvalds 本人则明确表示自己暂无退休打算。被问到未来是否会交棒时，他依旧以一贯的幽默回应，暗示自己更倾向于“继续干下去”。随后他又补充了一个更现实的理由：家里人同样不希望他突然闲下来，尤其是太太，大概更不想每天被一个无所事事、没事找事的丈夫缠着。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这份新的“为计划而写的计划”由资深内核贡献者 Dan Williams 起草，并在最近于东京举行的 Linux Kernel Maintainer Summit 上讨论。Williams 介绍它时还自嘲：这是个“与我们终将走向死亡相关、但很振奋的话题”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;不指定唯一继承人&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Torvalds 也解释了这次为何会把“接班”议题正式摆上台面：部分原因是他此前与 Linux 基金会的合同在去年第三季度到期，基金会技术顾问委员会的人都知情。虽然合同随后已续签，但这段时间确实促使大家把风险管理讨论得更具体。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;计划并没有给出一个“唯一继承人”。相反，它明确了一套选择流程：一旦需要交接，由社区召集一次类似“秘密会议”的讨论机制，集中权衡候选人或候选团队，尽量做出对项目长期健康最有利的决定。有维护者开玩笑说，干脆学选教皇：把人都锁在房间里，等决定出来再放出一缕白烟。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;文件提到一个开源圈常说的“公交车系数”（bus factor）梗：假设项目的关键人物哪天突然“消失”（比如出了意外），项目还能不能照常运转？因为 Torvalds 仍是顶层合并与发布的最终把关人，所以从风险角度看，Linux 在这一环节几乎等同于“系数为 1”——也就是关键节点过度依赖一个人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不过在现实中，大家也大致心照不宣：真要临时接手，“企鹅之王”的角色多半会落到 Greg Kroah-Hartman 身上——他是 Linux 内核稳定分支的维护者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Torvalds 还在 2024 年和好友 Dirk Hohndel（Verizon Open Source 负责人）聊过这个话题。Hohndel 认为，要成为 Linux 的主维护者，需要极其丰富的经验；而目前最自然的“备份选项”就是 Greg Kroah-Hartman。Torvalds 的看法则更偏向长期视角：关键不在于某个人，而在于谁能获得社区的信任；这种信任通常来自长期参与、稳定协作，以及社区对其工作方式的充分了解，但“资历够久”并不意味着必须三十年如一日。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kroah-Hartman 也确实曾短暂顶上过。2018 年 Torvalds 一度暂离内核工作、反思并改善自己对待其他开发者和维护者的方式时，Kroah-Hartman 曾临时承担顶层职责。不过，他的年龄甚至比 Torvalds 还大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;或许会由多人共同接棒&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此也有人提出，与其再找一位新的“终身仁慈独裁者”（BDFL），不如把顶层维护者的职责拆分给多位值得信赖的开发者共同承担。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;56 岁的 Torvalds 仍然是几乎所有进入 torvalds/linux.git 变更的最终裁决者。他常自嘲 Linux 的核心圈子正在“变老”。而维护者疲劳、以及核心子系统负责人后继乏人等问题，让这种紧迫感越来越强。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;可以确定的是：Torvalds 并不会在短期内让位。他仍会继续监督主线开发，并一直做到自己“做不动”为止。只是至少现在，那个终极的“Linus 依赖”风险终于有了明确的处理流程——等到真正需要的那一天，可以直接套用，而不必临时抱佛脚。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.zdnet.com/article/linux-community-project-continuity-plan-for-replacing-linus-torvalds/&quot;&gt;https://www.zdnet.com/article/linux-community-project-continuity-plan-for-replacing-linus-torvalds/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/rxKQhGxLH5lYkeo51kCZ</link><guid isPermaLink="false">https://www.infoq.cn/article/rxKQhGxLH5lYkeo51kCZ</guid><pubDate>Thu, 29 Jan 2026 08:12:34 GMT</pubDate><author>Tina</author><category>开源</category></item></channel></rss>