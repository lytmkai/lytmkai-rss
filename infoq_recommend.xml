<?xml version="1.0" encoding="UTF-8"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>InfoQ 推荐</title><link>https://www.infoq.cn</link><atom:link href="http://10.0.0.5:1200/infoq/recommend" rel="self" type="application/rss+xml"></atom:link><description>InfoQ 推荐 - Powered by RSSHub</description><generator>RSSHub</generator><webMaster>contact@rsshub.app (RSSHub)</webMaster><language>en</language><lastBuildDate>Mon, 19 Jan 2026 11:06:18 GMT</lastBuildDate><ttl>5</ttl><item><title>非科班出身、辍学生逆袭AI巨头，Claude Code创始人：不关注对手，那只会让我们迷失</title><description>&lt;p&gt;从 Meta 离职、加入 Anthropic，这个决定在今天看来并不意外，但在当时却并非顺水推舟。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对 Claude Code创建者 Boris Cherny 来说，这并不是一次普通的职业跳槽，而是一种价值判断：当大模型从“工具”逐步演化为具备自主生成与推理能力的系统，工程师究竟应该站在什么位置？是把它当作效率插件，还是把它视为一种需要被认真约束、引导和共同演化的新型技术力量？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;近日，Boris Cherny 做客一档名为《The Peterman Pod》的访谈栏目，主持人Ryan Peterman与Boris围绕这一系列问题展开了长达一个半小时的深度对话。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;访谈的前半部分，Boris回溯了自己从 Meta 转向 Anthropic 的动机。他并未从公司前景或个人发展谈起，而是从第一次使用 ChatGPT 的震撼说起。在他看来，大语言模型并不只是“更聪明的软件”，而更像一种尚处在早期阶段的“新生命形态”——它的能力增长呈指数级，影响范围远超工程本身，最终会重塑社会运行方式。正因为如此，他选择加入一个将安全、对齐与长期风险置于核心位置的研究机构，而不是继续在以产品速度和规模为优先目标的大厂体系内工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种价值取向，也直接塑造了 Anthropic 内部截然不同的工程文化。在鲍里斯的描述中，Anthropic 依然保留着创业公司式的“常识感”：工程决策不需要层层说服，安全不被视为拖慢产品的负担，而是与模型能力同步演进的前提条件。随着模型能力提升，风险不再只是内容失误或选举操纵，而是逐步逼近生物安全、社会系统性破坏等更高等级的问题。这并非科幻设想，而是工程师当下必须正视的现实边界。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在此背景下，Claude Code 的诞生与演进，成为这次访谈的另一条主线。Boris坦言，Claude Code 在相当长时间里并不是一款“好用的产品”。它之所以最终跑出来，并非因为早期体验领先，而是因为团队在一开始就选择“为未来六个月后的模型能力而设计”，而不是围绕当下模型的短板打补丁。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;随着 Sonnet 和 Opus 4 等模型上线，Claude Code 从辅助工具迅速跃迁为主力生产方式，在 Anthropic 内部，大量代码已经由模型生成，工程师的角色也随之发生变化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但这并不意味着“氛围编码”可以无条件替代人类判断。Boris反复强调，模型生成的代码与人写的代码必须接受同一套质量标准：不合格就不合并。不同任务对应不同协作方式——原型、临时代码可以交给模型快速推进，而核心逻辑仍需要工程师逐行审视。这不是“人被 AI 取代”，而是人类工程师与模型之间形成一种新的协同分工。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更重要的是，Claude Code 的使用场景正在溢出传统的软件工程边界。数据科学家、分析师、甚至销售团队，都在把它当作通用的工作执行工具，连接数据库、业务系统和数据源完成实际任务。这种扩散并非最初的产品设计目标，却揭示了一个趋势：当“写代码”本身变得门槛更低，软件能力正在被重新分配到更多角色手中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;贯穿整场对话的，是一个清晰却并不轻松的判断：软件工程正在经历一次结构性重写。工程师不再只是代码的直接生产者，而正在成为“智能体系统”的设计者、管理者和最后的责任人。Claude Code 只是一个具体案例，但它所揭示的，是一个更大的变化——当模型能力以指数级提升，工程文化、工作方式乃至风险边界，都必须随之重构。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以下为访谈实录，经由 InfoQ 翻译及整理：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Claude Code创建者，职业生涯起步于 Facebook&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：我想从你晋升为 Meta 高级工程师开始讲起你的故事。你晋升的那些项目背后有什么故事？当时你在哪里？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：如果我没记错的话，这个项目叫做“群组聊天”，目的是为了让 Messenger 和 Facebook 之间的联系更加紧密。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我在 Meta 参与的最初几个项目都与 Messenger 和 Facebook 有关。第一个项目是扎克伯格提出的将 Messenger 聊天记录和 Facebook 群组同步的想法。当时有几个项目旨在拉近 Messenger 和 Facebook 之间的距离。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最初的动机是，我们感觉公共空间社交产品正在消失，而人们的注意力更多地转移到聊天和更随意的实时空间。我们尝试了几个产品版本，最终“聊天和群组”版本取得了成功。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我记得当时应该是第三个或第四个项目。那时我在 Facebook Groups 部门，主要负责 Messenger 的相关工作，但 Messenger 的组织架构和我们离得很远。这个想法是当时的 PM Steve 提出的。我听了之后觉得，好啊，太棒了！就这么办！我就开始着手开发。很快有了进展，于是我申请了更多工程师，有三位工程师加入了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们获得了一些数据科学和设计方面的支持。项目最初在网页端启动，后来也稍微拓展到了移动端。我们验证了在 Facebook 群组内进行聊天的想法，并证明了这类产品是可行的。当然，也有很多方面最终都失败了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以现在的产品标准来看，当时的体验简直糟透了。那时候，大家都在用 Web 开发，各种各样的 bug 都完全可以接受。但现在，视觉效果和质量标准要高得多。产品不断发展壮大，而我们团队很小，所以每个人都得包揽所有工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我记得当时我们没有用户研究员，所以我会在午餐时间去食堂。我们会推出一个新功能，然后向食堂工作人员展示，问他们能不能找到打开聊天窗口的方法。有时候他们能找到，有时候找不到。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这是一项观察性用户研究。你可以观察人们在特定情况下如何完成任务，而无需过多提示，从而了解他们在哪些方面遇到困难，以及最终取得了哪些成果。我教会了团队如何进行这项研究，很快我们就会利用午餐时间去食堂，询问食堂工作人员（作为用户的代表）这种方法是否合理。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：有趣的是，你当时所处的早期 Facebook 文化允许工程师们在代码之外做很多事情。例如，你当时在做用户体验研究。我记得在你的经历中，你也做过一些设计工作，并且指导过其他人进行设计。我认为这在 Facebook 的企业文化中是一个非常有趣且独特的事情。对吗？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我觉得这一点非常重要。直到今天，在我所在的 Claude 团队中，我们仍然非常重视通才型人才。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我喜欢和通才共事。如果你是一位既会写代码又能做产品开发、设计，并且具备产品意识的工程师，那么你肯定想和用户交流。我非常喜欢和这样的工程师一起工作。现在我们所有职位都是这样招聘的：我们的产品经理会写代码，我们的数据科学家会写代码，我们的用户研究员也会写一点代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我非常喜欢这些通才。我的成长经历也是如此。从 18 岁创办第一家公司开始，我就得事事亲力亲为。在加入 Facebook 之前，我也一直在一些规模较小的公司工作，那里也一样，什么都得做。在大公司里，你可能会被安排在某个特定领域，但这其实只是个形式。工程技能的范围很广，除了编写代码，完成整个流程还有很多其他方面需要考虑。当时能在一家真正重视这种能力的公司工作，感觉真的很棒。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我觉得在那半年结束时，我得到了晋升，然后我觉得在那半年结束后，所有的工程师也都得到了晋升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ryan：在那些早期产品中，存在着你多次提到的“潜在需求”概念，这正是许多产品方向的推动力。你能解释一下“潜在需求”吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：潜在需求是产品设计中最重要的原则。纵观 Facebook 的成功产品，每一款都蕴含着潜在需求的元素。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，Marketplace 的诞生源于一项观察：当时 Facebook 群组中 40% 的帖子都是关于买卖物品的。Facebook 群组最初并非为商业用途而设计，但人们却用它来做这件事。你设计的产品要具有一定的可扩展性和易用性（即使被“滥用”）。然后，你分析数据，看看用户是如何“滥用”的，并以此为基础开发新的产品功能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;先是出现了 Facebook 群组，然后是买卖群组。买卖群组之所以发展迅速，是因为人们本来就想在 Facebook 群组里进行商业活动。接下来是 Marketplace，它只是人们这种意图的自然延伸。Facebook Dating 的发展也与之类似。观察发现，大约 60% 的个人资料浏览量来自互不相识的异性用户。这种传统的互相“窥探”行为证明了这种方法的有效性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;产品设计的核心原则是：你永远无法强迫人们去做他们原本不会做的事情。但你可以找到他们的潜在意图，并引导他们更好地利用这种意图，从而更轻松地实现目标。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;“跨部门工作简直是一场噩梦”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：在你的叙述中，你提到你曾跨部门工作，因为你负责弥合 Messenger 和 Groups 工程团队之间的鸿沟。你说存在一些明显的文化差异，这很困难。对于在文化差异很大的组织之间工作，你有什么建议吗？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我的天哪，说困难都太轻描淡写了。简直是一场噩梦。当时 Facebook 的目标是尽快推出优秀的产品。而 Messenger 则完全专注于可靠性和性能，他们只关心这些。这完全是截然相反的价值观。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这不仅仅是文化差异或工程师之间的问题。那个团队的工程师对我们抱有戒心，因为我们的工作可能会影响他们的绩效指标。他们的组织目标是稳扎稳打，在不影响核心指标的前提下稳步推进产品发布；而我们的组织目标是快速发布。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目标完全不同。他们关注的是服务级别协议规定的正常运行时间，而我们只关注日活跃用户数和用户参与度。这些文化价值观根深蒂固，不仅体现在人们的言谈中，更体现在组织架构、目标设定等各个环节。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;那个项目最终能部分成功，克服了价值观差异，关键在于：如果你想让价值观截然不同的团队成功合作，就必须找到某种共同的目标、共同的兴趣或共同的信念。让他们能够一起验证某个假设，并且如果验证成功，对双方都有益处。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Facebook 的“聊天和群组”功能很酷，但很多功能在 Messenger 上实现时却不太理想，原因就在于此。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：既然你现在知道了这些，你会如何改变现状？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我可能会去找高层（比如扎克伯格），然后说，如果你真的对这件事很认真，我们应该把 Messenger 并入 Facebook 的组织架构下。我觉得这件事后来确实以某种形式发生了。Messenger 最初在公司里，后来搬了出去，然后又搬了进来，之后又搬了出去。公司这么大，这种情况难免发生。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但我认为，从根本上来说，这类事情要想成功，不能只靠普通经理去协调。可能需要更高层的介入，调整组织架构，让它们更具合作性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：在你职业生涯的这个阶段，我看到你做了很多非常有趣的副业项目，我很好奇这些项目会产生怎样的蝴蝶效应。例如，在你加入 Meta 之前，你曾参与过 Undux 的开发，这是一个 React 的状态管理框架。我很好奇这段经历对你的职业生涯产生了怎样的影响？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：对我来说，支线任务非常重要。我招聘工程师时，这绝对是我会考虑的因素之一。我想要那些有副业项目的人，比如周末可以做一些有趣的事情。甚至包括那些对制作康普茶充满热情的人。你需要的是那些对工作以外的事物充满好奇心和兴趣的人。这些人全面发展，我喜欢和他们一起工作。我的很多成长都来自于参与这些副业项目。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;说实话，像 Undux 这样的工具，源于我觉得当时用 React 管理状态太复杂了。当时最先进的技术是 Flux，后来又出现了 Redux，但我完全搞不懂 Redux。我自认为只是个水平一般的产品开发工程师，不是那种技术高超的系统工程师。Redux 的概念，比如 reducer，更新一个小小的状态都需要非常复杂的流程，我理解不了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以我做了一个更简单的版本，效果不错。当时我在一家非营利组织做志愿者，他们开始使用这个版本，他们的工程师也很喜欢。加入 Facebook 后，我发现很多人在使用 Redux 时遇到困难，公司内部有一个 Redux 用户群，里面有很多问题，和我当初问的都一样。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当你作为工程师遇到问题时，有时可能只有你一个人遇到；但很多时候，其他人也会遇到同样的问题。培养一种“直觉”，能够预判其他人可能也遇到的类似问题，这非常重要。我遇到的这个问题显然是其他人也遇到的，我在用户支持帖子里也看到了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我在公司内部推出了 Undux。它还不错；虽然算不上很棒的产品，但比 Redux 简单。在 Facebook 的时候，我不知道该如何推广它，所以我就发帖宣传了一下。结果有几个人开始用了。我记得通知团队的 Jeff Case 是这项功能的早期积极使用者，我们因此熬了好几个通宵，调试一些棘手的通知相关 bug。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了推广这项功能，我写了个小脚本，抓取了提交问题的用户群体，并按团队进行了统计。我通过聊天工具联系了每个团队的技术负责人和经理，并为每个团队安排了一场技术讲座。在几周的时间里，我大概做了二三十场，甚至四五十场技术讲座。我记得当时骑着自行车在 Meta 园区里四处演讲，感觉特别棒，因为大家都很投入，也很兴奋有人关心这个问题并想解决它。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;曾经，Undux 是 Facebook 最流行的状态管理框架之一。但很快它就被 Recoil 和其他更现代的方案取代了。如今，Relay 之类的框架又开始流行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：这种副业项目会出现在你的绩效考核中吗？或者对你有什么帮助？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我觉得它应该写在我的绩效考核里了。按 Meta 的标准来说，这算是锦上添花。它本身并不能让你直接晋升到下一个级别。那段时间我还有很多其他的支线任务。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来，我突然对 TypeScript 非常着迷。这是我之前在一家公司用过的。当时相关的资源不多，所以我开始写一本关于它的书，因为总得有人做这件事。这门语言太棒了，设计非常出色，包含了很多当时其他语言不具备的理念，像条件类型、字面量类型、映射类型之类的，简直太疯狂了。即使是最资深的 Haskell 程序员也会惊叹，但之前却没有人系统性地写过这些内容。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我当时完全沉迷其中，写了这本书，几乎耗尽了我整整一年的业余时间。我不推荐别人也这样做，但深入研究的过程真的很有趣。当时我还在旧金山创办了世界上最大的 TypeScript 聚会。能见到 Node.js 的创始人 Ryan Dahl 以及其他这些著名的 JavaScript 大咖，真是太棒了。这让我意识到，他们也只是普通人；每个人都能创造出很酷的东西。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：后来你在 Meta 工作期间，或者甚至在 Anthropic 工作期间，最终有没有大量使用 TypeScript 或达到那种技术深度？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是啊，说起来挺有意思的；我以前其实对编程语言本身一点兴趣都没有。大概十年前，我骑摩托车的时候出了一场很严重的车祸，双臂都骨折了，身上绑着两个吊带。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：我的天哪。你是怎么写出代码的？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：那才是最难的部分。我整整一个月都不能写代码，而且我的手现在还有点疼。我写不了 JavaScript（按键多），所以我不得不学习其他按键次数更少的语言。我一开始学的是 CoffeeScript，因为它的括号比较少。这门语言现在应该已经没什么人用了。我也是通过 CoffeeScript 接触到 Haskell 和函数式编程的。你可以用更少的击键次数完成同样的事情，这正是我当时的动力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在加入 Facebook 之前，我在一家对冲基金工作，我的同事 Rick 对 Scala 非常着迷。他带我入门，也让我接触到了函数式编程。如果让我推荐一本对我的工程师生涯影响最大的技术书籍，我会毫不犹豫地推荐《Scala函数式编程》。你可能永远不会每天都用 Scala，但它教你思考编程问题的方式，与大多数人在学校或实践中接触的方式截然不同，这彻底改变了我的编码方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对我来说，Scala 和 Haskell、CoffeeScript 一样，是少数几种改变我思维的语言。第一步是 CoffeeScript，然后是 Scala，再然后是 TypeScript。这改变了我的思维方式，因为现在我编码时会用类型来思考。代码中最重要的就是类型签名，这比代码本身更重要。做好这一点能写出非常简洁、健壮的代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;即使在 Facebook，我主要用 Flow 和 Hack，后来在 Instagram 用 Python，这种思维方式也很有帮助。在 Anthropic，我主要用 TypeScript 和 Python，所以这一点仍然非常重要。更重要的教训就是要学会用类型来思考。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：在你职业生涯的这个阶段，你提到你刚入职时级别偏低，只是个中级工程师，尽管你经验丰富。你说现在回想起来，当时级别低反而是件好事。我很好奇你当时是怎么想的。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：在大公司里，对于项目影响和人员影响方面都有很多期望，具体标准因公司而异。很多事情要么关乎项目的影响，要么就是为了完成一堆任务，而这一切都非常耗时。刚开始的时候等级不够，反而给了我探索的空间，让我可以纯粹为了创造而创造，没有太多绩效压力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：没错。我很好奇这是否也有助于积累势头。如果你以中级级别加入，然后表现出色，所有人都会说“Boris太棒了”。这很不可思议。而如果你以更高预期级别加入，表现平平，情况就完全不同了。当你一加入就让所有人眼前一亮时，会产生一种奇妙的效果，你会给人留下非常深刻的第一印象。我认为这有助于建立良好的声誉，从而在未来获得更多的信任、更多的项目等等。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是的，我觉得完全正确。这对于任何公司来说都是很好的建议。很多时候，工程师跳槽的时候会非常积极地争取更高级别，比如“我想去另一家公司，我想升一级”之类的。这样做有很多弊端。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：接下来我想问一下是什么让你在 Meta 晋升为资深工程师（E6）。我很好奇你当时的职位，以及是什么推动你晋升到这个更高层级的领导岗位。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：当时的情况是，Facebook推出了群组聊天功能，并且有一个团队负责开发。在加入Facebook之前，我写过很多JavaScript，但在Facebook内部，我之前从未真正写过JavaScript，因为当时主要用PHP。我真的很想写JavaScript。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们当时专门为Facebook群组开发了一个网页界面。很多人使用网页版而不是手机版，因为群组管理员在电脑上用键盘操作起来更方便。但当时这个网站真的很糟糕，它是一个静态网站，完全用PHP编写，只是在不同的地方零散地注入了一些JavaScript代码，结果导致了各种不一致的状态和问题，用户体验很差。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我当时想用JavaScript重写整个界面，但遭到了公司内部的强烈反对，主要原因是我们已有的基础设施还没准备好。幸运的是，与此同时，Comet项目启动了，该项目旨在重写facebook.com的桌面版。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当时有很多核心成员在做这个项目，我真的很想参与。我主动联系他们，询问我能如何帮忙，并提议先在Facebook群组里进行测试和探索。我几乎是没问任何人就直接开始做了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来，我跟Facebook群组部门的领导们说：“嘿，Comet项目马上就要全面推行了。这会是一项艰巨的工作。但我们可以提前做好准备，为所有其他团队树立一个迁移标准，并与其他团队建立联系。”我仍然遇到了阻力，比如他们说“你不能安排20个工程师来做这件事”。经过多次讨论和讨价还价，我们最终组建了大约12名工程师的团队，因为这是一个相当大的迁移项目，大约需要一年时间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“群组”是Facebook所有产品中规模最大的一个，这有点出乎意料。这次迁移很成功。除了与这个基础架构团队建立联系和友谊之外，有趣的是，我们因此有机会影响Comet项目的发展方向。对于基础设施项目而言，产品团队通常无法左右项目方向，他们更像是客户。但在这个项目中，由于我们早期深度参与，我们创建了许多抽象概念，后来被其他基于Comet进行开发的团队所使用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;举一个具体的例子，比如“中继变更”。你需要发送API请求，并且需要某种状态一致性。之前存在一个bug：假设有一个按钮，每次按下它都会发送一个POST请求。为了良好的用户体验，你希望在按下按钮后，按钮的状态立刻切换，这需要使用乐观更新。当网络请求返回时，你还需要更新本地缓存以确保一致性。但如果你连续快速点击按钮，响应可能会乱序到达，最终得到的状态可能与用户界面上显示的状态不同。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我写了一个系统来排队处理这些变更，这样虽然保证了一致性，但牺牲了一点即时性。在当时这是一个合理的权衡，这个方案最终被广泛采用。我就是在这个过程中认识了Joseph和Relay团队里负责数据存储的其他人。这段经历真的很有趣。每当我看到工程师深入钻研，努力弄明白复杂系统到底发生了什么时，我都很欣赏。产品工程师并不意味着你不能构建基础设施，基础设施工程师也不意味着你不能和用户交流。对技术栈的其他部分保持好奇心就好。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;成功搞定大项目后，才有更多话语权&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：当然。你抢先一步进行Comet迁移和大规模的JavaScript重写，正如你提到的，这实际上让你拥有了更大的影响力和话语权。你所说的机会，是指构建这些对所有使用新平台的人都至关重要的基础产品架构吗？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是的，这就是一个例子。另一个例子是，Comet的质量比之前的版本高得多，因为它是一个单页Web应用，所以感觉更加流畅和完善。但我们当时还没有完全弄清楚“产品层面的质量”究竟意味着什么。我写了很多笔记试图定义它，也做了很多演讲，向其他团队的成员讲解我们对质量的理解，并就此展开讨论，共同塑造标准。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：您提到迁移到Comet需要大量人手。我很想知道，如果现在有了Claude Code、Codex等新的AI编码工具，情况会是怎样的。以您现在对Claude Code的了解，如果您负责评估这项工作，您认为现在需要多少工程师才能完成原本需要12名工程师花费一年才能完成的工作？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：为了迁移Facebook群组，最初是12位工程师，但最后可能动用了20到30位工程师，持续了大约两年时间，最终变成了一个相当大的项目。现在来看，可能只需要5位工程师，耗时六个月左右就够了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：也就是说，只需要四分之一的时间，以及不到一半的工程师？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是的，因为现在你可以让AI并行工作。你让它运行几个小时，它就能生成一个可用的PR。你甚至可以给它装上Puppeteer之类的工具，让它能看到UI并进行视觉调整。大概就是这样。现在，从编码的角度来看，环境已经截然不同了，因为模型更新迭代太快了。如果你三个月或六个月后再问我这个问题，我的答案肯定会完全不同。六个月后，答案可能就变成了：这实际上只需要一个工程师就能完成。现在的变化实在太快了，很难做出准确的估算，也很难预测它们未来会如何演变。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：在你职业生涯的这个阶段，你曾提到过一件事，也许是半开玩笑地说，那时你学会了在向副总裁评审提案时，总是提出三个选项。因为80%的情况下他们只会选择中间的那个。你这么做的想法是什么？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：这话虽然有点讽刺，但或许当时在Meta公司那种特定环境下有点道理。那些远离一线具体工作的决策者，他们想知道你是否认真研究过各种方案和权衡利弊，是否真的做了充分的工作。但同时，他们也想以某种方式参与决策。提供一个“折中”选项，对他们来说比较容易理解和接受。我这么说确实带有讽刺意味，因为并非所有领导者都这样。很多领导者会亲自深入参与决策，他们或多或少信任自己的团队。管理风格有很多种。我记得当时我们有一位技术水平可能不那么深入细节的领导，而这种方法算是帮助她进行决策的一种沟通方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：在你职业生涯的这个阶段，你与高层管理人员的接触最为密切。你提到你曾向一位高级总监汇报工作，并且参与了很多重要的项目规划讨论。我很好奇，向这样一位资深人士汇报工作，对你后续的成长产生了哪些影响？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是的，我觉得这很大程度上取决于工程师个人和公司文化。比如，我现在在Anthropic，我觉得在Anthropic，你向哪个层级汇报并不重要。公司里一些最资深的员工也是向部门经理汇报的。很多部门经理本身就是前首席技术官或非常资深的人士，所以实际上这并不构成障碍。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我认为向高级别汇报带来的压力，在某种程度上是Meta公司特有的文化现象。我觉得这里存在两种情况。一是，在Meta，你需要非常主动地找到自己的发展方向和上升路径。有些机会你可以自己发现，有些则需要你的经理或技术领导帮你识别和引荐。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Meta的PSC（绩效评估）流程出了名的严苛，你必须不断地强调和证明你的影响力。而“职责范围”是造成这种严苛体验的最大因素。如果你有足够大的职责范围，并且执行得当，就能产生显著的影响力。这就是秘诀。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我觉得在Meta，另一个特点是大家都没有很花哨的头衔。即使是最资深的工程师，头衔也只是“软件工程师”，我非常喜欢这一点。贝尔实验室的技术人员也是如此，Anthropic也是如此，但我们在这里更进一步：所有人的头衔都是“技术人员”。不管你是工程师、项目经理还是设计师，头衔都一样。我其实很喜欢这样，因为这样一来，你就可以跳出自己被默认设定的职责范围，去做那些你认为正确和必要的事情，而不用过分在意别人期望你做什么。我认为这种文化正是促成这种灵活性的原因。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：我看到了不设复杂头衔的很多好处。但我也能想到一种情况，也许这只适用于大公司：当你联系公司里的某个人，说“嘿，我想参与这个合作”，如果你的头衔是“总监”之类的，这就能让他们更容易理解你的层级、影响力和协作方式。如果你是设计师或其他职位，在Anthropic规模扩大了一些的现在，你感受到这一点了吗？也许因为大家现在都认识你，所以你没怎么感受到。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是的，这绝对是一个潜在的缺点。但我认为优点大于缺点。那就是你必须努力争取，用实力和贡献赢得尊重。我觉得这条原则无论在哪家公司都适用。仅仅因为你以前做过一件很棒的事，并不意味着你在新的环境里就理应自动获得权力和尊重。当然，每个人都应该得到基本尊重；但这不意味着你在一家新公司、一个新项目中就理应拥有决策权。即使是那些一开始就拥有“经理”头衔的人，也需要努力争取团队的信任。在某种程度上，拥有经理头衔反而可能让赢得这种信任变得更难。作为独立贡献者，无论如何你都必须用行动证明自己。我认为，正是因为没有那些预设的、等级森严的头衔，才使得这一切变得稍微容易一些，更注重实际贡献。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;如何从技术人转型为高管&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：在你职业生涯的这个阶段，你逐渐转型为技术主管或高级技术主管，我记得你讲过一些为数百名工程师制定工作计划的故事。你是怎么做到的？如果工作量如此庞大，而你又只有一个人，你是如何向领导层提出如此大规模的工作计划请求的？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是的，那段时间真是太疯狂了。我当时和蒂娜·萨奇曼共事很多，她现在在微软，但当时是我的经理。然后是我的上级伊芙。当时公司决定对Facebook群组投入更多资源。我刚加入的时候，群组部门大概只有150到200人，等我离开去Instagram的时候，好像已经有600到800人了。扎克伯格一直觉得Facebook应用的核心应该是社群，他希望我们加快速度，把这个想法变成现实。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;作为高管，最重要的就是让合适的人负责决策，然后给他们提供资源。在Meta，资源主要就是工程师。我们向扎克伯格推介了这个名为“社区即新组织”的内部项目。他为此投入了一大批人手，我们只需要弄清楚这些人具体要做什么。对他来说，如果事情很重要，就得投入大量人力。事后看来，我会采取不同的做法，大幅减少初期投入的人员，因为真正重要的是解决用户的问题，打造出色的产品，这必须自下而上地进行，需要随着新产品线找到市场契合点而逐步推进，不能一口气做完所有事情。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但当时，我们必须先把所有事情都规划好。有好几个星期，我都要写一份庞大的规划文档，内容大致是：“好，我们要安排30个工程师负责A项目。这里有三个技术方案，我们选方案二。下一个B项目，我们要安排20个工程师。这里有三个方案，我们选方案一。”就这样一遍又一遍地重复，才能确保这个庞大的项目计划不是完全异想天开。我们进行了一些基础的技术范围界定，大致估算了每个子项目需要的工程师人数。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其中有些事情很有意思。我记得我们曾经尝试合并Facebook群组和主页的数据模型。那真是一次非常棘手的迁移。要彻底实现这一点，需要很多年时间，可能还需要数百名工程师，因为必须跨数据模型、产品层、完整性系统和广告系统进行操作。当时，Yosef Carver刚刚加入；我记得他之前在Profile或Events部门工作，这两个部门与Groups部门合作推进这项工作。他当时正在研究这个问题，但还在犹豫不决，无法就数据模型做出最终决定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;于是我召集了一群人，说：“好了，公司所有相关的技术主管都来了，我们今天花三个小时，像玩游戏一样，来讨论一下架构设计。”我把大家分成两队，好像是蓝队和绿队（记不清了）。我们给每个人布置了同一个问题：如何合并这些数据模型，并给出了具体的要求。每个人都有三个小时的时间在白板上设计方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最酷的是，一开始我们都觉得这个问题棘手，不知道该怎么做。但最后，我们两队得到的两个方案竟然有80%的相似度！我们可以采取的行动变得非常明确，而那20%的差异也清楚地揭示了风险所在。我们可以通过一些技术性操作来预先承担一部分风险，但我们也清楚地知道可以立即开始执行哪些部分。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：是啊，我觉得这个形式很有意思：就像一个技术设计竞赛，所有资深工程师都参与其中，分成几个小组，在不同房间里同步进行设计。我以前从没听说过这种形式。你当初在公司内部提出这个设计竞赛的想法时，大家是觉得很兴奋，还是觉得这有点异想天开？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是有点非常规。这种事，你只能硬着头皮去做，靠行动推动。我直接跟所有相关的人说：“嘿，我们要这么做了”，然后就把会议日期记在了每个人的日历上。感觉挺有意思的；作为工程师，你肯定也想参与这种创造性的解决问题的过程。但有时候你需要漫长的过程来达成共识，有时候你则需要快速行动来打破僵局。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这种情况下，由于技术方向不明朗，采取行动至关重要。但同时，我自己也不知道确切的最佳路径，所以我们必须召集所有关键人员，通过这种高强度、高协作的方式快速达成共识。作为技术领导者，你总是需要在“推动共识”和“果断行动”这两件事之间寻求平衡。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：有了那次为数百名工程师规划项目的经历，你对那些需要快速进行项目范围界定的技术主管有什么建议吗？有什么对你来说行之有效的方法或原则？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我觉得我看到的最大问题是人们花费的时间太长，而且过于纠结细节。细节总是无穷无尽的。最好从宏观层面入手。大多数技术范围界定都可以在30分钟内完成一个非常粗略的版本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果你不了解所涉及的系统，现在你甚至可以让AI来帮忙。你只需要在代码库中运行一个查询，或者直接问AI：“要实现X功能，会涉及代码库中的哪些系统和模块？”它实际上可以帮你快速梳理出依赖关系。这真是个不可思议的改变。我以前做这些事情的时候，绝对想不到人工智能现在能帮我做到这些。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但回到一般性原则，我过去的建议是：设定严格的时间限制。用于初步范围界定的会议最多花30分钟。如果需要深入研究代码，最多几个小时。一定要联系专家，并列出所有需要咨询的专家名单。和他们所有人交流。但不要只是泛泛地征求他们的意见。给他们一个具体的假设或初步设计方案，这样他们才能真正给你有建设性的反馈，你才能以此为依据进行迭代和完善。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：继续你的职业经历。你晋升到高级职位的关键，似乎和Facebook的“公共群组”项目有关。我很想了解这背后的故事，以及其中发生了什么有趣的事？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：是的。“公共群组”项目源于我们想让Facebook群组更开放。我们当时想做一个看似简单、但实际非常复杂的改动：让用户无需加入，就能查看和评论公开群组的内容。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这听起来像改一行代码，但实现起来异常困难。因为它触及了核心的数据模型问题：在数据库里，一个发表评论但未“加入”的用户，到底算不算“群组成员”？这引发了我们内部激烈的技术讨论。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;过去的“加入”需要管理员批准，是一种信任投票。现在对于公开群组，行为变成了“关注”。那么，“关注”和“加入”在数据层面应该是同一回事吗？当时公司里一位资深的元老级工程师鲍勃，强烈认为这必须是两件不同的事，并要求进行大规模的数据迁移来区分它们。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这还引发了连锁反应：如果任何人都能评论，垃圾信息怎么办？我通过一个简单的蒙特卡罗模拟，展示了潜在的垃圾信息风险，最终成功说服了公司的诚信团队介入，帮助调整评论排名算法来应对。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了完成数据迁移等所有工作，我们组建了一个大团队。当时我和其他几位资深工程师同级，都需要我来协调指导，这让我一度感到有些“冒名顶替”。但最终，正是因为我推翻了之前鲍勃关于数据迁移的决定，才促成了我后来的晋升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我经过审核发现，最初的“成员”字段其实完全可以同时表示“关注者”和“群组成员”，强制区分只会让后续所有开发变得复杂。我敦促负责的工程师撤销了那次迁移。这个正确的技术判断，反而让鲍勃更认可我作为技术领导的能力，因为我能基于事实对资深人士的决定提出异议。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你和高级技术主管之间存在严重技术分歧，但结果反而加强了关系。对于如何处理这类分歧而不损害关系，你有什么建议？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;要敢于挑战权威&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我认为核心是赢得信任。在你拥有足够的技术信任之前，很难去挑战权威。一开始，可以更多地倾听、执行，表现出尊重和合作意愿。同时，你必须通过实际行动积累扎实的技术判断力。在赢得信任后，你基于事实和专业提出的异议，才更容易被接受。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ryan：关于“冒名顶替综合症”，以及领导那些和你同样优秀的工程师，你有什么建议？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：别想太多。其实没人真正知道自己在每个新层面上具体该做什么，大家都在摸索。这种感觉会随着时间慢慢消失。某种程度上，始终保持一点点“冒名顶替”感是健康的，那说明你还在努力突破舒适区。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：在你职业生涯的这个阶段，你更像技术主管，编码减少。你曾提到，在Meta，有时其他职能（如产品经理）支持不足，你认为这是让工程师更多关注产品、甚至参与产品管理的机会。你如何决定何时该自己顶上，而不是反复要求更多支持？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：关键在于理解利弊和背景。你需要从决策者的角度思考：他们关心什么？手头有哪些项目？做这件事的代价是什么？是否能帮他们成功？有些组织可能确实资源紧张，或认为你的项目优先级不够。有些组织则可能资源充沛。了解你所在的环境和决策者的处境，才能判断是应该自己主动补位，还是能够争取到资源。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你将自己的成功很大程度上归功于“副业项目”。你对工程师如何寻找这样的机会有什么建议？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我的很多想法来源于日常工作中那些重复、繁琐的部分。工程师的超能力就是自动化。我养成了一个习惯：在代码审查中，如果我多次评论同一类问题，我就会写一条规则来自动化检查它。很快，我几乎自动化了所有代码审查。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些“副业”往往就是去改进那些拖慢日常开发速度的基础设施或工具。这不仅能解放自己，也能惠及整个团队。一个核心原则是：如果你遇到了某个问题，很可能其他人也遇到了。为自己打造解决方案，往往就是为很多人打造解决方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;为何从 Meta 转向 Anthropic&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你从 Meta 离职加入 Anthropic，当时是怎么做出这个决定的？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我第一次用到 ChatGPT，是它刚推出不久的时候。当时我在日本，一个小地方，几乎没有人能和我讨论技术。我每天刷 Hacker News，用到 ChatGPT 后的第一反应是：这东西太不可思议了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在回头看我们已经习以为常，但当时的大模型给我的感觉，更像是一种“新生命”。它不仅是一项技术，而是一种可以被培育、被引导的存在。我本人很喜欢科幻小说，尤其是硬科幻，所以当我意识到这类模型意味着什么时，心里只有一个想法：我一定要参与其中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来我去了解哪些实验室在做这件事，也和一些在不同研究机构工作的朋友聊过。第一次和 Anthropic 的创始团队吃饭时，我随口提到了一本科幻小说，结果发现桌上几乎所有人都读过，还能继续讨论别的作品。那一刻我意识到，这是一个真正认真思考“这些技术会把世界带向哪里”的地方。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;人工智能正在改变社会，而且是从工程领域开始，逐步扩散到各个层面。我也很清楚，这项技术存在很多潜在风险，甚至可能走向非常危险的方向。对我来说，加入 Anthropic 几乎是顺理成章的选择——如果我能做点什么，那就是站在一个真正把“安全”和“长期影响”当回事的地方。&lt;/p&gt;&lt;p&gt;在 Meta，安全往往被当成一种负担，是和产品对立的事情。但在 Anthropic 完全不同。我们在安全和对齐研究上投入了大量算力和人力，甚至因为不确定模型是否足够安全而推迟发布。随着模型能力提升，风险也在快速上升，这已经不是科幻，而是现实问题。我很庆幸自己能参与其中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：加入 Anthropic 之后，你感受到的工程文化和以前最大的不同是什么？&amp;nbsp;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Boris：有两点特别明显。第一，公司虽然已经不小了，但仍然保留着创业公司的“常识感”。很多事情不需要复杂的流程去推动，大家天然会做正确的决定。这是大公司最容易丢失的东西。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第二，对我个人来说，最重要的是使命感。它让我每天都愿意来上班，甚至周末也愿意写代码，不是因为 deadline，而是因为我想这么做。我在 Facebook 群组项目里感受过类似的氛围，但在 Anthropic，这种感觉更强烈，也更一致。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Claude Code 为什么能跑出来&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你是 Claude Code 的核心推动者之一。当初市面上也有不少类似工具，Claude Code 真正不同的地方在哪里？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：一开始，大家对“AI 编程”的理解非常狭窄，基本等同于自动补全。即便有一些智能体的概念，也更多是问答工具，而不是能真正参与编程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;坦白说，在很长一段时间里，Claude Code 本身也并不好用。即便在内部，我可能只用它写了不到 10% 的代码。关键在于，我的主管一直提醒我：不要按“现在的模型能力”来设计产品，而要按“六个月后的模型能力”来设计。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;后来 Sonnet 和 Opus 4 发布后，一切发生了变化。短短几个月，我自己有一半以上的代码都交给 Claude Code 来写。现在在 Anthropic，很多团队 80% 到 90% 的代码都是用 Claude Code 生成的。公司规模虽然扩大了，但工程师的整体生产力反而显著提升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：有人担心模型生成大量代码，但质量不稳定、问题隐蔽，你怎么看？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：AI 编程和任何工具一样，是需要学习如何使用的。我们内部的原则很简单：不管代码是人写的还是模型生成的，标准完全一致。代码不好，就不合并。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不同场景需要不同方式。原型、临时代码，可以更“感觉驱动”；核心代码，就必须逐行推敲。大多数时候，我是和模型一起写代码：先制定计划，再让模型生成，再不断修改、清理。某些关键部分，我仍然坚持手写。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在的模型编码能力当然还不完美，但已经是“史上最差的一代”了。一年前还只是自动补全，现在已经是完全不同的世界。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：除了写代码，你觉得 Claude Code 还能用在哪些地方？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：我们公司里的数据科学家、分析师，甚至销售团队都在用它。有人用它写 SQL、跑分析、搭数据管道；销售团队把它接入 Salesforce，直接干活。这完全超出了我们最初的设计预期。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你怎么看 Claude Code 和 Codex、OpenAI 之间的竞争？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：说实话，我几乎不看其他产品。过度关注竞争对手，很容易让团队迷失方向。我们只专注一件事：解决我们自己、Anthropic 研究人员以及用户真正遇到的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你不是计算机科班出身，这对你有影响吗？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：几乎没有。我学的是经济学，后来辍学创业。编程是一项高度实践性的技能，最重要的是动手做、做出产品。理论当然有价值，但对我个人来说，从来不是关键。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你效率很高，有什么秘诀？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：现在我的答案只有一个：学会用 Claude Code，而且是同时用多个。你不再是亲自写每一行代码，而是在做统筹、调度和判断。这就是工程的未来。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Ryan：你觉得工程师会不会越来越像管理者？&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Boris：某种程度上是的。但我依然很享受安静地写代码。现在我每天早上都会启动几个 Claude Code 代理，让它们先跑起来，等我到电脑前再检查、合并或修改。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这听起来很疯狂，但它确实有效。甚至一些多年不写代码的管理者，现在也能重新参与进来。我们熟悉的“写代码”这件事，正在发生根本性的变化，而且正在变得对更多人开放。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=AmdLVWMdjOk&quot;&gt;https://www.youtube.com/watch?v=AmdLVWMdjOk&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/5gxv5efXhF6fpzXsgcJy</link><guid isPermaLink="false">https://www.infoq.cn/article/5gxv5efXhF6fpzXsgcJy</guid><pubDate>Mon, 19 Jan 2026 11:00:00 GMT</pubDate><author>李冬梅</author><category>AI 工程化</category></item><item><title>Agent 不是渐进升级，而是要“换代”了：Cursor 工程负责人放话未来三到六个月，行业将迎来大变局</title><description>&lt;p&gt;整理 | 华卫、Tina&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去一年，编码 Agent 的变化速度，已经快到让人很难用“功能升级”来形容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果把时间拨回到一年前，Agent 还主要停留在代码补全、对话式改几行代码的阶段；而今天，在 Cursor 内部，工程师已经开始同时运行多个 Agent 并行“甩活儿”，让它们在代码库中自主修改、调试、复盘，再由人类在最后阶段集中审核结果。开发者不再盯着 Agent 的每一步操作，而是开始习惯“等它跑完再看答案”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在最近一次访谈中，Cursor 工程负责人 Jason Ginsberg 给出了一个明确判断：这不是渐进式优化，而是一场正在发生的“换代”。更重要的是，他把这场变化的时间窗口，压缩到了未来三到六个月——在他看来，Agent 将不只是“更聪明”，而是会真正接管更长周期、更复杂的工程任务，整个行业的工作方式也将随之重塑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下面是详细对话内容，我们在不改变原意的基础上进行了翻译和删减，以飨读者。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;一年多时间，编码Agent“翻天覆地”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Harrison Chase：Jason，你能跟大家简单介绍一下自己吗？也给大家讲讲 Cursor 是什么吧。&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：好的。我目前在做一款 AI 编程工具，已经在 Cursor 工作了六个月，担任该产品的工程负责人。不过说实话，我日常的大部分时间还是在写代码和做设计工作。在加入 Cursor 之前，我在 Notion 负责 Notion Mail 相关工作。几年前，我创办了一家名为 Skiff 的公司，后来这家公司被 Notion 收购了。所以，我一直都在从事产品开发相关的工作，而且主要聚焦在生产力工具领域。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：非常棒。我有很多话题想和你探讨。要不我先抛砖引玉，问问你对编码Agent的发展历程，以及这些年来人机交互模式演变的看法吧。你们可以说是这个领域的先行者之一，我认为编码Agent的发展经历了几个阶段的转变：从最初的代码自动补全，到集成在集成开发环境（IDE）中的对话式交互，再到如今出现的各类终端工具，以及基于云端的异步Agent。我很想听听你的看法，你觉得这样概括其用户体验的演变历程是否准确？或者你们团队是如何看待这一发展过程的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我认为编码Agent的发展确实可以用 “翻天覆地” 来形容，而且这些变革基本上都是在一年多一点的时间里发生的。正如你所说，Cursor 最早开启了代码自动补全的先河，这种模式主要是在逐行的层面上提供辅助，适用范围也基本局限在单个文件内。而此后，几乎每隔几个月，我们就不得不提升产品的抽象层级，这其实是一个极具挑战性的产品设计难题。显然，Agent的出现让开发者能够在多个文件之间灵活切换，并且可以放心地让Agent自主完成代码修改工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在过去两个月左右的时间里，我发现行业又出现了新的转变：开发者现在已经能够做到从项目启动到结束全程信任Agent，并且会对整个代码库中多个文件的内容进行批量审核。因此，我们不得不对产品的整体布局进行大幅重新设计，将核心从逐行的代码差异对比，转向更偏向代码审查的模式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;展望未来的产品开发方向，我们的工作重心其实会更多地放在多Agent协同运行上。我们需要实现的是，能够快速验证这些Agent是否在正常运行，并且可以让它们并行工作，同时避免受到当前单一对话模式下各种选项和选择的束缚。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：推动这些变革的核心因素是什么？仅仅是因为大模型的性能变得越来越好，还是有其他更多的影响因素？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我认为大模型性能的提升是一个很关键的因素，这让开发者能够更加信任Agent编写的代码质量。要知道，以前大家必须对Agent生成的代码进行非常全面细致的审查。&lt;/p&gt;&lt;p&gt;同时，现在也有了更完善的代码审查工具。比如我们有 BugBot，市场上其实还有很多类似的工具，它们都能够自动检查代码中存在的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，我觉得从行业文化层面来看，开发者们对Agent工具的接受度和使用信心也在不断增强，甚至可以说已经 “上瘾” 于这类工具带来的便捷。而且，一旦习惯了完全依赖Agent进行编码的工作模式，再切换回传统的编码方式其实是很困难的。所以现在，我们能看到越来越多的开发者已经将Agent辅助编程作为默认的工作方式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;最顶尖工程师的干活秘诀：全靠Agent？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：你观察到大家使用 Cursor 的方式都有哪些不同？或者你自己平时是怎么使用 Cursor 的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：其实在我们公司内部，工程师们使用 Cursor 的方式就五花八门。甚至团队里有几位工程师，他们完全不使用 Cursor 的Agent功能，比如负责安全和基础设施的同事。所以，确实有一部分用户非常依赖代码自动补全功能，日常使用中大部分操作都是基于补全功能完成的。但令人意外的是，我发现团队里一些最顶尖的工程师，我们称他们为 “核心用户”，他们做任何工作都会完全依赖Agent，甚至会同时运行多个Agent并行处理任务。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;至于我个人的使用习惯，我并不会去设计那些复杂繁琐的提示词，也没有什么所谓的 “Agent使用秘籍”。我写的提示词往往都很简短，甚至还会带有拼写错误。我会针对手头不同的工作任务，或者同一个问题的不同模块，同时启动多个Agent，然后等待它们返回结果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前我用得最多的是我们今天刚刚发布的一个新功能：调试模式。这个模式下，Agent能够通过生成日志来进行自我评估，之后开发者复现相关操作步骤，Agent就会通过查看日志判断问题是否得到解决。这个功能非常实用，因为它相当于通过投入算力去不断尝试解决问题，最终攻克那些手动排查起来极为棘手的难题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：调试模式具体是什么样的？为什么需要专门设置这样一个模式？难道不能自动完成调试吗？直接给Agent下达调试指令不也可以吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：其实我也认同你的这个想法。所以在开发调试模式的时候，我们内部确实有过不少争论。主要原因在于，Cursor 目前已经有很多功能模式了，如规划模式、询问模式等等，这些模式其实不太容易被用户发现。我们一直认为，这些模式都很实用，理想的状态应该是，Agent能够根据用户的操作场景，自动匹配并启用最合适的模式，无需用户手动切换。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而现阶段调试模式之所以需要手动开启，是因为它的交互方式比较特殊。在运行过程中，Agent会暂停当前的工作，向用户提问以获取反馈。如果用户不熟悉这种交互逻辑，可能会觉得比较困扰。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：Agent具体会询问哪些问题，又需要用户提供什么样的反馈呢？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我举个例子吧。假设我正在开发一个前端应用，遇到了一个很让人头疼的问题：菜单总是在左上角弹出。这时候我会对Agent说：“这个菜单需要锚定到按钮的位置。” 随后，Agent会启动服务器，并在整个代码库中添加大量日志，同时提出一系列可能导致该问题的假设，如 “可能是某个定位参数设置错误”、“可能是事件绑定逻辑有问题” 等。之后，Agent会提示我：“麻烦你点击这个按钮，打开菜单，看看问题是否解决。” 如果我反馈问题依然存在，Agent就会查看生成的日志，然后分析判断：“这个假设成立，那两个假设不成立”。通常这样反复两三次之后，Agent往往就能找出并解决问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：你觉得人类还需要手动操作多久？就不能让Agent自主完成点击、测试这类操作吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：一两个月内，毕竟这个行业的发展速度实在太快了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：刚才你提到了Agent的多种不同模式，比如规划模式、解释模式、调试模式等等。这些模式在实际应用中到底意味着什么？难道只是为Agent设置不同的提示词这么简单吗？还是说背后有更复杂的逻辑？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：很多时候，确实就是修改一下系统层面的提示词。不过在某些情况下，我们也需要对用户界面进行相应的调整。比如规划模式现在也加入了交互提问功能，运行过程中会主动打断用户操作，寻求反馈。用户有时也可以自行设置参数，如调整Agent打断的频率等。再比如询问模式，它不只是依赖特定的系统提示词，还会限制Agent调用某些与文件编辑相关的工具，以此来保证功能的稳定性和可靠性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：回到之前的话题，关于大家使用 Cursor 的不同方式，你觉得未来使用编码Agent或者说 Cursor，存在所谓的 “最佳方式” 吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我觉得并没有什么 “最佳方式”，具体的使用方法很大程度上取决于工程师的个人工作习惯以及他们所处理的具体工作内容。目前行业里，既有异步运行Agent的应用场景，也有开发者深度参与、实时交互的模式，就像一边编程、一边像画画一样实时调整代码或者进行可视化的编辑操作。不过我经常在推特上看到一些所谓的 “Agent使用技巧”，其实对此我是有点持保留态度的。很多人会说 “这才是使用Agent的最佳方式”，但在我看来，这些技巧往往是凭空杜撰的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们团队内部其实并不会使用那些冗长复杂的提示词，也不会采用多阶段规划的策略。大多数时候，我们都是快速迭代，如果Agent运行的结果不理想，就直接终止进程，重新启动Agent。通常这种方式的效率是最高的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;自然 “唠嗑”是Cursor最终交互模式？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：如果让你预测一下一年后的情况，你认为开发者在 IDE、终端以及其他形态的载体上使用 Cursor 的时间占比会是怎样的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：当然，我肯定会带有一定的主观偏向性。但我认为，终端工具并不会成为用户的首选。我觉得，真正驱动行业发展的是用户对Agent的信任度不断提升，他们更希望等到Agent完成所有工作后再查看最终的修改结果，然后决定是否采纳，同时也愿意让Agent运行更长的时间，以实现更智能的处理。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而 IDE 之所以至关重要，是因为它是为整个软件开发周期量身打造的工具。从项目的构思规划，到运行代码修改、查看代码内容、清晰对比代码差异、提交代码合并请求，再到在浏览器中预览效果所有这些环节，都可以无缝集成在 IDE 的模块化功能之中。这一点其实很容易被忽视，毕竟 IDE 的这些功能是经过了数十年的发展才逐步完善起来的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我认为，当前行业的一个明显趋势是，产品层面的设计变得越来越重要。现在 Cursor 用户使用频率最高的功能，如规划模式，其实都需要可视化编辑器的支持，用户需要能够在编辑器中添加注释，并进行实时交互。一旦脱离了按钮、弹窗和菜单这些可视化交互元素，用户与工具的交互难度会大大增加。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不过，我觉得未来并非所有操作都必须局限在笔记本电脑的 IDE 中完成。这种模式并不会被完全取代，具体的使用场景会根据实际需求灵活变化，适用的场景也会更加广泛。用户在更多场景下，都能够使用到 Cursor 这样的工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：未来会有更多场景都能用上像 Cursor 这样的工具。你们应该有对应的官网吧？用户可以直接在网页上进行交互操作，是这个思路吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：对，我们确实有官网。这么做的原因是用户可以通过手机等设备随时随地访问。我觉得在不远的将来，用户完全可以戴着 AirPods，开启语音模式，和Agent实时沟通、碰撞想法，让Agent不断优化方案。等用户到了办公室，打开笔记本电脑，就已经有一堆代码修改记录或者演示视频等着审核了，到时候只需要简单确认通过或者驳回就行。如果某些细节还需要微调，再把项目下载到本地修改就好。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：我认为 Cursor 真正的优势，在于围绕Agent交互打造的整套设计和用户体验体系。你之前在 Notion 工作过，我记得即便是在生成式AI普及之前，Notion 的设计和用户体验就已经广受认可了。当然，他们在生成式AI时代也很好地完成了转型。从一家在生成式AI普及前就拥有出色设计积淀且顺利完成转型的公司，再到如今专注Agent相关工作，你觉得Agent的出现给产品设计和用户体验带来了哪些变化？现在的工作模式和之前有相似之处吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我觉得总体来说，我们产品的大部分设计其实并不是AI专属的。要知道，产品可用的交互组件和用户体验模式就那么多，市面上的应用本质上也都是基于一些传统的模式搭建的，如收件箱、仪表盘、聊天界面，这些都是很成熟的设计。所以我们的工作核心，更多是把这些现有的设计模式进行合理组合，然后在产品中恰当地呈现出来。这一点和 Notion 的产品理念是相通的，同时也是 Cursor 和集成开发环境（IDE）的核心特质：极高的模块化程度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;作为用户，你会发现每个人的 IDE 界面布局都可以千差万别。你可以自定义面板布局，把任意组件拖放到任意位置，和坐在你旁边的同事设置出完全不同的界面。我认为这种模块化设计对产品的适应性至关重要，毕竟如我之前所说，Agent的能力发展日新月异，用户对产品的需求和期待几乎每隔几周就会发生变化。几个月前我们推出 Cursor 2.0 的时候，并没有把原来的产品推倒重来，只是把各个功能模块重新组合，调整为侧边栏收件箱式的管理布局，同时优化了聊天界面的信息密度而已。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：听你这么说，很多组件的底层逻辑其实是相通的。那有没有出现新的组件？或者某些组件的优先级发生了变化？毕竟这些组件最初都是为 “人类与软件交互”“人类通过软件协作” 的场景设计的，现在加入了Agent这个新角色。这其中有没有产生什么新的变化？还是说其实本质上没有太大不同？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我认为底层的设计逻辑和核心要素其实没有变，关键变化在于谁在主导界面交互。而在这个核心框架下，其实可以演变出无数种交互形式。就拿交互的抽象层级来说，一年前大家使用Agent的时候，都恨不得盯着它的每一步操作，全程 “盯梢”。但现在Agent的操作步骤变得无比繁杂，用户根本看不过来。所以我们需要优化信息呈现方式：如何对操作步骤进行分组？如何提炼关键信息？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当用户足够信任Agent的操作后，我们就需要把重点放在文件的实际修改内容上，并且为这些修改添加更详细的注释说明。当然，我们也可以进一步提升交互的灵活度，比如聊天对象不再局限于单个Agent，而是可以同时和多个Agent对话。这就需要一套更智能的后台交互逻辑来支撑 ，系统要能识别用户在和哪个子Agent对话，并且协调这些Agent完成对应的修改。未来这种交互的抽象层级还会不断提升。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：你觉得交互的抽象层级最高能达到什么程度？我知道预测未来很难，但还是想听听你的看法。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我觉得未来，我们现在看到的各种操作选项，如选择模型、选择功能模式、选择运行环境这些都会逐渐消失。最终的交互模式会变得像和真人对话一样自然。但这并不意味着任何人都能随便写代码，在那个阶段，这个工具依然是为专业工程师服务的。因为你还是需要具备专业的行业术语知识，清楚自己想要修改的内容是什么。做产品的人，要明确自己想要的工作流程和功能需求；做基础设施的人，要足够了解代码库，知道什么样的架构和系统设计最适合当前要开发的项目。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而且我想强调的是，随着抽象层级的提升，我们并不会摒弃现有的功能。用户依然可以随时深入底层，查看细节、调整参数。只是产品的默认交互方式会不断优化升级。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Cursor内部工作揭秘：少审代码、高频反馈&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：你之前提到了人类在Agent工作流程中的角色，比如查看代码差异、进行代码审查。你觉得AI会给代码审查工作带来哪些改变？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：首先，就我们产品团队的工作模式来说，现在人工审查的比重已经大幅降低了。我们有一个叫 BugBot 的工具，它会自动检测代码问题，并且自主完成修复，还会在持续集成（CI）流程中不断迭代优化。这个工具的表现非常出色，也让我们对AI审查的代码质量更有信心。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其次是信息的语义化分组。用户查看代码差异时，可以清晰地看到Agent做了哪些修改。我们甚至可以展示Agent的原始指令，更理想的状态是，Agent能够像人类一样，在处理大型代码合并请求时，为每一处修改附上注释，说明这么做的原因。我觉得这虽然算不上颠覆性的变革，但确实能给代码审查工作带来显著的优化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：出于好奇，我想问一下，Cursor 的工程师用 Cursor 写代码，用 BugBot 审查代码，那他们还需要和其他工程师沟通协作吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：哈哈，这个问题很有意思。如果你以工程师的身份加入 Cursor，会立刻发现一个现象：所有人都在深度使用自家产品。我记得我入职第一周的时候，修改了一个快捷键设置。那个快捷键是 Alt+Shift+Command+J，非常冷门，我当时觉得选这个键肯定没人会注意到。结果刚改完不到半分钟，就有三个同事在 Slack 上发来消息：“你改的这个快捷键直接打乱了我的工作流程！到底怎么回事？”几乎任何产品改动，都会立刻收到同事们的强烈反馈。我觉得这其实是一件好事，大家就是在这种高频的反馈和交流中，快速推进产品迭代的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：从组织管理的角度，你们有没有采取什么措施来鼓励或者引导这种高频反馈的协作模式？毕竟大量的反馈涌进来，有时候也会让人应接不暇。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：在我创办自己的公司之前，工程师们也会用邮件沟通，但用得并不多。大家甚至会说：“邮件只用来收垃圾邮件和购物通知，可别用它来发长篇大论的工作内容。”而在Agent这个赛道工作，其实完全不需要依赖邮件这种低效的沟通方式。我们团队的所有人都全身心投入工作，毕竟这是一个竞争非常激烈的领域，大家都对产品开发充满热情，会自然而然地用各种即时沟通工具协作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另外，我在规划产品功能时，会遵循一个核心原则：我能开发什么功能，让自己的日常工作更轻松？ 具体来说，就是思考 “做什么能帮我明天更高效地完成工作，不用再处理那些烦人的报错和问题”。这个原则指导着我们的大部分工作。毕竟这种功能开发出来之后，我们自己能立刻受益，比如修复了一个烦人的漏洞，以后上班就不用再被这个问题困扰了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;迭代狂飙背后，核心功能竟来自员工 “自嗨”？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Harrison Chase：你觉得你们的产品路线图，有多大比例是由 “让自己工作更轻松” 这个需求驱动的？又有多大比例是来自外部用户的需求？这个比例随着公司发展有变化吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：这个比例确实随着公司规模的扩大在变化。现在我们也会制定月度的产品路线图和目标，但说实话，我们很多核心功能都来自自下而上的创新。比如 Cursor 的Agent功能，这可以说是大家提到 Cursor 时最先想到的核心功能。这个功能是我们团队的一个人开发的，最开始所有人都不看好这个想法，但他很快做出了原型。大家试用之后都惊叹：“哇，这东西居然真的能用！”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我之前提到的调试模式也是如此。感恩节假期的时候我闲着没事，就开发了这个自己很需要的功能，现在这个功能也即将上线。这些功能的开发初衷，都是为了解决团队内部的需求。我们判断一个功能是否具备发布条件，一个重要的衡量标准就是内部的使用率和认可度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：你们的产品迭代速度快得惊人，是怎么保持这种高效的开发节奏的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：说实话，我们的工作流程其实非常精简，没有太多繁琐的制度。公司里虽然有几间会议室，也有一两位产品经理，但我们很少通过撰写文档或者开对齐会议来推进工作，大部分的讨论和决策都是在代码层面完成的。而这一切能够实现的核心原因，是我们对人才的极高要求。今年年初的时候，公司总共也就 20 人左右。之所以团队规模增长缓慢，就是因为我们的招聘门槛高到近乎苛刻。我们会反复评估：这个人很优秀，但他能成为团队里最顶尖的那批人吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;正因为团队里的每个人都足够出色，所以我们可以放心地把任务交给任何一个人。团队成员的主观能动性都极强，从提出想法、设计用户体验，到在推特上回复用户的支持请求、和企业客户沟通需求，再到最终将功能落地，整个流程都能独立完成。所以说，我们能保持这样的速度，归根结底还是人的因素。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：你们是如何规划产品路线图的？你刚才提到了以月为单位的规划周期，这是目前的常规规划时长吗？有没有更长期的规划？另外，行业技术迭代的速度实在太快了，你们是如何平衡 “跟进现有技术浪潮” 和 “实现技术跨越式发展” 这两者的？会不会主动预判技术趋势，提前布局未来方向？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我们确实会投入不少精力去思考未来，比如预判未来三个月可能实现的技术突破，然后主动押注相关方向，团队里有相当一部分人都在做这类前瞻性的工作。我们制定的月度路线图更多是围绕核心产品功能展开，聚焦于用户的实际需求以及那些能优化日常使用体验的功能。而那些需要投入两个月时间重构底层逻辑的重大项目，则会纳入更长期的规划范畴。&lt;/p&gt;&lt;p&gt;此外，我们的应变能力其实非常强。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有时候我们会提前拿到新模型的测试版本，试用之后如果发现它在某些方面表现特别出色，团队成员往往会主动利用周末时间加班，争取在新模型正式发布前就完成相关功能的开发。很多重要功能其实几天之内就能搭建完成。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：说到模型，你们发布了自研的 Composer 模型。开发这个模型的初衷是什么？目前用户的使用情况如何？这个模型有没有改变大家使用 Cursor 的习惯？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我们发现，工程师使用我们产品时的编码场景，需要有专门适配的模型来支撑。Composer 模型就是针对这类场景打造的，它定位非常明确，具备速度快、质量高、逻辑智能三大特点，尤其适合 “人机实时协作” 场景。我自己做前端开发时就经常用它，因为我需要频繁做出细微的交互设计决策，这就要求Agent能在几秒内给出反馈。Composer 就像一个高效的协作伙伴，能快速响应需求、碰撞想法，和那些适用于长周期异步任务的模型形成了很好的互补。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：Cursor 的Agent相关研发工作是全员参与，还是有专门的团队负责？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我们确实有专门的团队负责Agent的性能优化，他们主要聚焦于工具链、调度框架的搭建以及效果评估。但正如我之前所说，我们的团队架构并不僵化，没有严格限制大家的工作范围。比如核心产品团队的工程师在开发规划模式时，如果需要对Agent进行调整，就会和Agent团队密切协作。而且在开发过程中，我们依然会深度使用自家产品进行测试，团队成员会分享使用感受，以此来评估功能的实际效果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：无论是Agent团队的成员，还是其他团队中擅长Agent研发的工程师，他们身上有没有什么共同特质？他们的专业背景或者个人能力有没有什么特别之处？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我觉得他们大多是偏产品方向的人才，而不是传统意义上的机器学习或算法研究专家。这些人经常在不同团队之间轮岗，因为Agent研发需要对用户的最终使用体验有很强的直觉，同时还要能准确解读团队的反馈意见。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：上周你们和 OpenAI 合作发布了一篇博客，内容是针对 OpenAI 的新模型优化 Cursor 的Agent调度框架。我在推特上经常看到大家讨论 “Agent调度框架” 这个概念。你们是如何看待模型的底层支撑架构的？这类架构是否需要和特定模型深度绑定？比如 Composer 模型和 CodeLlama 模型，对应的架构会不会有很大差异？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我其实没有深度参与这方面的工作，但据我了解，我们的核心目标是打造高度灵活的架构。毕竟我们需要不断尝试新技术、新功能模式，所以架构必须能够随着模型能力的升级快速适配。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Harrison Chase：很有道理。毕竟整个行业都在飞速变化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;开放问答&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;提问者 1：刚才提到了新增的可视化浏览器功能，我发现有些工具比如 Lovable 也有类似的功能。请问这个功能是朝着 “沉浸式可视化编码” 的方向发展吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我觉得它并不是为沉浸式可视化编码设计的。就像我之前说的，这个功能最初是我为自己开发的，我本身就是一名做产品的工程师，它的核心用户群体其实是专业工程师和设计师。大家在开发应用时，肯定都遇到过这种情况：精心设计的界面，最后却变成了大家都看腻了的紫黄渐变配色。这个功能就是为了让大家能够精准把控细节，比如把内边距调整到精确的像素值。它为用户提供了一套更直观的 “视觉化操作语言”，比纯文本指令的精度更高。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而且就算不使用侧边栏，你也可以直接点击页面元素，随时输入提示词下达指令。借助这个功能，你可以在几秒内同时启动六个Agent。如果开启热重载功能，你的网站会实时呈现修改效果，用起来其实还挺有意思的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;提问者 2：我特别喜欢你们的浏览器Agent，一直在用。但我发现一个小瑕疵：我想持续迭代优化设计方案，可Agent总是会中断我的工作，直接提交代码合并请求。未来有没有可能实现不间断的持续迭代？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：当然可以。未来的发展方向就是让Agent具备自主评估能力，根据需求长时间持续运行、循环迭代。现在的调试模式还需要人工点击按钮来确认日志信息，但这只是过渡方案。理想的状态是，Agent能够自主完成评估、迭代，直到彻底解决问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;提问者 3：我不知道你是否深度参与Agent相关的研发工作，但我注意到 Cursor 的内存管理功能做得很好。它可以根据工程师个人、部门乃至整个公司的偏好、规则和流程，自主管理相关信息。我们都知道，信息和上下文对Agent来说至关重要。请问你们有没有计划进一步拓展和升级这个功能？尤其是在长上下文处理方面，你们有什么思路？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我们正在进行大量的实验和探索。目前已经落地了规则管理、内存记忆、技能库等多个功能模块。现阶段，我们主要在研究高效的信息摘要技术。另外，借助我们的自研模型，我们也在探索让模型自主识别对话或代码中反复出现的关键信息。当然，跨组织的信息共享功能也很值得探索。不过这里有个需要注意的点，相关规则和信息可能会随着模型的迭代而过时。所以我们必须确保用户能够轻松更新这些内容，避免被过时的规则束缚。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;提问者 4：关于你们发布的 Composer 模型，我认识一些开发者，他们基于 Gemini 模型微调了一个医疗领域的专用模型。但他们发现，这个微调后的模型效果还不如直接用原生 Gemini 模型做单次提示词调用。他们分析的原因是，微调模型需要持续维护，要跟上 Gemini 等基础模型的更新节奏。请问你们是如何制定策略，确保 Composer 模型不会落伍的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：你说的是 Composer 模型，对吧？我们会持续对它进行迭代优化，它并不是一个静态的模型。我们的核心关注点，是在速度和智能之间找到最佳平衡点，满足 Cursor 用户在大部分场景下的需求。不过在长上下文处理这类特定领域，我们确实还有提升空间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;提问者 5：我自己是产品经理，一直在用 Cursor 做原型开发，甚至在团队里还客串设计师，用它替代 Figma。我很好奇，有没有用户是在使用 Cursor 之前，从未安装过任何集成开发环境（IDE）的？这类用户会不会成为你们未来重点关注的群体？毕竟现在的编码Agent已经足够强大，很多工作都能在上面完成。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：坦白说，我们目前并没有把这类用户作为核心关注点。当然，我们认同工具的使用门槛确实需要不断降低，而且 Cursor 的易用性也在持续提升，比如新增的浏览器工具对设计师就很友好。但我们的核心目标，其实是赋能顶尖工程师。我们一直在思考：如何让世界上最优秀的工程师变得更加强大？在这个过程中，我们开发的工具自然会惠及更多人群。不过在产品优化方面，我们确实还有很多工作要做，如优化新手引导和环境配置流程。毕竟设计师和产品经理在配置 GitHub 等工具时，经常会遇到困难。我们希望通过优化这些环节，吸引更多用户尝试 Cursor。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;提问者 6：我一直在尝试用 Cursor 做智能合约的验证矩阵构建和试运行逻辑测试。请问在深度质量检测和安全加固方面，有没有什么不太为人知的实用工作流可以推荐？或者刚才提到的调试工具能不能派上用场？我对智能合约的质量检测特别感兴趣。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：说实话，我们正在尝试让Agent自主完成测试工作，不过这项功能目前还没有完全发布。对于从事质量检测工作的人员来说，我强烈推荐试试我们刚发布的调试模式。这个功能定位问题的逻辑非常清晰，几乎可以说是确定性的，用起来会很有帮助。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;提问者 7：您认为未来两到四个月，Cursor 面临的最大机遇是什么？会不会是语音Agent？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jason Ginsberg：我觉得机遇不在于语音Agent。用户现阶段最核心的需求，其实是让Agent变得更智能、运行时间更长、能处理的任务更多。现在的很多Agent，本质上只是在 “读取代码”，并不能真正判断修改后的代码是否有效。未来的发展空间非常大，我们可以投入更多算力，让Agent承担更多人类目前负责的校验工作。我觉得未来三到六个月，整个行业都会迎来巨大的变革，非常值得期待。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=dKSGK-fPFyU&quot;&gt;https://www.youtube.com/watch?v=dKSGK-fPFyU&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/t2GqLirT9xsmYmKLW22C</link><guid isPermaLink="false">https://www.infoq.cn/article/t2GqLirT9xsmYmKLW22C</guid><pubDate>Mon, 19 Jan 2026 10:32:18 GMT</pubDate><author>华卫,Tina</author><category>AI&amp;大模型</category></item><item><title>最烦做演讲！黄仁勋曝英伟达养了61个CEO、从不炒犯错员工：CEO是最脆弱群体</title><description>&lt;p&gt;整理 | 华卫&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“世界上不会再出现第二个我这样的 CEO 了。”近日，英伟达联合创始人兼首席执行官黄仁勋（Jensen Huang）在一场私人访谈中这样说道。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据称，这场深度对话已经酝酿了三十年，将黄仁勋鲜为人知的一面展现在大众眼前。主持人Jodi Shelton与黄仁勋的职业交集始于三十余年前，彼时，图形处理器（GPU）尚未掀起席卷全球的AI革命。从加速计算的源头到生成式AI的前景，这场对话堪比一堂远见大师课。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在访谈中，黄仁勋表示，从某种意义上说，英伟达其实有 61 位 “CEO”。过去这些年，包括他在内，很多人都犯过严重的错误，但在英伟达，从来没有人因为犯错而被解雇。“我们打造了一个足够安全的环境。”他还透露，CEO 这个职位，远比人们想象的要脆弱得多。“实际上，我们可能是公司里最脆弱的一群人。不过对我来说，承认这种脆弱，并不是什么难事。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有意思的是，他提到，在很多方面，自己都算是一个 “不情愿的 CEO”。“公开演讲简直让我怕得要死。比起待在公司外面抛头露面，我更喜欢扎根在公司内部；比起发表演讲，我更喜欢安静做事；我甚至一点都不喜欢做主题演讲，但为了公司，我必须去做这些事。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，黄仁勋称，英伟达的成功，绝不是靠产量取胜。“虽然是英伟达发明了 GPU，但从产量来看，我们其实是全球最小的 GPU 制造商。很多不知名的厂商，GPU 产量都比我们高。”而“没有终极目标” 这一点，对英伟达的发展真的起到了至关重要的作用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于五年后的世界，黄仁勋断言，英伟达和整个行业在AI领域的投入，必将彻底改变计算机的运作模式，未来的计算机，将从 “由人类编程” 进化为 “在人类引导下自主学习编程”。并且，100% 的工作岗位都会发生变化，但不会有 50% 的岗位消失。未来的趋势不会是就业岗位减少，反而是大家会变得比现在更忙碌。并且，那些现在没有工作的人，很可能会因为AI获得谋生的手段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;网友们纷纷就此次访谈对黄仁勋评价道，“我从未见过他如此坦诚直率，真是不可思议。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以下是详细对话内容，我们在不改变原意的基础上进行了翻译和删减，以飨读者。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;“走了整整33年才看到成果”&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Jodi Shelton：大众其实特别好奇像你这样的人，毕竟你们正在定义科技的未来，而科技的未来就是整个世界的未来。所以我们想做的，是挖掘你成功光环背后的个人经历以及支撑你走到今天的价值观。你对这个定位怎么看？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：说实话，不太喜欢。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：真的不喜欢吗？可你现在是名人啊，大家都想了解名人的故事。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：我从不觉得自己是名人，也根本不是什么名人。我只是恰好执掌着一家举足轻重的企业，是这家堪称史上最成功的科技公司之一的 CEO。很早以前，我们就做了一些正确的决策。回溯到 1993 年，我们就立志要重塑计算行业，而且对于计算机的架构，我们有着自己独到的见解。在很长一段时间里，这个观点都不被看好，甚至颇具争议。要知道，当时整个行业的焦点都在微处理器和 CPU 上。说起来，我和你就是在那个时期认识的。我们早在 1993 年底或者 1994 年就相识了，对吧？从那时起，英伟达就在做我们现在依然在做的事：重塑计算。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：没错，我记得很清楚。那时候的硅谷，正处在 CPU 为王、摩尔定律大行其道、个人电脑革命如火如荼的年代。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：是啊。而且我们早期的客户，全都是 PC 芯片组领域的初创公司。这些企业可以说是半导体行业辉煌版图的奠基者，像Cirrus Logic、S3 Graphics、Western Digital、Trident Microsystems，你还记得这些名字吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：当然记得。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：这些公司，称得上是英伟达的 “前辈”。而现在，我们依然在这条路上前行，致力于打造一种全新的计算模式。这条路，我们走了整整 33 年才看到成果。我只是恰好成为了这家公司的 CEO，仅此而已。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：可能对你来说，这一切是水到渠成，但对整个世界而言，英伟达的崛起堪称横空出世。大概从 2023 年 11 月起，整个世界的科技格局都因你们而改变。你是怎么看待这次转型的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：要知道，想要创造未来，就必须在未来到来之前，先置身于未来之中。坦诚地说，从我们发明 CUDA 技术、推出相关产品的那一刻起，就已经踏上了通往未来的道路。英伟达最让我骄傲的一点是：我们不仅擅长技术发明，更擅长把技术转化为产品推向市场。世界上有太多的公司、科研人员和发明家，他们确实创造出了先进的技术，但最后往往只能感慨 “这个技术我早就做出来了”、“这个想法我早就有了”。每次听到这种话，我都觉得很惋惜。这些优秀的发明家，遗憾的是没能遇上同样优秀的产品创新者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所谓产品创新者，就是能把一项技术发明转化为一款能推向市场的成熟产品的人。而这还不够，你还得为产品制定精准的市场策略，甚至需要亲手培育出一个全新的市场，让市场能够接纳你研发的产品和制定的策略。英伟达就是这样一家公司，我们具备技术发明、产品创新、策略制定、生态构建乃至市场培育的全链条能力，而且我们已经多次成功做到了这一点。所以对我来说，这种 “身处未来” 的状态，已经持续了很长时间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：确实如此。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：很久以前，我们有一个战略，现在已经不怎么提了，叫 “CUDA 无处不在”。很多人都听过我当年四处推广 CUDA 的故事，跑遍各大高校、初创企业和成熟企业。有时候，台下听众加起来也就三个人，但我还是会掏出笔记本电脑，为他们演示 CUDA，告诉他们这项技术将如何改变世界。我走访了无数科研机构和实验室，参加了数不清的行业会议，推广 CUDA 的次数，估计比世界上任何人都多。长久以来，我一直沉浸在这样的 “未来图景” 里，讲的故事多了，甚至会产生一种 “未来已经到来” 的错觉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：确实有这种感觉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：所以现在看到这一切成为现实，我依然满心欢喜。而且在我看来，这一切其实并不意外，因为支撑英伟达发展的是计算机科学领域最根本的底层逻辑，不是靠一时的直觉，也不是凭主观的喜好。从很多方面来说，如今的成果是一种必然。但我想说的是，当你把一件事物的速度提升一千倍，或者规模扩大一千倍、体积缩小一千倍时，无论这件事物原本是什么，都会发生质的飞跃。而这种质变最终带来的结果，往往是超乎想象的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们早就预见到深度学习技术有着巨大的扩展潜力，这也是我们举全公司之力押注这一领域的原因。我们知道，AlexNet（深度卷积神经网络）绝不会是深度学习的终点，这种技术架构天生具备极强的可扩展性，再加上全球海量的数据资源，深度学习的爆发是水到渠成的事。不过我当时也清楚，有一项技术会成为我们前进路上的障碍，那就是无监督学习，或者说自监督学习，也就是让计算机摆脱人工标注数据的束缚，实现自主学习。因为人工标注数据的效率，迟早会成为技术发展的瓶颈。而当无监督学习技术取得突破的那一刻，我就知道，我们的时代来了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;就在不久前的投资者路演上，还有人跟我说，我当时就明确跟他们提过这场 “质变”。如果你去回看当时的财报电话会议，就会发现每当谈到对世界至关重要的技术话题时，我都会把这一点讲得非常透彻。在每一场投资者路演，在每一个我演讲的场合，我都会强调这个观点。如今，无监督学习技术确实取得了重大突破，深度学习的规模效应也彻底释放出来，我们才算真正驶入了发展的快车道。但即便如此，这项技术如今能解决的问题，依然让我感到惊喜。我们早就预料到技术会发生质变、计算平台会迎来变革，但我们没想到，变革的成果如此丰硕。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们现在能够解读蛋白质的 “语言”、细胞的 “语言”、量子的 “语言”，能够读懂世间万物的各种表征形式。过去我们用来描述信息的方式，如今正在被彻底重塑。从几何图形、纹理材质到如今的 3D 高斯和 3D 点云，信息的呈现形式日新月异。这种感觉就好像人类突然变得无比聪慧，连英语这种语言体系都随之改变了。我们不再沿用过去的词汇、语法和句式，因为我们的智慧已经进化到了一个全新维度，能够用一种全新的方式进行交流。或许未来人类的交流方式会变成简单的 “嘀嘀嗒嗒” 的信号声。这让我想起了电影《降临》里的场景，人类突然开始用抽象的图形进行沟通，仅仅通过图形就能传递海量的信息，实现更深层次、更高效率的交流。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最不可思议的是，我们现在解决的很多问题在过去是完全无法想象的，而且解决问题的速度也远超以往。过去我们常说摩尔定律，而现在英伟达的发展速度完全可以用 “英伟达定律” 来形容，比过去快了整整一千倍。未来十年必将是波澜壮阔的十年，光是想想就让人无比兴奋。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：要做到你所做的这些事，要能够预见未来，并且坚信未来一定会到来，需要何等强大的自信啊。就像你之前说的，我们 1994 年就认识了，这么多年来，你一直都是这个样子。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：是啊，我记得很清楚。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：那时候我才二十几岁。你应该比我大一点吧？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：当时我差不多 29 岁，快 30 岁了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;英伟达有61位“CEO”，从没有人因犯错而被解雇&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Jodi Shelton：我还记得我们第一次见面的场景，当时我是为了给杂志写稿采访你。我问你：“黄仁勋，硅谷人才流动频繁，很多人来了又走，你会担心这个问题吗？” 毕竟当时很多 CEO 都在抱怨这件事。而那时你才 29 岁或 30 岁，你是这么回答我的：“英伟达既不是教堂，也不是监狱。想来的人可以来，想走的人也可以走。” 我当时听完特别震撼，心里想着：“这个人到底是谁啊？” 年纪轻轻，却有着如此的自信和智慧。我还听过一个类似的故事，张忠谋（ Morris Chang）第一次见到你的时候，你当场就说：“我会成为你最大的客户，至少也是最大的客户之一。” 他当时的反应是：“哇，这小伙子可真有魄力。” 所以我很好奇，你这么年轻的时候，这份自信是从哪里来的？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：哈哈，你要知道，什么都懂其实也挺痛苦的，我开玩笑的。对了，张忠谋要是知道英伟达现在是台积电最大的客户，一定会很开心的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：那是肯定的，他肯定会为你感到骄傲。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：我也为他感到骄傲。要知道，在个人电脑革命时期，英伟达就曾是台积电最大的客户。如今，我们再次成为了他们最大的客户，对此我感到非常欣慰。言归正传，我觉得一个人必须坚信自己所相信的东西。而且这份信念，不能建立在道听途说之上，不能因为别人说了什么，你就去相信什么。你必须认真思考，梳理出自己相信这件事的逻辑，并且把这些逻辑拆解成可靠的底层原则。之后，你还需要定期检验这些原则，确保你所秉持的信念、所付诸的行动，都是建立在坚实的基础之上的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果这个基础不够稳固，或者因为某些原因发生了变化，那就说明它可能并非真正的底层原则 ，也许它并没有锚定在物理规律或客观事实之上。一旦出现这种情况，你就要重新评估，然后及时调整方向。我一直都是这样做的。而且，如果你真心相信一件事，就应该付诸行动去实现它。我从 1993 年起就坚信我们正在做的事情，直到今天，这份信念依然没有改变。正因为坚信不疑，所以我才会不断地推演，不断地在脑海里进行逻辑梳理。我会持续复盘过去的决策，也会不断预判未来的趋势。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;就像昨天我们开了那么多场会议，每场会议上，我都会重新梳理我们一路走来的逻辑。你会发现，过去的那些假设，有些是正确的，但也有些是错误的。正是因为我们足够灵活，能够根据实际情况及时调整方向，才最终走到了今天。所以，时常回头复盘、重新推演过往的决策，是一件很有意义的事，它能帮你更好地锻炼向前推演的能力。正因为我一直坚持这样做，所以我始终活在自己认定的真相里。直到现在，我依然觉得自己只是英伟达的一名员工。我非常在乎这家公司，但公司里有很多人都和我一样，对这家公司倾注了深厚的感情。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在一家治理完善的公司里，CEO 的角色定位是很明确的。CEO 需要向董事会汇报工作，而董事会则要对股东负责。如果 CEO 的工作表现没有达到董事会的预期，不管董事会有 12 位、13 位还是 15 位成员，他就会被解雇。所以说，CEO 其实也是公司这个组织里的一名员工。这就是为什么我说，英伟达既不是教堂，不是想来就能来；也不是监狱，不是想走都走不了。这种心态能让你始终保持脚踏实地，保持谦逊，保持锐意进取的状态，因为你必须每天都努力，才能对得起自己的这份工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有时候会有人问我：“黄仁勋，你热爱自己的工作吗？” 我会告诉他们，我并非每天都热爱这份工作，但我每天都会全力以赴去做好它。我觉得，这种态度源于两个方面：第一，我坚信自己是这份工作的最佳人选；第二，我必须每天都努力，才能配得上 “最佳人选” 这个身份。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：在大家眼里，你就是英伟达的代名词，英伟达就是你。这么多年下来，你已经和这家公司深度绑定了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：我应该是英伟达内部被拍照最多的人吧。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：没错。不过，要是将来换了新的 CEO，这个人真的能接好你的班吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：世界上不会再出现第二个我这样的 CEO 了。原因很简单，我是被这家公司一步步培养起来的。刚创立英伟达的时候，我对怎么当 CEO、怎么做战略规划、怎么打造产品、怎么开创一个全新的行业，一窍不通。我只知道怎么融资，却不懂怎么和股东沟通，不了解股东、政策制定者、各国领导人以及企业管理者的想法，也不知道该如何把握员工的心态、如何打造企业文化，甚至连 “企业文化” 这个词到底意味着什么，我都无法准确界定，让我制定公司战略那更是天方夜谭。这就是我第一天接手工作时的真实状态。而在过去的 33 年里，我在这些领域都一步步做到了得心应手。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果说这个世界上有谁能称得上是 “企业战略宗师” 或者 “行业开创者”，那这个人大概就是我这样一个小个子。我把自己的整个职业生涯都投入到学习这些能力上，而且我本身就是个好学生。除此之外，我对这份工作的投入程度和深厚感情，是很难通过招聘来复制的。在我心里，英伟达就像我的孩子一样，我对它倾注了全部的心血。我的家人也陪着我一起，为这家公司的成长付出努力。这种对公司的特殊情感，是很难被替代的。毕竟 33 年来，我见证了英伟达的每一次成功、每一次失败、每一次挫折，亲历了它做过的所有明智决策，也目睹了它犯下的各种错误。这种对公司的深刻理解和情感联结，不是随便招一个能力出众的人就能替代的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不过从另一方面来说，英伟达的管理团队架构其实早就做好了准备。我现在有将近 60 位直接下属，他们中的每一个人，放到其他公司都能胜任世界级 CEO 的职位。我总是当着他们的面推演各种决策逻辑，我的每一个决定，都是在他们的注视下做出的，我会把背后的思考过程原原本本地讲给他们听。公司的每一次成功、每一次挫折、每一个挑战、每一场困境，我都会和他们一起复盘。所以从某种意义上说，英伟达其实有 61 位 “CEO”。他们每个人都对这家公司饱含深情，很多人已经在这里奋斗了 33 年。我认为，英伟达的成长模式是独一无二的，这也造就了它无可比拟的韧性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：显然，你搭建的这套管理架构在行业内已经成了一段传奇，所有人都在谈论你这近 60 位直接下属。要让这样的架构顺畅运转，这些人肯定都得是万里挑一的顶尖人才。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：没错。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：他们不光要头脑聪明，毕竟硅谷从来不缺聪明人，更得是适配英伟达的顶尖人才。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：确实如此。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：那你能不能跟我说说，你是怎么筛选和培养这些人才的？另外，我记得你有个原则，找不到合适的人，就宁可让职位空着。我想到了Colette Kress的例子，你当时面试了 22 位首席财务官候选人，最终才选定了她。现在她在华尔街已经是一位传奇人物了。你当初是怎么选中她的？你选拔这类核心人才的标准是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：在我看来，宁让职位空着，也不能让不合适的人占着位置，所以我从来不会急于招人。就算 CEO 的位置暂时空缺，或者某个副总裁职位没人接任，公司的运转也不会停滞。只要你坚信这一点，坚信 “空位胜于错配”，你就有足够的时间去寻找那个真正合适的人。这个合适的人选，需要满足很多条件，其中很重要的一点，就是你得发自内心地欣赏他、认可他。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我记得Colette Kress入职第一周的时候，就问过我：“黄仁勋，你希望我在首席财务官这个岗位上干多久？” 我告诉她：“只要我们还活着，只要死亡不将我们分开，你就一直干下去。” 因为任何其他答案都是没有意义的。这份工作没有所谓的 “截止日期”，唯一的终点，就是当她觉得英伟达不再适合自己的时候。这个原则不仅适用于Colette，也适用于我那 60 位直接下属。我愿意为了等待合适的人，让职位空很久。而在这个过程中，公司依然会稳步向前。无论这个空缺的职位对应着什么使命、什么工作，大家都会主动顶上。退一步说，就算没人接手，我也会尽全力扛起这份责任，保证公司正常运转。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这就是我的用人哲学，永远不要让不合适的人占据岗位，耐心等待那个对的人出现。经常有人问我，什么样的员工才算优秀员工，什么样的管理者才算卓越管理者。说来奇怪，我其实没有标准答案。因为能走到我面前的人，都足够聪明、足够能干。你随便找一个首席财务官，我敢保证他绝对胜任本职工作。其他岗位的候选人也是如此。在我看来，英伟达之所以能创造奇迹，关键不在于单个人的能力有多强，而在于团队成员之间的 “化学反应”。更重要的是，这源于我们的企业品格。这种品格，才是一家伟大公司的核心竞争力。市面上有很多公司都在做芯片，虽然是英伟达发明了 GPU，但从产量来看，我们其实是全球最小的 GPU 制造商。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这话听起来可能有点不可思议，但事实就是如此，很多不知名的厂商，GPU 产量都比我们高。很明显，英伟达的成功，绝不是靠产量取胜。我认为，真正的秘诀在于我们独特的企业文化和企业品格、团队在逆境中凝聚在一起的力量。在外人看来，我们似乎总是一帆风顺，但其实研发 Grace Blackwell 芯片的过程，差点拖垮了整个公司。但我们硬是咬牙扛了过来。这个项目的复杂度和规模都是前所未有的，外界对我们的期望也高得离谱。我们最终不仅达标，甚至超出了所有人的预期，而支撑我们做到这一点的，100% 是企业品格。这不是靠智商，也不是靠勤奋就能实现的，毕竟这个世界上，聪明又努力的人太多了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种企业品格，是没法通过面试来筛选的。但我始终相信一件事：几乎任何人进入英伟达之后，都会被这种品格所感染、所塑造。这就是我们公司最神奇的地方：我们能够承受挫折，能够直面各种艰巨的挑战，并且一次次从困境中突围。很少有公司的团队能做到这一点。通常来说，当公司遭遇重大挑战后，总会有人因为心存不满离开，或者因为被当成 “背锅侠” 而被解雇。在团队合作中，出了问题总要有人承担责任，这是毋庸置疑的，就像一场球赛输了，我们必须清楚是谁失误丢了球。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在英伟达，我们打造了一个足够安全的环境。过去这些年，包括我在内，很多人都犯过严重的错误，这些失误大家都看在眼里，但从来没有人因为犯错而被解雇。久而久之，英伟达就形成了自己独有的文化和特质。这种文化的核心，就是包容、宽恕，以及从错误中学习。对我来说，有两件事至关重要：只要团队里的每一个人，都为了共同的目标拼尽了全力，这就足够了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;敢叫板 20 岁新锐的黄仁勋，也有至暗时刻？&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Jodi Shelton：刚才聊到 “痛苦与磨砺” 的理念，你可以再深入谈谈吗？我最近听Andy Karp 在播客里说，“人生的二十几岁，要么用来享乐，要么用来打拼事业”。你认同这个观点吗？当然，不是每个人都能成为帕兰提尔或者英伟达的 CEO，但对年轻人来说，想要在事业上有所成就，到底需要付出什么？你想给年轻人传递怎样的职业与成功之道？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：Andy&amp;nbsp;很睿智，总能说出一些深刻的人生哲理。不过我对这类说法，倒没那么执念。我一直很佩服张忠谋先生，他一直工作到 80 多岁，思维依然敏锐得像一把刀。如果要在维基百科里查 “大器晚成” 这个词，配图说不定就是他。能在人生最具创造力的阶段，持续奋斗 50 年，这难道不是一件幸事吗？我自己也倾向于这种人生轨迹。对我而言，投身于有价值的事业，远比用后 20 年的时间环游世界更有意义，当然，环游世界本身也没什么不好，只是我现在就已经在满世界奔波了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不得不承认，二十几岁的我，确实更聪明、专注力更强、思维速度也更快。但那个年纪的人，往往缺少一样至关重要的东西，阅历沉淀出的智慧、处理复杂问题的分寸感、制定长远战略的眼光，以及长线思维的能力。这些能力，光靠读书是学不来的。现在的年轻人可以刷短视频，通过共情去感受别人的经历，算是一种间接的经验积累，这种模仿式学习确实有价值。但还有一样东西，是无法通过旁观习得的，那就是坚韧的意志，是直面痛苦与挫折时，懂得如何应对的底气；是熬过精神内耗、挺过煎熬时刻、战胜内心恐惧的勇气。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;经营公司的过程中，恐惧是真实存在的。我们的决策，关乎数万人的生计。当公司发展不顺时，一个感受不到恐惧、焦虑和脆弱的领导者，反而是不合格的。如果对结果毫不在意，那未免也太冷漠了。而这些真切的感受和应对的能力，只有亲身经历过，才能真正掌握。所以我觉得，两种人生选择没有绝对的对错。年轻时打拼，确实精力充沛，可以熬夜加班，可以付出十倍的努力，更容易早早取得成功。但我现在身上拥有的东西，是三十岁时的我完全不具备的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如今的我，思维速度虽然慢了，但依靠智慧和经验积累的思维模型，能更快地找到正确答案。就算和二十岁的年轻人同台竞争，我也有信心不输给他。他们未必能胜过现在的我。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：那我们来聊点更私人的话题吧。能不能说说你的童年？哪些高光或至暗的经历，对你如今的性格特质产生了直接影响？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：我从来不觉得自己是天赋异禀的人，智商也算不上出众。小时候入学需要参加考试，我当时的成绩确实很不错，那会儿的考试还是全国性的。我记得母亲总是逢人就说，我是个非常聪明的孩子。不管这话是不是真的，她反复的肯定，无形中给了我一种压力，我必须变得足够聪明。这件事让我意识到，无论是为人父母还是做管理，给身边的人或者整个公司设定一个超出常理的高目标，往往能激发他们的潜能，让他们迎难而上。当然，也有人会被这样的目标吓退，但对我而言，这种激励起到了积极的作用。这是我第一个想到的童年片段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一件事，是关于我母亲的。当年我们学习英语的时候，她其实根本不懂英文，而且我觉得她可能连高中都没毕业。但这丝毫没有妨碍她每天教我们学英语。你可能会觉得不可思议，一个完全不懂英语的人，怎么教孩子学英语？她的方法很简单：买一本韦伯斯特词典，照着单词的拼写规律，写下英文单词，再标注上中文释义，把纸对折做成单词卡，然后逼着我们背下来。我们的发音准不准确，她其实也无从判断。但这件事，让我学到了一个道理：一个人只要有足够坚定的意志，就算暂时不知道该怎么做，也不该停下脚步。很多事情，其实并没有想象中那么难。小时候的这段记忆，我一直记到现在。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有一段经历，是我们搬到肯塔基州之后。我当时是学校里年纪最小的孩子，就读的奥尼塔浸会学院坐落在山顶。每天上学，我都得走下山坡，穿过一条河，再走过一片广阔的田野，才能到达那所小小的学校。那是 1973 年，我是整个镇上第一个出现的中国孩子。镇上的那些孩子都很野，每次我过吊桥的时候，他们都会找我的麻烦。那座吊桥的桥面是木板铺的，有些木板已经缺失了，桥下的河水很深。而那些孩子，就守在桥的另一头等我。那时候我才 9 岁。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：天哪，才 9 岁。眼前是一条河，一座破吊桥，桥对面还有等着找麻烦的孩子，这简直太糟糕了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：是啊，但我每天都得走这条路去上学。这大概就是童年时期的 “痛苦与磨砺” 吧。每天早上都是这样。下午放学回家后，我还有任务：打扫卫生间。那时候家里的每个孩子都有分工，我哥哥当时 11 岁，他的活儿是去烟草农场干活，而我的工作就是打扫卫生间，每天都要做。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：你觉得当年那些找你麻烦的孩子，知道你现在的成就吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：奥尼塔浸会学院的校长最近还发邮件给我呢。他们每年都会给我寄圣诞礼物，知道我喜欢吃肯塔基风味的香肠肉汁配饼干。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：这个爱好是在肯塔基养成的吧？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：没错。我记得我 45 岁生日的时候，家人带我回了一趟母校。当年食堂里做饭的阿姨们居然还健在，特意回来给我做了一顿饭。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：天哪，这也太暖心了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：真的特别感动。她们给我做了正宗的肯塔基香肠肉汁配饼干，味道还是小时候的样子。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：你的父母见证了你的成功吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：当然，他们现在身体还很好，特别为我骄傲。他们对我的事情了如指掌，我父亲会读所有和我相关的报道。要是看到有人说我的坏话，他还会生气。我总劝他别什么都看，不然天天都得生气，别理会那些负面新闻。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：挺有意思的。现在功成名就了，你会怀念那些还没这么受关注的日子吗？会想念那些平凡的小事吗？比如你很爱车，现在却没什么机会开车了吧？我记得你是我认识的人里，第一个也是唯一一个拥有柯尼赛格跑车的人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：克里斯蒂安・冯・柯尼赛格真是个天才设计师，那辆车太棒了。启动的时候，引擎声和蝙蝠侠的座驾一模一样。而且启动它得按七个步骤，因为动力实在太强劲了，不能随便让别人碰。不过我现在已经没有那辆车了，也确实很少开车了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：会想念开车的感觉吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：有一点吧。我现在还是会关注新车，比如新款的法拉利，每次看到都觉得很惊艳，这些车真的是工程学的杰作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：确实很厉害。我去过法拉利的工厂，亲眼看到一辆车从工业器械一步步变成顶级消费品，现在甚至成了艺术品，这个过程太震撼了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;黄仁勋眼中五年后的世界&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Jodi Shelton：如果五年后我们再坐在这里，你觉得到那时的世界会是什么样子？哪些变化会让我们最惊讶？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：如果我们回归底层逻辑，再结合现实的实用性和技术落地的规律来判断，有几件事是可以预见的。首先，英伟达和整个行业在AI领域的投入，必将彻底改变计算机的运作模式 ，未来的计算机，将从 “由人类编程” 进化为 “在人类引导下自主学习编程”。过去我们是手把手教计算机学日语，未来我们只需要告诉它 “去学日语” 就够了。未来的计算机，将能够处理比现在大十亿倍的问题规模。这个变化的影响之大，我们现在甚至无法完全想象，因为提出解决方案是一回事，而能否构想出需要解决的问题，就是另一回事了。很多问题之所以无法被解决，往往是因为我们连如何定义和描述它们都做不到。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;未来，无论是数字生物学、物理科学、量子物理还是材料科学的复杂难题，都会变得容易攻克。就算是交通拥堵这种日常问题，也能得到极大改善。就拿智能电网来说，现在的电网存在大量能源浪费，AI会精准计算出所需的能源量，实现按需分配，从根本上避免过度供应造成的损耗。AI解决这些日常难题的能力，会让人惊叹不已。到那时，每一个科学领域都会被重塑，当下所有的难题都会被技术赋能、迎刃而解。工具的速度提升了，难题自然就显得 “渺小” 了。举个例子，如果飞机的速度能达到 10 马赫，整个世界就会变得 “小” 很多， 喷气式飞机的出现，其实已经让世界变小了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;英伟达制造的计算机也是如此，极致的运算速度让所有问题都变得更容易被解决。就像 OpenAI 的研究人员曾经说的：“为什么不把整个互联网的数据都喂给计算机呢？” 因为在算力爆发之后，全球互联网的数据量，突然就显得微不足道了。现在我们看互联网数据，也会觉得体量很小，原因就在这里。这种心态，未来会渗透到几乎所有的科学领域。过去人们会说 “这是个无解的难题”，未来大家只会觉得 “这事儿很简单”。五年后，每一位科学家、工程师、企业家和创新者，都会抱着这样的心态。曾经的难题变得简单，我们就能解决更多的问题。这是第一个必然结果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第二个结果，就是企业的生产效率会实现质的飞跃。今天的难题变成明天的小事，供应链管理会变得无比顺畅，浪费现象基本消失；计算机的设计流程也会简化，我们可以尝试更多的方案。这并不是说我们会每年推出更多的产品，我们还是保持一年一款的节奏，但每一款产品都会经过更多次的迭代优化，最终呈现的成品会比现在好得多。这样一来，公司的效率会更高，利润会更丰厚，所有企业都会变得更赚钱，整个社会的财富也会随之增长。但还有一个值得深思的点：当所有我们能想到的问题都变得可以解决时，我们就会去探索更多新的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以，未来的趋势不会是就业岗位减少，反而是大家会变得比现在更忙碌。因为以前那些被认为 “不可能完成” 的任务，现在都摆上了台面；那些因为成本太高而无法开展的实验，现在都可以去尝试，AI还会帮我们推进这些实验。只要我们有足够的想象力，所有搁置的难题，都会找到解决的路径。我可以做一个思想实验。现在我工作时，身边围绕着 60 位顶尖人才，而他们每个人又带着数千名精英。这些人在各自的领域里，能力都远超于我，对我来说，他们就像是 “领域内的人工超级智能”。但和他们合作，我完全没有障碍。现在我使用的 OpenAI、Gemini、Grok、Perplexity、Anthropic 这些AI工具，在很多方面也已经比我聪明了，但我每天都在和它们高效协作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不过有一个很有意思的变化：以前我给团队布置一个问题，需要等两三天才能得到反馈和答案，这段时间里我可以思考下一步的计划 ，因为我的决策需要基于这些中间结果。但如果这些答案能在一秒钟内就反馈给我，会发生什么？我的工作节奏会变得无比紧凑，因为我会成为所有事情的关键节点。刚得到一个答案，立刻就要推导下一步，马上启动新的实验。你不觉得吗？现在信息技术的提速，已经让我们变得更忙碌了。信息、知识和答案的获取速度越来越快，我们作为决策节点，自然会比以往更忙。我觉得未来很多人都会有这种感受。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最后一点，对于那些没能赶上之前科技浪潮的人来说，AI会填平技术鸿沟。我特别喜欢 “氛围编程” 这个概念，现在任何人都可以成为软件程序员，借助 AI 写出的代码，甚至比很多专业程序员的作品还要好。我很欣赏 Cursor 这家公司的成果，前几天还见到了 Lovable 的 CEO，他是个很厉害的人，他们的公司在瑞典。AI会帮助那些在自己的领域很有天赋，但不懂如何用技术放大自身能力的人实现能力的跃迁。Lovable 的 CEO 就跟我说过，很多人用他们开发的软件创办了小公司，现在每年能赚 2300 万美元。这太不可思议了。这些人终于能融入全球经济体系，不再被技术门槛挡住去路，这一切都是AI的功劳。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;五年后的世界，大家会拥有更有价值的工作，经济效率会大幅提升，GDP 有望实现增长，劳动力短缺的问题会得到缓解，通货膨胀也会回落。更多的科学领域会被开拓，更多的难题会被解决。当然，也有一些悲观的论调，认为AI会让一半的人失去工作。但我觉得，更可能发生的情况是：100% 的工作岗位都会发生变化，但不会有 50% 的岗位消失。而且，那些现在没有工作的人，很可能会因为AI获得谋生的手段。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，我们的技术会发生翻天覆地的变化，但这些技术层面的革新，反而不是最有意思的。五年后，计算机还是计算机，只是应用变得更智能了，本质上还是软件。我们依然会做电商，只是可能不用自己逛网站了，会有智能代理帮我们购物，但商品还是来自亚马逊这些平台。很多事情，其实都会保持原样。最后我还有一个小小的愿望或者说期待：希望我们在机器人和人形机器人领域的研究能结出硕果，希望未来每个人都能拥有属于自己的 R2-D2 和 C-3PO，它们可爱又贴心。就像在 GTC 大会上，我每次都会邀请迪士尼的机器人上台，那些机器人真的太萌了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为什么不让每个人都拥有一个呢？我还希望迪士尼能把这些机器人做成周边商品，它们真的值得。我的宠物猫莫莫和库玛，也需要这样的 “宠物玩伴” 不是吗？我真心希望这个愿望能实现。现在有很多孤独的人，已经有不少人联系过我，希望能拥有可以在家陪伴自己的机器人，尤其是那些独居的老人。机器人能给他们带来陪伴和帮助，而且它们本身又那么可爱，这绝对是我们技术发展带来的意外之喜。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：如果以后有机器人帮我们做饭、打扫卫生，你还会像现在这样，饶有兴致地看着别人做饭吗？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：当然会。原因很简单，我现在完全有能力不用自己做饭，但我还是会选择下厨。我们完全可以雇很多佣人，但我们没有这么做。我和洛里一直都是两个人自己过日子。昨晚她做了墨西哥辣椒肉酱，味道棒极了，全程都是她一个人忙活的。以后我们大概率还会保持这样的生活。对我来说，最幸福的时刻，就是孩子们回家来，我们一起下厨做饭，喝喝小酒，这就是最完美的时光。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：一家人在厨房里忙活，这种亲密感真的太美好了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：是啊，人生的幸福莫过于此。我们打拼奋斗，不就是为了这样的时刻吗？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;“不爱演讲的黄仁勋”：CEO是公司里最脆弱的一群人&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Jodi Shelton：当一切尘埃落定，你希望后人如何记住你？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：首先，能被人记住，本身就是一件很幸运的事。我很庆幸，凭借英伟达的成就，凭借我们打造的事业，凭借我们在全球最重要的科技产业：人类最核心的工具 “计算机” 领域留下的印记，英伟达很可能会在我离开这个世界很久之后，依然对这个世界有着重要的意义。我很庆幸自己能和克里斯、柯蒂斯一起创立这家公司，很庆幸自己能一路学习成长，没有成为拖垮公司的那个短板，反而常常是推动公司走下去的一份力量。我们打造的这家企业，对整个世界都有着深远的影响，而不只是局限于某个行业或某个群体。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;能做到这一点的人，在这个世界上并不多。我很庆幸自己作为创始人，能亲身参与并见证这一切，见证英伟达成长为如今的模样，见证它对全球各行各业产生实实在在的影响。公司里有很多已经工作了 33 年的老员工，他们的人生因为英伟达变得更加丰盈；现在甚至已经有第二代、第三代员工加入我们。我们在全球各地建立了自己的团队，我很荣幸能和这些员工并肩作战，分享他们一路走来的绝望与喜悦、希望与悲伤。这样的经历，并不是每个人都能拥有的。我为我们在中国的团队感到骄傲，为我们在印度的员工们由衷赞叹，也为欧洲、加拿大的团队感到欣慰。我们在加拿大的团队正在不断壮大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我还希望有朝一日，英伟达能把业务拓展到南半球，让更多地区的人们，也能享受到我们今天所拥有的技术成果。昨天我还和人聊起我们在非洲开展的工作，聊到我们应该在拉美和东南亚投入更多精力。我真的为我们公司带来的这些影响感到自豪。所以，人们会怎么记住我？或许，他们会记得我是英伟达的创始人之一，是这家公司的缔造者之一。或许，还会记得我是个好人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：这是毋庸置疑的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：他们或许还会觉得，我是个风趣幽默的人，不喜欢端着架子。其实在很多方面，我都算是一个 “不情愿的 CEO”。比起待在公司外面抛头露面，我更喜欢扎根在公司内部；比起发表演讲，我更喜欢安静做事；我甚至一点都不喜欢做主题演讲，但为了公司，我必须去做这些事。我确实是个不太情愿的 CEO，但我绝对是个满腔热忱的英伟达建设者。只要是为了公司发展必须做的事，我都会全力以赴。说了这么多，其实我也不知道，人们最终会如何记住我。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：我觉得，看到好人获得成功，总是一件令人开心的事。这么多年来，看着你一路打拼，经历起起落落，最终收获成功，我真的由衷地为你高兴。你这一路走来，见过了形形色色的人。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：是啊，真的见过了太多人。我想提醒所有的 CEO，没有人能单枪匹马地成功。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：确实如此。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：我们虽然是 CEO，但这个位置总需要有人来坐。如果不是早年大家对我的提携与帮助，比如你一直不遗余力地宣传英伟达还有张忠谋奖带来的认可，这些都对我意义重大。张忠谋奖大概是我人生中获得的第一个真正有分量的奖项，直到今天，它对我来说依然意义非凡。这个奖项以他的名字命名，而且他还亲自参与了评选，这份认可真的让我铭记于心。还有那些和我们合作的企业，他们的慷慨相助，我也一直记在心里。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其实 CEO 这个角色，很多时候都需要寻求帮助。我已经记不清有多少次，我是这样开启一段对话的：“我需要你的帮助。” 很多时候，我是真的需要帮助，而且对方往往是唯一能帮到我的人。一路走来，很多人都慷慨地伸出援手，分享他们的知识，教我做事的方法，帮我解决棘手的难题。这或许才是 CEO 这个角色带给我的真正启示，这个职位远比人们想象的要脆弱得多。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：而且还是一个很孤独的职位，对吧？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：确实可能会感到孤独。但我想说，这种孤独更多是存在于我们的内心世界。当你试图解决一些棘手的难题时，往往需要长时间独自思考，自己跟自己对话。公司发展的每一次转型、每一次跨越，每一次我推动公司自我革新的时刻，我都不知道自己独自思考了多少个小时。在那些时刻，你会真切地感受到孤独。但我们也要明白，其实有很多人都希望我们能成功。就像你之前说的，你很乐意看到我成功，我知道你是真心希望我好，而我也同样希望你能越来越好。从这个角度来说，我们其实并不孤单。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以说，CEO 这个职业，是一份充满脆弱感的工作。你无法单打独斗完成任何事，很多时候都需要依赖别人的帮助与善意。或许在外界看来，我们是强大的领导者，但实际上，我们可能是公司里最脆弱的一群人。我经常说，我是公司里唯一一个离开别人的帮助就寸步难行的人。我想，大多数 CEO 应该都是如此。这或许就是这份职业带给我们的感悟：CEO 们，远比他们愿意承认的要更加脆弱。不过对我来说，承认这种脆弱，并不是什么难事。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;“没有终极目标” ，才成就了英伟达？&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Jodi Shelton：接下来我们用快问快答收尾。你见过的最聪明的人是谁？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：这个问题我没法回答。我知道大家心里对 “聪明” 的定义，就是智商高、会解决问题、技术能力强。但在我看来，这种能力早已经成了一种 “通用品”。而且我们很快就能证明，AI处理这类问题是最轻松的，不是吗？举个例子，以前大家都觉得软件编程是最考验智商的工作，结果呢？AI最先攻克的领域之一就是编程。所以说，“聪明” 的定义，其实和大多数人想的完全不一样。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在我看来，从长远来讲，真正的 “聪明”，是那种兼具技术洞察力与人文同理心的能力，是能够洞察弦外之音、预判未知风险、看透表象背后本质的能力。那些能 “见人所未见” 的人，才是真正的聪明人，他们的价值是无可估量的。这种人能凭借数据、分析、底层逻辑、人生阅历、智慧经验，再加上对他人的感知，敏锐地捕捉到潜在的风险，在问题发生之前就提前规避。我觉得这才是 “聪明”，而且拥有这种能力的人，说不定在学术能力评估测试（SAT）里的分数惨不忍睹。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：外界对你有什么误解？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：这些问题都好犀利啊。首先，我都不知道外界对我有什么印象。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：比如，大家觉得你喜欢抛头露面，觉得你是个很棒的演讲者，所以肯定很享受做演讲的过程。但你之前已经说了，事实并非如此。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：对，完全相反。公开演讲简直让我怕得要死。不是说站在台上的那一刻害怕，而是现在，想到两周后在华盛顿举办的 GTC 大会，我就焦虑得不行。不，应该说，我已经焦虑一个月了。这种事总是让我心神不宁，脑子里时时刻刻都想着，压力特别大。公司内部的会议演讲也让我紧张到极致。因为台下坐的都是对我而言最重要的人，从某种程度上说，这是我做过的最重要的演讲。但这种演讲根本没法准备，我要讲的所有内容，其实都能在网上的某个视频里找到，他们完全可以自己去看。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我很讨厌把那些内容重复一遍讲给他们听，因为你绝不会回家对着家人做一场 GTC 主题演讲，对吧？我也不想那样做。演讲内容必须是真诚的、独一无二的、对听众有价值的、有意义的，能给他们带来改变。毕竟我还在领导这家公司，我希望通过演讲达成一定的目标。所以我必须拿出全新的内容，但不到演讲结束的那一刻，我永远不知道最终效果会怎么样。大家都觉得财报发布周我会很紧张，但说实话，我一点感觉都没有。真正让我紧张的，是公司的内部会议演讲。所以外界的这个印象，真的大错特错。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：你最受不了的事是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：在关键时刻，有人不认真听我说话、不理解我的问题，还胡乱回答。尤其是在我们处理非常棘手、非常困难的问题时，我们需要的是事实，是真相。这个时候我提出问题，如果有人答非所问，我会立刻火冒三丈。我实在无法理解，为什么有人意识不到这场会议的重要性？我们正在为一件至关重要的事努力，我们需要尽快找到真相、解决问题。我到现在都想不通这一点，这种情况每次都会激怒我。谁要是想惹我生气，这招百试百灵。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：这下我们知道怎么让黄仁勋发火了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：最后一个问题，是最近有人问我的，我特别喜欢这个问题。如果让你回到 20 岁，你是想回到自己当年的那个年代，还是活在当下的 20 岁？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：我会毫不犹豫地回到自己的那个年代。因为我觉得，我们那一代人的 20 岁，比现在年轻人的 20 岁更快乐。我总觉得，每个人都应该拥有一段 “懵懂无知” 的时光，不必从第一天起就背负着全世界的重担。我坚信这一点，没人能说服我。有时候，“无知” 也是一种快乐，甚至是一种超能力。如果当初我知道创立英伟达是一件 “不可能完成的任务”，那今天的英伟达根本就不会存在。事实就是，创立英伟达这件事，本来就是天方夜谭。但当时的我什么都不懂，所以没人能说服我放弃。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我觉得，乐观的人都这样，你永远没法说服他们 “这件事做不成”。他们就是这么 “无知”，对现实的艰难视而不见，所以才会充满乐观。这难道是坏事吗？现在的年轻人，过早地接触到了太多信息，变得越来越愤世嫉俗。他们并不是天生就这么消极，而是因为看到的东西太多太杂了。其实大可不必如此。人需要培养内心的乐观精神，需要在心里留存一份善意，学会只看到世界美好的一面。我们得锻炼这种能力。我们那一代人，有更多这样的机会。我们 20 岁的时候，就是这样的，乐观得像超人一样，觉得凡事皆有可能。所以，我肯定会选择回到自己的 20 岁。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Jodi Shelton：真是个完美的收尾。无知是福啊。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;黄仁勋：没错，无知是福，无知也是一种超能力。任何一个想要开启新征程的人，如果不是因为这份 “无知”，他们一早就会因为觉得事情太难而放弃了。我真的很庆幸，自己当年虽然也算勤奋、也算有一些能力，但那份 “无知” 帮了我大忙。我那时候做任何事都抱着一种心态：“这能有多难？” 结果后来才发现，简直难到超乎想象。你根本没法想象。你看看我今天建立的这一切，如果当初我就知道前路会有这么多艰辛、这么多挫折、这么多失望，把这些困难全都摆在我面前，我绝对不会去做的，绝对不会。所以说，“无知” 真的是一种超能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有一种超能力，就是“没有终极目标”。英伟达就没有什么终极目标。总有人问我：“黄仁勋，你的计划是什么？” 我们没有计划，“活下去” 就是我们的计划。我们对未来的世界有憧憬，我们会畅想技术会如何改变世界，但我们 100% 的计划，就是让公司一直运营下去。以前也有人问我，现在也经常有人问：“黄仁勋，你的人生目标是什么？” 我没有什么人生目标，就是想一直工作，一直有事可做，能和一群优秀的人一起做有意义的事。这就是我的目标。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以说，从很多方面来讲，“没有终极目标” 这一点，对英伟达的发展真的起到了至关重要的作用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=8FOdAc_i_tM&quot;&gt;https://www.youtube.com/watch?v=8FOdAc_i_tM&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/BexlqSeAfD1svmVOXpc1</link><guid isPermaLink="false">https://www.infoq.cn/article/BexlqSeAfD1svmVOXpc1</guid><pubDate>Mon, 19 Jan 2026 10:26:06 GMT</pubDate><author>华卫</author><category>AI&amp;大模型</category></item><item><title>二十年，重新出发！第 20 届 D2 技术大会「AI 新」议题全球征集正式开启</title><description>&lt;p&gt;二十年，是一个坐标。从 Web 2.0 的萌芽，到移动互联网的爆发，再到云原生时代的重塑，D2 技术大会伴随开发者走过了整整二十载风雨。&lt;/p&gt;&lt;p&gt;今天，我们站在了一个更加宏大的分水岭。AI 不再是遥远的科幻逻辑，它正以一种近乎“重构”的姿态，系统性地改写终端技术的底层范式：从代码生成的协作，到架构设计的逻辑，再到交互体验的边界。&lt;/p&gt;&lt;p&gt;第 20 届 D2 技术大会，年度主题定为——「AI 新」。&lt;/p&gt;&lt;p&gt;它既是我们的时代判断，也是我们的集体宣言。它是 AI 驱动的创新，也是终端人对技术边界追逐的热爱之新。&lt;/p&gt;&lt;p&gt;此刻，我们正式向全球开发者、架构师、技术领袖及创新实践者发出邀请：来 D2，分享你对 AI 时代终端技术的独到见解，共同定义下一个二十年的生产力！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;七大核心专场，期待你的真知灼见&lt;/p&gt;&lt;p&gt;我们渴望真实工程中的突破，珍视深度思考后的落地，让技术回归解决问题的初衷。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;01 AI Coding：从写代码开始，重构工程本身&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是本届 D2 的主干专场。AI 正在从“辅助助手”升级为“协作伙伴”。&lt;/p&gt;&lt;p&gt;征集方向：&lt;/p&gt;&lt;p&gt;AI Agent 编程工具的研发与设计&lt;/p&gt;&lt;p&gt;侧重 Agent 型 AI 编程工具在本地与远程形态下的架构与产品设计。征集议题包括 IDE 深度集成、上下文采集与记忆管理、代码库索引检索、任务规划与工具调用、执行沙箱与权限控制、审计与回放、可观测性、成本/延迟优化与多模型策略等。重点关注可靠性与可控性：减少误改、支持规范化交付与团队协作。&lt;/p&gt;&lt;p&gt;AI-Native 开发实践&lt;/p&gt;&lt;p&gt;聚焦真实项目中 AI 编程的可复用方法。征集包含 Spec 驱动开发（结构化需求/验收标准/契约/测试）、AI 编程 Workflow 探索（从需求到 PR/发布的流水线）、以及团队级 AI 驱动研发实践（流程改造、提示/模板沉淀、质量门禁、效率与质量度量、失败复盘）。重点是“怎么做得稳、做得快”。&lt;/p&gt;&lt;p&gt;AI Coding 前沿研究与技术趋势&lt;/p&gt;&lt;p&gt;关注下一代 AI Coding 的关键技术与趋势。征集议题包括长上下文与复杂依赖、代码语义理解与程序分析结合、自动化评测与基准、对齐与安全、多智能体协作、可靠性与可解释性增强等。重点探讨研究如何走向工程落地与可验证的效果提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;02 AI 创新体验：当交互正在被重写&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;终端是 AI 被感知的最前线。交互范式的巨变已经发生。&lt;/p&gt;&lt;p&gt;征集方向：&lt;/p&gt;&lt;p&gt;UI 范式重塑&lt;/p&gt;&lt;p&gt;探讨从 GUI 向 LUI 或 AUI 的代际演进。聚焦 Agent 驱动下的意图识别、动态 UI 生成及个性化界面即时构建。征集议题包括主动交互设计、多 Agent 协作下的用户反馈回路、以及如何利用 AI 简化复杂业务流的操作门槛。&lt;/p&gt;&lt;p&gt;空间智能体验&lt;/p&gt;&lt;p&gt;聚焦多模态感知与空间计算的深度融合。涵盖视觉、语音、触觉在 3D/XR 环境下的集成交互，以及 AI 驱动的实时场景理解与数据可视化。重点探讨如何利用空间智能让数字世界更符合自然认知，实现高沉浸感的智能反馈。。&lt;/p&gt;&lt;p&gt;具身交互探索&lt;/p&gt;&lt;p&gt;关注 AI 进入物理世界后的交互挑战，从 AI Wearables、AI PC 到机器人具身智能。探讨硬件约束下的自然语言处理、人机交互（HRI）实践及环境感知反馈。重点关注如何通过端侧智能赋予硬件产品生命力，解决真实场景下的交互痛点，探索用户真正愿意买单的终端新价值点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;03 AI 语言 &amp;amp; 框架：模型时代，语言与框架如何进化&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当 AI 成为“默认能力”，底层技术如何适配？&lt;/p&gt;&lt;p&gt;征集方向：&lt;/p&gt;&lt;p&gt;语言与编译器演进&lt;/p&gt;&lt;p&gt;探讨编程语言如何适配“人机共写”新常态。征集议题涵盖 LLM 友好型语法设计、智能化类型系统、AI 辅助的编译优化与静态分析等。重点研究如何通过语言特性的进化，提升 AI 生成代码的质量、安全性与复杂逻辑表达力。&lt;/p&gt;&lt;p&gt;Agent 框架重构&lt;/p&gt;&lt;p&gt;当 Agent 成为系统编排者，探讨传统框架的抽象层重塑。征集议题涵盖声明式意图驱动的框架设计、元数据驱动的界面自动生成、以及为 AI 重新设计的组件模型。重点关注框架如何提供更高级别的抽象，以支持多 Agent 在复杂业务逻辑中的无缝协作、状态同步与逻辑自治。&lt;/p&gt;&lt;p&gt;智能运行时与内核&lt;/p&gt;&lt;p&gt;推动 AI 从工具层下沉为系统的核心能力。聚焦内置 AI 推理能力的运行时引擎、模型与容器/内核的深度集成，以及 AI 驱动的动态资源调度策略。重点探讨端云协同背景下，如何模糊开发与运行、模型与逻辑的边界，实现具备自适应、自进化能力的智能运行基座。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;04 AI 智能测试：质量与效率，不再只能二选一&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;测试不再是滞后的环节，而是 AI 介入最深、收益最显性的战场。&lt;/p&gt;&lt;p&gt;征集方向：&lt;/p&gt;&lt;p&gt;用例生成与自愈&lt;/p&gt;&lt;p&gt;探讨利用 LLM 实现测试全生命周期的自动化。征集议题包括基于语义理解的单元/集成测试生成、复杂业务场景下的测试数据合成，以及 UI 自动化脚本的自愈（Self-healing）机制。&lt;/p&gt;&lt;p&gt;风险洞察与优化&lt;/p&gt;&lt;p&gt;聚焦利用 AI 提升质量保障的精准度与效率。征集议题涵盖基于变更分析的智能回归测试缩减、线上异常的实时检测与根因定位，以及多维度的质量风险预测模型。探讨如何利用算法在海量代码变更中快速锁定高风险区域，解决快速迭代与质量稳定性之间的核心矛盾。&lt;/p&gt;&lt;p&gt;治理与角色演进&lt;/p&gt;&lt;p&gt;关注 AI 引入后测试流程与组织效能的系统性重构。核心议题包括 AI 测试工具的 ROI 分析、人机协同模式下的 QA 职责重定义，以及在规模化工程中构建“默认内置 AI”的质量防线。探讨如何通过技术赋能，打破质量与效率的零和博弈，重塑技术团队的质量文化与评价体系。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;05 AI 智能生产：从工具走向生产系统&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关注 AI 在真实业务落地时的“最后一公里”。&lt;/p&gt;&lt;p&gt;征集方向：&lt;/p&gt;&lt;p&gt;业务深度嵌入&lt;/p&gt;&lt;p&gt;探讨 AI 如何从外部辅助工具进化为业务逻辑的核心。寻找在复杂业务场景中的落地架构案例，关注如何处理模型输出的不确定性以交付“确定性”结果。重点探讨 AI 对传统业务流程的深度重构，在提升用户价值的同时，确保生产系统的稳定性、安全性与商业收益。&lt;/p&gt;&lt;p&gt;规模化生产交付&lt;/p&gt;&lt;p&gt;聚焦 AI 从原型验证（PoC）走向规模化交付的工程拐点。征集议题涵盖支持大规模 AI 应用的工程底座、端到端 AI 生产平台的演进、以及 FinOps 成本分析与合规治理。探讨如何构建标准化的平台能力，支撑 AI 跨团队、跨业务的高效迁移与持续稳定运行，实现技术普惠。&lt;/p&gt;&lt;p&gt;全链路协同提效&lt;/p&gt;&lt;p&gt;关注覆盖需求、设计、交付及运维的 AI 全链路闭环。核心议题包括新一代人机协作下的流程重塑、领域专用 Agent 的生产环境编排，以及科学的效能度量方法。探讨如何通过技术与组织的双重演进，实现软件生产体系的跨越式提效，将 AI 潜能真正转化为规模化的实际业务产能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;06 终端技术：重构 AI 时代的性能底座&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;底层基础设施如何承载高算力与高响应需求？&lt;/p&gt;&lt;p&gt;征集方向：&lt;/p&gt;&lt;p&gt;架构适配与演进&lt;/p&gt;&lt;p&gt;探讨终端架构如何重构以深度兼容 AI 能力，重点研究如何调整传统的软件拓扑结构，以支持 AI 在终端侧的无缝集成、高效编排与复杂的应用状态管理，提升端侧智能的响应实时性。&lt;/p&gt;&lt;p&gt;运行时与性能优化&lt;/p&gt;&lt;p&gt;聚焦通过底层技术突破 AI 运行的性能瓶颈。征集议题涵盖面向 AI 指令集优化的编译器技术、异构算力的极致加速实践，以及轻量化端侧容器演进。探讨如何通过运行时与系统内核的深度协同，在有限的硬件资源限制下，实现极致的推理速度与能效比。&lt;/p&gt;&lt;p&gt;端侧工程与协同&lt;/p&gt;&lt;p&gt;核心议题包括模型量化、蒸馏与剪枝的终端实战、端云协同推理架构，以及隐私安全约束下的端侧学习。探讨如何构建高效的端云配比方案，在保障响应速度与数据隐私的同时，实现计算成本与用户体验的帕累托最优。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;07 一人公司：技术人的个体放大器&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是最具时代情绪的专场。AI 正在让“超级个体”成为可能。&lt;/p&gt;&lt;p&gt;征集方向：&lt;/p&gt;&lt;p&gt;全栈生产力飞跃&lt;/p&gt;&lt;p&gt;探讨 AI 如何打破专业壁垒，实现“一个人就是一支团队”。分享利用 AI 协同完成从需求定义、全栈开发、交互设计到市场增长的全链路实践。&lt;/p&gt;&lt;p&gt;商业闭环与实战&lt;/p&gt;&lt;p&gt;聚焦超级个体的商业化落地与可持续经营之道。征集独立开发者的 AI 实战案例，涵盖极致成本控制下的产品生存策略、AI 辅助的商业决策与自动化运营。探讨在 AI 时代，个体如何构建轻量化、高利润的商业模式，并成功应对从单兵作战到规模化营收的真实挑战。&lt;/p&gt;&lt;p&gt;职业路径重构&lt;/p&gt;&lt;p&gt;探讨从“专项开发者”向“产品主理人”转型的思维重构、AI 时代的个人品牌经营，以及个体长期竞争力的构建。研究在组织边界日益模糊的未来，技术人如何利用 AI 工具集寻找更具自主性的创作路径，定义下一代极简且高效的职业范式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;顶尖出品人矩阵：为议题深度护航&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/fa/fa61443638c019387c39c770e16936f2.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;本届 D2 各专场由行业资深专家领衔，他们不仅是评审者，更是议题的“合伙人”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们寻找的不仅是一个演讲者&lt;/p&gt;&lt;p&gt;更是一个在 AI 工程深水区挣扎过、思考过、最终破局的见证者&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;隐风| 淘天集团-用户&amp;amp;内容终端技术负责人云谦| 蚂蚁集团-高级前端技术专家悟石| 淘宝闪购-消费者端技术负责人渚薰| 前淘宝互动游戏专家偏右| 蚂蚁集团-支付宝体验技术前端平台负责人张磊| 字节跳动 Web Infra 技术负责人泠乐| 淘天集团-淘宝终端质量负责人茹炳晟| CCF TF 研发效能 SIG 主席 / 复旦大学 CodeWisdom 成员达峰| 蚂蚁集团-平台体验技术部负责人穆宸| AliExpress-终端技术负责人 / D2 负责人永霸| 淘天集团-交易终端技术负责人崔红保| DCloud CTO / uni-app 跨平台框架负责人秦粤| 阿里云-数据库高级前端专家梓骞&amp;nbsp;| 启智云图 CEO / Lovrabet 产品创始人&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;出品人寄语：“在 D2，我们致力于将前沿的 AI 实践提炼为系统化的技术范式。我们期待与你一同锚定 AI 时代的工程坐标，让每一份实战洞察都汇聚成定义未来的行业基准。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;🌟&amp;nbsp;为什么来到 D2 舞台&lt;/p&gt;&lt;p&gt;顶尖技术影响力：D2 是国内终端技术的风向标，线下规模 2000+，线上覆盖数十万专业开发者。二十周年里程碑：参与第 20 届这一极具纪念意义的盛会，与业内最具创新精神的技术人同频共振。常态化社区联动：优质内容将同步至稀土掘金、InfoQ、AI 产品榜等联合承办方平台，获得持续的行业曝光与认可。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;🗓️&amp;nbsp;议题提交指南&lt;/p&gt;&lt;p&gt;截止时间：&amp;nbsp;2026年1月23日（请关注官网最新动态）议题要求：内容具有前瞻性、实战性或深度思考；拒绝纯广告，强调技术细节与真实的踩坑经验&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e1/e113f9df884fa02d84448c5d0828beaf.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;扫码提交议题&lt;/p&gt;&lt;p&gt;二十年是一个里程碑，更是重新出发的起点。在「AI 新」的浪潮中，让我们一起，用 AI 驱动创新，用终端之心热爱创新。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;*本文由极客时间企业版代发&lt;/p&gt;</description><link>https://www.infoq.cn/article/RJ1OxNTaCwuh6Y12O8dc</link><guid isPermaLink="false">https://www.infoq.cn/article/RJ1OxNTaCwuh6Y12O8dc</guid><pubDate>Mon, 19 Jan 2026 08:12:09 GMT</pubDate><author>极客时间企业版</author><category>AI&amp;大模型</category></item><item><title>Cursor推出动态上下文发现功能，提升了Token的使用效率</title><description>&lt;p&gt;Cursor推出了一种新方法，用于减少发送给大语言模型（LLM）的请求上下文的大小。这种方法名为&lt;a href=&quot;https://cursor.com/blog/dynamic-context-discovery&quot;&gt;动态上下文发现（Dynamic Context Discovery）&lt;/a&gt;&quot;，它摒弃了以往在请求开始时就包含大量静态上下文的做法，转而让智能体（agent）按需动态检索所需信息。这种方式不仅显著减少了token消耗，也避免了将可能令人困惑或无关的细节混入上下文。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了实现动态上下文发现，Cursor采用了五种不同的技术。这些技术有一个共同特点，即以文件作为LLM工具的主要接口，使内容能够由智能体动态存储和获取，而不是一次性塞满有限的上下文窗口。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;随着编码智能体能力的快速提升，文件已成为一种简单而强大的基础原语（primitive）。相比引入另一种尚无法完全适应未来需求的抽象层，使用文件是一种更安全、更务实的选择。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Cursor使用的第一项技术是将大规模输出（比如，shell命令或其他工具的输出）写入文件，确保关键信息不会因上下文截断而丢失。随后，智能体可根据需要使用tail等命令读取文件末尾的内容。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其次，针对上下文过长时被摘要压缩而导致信息丢失的问题，Cursor会将完整的交互历史保存到文件中，使智能体能在后续需要时检索缺失的细节。同样，&lt;a href=&quot;https://cursor.com/docs/context/skills#agent-skills&quot;&gt;领域特定的能力&lt;/a&gt;&quot;被存放在文件中，智能体可通过&lt;a href=&quot;https://cursor.com/blog/semsearch&quot;&gt;Cursor内置的语义搜索工具&lt;/a&gt;&quot;动态发现相关文件。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于MCP 工具（Model Context Protocol 工具），传统做法是在请求初始阶段就加载所有MCP服务器提供的工具描述，而Cursor修改为仅传递工具名称。当任务实际需要某个工具时，智能体才会动态拉取其完整定义。这一策略大幅降低了token总量：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;智能体现在只接收少量的静态上下文（包括工具名称列表），并在任务需要时主动查询具体工具。在一项A/B测试中，对于调用了MCP工具的运行实例，该策略平均减少了46.9%的总token使用量（结果具有统计显著性，但方差较大，这取决于所安装MCP服务器的数量）。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ec/ec1873f6d16ffc8ddc77bd79169d9beb.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，这种方法还带来一个额外的优势，那就是智能体可以监控每个MCP工具的状态。例如，比如某个MCP服务器需要重新认证，智能体可以及时通知用户，而不是完全忽略该问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最后，所有终端会话的输出会同步到文件系统。这使得智能体能更轻松地回答用户关于命令失败原因的问题。同时，通过将输出存入文件，智能体可使用grep等工具仅提取相关的信息，进一步压缩上下文规模。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在X上，用户@glitchy指出，&lt;a href=&quot;https://x.com/Glitchymagic/status/2008645395485020480?s=20&quot;&gt;虽然减少token是重要目标，但是尚不清楚这种动态机制是否会增加延迟&lt;/a&gt;&quot;。@NoBanksNearby则认为，动态上下文发现“&lt;a href=&quot;https://x.com/NoBanksNearby/status/2008644561674137888?s=20&quot;&gt;在同时运行多个MCP服务器时，对开发效率提升巨大&lt;/a&gt;&quot;”。&lt;a href=&quot;https://x.com/casinokrisa/status/2008862311336047058?s=20&quot;&gt;@casinokrisa&lt;/a&gt;&quot;也对此表示赞同：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;token数量几乎减少了一半，既降低了成本，又加快了响应速度，尤其是在多服务器场景下。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最后，@anayatkhan09&lt;a href=&quot;https://x.com/anayatkhan09/status/2008790121966170181?s=20&quot;&gt;提出了可能的优化方向&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;下一步应该是向用户开放动态上下文策略，让我们能针对不同代码仓库调整优化的激进程度，而不是对所有工具一视同仁。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据Cursor官方表示，动态上下文发现功能将在未来几周内向所有用户开放。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/cursor-dynamic-context-discovery/&quot;&gt;AI-Powered Code Editor Cursor Introduces Dynamic Context Discovery to Improve Token-Efficiency&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/WJL8IKHd99G4zrEyTO99</link><guid isPermaLink="false">https://www.infoq.cn/article/WJL8IKHd99G4zrEyTO99</guid><pubDate>Mon, 19 Jan 2026 08:00:00 GMT</pubDate><author>Sergio De Simone</author><category>AI&amp;大模型</category></item><item><title>Agoda是如何将多个数据管道统一为单一事实来源的</title><description>&lt;p&gt;Agoda近日分享了他们如何&lt;a href=&quot;https://medium.com/agoda-engineering/how-agoda-enhanced-the-uptime-and-consistency-of-financial-metrics-ef7d54c4e4f0&quot;&gt;将多个独立的数据管道整合为一个基于Apache Spark的集中式平台&lt;/a&gt;&quot;，以消除财务数据中的不一致性的。该公司构建了一个多层质量保障框架，结合自动化校验、基于机器学习的异常检测以及与上游团队签订的数据契约（data contracts），确保用于财务报表和战略规划的财务指标准确无误，同时每天处理数百万笔预订交易。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一问题源于一个典型的企业架构模式，Agoda的数据工程、商业智能（BI）和数据分析团队各自开发了独立的财务数据管道，并使用不同的逻辑和定义。尽管这种做法在初期提供了简单性和清晰的责任边界，却导致了重复计算和全公司范围内指标不一致的问题。正如Agoda工程团队的&lt;a href=&quot;https://www.linkedin.com/in/warot-jongboondee-87032ab9/&quot;&gt;Warot Jongboondee&lt;/a&gt;&quot;所解释的那样，这些差异“可能对Agoda的财务报表产生实质性的影响”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/79/79a40041814672a3081a9fd57fb07f2b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;独立的财务数据管道 (&lt;a href=&quot;https://medium.com/agoda-engineering/how-agoda-enhanced-the-uptime-and-consistency-of-financial-metrics-ef7d54c4e4f0&quot;&gt;图片来源&lt;/a&gt;&quot;)&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了解决这一挑战，Agoda推出了名为Financial Unified Data Pipeline（FINUDP）的统一财务数据管道，作为销售、成本、收入和利润率等关键财务数据的单一事实来源（single source of truth）。该系统基于&lt;a href=&quot;https://spark.apache.org/&quot;&gt;Apache Spark&lt;/a&gt;&quot;构建，每小时向下游团队提供更新，用于对账和财务规划。整合过程耗费了大量的精力：协调产品、财务和工程等多个利益相关方就统一的数据定义达成共识耗费了很长的时间；初始版本的运行时间长达五小时，后通过查询优化和基础设施调整，最终缩短至约30分钟。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/74/7447722c9d9d79a59fbcc418d53870a0.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;财务统一数据管道（FINUDP）的架构(&lt;a href=&quot;https://medium.com/agoda-engineering/how-agoda-enhanced-the-uptime-and-consistency-of-financial-metrics-ef7d54c4e4f0&quot;&gt;图片来源&lt;/a&gt;&quot;)&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Agoda的质量保障框架采用了多重防御机制。自动化校验会检查数据表中的空值、数值范围约束和数据完整性。一旦关键业务规则校验失败，管道会自动暂停，以防处理可能错误的数据。团队使用&lt;a href=&quot;https://quilliup.com/&quot;&gt;Quilliup&lt;/a&gt;&quot;来比对源表与目标表。与上游团队的数据契约（Data Contracts）会明确约定数据格式、内容和质量要求，任何违反契约的行为会立即触发告警。机器学习模型会持续监控数据模式，识别潜在异常。三级告警系统确保通过邮件、Slack通知以及内部工具实现快速响应，如果数据更新延迟，系统会自动升级至Agoda的7×24小时网络运营中心（Network Operations Center，NOC）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一做法契合了行业的整体趋势。根据最新的行业调研，&lt;a href=&quot;https://www.precisely.com/data-integrity/2025-planning-insights-data-quality-remains-the-top-data-integrity-challenges/&quot;&gt;64%的组织将数据质量问题视为最大挑战&lt;/a&gt;&quot;。Gartner指出，&lt;a href=&quot;https://atlan.com/data-contracts/&quot;&gt;数据契约&lt;/a&gt;&quot;正成为“&lt;a href=&quot;https://www.gartner.com/en/documents/5929107&quot;&gt;管理、交付和治理数据产品的一种日益流行的方式&lt;/a&gt;&quot;”。这类生产者与消费者之间的正式协议，明确定义了数据模式（schema）和质量标准。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，集中化也带来了明确的权衡取舍（trade-offs）包括，开发速度下降，因为任何变更现在都需要对整个管道进行测试。数据依赖，管道必须等待所有上游数据集就绪后才能启动。详尽的文档编写和广泛的干系人共识拖慢了落地进度，却建立了跨团队的信任。Jongboondee表示，集中化“要求在每个环节都进行更紧密的协作和审慎的变更管理”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前，该系统已经实现了95.6%的可用性，并朝着99.5%的目标迈进。所有变更均需经过影子测试（shadow testing），也就是，在合并请求中，新旧版本的查询会并行运行，并自动比对结果。此外，还有一个与生产环境完全一致的专用staging环境，允许团队在正式发布前进行充分的验证。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;FINUDP项目表明，当企业处理大规模关键业务数据时，正逐步从零散的、事后补救式的质量检查，转向架构层面强制执行的、端到端的可靠性体系。这种体系优先保障数据的一致性与可审计性，而非单纯的开发速度，这一转变在财务数据日益支撑报表生成、机器学习模型训练和监管合规流程的今天，显得尤为关键。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/agoda-unified-data-pipeline/&quot;&gt;How Agoda Unified Multiple Data Pipelines Into a Single Source of Truth&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/FCovAhOpFvEryKZFFxy9</link><guid isPermaLink="false">https://www.infoq.cn/article/FCovAhOpFvEryKZFFxy9</guid><pubDate>Mon, 19 Jan 2026 07:26:00 GMT</pubDate><author>Eran Stiller</author><category>大数据</category><category>机器学习/深度学习</category></item><item><title>从 Greenplum 到 Doris：集群缩减 2/3、年省数百万，度小满构建超大规模数据分析平台技术实践</title><description>&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;度小满引入 Apache Doris 替换原有 Greenplum，实现整体查询效率提升 82%，与此同时，集群缩减 2/3、年省数百万的巨大效益。本文将分享度小满如何基于 Doris 从0 到 1 构建超大规模数据分析平台，并围绕平滑迁移、异地多活容灾等方面，分享实践经验。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本文整理自度小满 Doris 数据库负责人汤斯在 Doris Summit 2025 中的演讲，并以演讲者第一视角进行叙述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;度小满金融（原百度金融）作为一家覆盖现代财富管理、支付、金融科技等多板块的科技公司，数据的分析处理对其极为重要，已经深度融入业务生命周期的每个环节，是进行风险控制、商业决策、用户体验优化及运营提效的基石。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着业务高速发展，度小满原有基于 Greenplum 搭建的 OLAP 平台，逐渐暴露出三大痛点：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;规模与稳定性瓶颈：存储已接近饱和，扩容至百余台已接近硬件规模的承载上限，如果继续扩容，将面临更严重的稳定性挑战。性能与体验不佳：Greenplum SQL 查询执行速度慢，且经常出现 “计算时间远小于排队时间” 的情况，严重影响业务分析效率。缺失技术支持：当前使用的 Greenplum 6 版本技术架构已显得陈旧，并且 2024 年 Greenplum 宣布将停止开源，后续的技术支持与迭代升级将无法保障。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了应对这些痛点，度小满金融迫切寻找更为高效、稳定且具备现代化技术架构的数据处理解决方案，以支持其未来的业务发展。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Apache  Doris：高吞吐、快查询&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;面对日益增长的业务体量与复杂多变的分析需求，选用一个高效、可靠的数据库系统，已成为支撑业务稳健发展与快速创新的关键。Apache Doris 以其出色的性能表现与高度灵活的架构，成为众多场景下的优选方案。为深入验证其在海量数据与复杂分析场景中的能力，我们展开了一系列性能测试，关键结果如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;查询性能：在 1TB TPC-DS 标准测试集中， &lt;a href=&quot;https://doris.apache.org/&quot;&gt;Apache Doris&lt;/a&gt;&quot; 的查询速度约是 Greenplum 6 的 20-30 倍。导入性能：在基于 Flink 写入的 TPS 测试中，基于单分片导入，压测最大 TPS 为：5000W/s。JSON 数据处理：针对新推出的 Variant JSON 数据类型，测试显示：存储 2-3 万 Key 时，其空间占用仅为普通 JSON 的 1/10 甚至更低，查询效率则提升至 10 倍以上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;综上可知，Apache Doris 在写入吞吐、响应速度及存储效率上表现卓越，有力证明了其应对大规模、实时化、半结构化数据分析挑战的坚实技术基础。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;基于 Apache Doris 的大规模数据分析平台&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在上述详实的选型调研之后，我们决定采用 Apache Doris 替代原有 Greenplum 集群，构建超大规模数据分析平台。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/72/728fb136c52d15fb124f6f7853979806.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为验证 Apache Doris 在真实业务场景中的表现，我们先进行了小范围试点，部署了少量 Doris 集群，并先行接入几个关键业务方。试点期间，系统在性能、稳定性和易用性方面获得高度评价。基于这一积极反馈，我们稳步扩展 Doris 集群规模，最终在效率与成本上实现大幅提升：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;整体效率：端到端分析任务耗时从 274 秒降至 47 秒，效率提升 82%，任务超时查杀比例从 1.3%骤降至 0.11%，降幅达 91%，彻底解决高峰期排队问题实现 0 排队，使分析师的工作不再因拥堵而中断，体验和生产力均有极大提升。集群成本：在同等资源成本下， Doris 仅以  1/3 的集群数量即可提供与 Greenplum 同等的服务能力，存储性能提升 200%。截至目前，已完成 百余台原 Greenplum 服务器的清退工作，以更少的硬件资源支撑了更高的计算与存储需求，实现年度硬件成本节约数百万元。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;从 0-1 数据平台建设经验&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们基于 Apache Doris 成功替换了 Greenplum，完成了从 0-1 的数据平台重构，覆盖架构设计、数据流转与业务协同的系统性工程。以下将围绕快速平滑迁移、异地多活容灾与全链路生态集成三个核心环节，展开具体实践。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;01 快速迁移&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为保障业务连续性与数据安全，我们开发了自动化迁移工具 SqlGlot，将大规模数据从原有 GP 集群迁移至 Doris 集群。整个过程历经半年，累计迁移 PB 级规模数据，全程业务无感知。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;表结构迁移：在表结构迁移阶段，团队从 GP 系统中导出表结构及相关元数据，借助 SqlGlot 工具实现字段映射与语法适配，并在此基础上完成分区构建与分桶策略设计，确保每个分桶数据量控制在 1G～3G 的合理范围内。该流程最终成功转换超过 20,000 张表，并保障了所有表的分区与分桶结构符合业务与性能要求。表数据迁移：我们通过分布式导出将 GP 数据并行迁移至 Doris 机器，并基于 Doris 官方推荐的 Stream Load 进行并发控制，以文件流式加载的方式高效导入数据至 Doris 集群。整个过程累计完成 PB  级规模数据迁移，稳定支持了 5000+ 次数据同步任务。SQL 迁移：为解决因业务规模庞大、场景复杂而导致的官方工具语法支持不全的问题，我们基于 SqlGlot 并结合正则匹配能力，将 PostgreSQL SQL 高效转换为 Doris SQL。整个迁移流程包括“转换成功 → 执行成功 → 数据一致” ，累计完成约 47 万个 SQL 的转换，实现 95% 的执行成功率 与 92% 的数据一致率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;02 异地双机房灾备&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为保障数据安全并实现集群高可用，我们基于 Apache Doris 构建了异地双机房灾备架构，确保数据与服务具备跨机房容灾与双活能力。核心设计如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d5/d5dbbf320edfc51d1d189eb7faf7b584.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们将所有 Doris 集群节点均匀部署于 A 与 B 两个异地机房，通过设置 tag.location 属性明确节点所属机房。用户账号按机房绑定，访问请求通过轮询机制自动分配，实现负载均衡（例如首次请求路由至 A 机房，第二次则路由至 B 机房）。建表时通过配置 location 参数，确保每张表在双机房各保留 2 个副本，从而达成数据异地双活与故障自动切换。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;关键配置示例：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;设置节点机房标签&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;sql&quot;&gt;alter system modify backend ”BE1:9050&quot; set (&quot;tag.location&quot; = &quot;group_a&quot;);
alter system modify backend ”BE2:9050&quot; set (&quot;tag.location&quot; = &quot;group_b&quot;);
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;建表时指定双机房副本分布&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;sql&quot;&gt;CREATE TABLE ubevent 
(ts DATETIME, uid INT, ...) 
DUPLICATE KEY(ts) 
DISTRIBUTED BY HASH(uid) BUCKETS 10
PROPERTIES (&quot;replication_allocation&quot; = &quot;tag.location.group_b: 2, tag.location.group_a: 2&quot;);
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;03 生态整合&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为构建高效、稳定、易用的数据平台，我们还围绕 Apache Doris 进行系统性生态整合：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;计算引擎无缝集成：通过 Doris 官方提供的 Spark Connector 与 Flink Connector，实现了与现有 Spark、Flink 计算引擎的高效对接，保障了数据流水线稳定运行。运维体系化与自动化：集成 Prometheus、Grafana 及 Doris Manager，构建了覆盖监控、告警、管理与调优的自动化运维体系，全面提升集群稳定性与运维效率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;优化经验&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为进一步提升数据平台的效率及资源利用率，在实际落地过程中，围绕集群、负载、存储等多维度总结了以下优化经验：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;01 集群隔离&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当前我们有多个 Doris 集群，为合理承接不同业务方的接入需求，我们主要依据业务成本与稳定性要求两大维度进行评估与路由。通常而言，稳定性越高，对应成本也越高。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;新建集群时，稳定性最优，但相应成本也最高。为在成本与稳定性之间取得平衡，我们大多场景是基于 Workload Group 资源硬隔离方案，对 CPU 与内存进行资源组级别的隔离，有效减少不同业务负载间的资源竞争。若业务对稳定性的要求超出共享集群所能提供的范围，则仍需要通过新建独立集群来满足。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;02 存储压力&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在 Apache Doris 的落地与运维过程中，我们曾面临因业务快速增长带来的高达 80%-90% 的磁盘存储压力。针对这一问题，进行了一系列优化：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;控制表生命周期：部分业务或因对动态分区相关语法不熟悉，未主动采用该策略。为此，集成动态分区的参数配置，简化了开发难度，并提供统一注册入口，业务开发人员仅需选择是否开启、保留天数即可。修改压缩格式：将默认压缩算法从 LZ4 切换为 ZSTD。实测表明，存储空间平均节省约 50%，虽带来约 20%～30% 的 CPU 与内存负载上升，但整体 ROI 仍然较高。存储指标监控告警：为预防因误操作或异常行为导致的存储激增，建立了针对“人员”与“表”双维度的监控体系。环比分析业务人员数据占用趋势及单表每日增长量，可自动识别异常（如单日增长飙升至日常 10 倍），并及时触发告警及通知。Hive 与 Doris 打通：在基于 Kerberos 认证的 Hive 环境中，对 Doris Hive Catalog 功能进行了二次开发，实现跨系统的直接数据访问，无需依赖 Flink 等同步工具，简化了架构并提升了数据使用效率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;03 负载均衡&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为确保系统在负载高峰期的稳定运行，特别是应对异常 SQL 与大查询带来的资源压力，应对措施如下：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;双机房负载均衡：基于已有的异地双机房架构，通过轮询机制实现业务流量在 A 与 B 机房之间的自动分发：首个 SQL 请求路由至 A，次个请求则导向 B，以此循环，确保双机房负载均衡，避免单点资源过载。SQL 参数限制：通过 enable_query_memory_overcommit = false、exec_mem_limit = 256 * 1024 * 1024 * 1024 等参数将最大占用内存限制为 256G，避免集群被打满，后续计划降至 60G。Workload 资源队列动态调整：基于任务类型划分资源队列，配置 CPU 的软隔离和内存的硬隔离，并支持错峰调度。比如：例行任务通常在夜间执行，为其创建专门资源队列，数据分析等公共任务大多在白天执行，将配置更大的资源队列，随着白天/夜间需求的变化动态调整资源。此外，依据各队列负载设定并行度与并发数，控制任务排队时长。异常 SQL 拦截：实时识别与拦截异常 SQL，避免其影响 BE 节点稳定性。初期使用 Doris 内置正则规则进行拦截，但规则复杂导致 CPU 开销上升。为此，我们将拦截逻辑外移至平台层执行，以避免正则匹配及超大 JOIN 导致的 CPU 负载过高。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;04 集群稳定性&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着集群规模不断扩大，保障 FE、BE 节点稳定性成为运维工作的核心挑战，为此，我们构建了以下保障体系：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;分层触达+全维度覆盖：根据不同指标优先级设置通知电话、短信、飞书提醒，P0 监控准确率 ≥80%；自动异常处理：为 FE 和 BE 的宕机重启设置了自动化处理方案，在识别到服务卡住时，系统会自动重启进程。此外，对于磁盘掉线，将自动下线故障盘并触发副本补齐。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们同时采用对战分析、火焰图和日志查看等方法进行详细记录，以便后续调优。此外，编写了 SOP 手册，涵盖不同场景的应对措施，并进行了异常处理演练。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;结束语&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;截至目前，我们已搭建 3 个基于 Doris 2.1.10 版本的线上集群，其中最大规模的集群达万 core 级别、上百 TB 内存和 PB 级磁盘。目前仍在扩容中，计划在年底前新增百余台 CN 节点和数十台 Mix 节点。未来，我们将重点关注并探索以下能力：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;存算分离：重点关注 Doris 3.X 版本的存储分离架构，推动落地实践。湖仓一体：全面打通数据湖与数据仓库，目前已小规模试点 Paimon；此外，针对数据外置场景，计划通过异步物化视图提升查询性能。智能物化视图探索：引入语义建模与 AI 智能分析，降低研发与业务沟通门槛，并对智能推荐与模板化方案进行探索与实践。&lt;/p&gt;</description><link>https://www.infoq.cn/article/kflvtWGPeXN40M3OPzff</link><guid isPermaLink="false">https://www.infoq.cn/article/kflvtWGPeXN40M3OPzff</guid><pubDate>Mon, 19 Jan 2026 07:04:20 GMT</pubDate><author>SelectDB</author><category>数据库</category></item><item><title>解决移动分析碎片化困局：Uber的平台引领之道</title><description>&lt;p&gt;为了标准化iOS和Android平台的事件工具，Uber工程团队&lt;a href=&quot;https://www.uber.com/blog/how-uber-standardized-mobile-analytics/&quot;&gt;重新设计&lt;/a&gt;&quot;了其移动分析架构，解决了所有权分散、语义不一致和跨平台数据不可靠的问题，目标是简化工程工作，提高数据质量，并为骑手和司机应用的产品和数据团队提供可靠的洞察。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;根据Uber工程师的说法，移动分析对于决策、功能采用和衡量用户体验至关重要。随着应用程序和团队的增长，工具变得分散。功能团队独立定义并发出事件，共享UI组件常常缺乏分析钩子，类似的交互在不同的团队中有不同的记录方式。其结果是，超过40%的移动事件属于自定义或临时事件，这不仅增加了分析复杂度，还降低了聚合指标的可信度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了应对这些挑战，工程师将核心分析职责从功能级代码转移到了共享基础设施。他们与产品、设计和数据科学团队合作，定义了点击、展示和滚动等标准事件类型。这些事件基于共享模式通过代码生成，在UI组件层进行监控，通过集中式报告层输出，由后端服务进行数据增强，并通过Uber的分析管道进行消费。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/57/57752b438115618e1209bd6e40755fb7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Uber移动分析系统架构（图片来源：&lt;a href=&quot;https://www.uber.com/blog/how-uber-standardized-mobile-analytics/&quot;&gt;Uber博客&lt;/a&gt;&quot;）&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其中一项关键决策是将分析逻辑嵌入到平台级UI组件中。工程师引入了分析构建器，用于管理事件生命周期、元数据附件和事件发出逻辑，使功能团队可以开展标准化的分析工作而无需编写自定义工具。他们对包含100个展示记录组件的示例应用做了性能测试，结果显示，CPU使用率或帧率没有退化，这是在性能敏感设备上推广该工具的先决条件。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/6e/6e7e6bc5e3ff85d7b89f1160a0a08a1c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;ImpressionAnalyticsBuilder类事件生成的数据流图（图片来源：&lt;a href=&quot;https://www.uber.com/blog/how-uber-standardized-mobile-analytics/&quot;&gt;Uber博客&lt;/a&gt;&quot;）&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该平台还实现了常见的元数据收集。应用级元数据（如接送地点或餐厅UUID）会自动记录，而事件类元数据（包括列表索引、行标识符、滚动方向和视图位置）则由AnalyticsBuilder捕获。界面通过Thrift模型实现了标准化，可以确保容器视图、按钮和滑块的日志记录保持一致。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/76/76e670c370d6f7564e3dacf0d9bab52f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;分析元数据金字塔概览（图片来源：&lt;a href=&quot;https://www.uber.com/blog/how-uber-standardized-mobile-analytics/&quot;&gt;Uber博客&lt;/a&gt;&quot;）&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了验证平台有效性，工程师通过新旧API对两个功能进行了dual-emitted分析。查询结果表明，跨平台事件量、元数据及界面是匹配的，而像滚动开始/停止计数和视图位置等语义也保持了一致。试点应用揭示了平台和记录方法的差异，并突出了列表增强的好处——将多个行事件合并为单个标准化事件，简化了查询并提高了可测试性。功能团队还采用了可见性检查机制，减少了自定义实现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;试点应用之后，Uber分析团队进行了旧事件到标准化API的迁移，使得产品团队可以专注于他们的路线图。在需要支持的地方，他们创建了自动化脚本，扫描iOS和Android代码，评估高优先级事件，并生成适合迁移的列表。平台团队还添加了一个linter，目的是拦截使用非标准API新建的点击或展示事件，防止它们进一步漂移。根据工程师的反馈，跨平台一致性得到提升，元数据和语义保持了统一，工具代码量减少，展示计数更可靠，并实现了可扩展的开箱即用UI交互覆盖功能。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;展望未来，Uber工程师正在通过组件化增强分析功能，为按钮和列表等UI元素分配唯一ID，以便标准化事件命名和元数据，进一步减少开发人员的工作量。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/uber-mobile-analytics-platform/&quot;&gt;https://www.infoq.com/news/2026/01/uber-mobile-analytics-platform/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/AIuL3zoje0zRZX7CgB2r</link><guid isPermaLink="false">https://www.infoq.cn/article/AIuL3zoje0zRZX7CgB2r</guid><pubDate>Mon, 19 Jan 2026 06:02:00 GMT</pubDate><author>作者：Leela Kumili</author><category>架构</category><category>安全</category></item><item><title>阿里云 CIO 全面深度解析：企业 AI 大模型落地实践「 RIDE 方法论」</title><description>&lt;p&gt;据麦肯锡发布的《The state of AI in 2025》全球调研报告揭示， 88% 的企业已在至少一个业务职能中常规使用 AI（如 IT、营销、知识管理），但  62% 仍处于实验或试点阶段，仅有少量实现企业级的规模化部署。我们可以理解为，当下企业的 AI 落地正呈现“高采用、低价值”的典型特征，多数企业卡在试点到规模化之间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/84/84bd4dfab1e1871019a3cc5867d459b9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;麦肯锡《The state of AI in 2025》报告&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;AI 应用进入深水区，竞争的核心已经转向规模化的落地能力，而非技术本身。这也指向一个重要问题：当下的 CIO 群体，想真正实践 AI 大模型在企业的有效落地，实现规模化价值，要化解过程中的诸多坑点与难点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本文整理自阿里云智能集团副总裁、 CIO 蒋林泉在 AICon 2025 年 8 月所分享的 “阿里云大模型应用落地实践之路”，并完整呈现他对企业AI落地的经典方法论“RIDE”和数字人案例。文中，通过规模化上线的 28 个数字人的成功实践经验，分享从组织共识挑战、业务机会识别，到 AI 指标衡量，再到产品工程落地的体系化思考，以蒋林泉的第一视角，解析企业 AI  真实落地的系统路径。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;第一视角观察&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是我自担任阿里云 CIO 三年以来，第一次对外发表演讲。此次分享浓缩我过去三年在阿里云带领团队推进数字化与智能化进程中沉淀的案例与经验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在担任 CIO 之前，我主要负责阿里云飞天核心系统的产品和研发工作，当时对外的演讲内容更多围绕飞天和阿里云的产品，角色也更偏向于“乙方”的产研身份。而今天，以阿里云 CIO 的身份首次对外演讲，更多是站在“应用开发者”的角度，分享如何在企业内部场景中推进数字化和智能化落地的一些实践与体会。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/1b/1b2533ae16f00775108b486dba8de950.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;阿里云智能集团副总裁、 CIO 蒋林泉&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去两三年，我带领团队致力于推动 AI 大模型在企业各类场景中的落地应用，在这个过程中有很多感触。想先谈一下，在这个阶段里的一些观察和思考。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在当今时代，我们常常会思考一个问题：一个人或者一个组织发展得这么好，到底是时代的原因，还是自己努力的原因？其实最主要还是时代的原因。我们能够发展到今天，很大程度上是因为坐在了一个很好的“电梯”。比如搭上了中国这个电梯，中国互联网的电梯，以及我所在的阿里巴巴这个平台的电梯。平台本身发展得很好，在上面自然也发展得很好。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;换句话说，在电梯里做俯卧撑，还是在平地上做俯卧撑？两者达到的高度是不一样的。个人努力固然重要，但更重要的是平台。我认为，在这个时代，AI 就是那个最大的电梯。无论是组织还是个人，有没有搭上 AI 这趟电梯，将直接决定在未来能够达到的高度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d8/d8c8ae65217f6c22f5268e44ab58a999.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;ARK INVEST 报告&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;根据 ARK INVEST 以往的一份调研报告预测，到 2030 年，算力性能相较于现在将增长 1000 倍。这是什么概念？在 AI 时代之前，我们常常讲摩尔定律，技术性能大约每 18 个月翻一番。而在 AI 时代，技术发展的速度被极大地加快了。如果不能及时搭上 AI 这趟高速电梯，大概率会落后于时代。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;基于这样的认识，我们发现，无论是企业还是个人，都开始逐渐意识到 AI 的重要性。意识到这一点后，许多企业，包括 CEO 和业务部门，开始变得焦虑起来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这就涉及到，这一轮科技革命与以往的科技革命最大的不同之处。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在整个信息技术产业中，无论是 PC 互联网还是移动互联网时代，技术在企业中的应用过程是一个渐进的过程，非常循序渐进。那个时候，企业的 CEO 看到业界的炒作、厂商的炒作，都比较冷静，可以慢慢来。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然而，这一次的情况却截然不同。我觉得这是第一次，企业 CEO 和业务部门比 IT 团队、比供应商还“上头”。因此，我们可以说，现在企业内部最大的矛盾，就是业务部门在社交媒体、PR 渠道里看到的 AI，往往呈现出一些“炸裂”、“梦幻”的效果，而 IT 部门或者说 CIO，在实际生产力上的发展却是不均衡、不充分的。这种矛盾体现得非常突出。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在阿里巴巴集团内部，以及我与业界几十位 CIO 交流的过程中，观察到，在企业内部，这种现象大量存在。企业中会涌现出很多 Idea，做出很多 Demo，上线很多技术平台，一个团队里，恨不得要搭好几套 Dify 平台，各种智能体平台都在搭建。但是，在这些过程中，还是技术主导比较突出，更多是拿着平台去做 Demo，业务方的参与往往比较浅层。这类现象在企业里是比较过剩的，可以说整个企业都充斥着类似的情况。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/78/78d6cdd7990881aa70079cdefc1c6083.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与此同时，我在企业中普遍观察到，很多方面的投入都严重不足：是否真正深入到业务本身去做价值识别，或去正确地定义产品，以及如何开展知识工程（注意，这里我们不再仅仅是传统的软件工程，而是知识工程），还有我们强调的业务专家知识动员。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，我们认为，如果要在企业里真正用好 AI，并且产生实际的业务结果，就要做非常大的投入。恰好，在这个领域，我们做了很多探索和实践。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;阿里云企业大模型应用实践落地&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来，想向大家展示阿里云内部企业 AI 大模型业务落地的全景图。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这张图中，我们可以看到很多“数字人”，无论是在阿里云的官方网站、CRM（客户关系管理系统）、业务支撑系统，还是在内容管理系统、人事管理系统中，这些数字人都已经广泛地落地应用，并在原来的业务中发挥真实的效果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在过程中，我们已经落地了大约 28 个数字人项目，从中挑几个有代表性的例子来分享，让大家更有体感。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ed/edf0d08a52ae28b3e83b7faee353744c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;AI 翻译数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大家都知道，翻译是大模型非常擅长的事情。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但在阿里云，我们遇到过很大的挑战。作为一家公共云服务提供商，为客户提供服务时，文档的作用至关重要（ ToB 的服务非常依赖文档）。阿里云拥有 300 多个产品，十几万篇文档，涉及上亿文字。其中有一个非常大的痛点在于“出海”，我们要出海到日本、美国、欧洲、印尼，还有土耳其，而我们的开发者要高度依赖文档，来操作云计算服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;问题在于，我们缺乏既懂本地语言，又懂云计算的人才，技术类的翻译必须同时具备这两方面的能力。但即使有足够的资金，也很难招聘到这样的人才。过去，我们只能选择“忍”，仅翻译了英文文档，以及部分日文文档，而其他语言的翻译工作基本停滞不前，这也导致海外开发者的反馈不佳。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这一轮 AI 技术突破之前，我们尝试过用传统 NLP 来做翻译，但效果根本不行。到了 ChatGPT 3.5 版本，我们发现自然语言处理技术，仍然无法满足我们的需求。而到了 ChatGPT 4 版本，我们再次尝试发现，翻译质量终于能和那些“既懂技术又懂本地语言”的专业译者打平。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而且，当时也做了计算（时间在一年多前），每篇文档的翻译成本，仅为当初专业技术翻译团队的 1/200。从那时起，我们开始大量使用大模型进行翻译工作，到现在，我们已经完成了印尼语的全部翻译工作。这意味着，解决了原本靠资金也无法解决的组织问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果用专业的评分来看，过去，用懂本地语言、懂技术的专业翻译团队来翻译，评分大约为 4.12 分（满分 5 分）。现在，我们用 AI 来翻译，评分能够达到 4.68 分。在海外市场，我们发现海外网站的用户体验以及 NPS（净推荐值）都得到了显著提升。因此，这不仅仅是一个成本问题，更是通过 AI 解决了过去无法解决的难题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;技术文档验证数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;刚才提到，阿里云有十几万篇文档，覆盖三百多个产品。其中，有一半是操作指南和解决方案，客户需要完全依照这些文档进行操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里一个很大的问题是：传统IT产品可能是半年或一年一个版本，文档和产品可以同步开发。但我们是互联网模式的 IT 系统，我们的情况是，线上功能不停迭代，功能的迭代和我们文档的一致性，就要实时保证。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原来，也是依赖外包团队进行文档验证和测试，由于“带宽”限制，只能解决中文文档的验证问题。每六个月会把所有文档“跑”一遍，去验证它们和线上功能是否一致，经常会发现有很多版本不一致的问题。但这个过程本身就有很大问题：首先一轮验证就需要六个月时间，当第一个月验证并修复好的内容，到第六个月，验证可能又变得不一致了。原来，我们一直没能把这个问题解决，导致客户经常会遇到功能与文档不符而操作不下去的问题，这就要求我们提供最新内容。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;现在我们是怎么做的呢？用 AI 来模拟这个过程：它会左边打开技术文档，右边操作浏览器里同步打开阿里云网站，然后严格按照文档里的步骤进行操作。过程中，AI一旦卡住或无法继续，就大概率意味着文档和实际功能不匹配。虽然少数情况是云产品控制台本身的问题，但绝大部分的确是文档与功能不一致。当AI发现不一致时，它会立刻把不一致的“单拎”出来，并自动创建一个Aone需求单。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们后续还有一个“文档修复数字人”，它会“接手”这个Aone需求单，分析实际情况与文档描述的差异，并做修复。然后，它会把这个修复好的文档，给到我们technical writer做确认，确认后就能上线了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这之后，过去需要六个月才能完成一轮的验证工作，现在只要一个星期。同时，我们现在也把这套验证机制应用到日文、英文以及其他语种上，确保国际站的功能和文档也能保持一致。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去靠人工验证时，一致率到底是多少？验证质量好不好？覆盖度够不够？这些其实都是一个“unknown”的状态。而现在，一切都变得清晰、可量化了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;网站 AI 助理数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第三个案例是网站AI助理。阿里云有几百万客户，那我们的自服务模式是怎样的呢？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们来看一组数字：每天大约 97% 的客户访问阿里云，都是通过自助操作，只有 3% 的客户会选择“提工单”。而在这3%的客户中，百分之七八十的任务也还是由自己解决的，只有极少数最终会变成需要人工介入的工单。所以，我们的客户绝大部分是自服务的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但即便如此，由于我们的客户基数太大，这“漏”进来的一小部分工单，依然需要我们服务团队投入大量人力去处理。在这些工单里，有一半都属于“咨询工单”。什么是咨询工单呢？就是客户遇到问题直接提问，我们的小二在后台查文档、翻知识库（Knowledge Base），找到答案再回复给他。这类工单纯粹是信息问答，不涉及操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这类工单主要有几个问题：第一是一半的工单服务成本很高，第二是个时效问题。我们统计过，过去一个咨询工单的平均关闭时间，绝大部分要到5个小时左右。也就是说，一个客户平均想要解决这种咨询问题，需要花费大量时间才能解决。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;网站 AI 助理上线后，大量的咨询问题已经由 AI 直接回答了，而平均响应时间是 10 秒左右。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，我们正在和服务团队合作，与服务团队共同承担全年工单降量，我们一起努力，希望通过 AI 在网站自服务的深入应用和渗透来实质拓展服务带宽，更重要的是，能够一起提升阿里云的客户服务体验。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;智能电销辅助数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;刚才讲的是服务，探讨了如何帮助客户解决咨询工单和自助诊断的问题，把服务体验提升了。现在来看另一个场景：销售。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;阿里云要服务上百万的企业，无法对每一家企业都用直销的方式去覆盖。因此，我们有很大一块业务是面向中小企业（SMB），通过电话销售来帮助我们客户实现售前咨询，以及售前购买的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;电话销售小二的日常工作，主要分为话前、话中、话后三个环节。话前： 小二需要做计划，规划当天要打哪些电话、了解客户的商机、准备话术，并排好优先级。需要这样一个准备过程，才能保证一天的工作有序高效；话中： 就是与客户的实际沟通；话后： 需要复盘，记录通话小结，整理哪些需要follow-up，哪些需要申请折扣。需要处理的问题都要记下来，这样才能闭环到后续的业务处理，形成一个完整闭环。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;现在，我们在这三个环节都提供了 AI 数字人。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;● 在“话前”，由AI来完成通话计划，包括怎么打，话术是什么。过去小二自己排计划要花半个多小时，现在一上班，计划就已经生成好了，可以直接开工。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;● 在“话中”，我们提供了一个智能辅助提醒。当小二与客户通话时，系统会根据对话内容，在工作台右侧实时提醒他如何回答，比如客户在说他想要这个，建议你这么回答。目前已经在辅助小二去解答客户非常复杂的一些云计算咨询问题。目前话中提示小二的采纳率已经达到了50%。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;● 在“话后”，像通话复盘、撰写小记、follow up，包括后续的通话质检，这些工作都交给了一个自动化的AI数字人来完成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过这种方式，我们的小二可以从繁杂的事务性工作中解放出来，集中精力在真正的销售沟通上，大幅拓宽了我们销售的服务带宽。同时，AI 的智能计划、实时辅助和后续复盘，也极大地提升了我们服务客户的质量。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;智能质检数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;AI 应用到电话质检之前，这几乎是一个原理上无解的事情。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原来我们大规模的外呼电话作业过程，是非常难被知晓的。比如中间过程是否按照公司的作业规范进行？与客户的沟通是否足够礼貌？更有时候，有的外呼人员可能会把客户引导到私下公司去联系、去成交。但原来，我们是很难去做这个电话质检的，因为这是语音作业，很难管理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而现在，我们用 AI 把所有的电话语音全部智能化，从而识别里面所有的这些问题，再通过统一的质检标准，就能够得到一个规模化的质检。于是，这个AI质检能够大规模地提升我们的服务质量与效率，覆盖全量业务场景，关键还能控制我们的业务风险（避免产生额外的风险）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;可以说，这件事我们原来几乎是无法搞定的，因为原来是靠抽样，也就是人工抽样去听那些电话录音，如果抽样抽到了问题，再去一个个处罚，但效率是非常非常低的。它的抽样完整性、抽样覆盖度都几乎是没法被使用的（覆盖度仅有2%），不同质检员的判断差异也很大，对人力的消耗也很厉害。所以，现在通过AI质检数字人，能够让覆盖度提升到100%，质检的准确率也远高从前，带来的最终效果是非常好的，这使得整个服务质量能够规模化地提升上去。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;智能外呼数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;刚才我们讲到AI如何辅助做事，这里则是一个能直接进行智能外呼的数字人。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;众所了解，云计算本身是非常复杂的，如何招聘到足够多的外呼坐席人员，让他们既具备相关技能，又熟悉云计算知识，同时还能够耐心地每天坐在工位打一天的电话，这对我们来说是一个巨大的痛点。因为招聘和能力培养难度很大，人员流动率非常高，这使得无论是销售服务，还是电话服务的质量，都存在明显的短板。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本质来看，这是一个短线影响业务增长，长线影响服务满意度与企业品牌塑造的问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们在前期已经有一定的知识积累，包括语音、多模态等方面的经验，因此，我们通过 AI 的方式直接引入智能外呼。它直接上场，与我们的客户沟通，挖掘销售商机，交付给服务团队去做主动的服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，在潜在客户的线索清洗、免费试用、转生产、以及产品即将到期的续费提醒等主动外呼场景中，这个数字人已经上线运行了。目前，我们还在开发场景包括产品到期的主动关怀、NPS 调研等，上线后，预计可以拓展出“能交付结果的”上百个 HC 的服务带宽。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;数字 AI 客服的外呼，还有些不一样的特征。首先，它可以灵活、快速地按需扩容，而且，它的声音可以做得更甜美，也可以做得更有情商。更重要的是，在技术的不断加持下，这个AI小二解决问题的能力，可能已经超过了原来人类员工的平均水平，而且还在不停地提升。目前，我们的智能外呼数字人可以像“金牌销售”一样工作，非常接近真人体验。未来会有更多的想象空间，让它能够更好地服务阿里云客户，提升我们的服务质量。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;直销辅助数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;分享了很多电销案例，这里谈谈“直销”场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在阿里云的直销业务中，我们面临着一个核心挑战：销售如何变得更加专业和高效，促进公司业绩增长？在实际工作中，我们的销售团队遇到了两大业务痛点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一个痛点：云计算销售要求高、招聘难、培养成本高。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;云计算销售不仅需要具备良好的客户拓展能力，还需要深入理解云计算技术与行业应用场景。复合型人才稀缺，招聘难度大、周期长，新人从入门到胜任，需要经历数月的培训与实战积累，培养成本居高不下。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二个痛点：销售运营专业服务带宽不足。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;销售运营、数据BI、财务、法务等运营中台的服务带宽，无法充分支撑前线销售需求，难以及时响应每一位销售人员的专业支持诉求。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了解决这些问题，我们将整个销售流程分为“拜访前”和“拜访后”两个关键环节，在每个环节都提供AI数字人的全方位支持。核心围绕销售作业的有效性展开，让直销过程实现“在线化”，全面提升销售过程的辅助效率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;拜访前：销售“一键”获取客户“谈参”，了解客户用云信息、技术类型、解决方案、竞对情况等全面画像。过去，销售自己从各渠道去查询要花1个多小时，现在，10分钟就能查询到，而且信息质量更优、内容更全面，有效促进了与客户key person的高质量拜访。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;拜访后：我们提供AI对拜访过程的全方位复盘，包括商机要点是什么，客户对阿里云品牌表现出的情感倾向是什么，建议后续怎么推进客户成单。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过AI软硬结合的优势，我们让直销的销售过程实现“在线化”，高质量拜访小记达到100%全面覆盖，新销售也能通过高质量在线信息资产快速学习，上手周期缩短50%，大幅降低新人培养成本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种方式，相当于拓展数百位专业销售运营为销售团队“贴身辅助”，销售人员得以从繁琐的流程性工作中解放出来，能够更专业、更高效地服务客户，大幅提升了销售有效性，有力促进了公司业绩增长。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;合同风险审核数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;ToB 业务的一大特征，是有大量的政企和大客户，他们通常不会使用我们的标准合同。这些合同金额巨大，需要进行严格的风险审核，涵盖财税法、风控、信控等多个方面的风险。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去，要完成这样的风险审核，我们需要专业的法务、财务等领域的精英人士，他们大多来自国际四大会计师事务所。然而，鉴于我们业务规模庞大，不可能招聘到足够多的精英来从事这项工作。因此，我们在合同风险审核方面遇到了巨大瓶颈，审核时间过长，最长甚至可达 5 个月，平均也需要两周到一个月。这极大地拖累了业务效率，包括服务大客户的效率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了解决这一问题，我们培养了一大批“数字人”，包括财务数字人、信控数字人和法务数字人。并且，把这些数字人送到合同撰写端，让他们在销售和客户沟通、合同拟定的瞬间，就能够实时识别潜在风险并提示谈判方案，而不是等到审核端后才发现问题，再回过头去处理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在合同审核端，我们通过审核标准数字化、专家经验数字化，用统一的标准执行，极大提升了准确率。而AI也正是实现知识工作线下流程线上化的体现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过AI技术，我们不断拓展中后台的服务带宽，解决商业拓展流程中的效率瓶颈。后续，我们也期望它在风险拦截上的能力，能够持续提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;员工服务数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为什么特别提到员工服务数字人？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因为大型企业里，HR 系统有一个显著特征，就是非常分散。比如请假、体检、福利、在职证明等，各式各样的流程和服务都散落在不同的系统里。与此同时，各类政策也同样分散，包括公司内部的福利政策、外部的人才政策等等。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;员工在需要获取这些信息或使用这些系统时，会遇到两个难点：第一，这些服务是低频使用的；第二，它们分散在不同地方，获取难度非常大。由于是低频服务，无法配备一个庞大的服务团队来支持，所以 HR 团队的负担很重，而员工的服务体验也不足。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了解决这一问题，我们将这些低频、分散的服务全部整合到一个智能体中，通过钉钉平台打造了一个“云小宝”（数字人），为员工提供统一的智能服务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们发现，通过引入智能体，折算下来相当于节省或新增了几十名员工在为大家服务。更重要的是，员工的体验得到了极大提升，比如，我们服务员工的响应时长已经从平均7.2分钟缩减到5秒。再比如，员工只需要用自然语言输入，如“下周一请假”、“国庆前后两天请假”或“为父亲预约体检”，系统就能迅速响应并完成操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h5&gt;面试智能辅助数字人&lt;/h5&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;还有一个场景，我们聊聊招聘。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先，我们对外招聘，核心是描述我们需要什么样的人。从这个角度出发，前置是OKR，我们通过AI分析每个部门日常在做什么，目标是什么，根据日常目标和事情，去看清楚招聘的JD（职位描述）是不是合理。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;再者，从JD开始，根据岗位要求，再结合当前的候选人简历信息，在面试的时候就会生成面试计划。面试时，结合岗位要求，面试官应该问哪些问题？根据最佳实践，怎么去考察候选人？这些专业问题在面试前，已经帮面试官提供好。面试中，通过对话过程，发现应该追问哪些问题，以及面试后，怎么总结面试过程中候选人是不是qualified这个岗位。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;通过AI，我们可以更结构化、体系化地来做这件事，使得面试过程管理，面试质量，以及对面试人评价的客观性，都得到很大的提升。这也彻底改变了原来仅仅通过电话形式的面试，因为它的过程是一个黑盒逻辑，而“黑盒”最大的问题是无法提升过程的质量，包括保持长期的、闭环的有效性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对一家公司来说，招聘是件非常严肃的事情，我们经常讲，如果招错一个人，会导致后面的事情是非常糟糕的。所以本质上来讲，面试智能辅助数字人，提升了我们整个组织在招聘进人方面的有效性。这不只是效率问题，而是能够规模化促使我们在面试过程中的专业性、面试评价的专业性得到质的提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;28个数字人全面上岗，真正产生业务价值&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f3/f3c3e51ab6dca7d2a3779dedeac199a8.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，我们有二十几个场景实现了数字人的智能化服务，这里只是挑选了10个来举例。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这些数字人应用背后的评估衡量，有一个共同逻辑：&lt;/p&gt;&lt;p&gt;一是折算拓展了多少人力；&lt;/p&gt;&lt;p&gt;二是业务效率提升了多少；&lt;/p&gt;&lt;p&gt;三是业务效果提升了多少。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们非常注重这一结构，因为每一个数字人上线落地，都必须衡量其对原来业务是否真正拓展了服务带宽 ，并且，是否比原来人工操作的效率和效果更好，这是非常关键的，与外界所谓的众多智能体最大的区别，就在于此。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这些智能体最终都是在对应的岗位上实际工作的。在我们的 HR 系统中，这些数字人被分配到对应的业务部门，向对应的业务团队汇报工作，与我们从外部招聘的员工没有任何区别。所以，它们必须在对应的岗位和业务团队中，发挥超过一定人数的实际任务执行作用，才能真正融入团队。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在我们的钉钉系统以及内部工作系统中，这些数字人与普通员工一样，拥有工号和头像。唯一的区别在于，它们的工号以“AI”开头，如 AI001、AI002，目前我们已经有大概 28 个智能体上线，后续还有更多智能体在排队等待上线。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然，在过去两年，带领团队推进业务落地的过程中，我也深刻体会到，真正将技术应用于业务并取得成效，没有那么简单。特别是，真正在业务中产生价值和仅仅做出一个 Demo 之间，是天壤之别。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来，想和大家进一步分享，我们在这一过程中遇到的困难，以及总结出的一些解决方法，希望能对大家有所帮助。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;大模型 E2E 落地坑点与解法 —— RIDE&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大家可能听过红杉提出的一个概念叫&amp;nbsp;RaaS，即“结果即服务”。这一概念的核心在于，如果仅仅提供工具和产品，让企业自行落地是不够的。所以，我们特别重视真正上线，并产生业务结果的项目。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我作为 CIO 所带的团队，在企业内部为业务部门提供的，就是这种&amp;nbsp;“以交付结果为导向的服务”。在推进 RaaS 的过程中，也总结出一套方法论，叫&amp;nbsp;RIDE。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e4/e49d732c30605558b4469bd17b2a70da.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;RIDE 包括四个关键步骤：Reorganize（重组组织与生产关系）、Identify（识别业务痛点与 AI 机会）、Define（定义指标与运营体系）、和 Execute（推进数据建设与工程落地）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;首先是&amp;nbsp;Reorganize。在 AI 时代，新的生产力下，原来的生产关系是非常不适应新生产力的发展，这种不适应会在每个毛孔里面表现出来，然后阻碍 AI 的发展和落地，所以要求我们要重新调整生产关系。第二，是&amp;nbsp;Identify。也就是我们需要精准地识别出企业中哪些问题适合用 AI 来解决，这要求我们首先明确问题的定义，然后结合 AI 的能力和业务需求，确定哪些问题可以通过 AI 得到有效的解决。然后是&amp;nbsp;Define。在明确了问题和 AI 的能力之后，我们需要精准地定义产品及其运营指标，进行准确的指标跟踪。最后才是&amp;nbsp;Execute。执行阶段是一个金字塔结构，上面是业务目标，下面是工程数据和评测，中间是工程应用算法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然，这套我们称之为 RIDE 的方法论，并非在做 AI 转型的第一天就有了，而是在二十多个智能体真正有效落地业务的过程中，我们发现，如果不遵循方法论中的这些步骤，项目很可能会失败。遵循这些步骤，虽然不能保证 100% 的成功，但至少可以提高成功的概率。这是一套用两年时间、用血泪经验总结出来的方法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Reorganize ｜重组组织与生产关系&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;书同文、车同轨 ：AI时代的通识教育&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们首先从&amp;nbsp;Reorganize&amp;nbsp;开始讲。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在落地第一年，我发现了一个问题：无论是业务团队还是我们自己的团队，对大模型的能力边界、发展程度、具体原理等基本概念的理解都存在差异，甚至在我自己的团队，产品经理、算法、工程团队内部都无法拉齐概念认知。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;为了解决这一问题，我们发起了一个行动，叫&amp;nbsp;“书同文、车同轨”。&amp;nbsp;我们要求全员参加&amp;nbsp;AI 大模型的认证培训。最主要的原因，是要解决大家在基本功和认知逻辑上的差异。我称之为&amp;nbsp;“AI 时代的通识教育”，相当于要在团队里重新走一遍“高中的教育”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一培训分为两类：大模型ACA认证（面向非技术人员）、 大模型ACP认证（面向技术人员），因为我们不仅需要技术人员之间能够对齐话语，也希望非技术人员和技术人员对齐话语。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种通识教育对于团队的协作至关重要，首先在我们 CIO 线内部已经完成了全员的认证，后面，我们的业务方，也就是我们的财务、人力、销售、中后台等都在做&amp;nbsp;全员认证。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，整个阿里巴巴集团都在用这个方法来做 AI 转型的基础教育，重新建立大家的基础认知。不然就会出现这种情况：大家都在谈论同一个概念，但其实理解的内容和现实完全不同。如果没有做过深入工作，很难体会到那种无力感，一旦通过通识教育统一认知，沟通效率就会显著提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/32/3210b1f4ab3dd2665737f14423be6824.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;阿里云大模型ACA认证：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://edu.aliyun.com/certification/aca13?spm=a2cwt.28380597.J_1564692210.17.28813487dUqGKW&quot;&gt;https://edu.aliyun.com/certification/aca13?spm=a2cwt.28380597.J_1564692210.17.28813487dUqGKW&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;阿里云大模型ACP认证：&lt;a href=&quot;https://edu.aliyun.com/certification/acp26?spm=a2cwt.28380597.J_1564692210.18.28813487dUqGKW&quot;&gt;https://edu.aliyun.com/certification/acp26?spm=a2cwt.28380597.J_1564692210.18.28813487dUqGKW&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;「企业免费体验」大模型认证：&lt;a href=&quot;https://edu.aliyun.com/learning/topic/llm-free-trial&quot;&gt;https://edu.aliyun.com/learning/topic/llm-free-trial&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这样的基础上，又设计了两个比赛。一个是产研提效比赛，一个是业务提效比赛。和其他大赛最大的不一样，我们的比赛是真正以 E2E 为衡量标准的。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比如产研比赛，我们要看的，是原来 E2E 同样粒度的一个需求，需要多少“人月”完成，而现在能减少到多少人月。而不是看代码采用率，因为代码采用率很容易“灌水”，而且它往往只能补全那些最容易写的代码，最难的代码可不容易补全。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在业务 E2E 方面，我们的比赛就是要真正进入业务场景，帮助业务去拓展，而且效果和效率都要超过原来。所以，这两件事非常重要，第一，是做“书同文，车同轨”的通识教育，因为 AI 时代的知识在不断发生巨变，每个月都在变，现实的实践知识和原来的基础知识都有大量的不同；第二，是“以赛促练”，整个组织通过正确目标下的比赛，大家会发现短板，发现相互之间可以学习的地方，就能够激发组织不断地去创新、去提效。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;数字员工 ：业务方与IT方 联合培养&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;再说说我们的数字员工。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;有一个非常关键的安排：我们的这些数字人最后都是汇报给业务部门的。这不仅关乎形式，更重要的是心理。我们不能让业务部门觉得，AI 技术会威胁到他们的工作，而是要让他们明白，AI 技术是来帮助提效的。如果这个关系没处理好，就会遇到无数的暗礁。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/88/88e14865fc7aa21a7640472b6bec9423.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以，我们把自己定位为数字人供应商，业务部门是 AI 先进组织，业务部门可以雇佣我们的数字员工，并与我们一起联合培养。&amp;nbsp;这样，业务部门会更愿意接受 AI 技术，减少阻力。所以这是第一点，我们把自己退到一个外包供应商的位置上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二点，我们还发现，AI 数字员工是不能扛责任的，也不能给它打“3.25”（低绩效）。这意味着，数字员工在系统里执行任务出了问题，谁来承担的问题。我们将 AI 数字员工汇报到业务部门，属于业务部门的人（让他们放心），并一起参与 AI 员工的培养过程，同时数字员工也会受到正式员工的监督，来承担相应业务领域的责任。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;定标准 ：AI要与人比，不与“神”比&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另外，我们经常听到一句话：ToC 还好，但 ToB 的大模型有幻觉，做不到 100% 正确。但实践经验告诉我们，其实人也有幻觉，而且人的幻觉还很大。如果认真看，在很多任务里，人其实也是不靠谱的，也经常会失败，只是企业没发现而已。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们强调的一点是：如果 AI 项目和业务部门真正达成了共识，并且通过培养逐步磨合，就必须认真回头来看，AI 的要求标准到底是什么？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果要求 100% 正确，其实就是把 AI 拿来和“神”比。但如果是和原来人做事的效果和准确率去对比，那就是和“人”比。所以，追求比人做得更好、更准，才是真正有意义的对标。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;那怎么避免和“神”比呢？回到前面所说，解决生产关系的问题，处理好内部业务的逻辑、目标和关系，这样才能真正实现 AI 和人比，而不是和“神”比。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/fc/fc59a744ddd066e6b79446f598c0a184.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在整个&amp;nbsp;Reorganize&amp;nbsp;的过程中，我们还发现，要把数字人汇报到业务部门，对 HR 部门来说，这就等同一个“正式员工”。注意，我们是真的把它当作正式员工来看待的，用它能否产出真正的业务结果来度量。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以我们在内部与 CPO（HR 负责人）沟通时，讨论过：怎么去度量 AI 数字人是否真的发挥了一个正式员工的效果？最后，我们确定了一个方向：AI 数字人必须有一个目标，就是在原有具体的业务流程里，接管一个重复且有价值的任务，并且能够折算出“相当于拓展出多少人力”，这就是唯一的目标。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但要&amp;nbsp;真正让数字员工上线、上岗，必须满足两个标准条件：&amp;nbsp;一是数字人执行原来任务的效率，一定要比原来提升一定百分比，一定要比原来执行任务的人效率高；二是数字人执行任务的效果，同样，也要比原来提升一定百分比。只有当数字人做到效率高、效果好时，才能“正式上岗”，进入业务部门工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Identify ｜识别业务痛点与 AI 机会&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;从三个特征，挖掘AI机会&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;刚才讲的是&amp;nbsp;Reorganize，如果不解决 Reorganize 的组织问题就会不断遇到暗礁，甚至没法往前走。但解决了组织的问题后，业务部门会说，好，我们来联合培养数字员工。那从哪里开始呢？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以第一件事就是业务机会的识别（Identify）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b2/b2496e59b238364c5d2bc83c77059b1e.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这轮 AI 革命的核心其实是 LLM（large language model），所以，我们在内部有一个逻辑：所有以 language 为中心的工作，都将被大模型深刻影响。比如电销、客服、招聘、OKR、文档、翻译、合同审核，还有研发类的 C language、Java language、SQL language 等，这轮以 language 为中心的工作受影响最大。所以第一个特征是&amp;nbsp;Language 类&amp;nbsp;工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二个特征是被重复执行、规模化执行。因为 AI 是自动化的，越大规模、越重复的任务，AI 越有机会去做。第三个特征是，如果本身缺人，甚至有人投诉效率低，那这个地方就是个大的机会。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这三个特征，是我们与业务部门一起来 Identify，识别哪些业务是可以着手的。这也是我们在内部形成共识后，如何去识别机会、定义机会的关键点。因为只有把问题定义清楚了，后面做事才会顺畅。如果解决错了问题，那投入就白白浪费了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;数字员工，以“单任务”为核心换算&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另外，我们刚才讲到，数字员工要在对应的任务里拓展目标，也就是拓展对应岗位的人力，实际面对各种场景具体怎么处理，又怎么核算？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f3/f33e3f605ada391bc70ba68a0fa1f467.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们的经验是，首先，有些“单任务岗位”，比如技术翻译，我们是按字收费的，那么，AI 翻译一个字多少钱，就可以直接线性替换了。一个人一天的产能可能是翻译 2 万字，那我们就差不多折算成 “2 万字的产能”等同于“一个人”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果是“多任务岗位”，比如产品经理，他一会儿做 PRD，一会儿分析工单，一会儿画 Demo，一会儿又去客户那里访谈。这种多任务岗位，我们发现往往有些任务是重复的、繁琐的，也不是高价值的。为了提效，非常适合将这些低价值任务，拆分成一个个“单任务岗位”，如工单分析岗位、产品原型设计岗位等，让数字员工去做。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这样，原岗位上的人就从繁琐工作中卸载出来，可以聚焦在更高价值的主线工作上，他们的幸福感也会爆棚。在换算方面，最终也都是”以单任务岗位为核心进行HC换算”，逻辑清晰明了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种方式原先主要是由外包承接，但受制于外包员工管理难度大、成本构成多、招聘周期长、稳定性低、用工风险高、能力上限低（薪资因素）等诸多原因，多方面都受到约束，无法大面积展开。当我们有了数字员工之后，自然解锁了这些约束，&amp;nbsp;这件事就变得更加切实可行。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Define ｜AI 的产品度量与运营度量&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;准确率是AI产品核心&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过了&amp;nbsp;Identify&amp;nbsp;这一步，下面就是&amp;nbsp;Define。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这个时代和以前做产品有很大不同。我们前面提到的一些产品大多都类似，比如都有交互、体验。在这个流程里，其实和上一轮移动互联网的产品没有区别。但&amp;nbsp;AI 产品有一个特别关键的点，就是“准确率”。&amp;nbsp;当然，除了准确率之外，还有响应时效性和安全合规等非功能性指标，比如在电销过程中，和客户实时对话，延迟必须非常低，不然客户会觉得交流效率不高，像机器人说话一样。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/9b/9b45111fb0badee9130ac4bc4cf4cb6f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此，实时性和准确性非常关键。如果准确性不够好，客户根本无法使用，也根本不可能真正上岗。所以，准确率是 AI 项目的第一核心指标，整个项目组都必须盯住它，这也是产品定义中最核心的部分，必须重新去&amp;nbsp;Redefine。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;运营与产品指标「协同度量」，才不掉坑&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此外，运营指标同样至关重要。如果只有产品指标和准确率指标，那大概率会掉到“坑里”。即使是在对内的业务项目里，原来移动互联网那些基本功也不能丢，比如：&lt;/p&gt;&lt;p&gt;DAU（每日活跃用户数）；用户提问数；渗透率，即目标客户的覆盖率；留存率（最关键）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果同一个客户今天用了，下周还愿意继续用，说明这个 AI 智能体真正帮他解决了问题。如果客户只用了一次就不再回来，那么无论前面的产品指标再漂亮，都没有意义，那可能就是定义错了问题。运营指标就是用来兜底的，如果不紧盯这些指标，很容易让产品、工程和算法团队陷入“自嗨”。什么叫自嗨？就是他们说“我的指标很好”，结果客户根本不用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;举个例子，在阿里云官网的 AI 助理中，我们就设定了这样的度量方式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如下图所示，左图展示了准确度的度量指标，时间线大约覆盖从去年到今年的一年时间。蓝色区域代表表现良好的部分（精准解决了客户的咨询问题和任务），黄色区域为中等水平（虽解决了任务，但伴有大量无关信息），红色区域则是表现差劲的部分（回答与客户问题完全不相关）。中间图展示了 DAU 和客户问题数，右图则是留存率。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/69/69aea369bbf9588752408a3a661b13a5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，我们的留存率实际上已经达到了一个相当高的水平（PPT中并未刷新数字）。从图中可以清晰看到，随着准确度的持续提升，DAU 和留存率也在稳步上升。但是反之，如果 DAU 和留存率始终停滞不前甚至下滑，即使你的工程和算法团队声称准确率很高，那无疑是自欺欺人的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;实际上，很多工程算法团队成员，可能并未意识到上述这一点。之所以能明确指出，是因为在左图的准确度指标上，我也曾经被多次误导，但这也并非团队有意为之。在如今的信息环境中，随便搜索公众号就能发现大量类似“用这一招，你的准确率能提升到 95%”的文章，但这些文章往往存在误导性，它背后都有一个前提条件，即在某个狭窄的小场景下，准确率能够达到 95%，然而在面对海量问题时，这一指标却难以提升（这一点稍后会详细分享）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Execute ｜推进数据建设与工程落地&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;掌握「产品研发工程金字塔」&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;定义好了产品和运营指标（Define），往下走才是执行（Exectute）阶段。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Exectute&amp;nbsp;阶段的关键在于：一定要用产品和业务目标来拉动。因为在牵引拉动的过程中，才能充分动员领域知识专家的参与和评测。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果没有知识专家的深度参与和强大的评测能力，大模型的应用上限是很难提升的，这是第一点。第二，如果项目目标缺乏价值，或者没有真正的痛点，那么会发现得不到资源的“祝福”。也就是说，一方面难以获得其他团队的配合，另一方面自身团队的价值感也难以维持，这将直接影响项目的推进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b3/b32b199df39f232cd6c8a4b1f77f6b2d.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在整个执行逻辑中，金字塔最下面是工程的数据与评测，我把这个放成最大的一块底座，因为这是基石——业务数据、业务 API 以及评测能力是大模型应用的基础，对这一部分的投入必须充足。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这一基础上，才是工程应用算法、预训练（Pre-training）、RAG 以及微调等等，这些在媒体报道里面出现的技术热词，并非不重要，但这些只是&amp;nbsp;“必要条件”。我观察到，大多数产研团队在这部分（工程 - 应用与算法）投入了 80% 至 90% 的时间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但想强调的是：这些只是必要条件，仅靠这些无法解决企业 E2E 落地的问题。哪怕你在必要条件上投入再多，再加 10 倍的努力，也无法实现真正的 E2E 落地。因此，必须设法补齐真正实现 E2E 落地所需的充分条件。&amp;nbsp;如果无法做到这一点，项目成功的希望将十分渺茫。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;常见的LLM AI应用范式：翻译、Agent&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在与业务团队沟通以及处理各种复杂问题的过程中，我们总结出了几种常见的模式：&amp;nbsp;首先是基础设施层面，涉及知识和数据的构建；中间是编排和调度，无论是大家熟悉的工作流编排，还是智能体自主规划编排，或是两者的结合；最上面是对客的产品与运营。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里，重点讲述图中深蓝色部分的两种模式：第一个是翻译模式，第二个是 Agent 模式，我认为主要分为这两种典型的应用模式。其中，翻译模式最容易取得成效，因为它相对简单；而智能体模式则较为复杂。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/7d/7d19b513a0cc83ac769f6db55472de5a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;翻译模式：关键在“蛋糕坯”&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;先谈谈翻译模式。&amp;nbsp;在公司内部，我们将所有翻译类模式统称为 AI 领域的“低垂果实”，这类模式相对容易实现。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一轮的大型语言模型背后的算法是 Transformer。Transformer 最早是 Google 为了翻译任务而开发，在不停做翻译的过程中衍生出了 Transformer 算法。随后，预训练模型如 BERT 也大量应用于翻译领域。所以，大模型的原理 Transformer 特别擅长做翻译。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;翻译又可以分为狭义翻译和广义翻译。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;狭义翻译指的是中译英、英译中等语言之间的转换。而广义翻译则涵盖更广泛的形式，比如：自然语音转成文本，再转成语音；自然语言转成 SQL 语言；自然语言转成 Java 语言；甚至让一篇论文用自然语言“翻译”成中学生能听懂的表述，这些都属于广义翻译范畴。无论是狭义翻译还是广义翻译，Transformer 都特别擅长，因此这是最容易出结果的地方。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a0/a03ff9f85ee03396d4af733c98d5a773.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但这里有一个坑：&amp;nbsp;虽然（图中）左边的翻译能力已经具备，但如果右边原有的系统还没准备好（not ready），就会出现问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;以 Chat BI 来说，为什么 Chat BI 在企业里没什么成功的案例呢？其实很大一部分原因在于，Chat BI 的逻辑无外乎就是：用自然语言翻译成 SQL，然后在后台的数据库或大数据系统里执行，再把执行结果取出来，再翻译成自然语言返回给人。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Chat BI 的实质，就是自然语言 → SQL → 执行结果 → 自然语言，这本质上还是一种翻译。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但我们会发现一个很有意思的问题：很多企业说要上 Chat BI，但如果原本数据库和里面的业务逻辑、数据口径积累不足，甚至连人都写不出对应的 SQL 来，那自然语言也一样翻译不出来。因为后台本身没有可执行的基础。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以我认为，企业里绝大部分在 Chat BI 上踩的坑，都来自于一开始就想做一个过于“宽”的东西。但是做了这个翻译之后，如果原来的系统 API 没准备好，数据没准备好，甚至连原来的人都无法执行这些操作，那自然语言翻译也没法落地。这就是最大的误区。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;因此我们在内部的逻辑是：要先Identify 原系统具备哪些能力。比如，如果你原来的 ODPS、数据库和数据中台本身已经有 BI 和运营，能够在某个领域里不断取数、用 SQL 分析数据，而且业务场景也很丰富，那么，那些高频的 SQL 语句才是真正值得作为翻译目标的部分，而不是盲目地去做一个 Chat BI。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以很关键的是要分成两个部分 ：一部分是翻译，一部分是原来系统的语言处理能力。我习惯这么来形容：原来的系统就是“蛋糕坯”，大模型翻译就是上面的“樱桃”。如果你现有的蛋糕坯是 ready 的，我放一个樱桃上去，你就可以吃樱桃蛋糕了。但是如果原来的蛋糕坯都没有，你让我做一个樱桃蛋糕，是做不出来的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里非常重要的一点是：要能够识别出原来的蛋糕坯是不是 ready ，然后在上面放上你的樱桃，而不是直接拿一个樱桃就装作是樱桃蛋糕。这个地方往往就是个误区。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;翻译模式是“低垂的果实”，容易做，但里面其实有非常多的坑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Agent 模式：关键在意图与知识空间&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;再说&amp;nbsp;Agent 应用模式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大家可以注意这样一句话：所有的 Agent 应用模式都是始于用户意图，终于意图满足。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果你不是从用户意图出发，最后又不是以是否满足客户意图来作为度量标准，去看待你的智能体，那一定会失败，没有任何成功的可能性。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这是我发现团队，甚至整个业界，最容易出现的问题。因此我们引出了一个方法，这是我在内部做智能体时，一定要去践行的方法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一件事情，要找到这个领域的“意图空间”。&amp;nbsp;当一个客户在智能体里和你交互时，他一定是带着意图的。那么这些意图都有哪些？比如客服场景里，客户会提出各种咨询问题，这些问题本质上就是一个空间、集合。所以，第一步就是要搞清楚这个集合的&amp;nbsp;边界和完整性。如果你不知道它的完整性，就无法去度量。只有在建立了完整的意图空间之后，才能继续往下做。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;于是，第一件事要建立意图空间。然后，当清楚地知道了意图空间，就要基于这个意图空间来准备&amp;nbsp;知识工程。也就是说，你的知识、文档是否完备？API 和结构化数据是否具备？能否真正满足客户的这些意图？我认为这是最基础的必要条件。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ec/ec59798c52a3434dbee1855bf4222dd3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;再者，有了知识、意图空间，接下来才能带着意图去做评测。&amp;nbsp;因为既知道用户的意图，也掌握了知识，这样才能真正开展工作。如果意图不清楚、知识不具备，其实就是“空转”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们的经验是：在客服场景里构建意图空间，从原来就在满足意图的领域出发，从&amp;nbsp;工单&amp;nbsp;里去分析和构建意图空间。有了意图空间之后，就可以对意图进行分类。分类完成后，再根据不同类别去检查和补全知识，做好知识工程。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这样，当&amp;nbsp;意图空间&amp;nbsp;和&amp;nbsp;知识空间&amp;nbsp;都建立好了，才有可能开展评测，也才知道如何去度量你的 Agent。只有具备了度量能力，才有可能进一步做工程和算法迭代，这个是原理决定的。这也是我们在内部做智能体的一个必修课。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里，简单总结一下两个模式： 翻译模式是樱桃，一定要先找到原来的蛋糕坯在哪里，再把樱桃放上去。如果蛋糕坯不 ready，只放个樱桃一定会失败。而 Agent 模式的关键则是：始于用户意图，终于意图满足。&amp;nbsp;这是一系列完整的逻辑方法。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Agent 落地要点：意图空间、品味&amp;amp;评测&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;接下来，我们就展开讲这个稍微复杂一些的 Agent 模式，看看在业务体系里实现 E2E 落地的一些关键要点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/0b/0b387cad2e57fd680552b6106c750368.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一，对意图空间的投入进行 ROI 评估。做一个 Agent，它的 ROI 高不高？这取决于意图空间的大小。如果工程所需的知识量庞大，意图也非常多、非常宽，那么所需要的投资就会非常大。意图空间越大，为满足这些意图所需要的知识、工程和迭代的投入也就越大。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以有一个非常清晰的结论：第一件事情，就是要控制意图空间的规模。如果不控制规模，会导致失败，因为后续的投入很难支撑。这里要记住一句话：如何去控制一个智能体的意图空间？如果没有控制好，或者不清晰，那么 ROI 根本算不出来。而一个算不出 ROI 的项目，成功的可能性将大打折扣。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第二，&amp;nbsp;我们经常讲，最近大家肯定也听说过，在 AI 领域里经常提到一个词叫“品味”。AI 时代里，品味非常重要。&amp;nbsp;那么品味来源于哪里？我自己猜测，要追溯到 1995 年乔布斯（Jobs）的一次采访。当时记者说：听说你比较粗暴、独裁，你怎么知道你的决定就是对的？乔布斯想了大约 10 秒，回答道：“归根结底，最后是品味决定的。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;品味和这一轮 AI 的关键问题——评测——高度相关。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/0e/0e5d44b291935bf9a2538dfc67f28ffe.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一轮和上一轮 AI 革命最大的区别在哪里？&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;上一轮深度学习主要是计算机视觉。那时候的数据评测怎么做？一张图给猫、狗、交通灯、汽车、人等等打圈，数据打标就是这么来的。所以评测时，只需要看分类对不对（猫有没有被错分成狗？对了就好）。ImageNet 就是这样做的，李飞飞当年找了很多外包团队来做标注，这种标注工作很适合外包，找普通人就能做。原因很简单，猫狗识别不难，就算是一些专家领域，比如故障识别、次品检测，标注也相对容易。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但这一轮情况完全不同。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大模型的输入是小作文，输出也是小作文。在专业领域尤其如此，很难直接度量。这就是为什么要强调品味——因为没有标准答案。我们都是经历过高考的。高考作文有没有标准答案？没有。开放题，比如写一篇中心思想总结，有没有标准答案？也没有。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;大模型的评测正是如此。所以，这一轮大模型最关键的区别在于：度量数据、评测没有标准答案。既然这是没有标准答案的，意味着成本最高，也就成为落地的瓶颈。&amp;nbsp;如何解决这个瓶颈？只能重投入。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Agent 落地要点：如何做好「评测」&amp;nbsp;&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然，这里讲的“品味”，就是如何做评测的问题。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/95/954a3b39d3b94c4660a5d04eb8f29e4a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们怎么去评测？评测是一件非常重的事情，这包括业务效果的评测能力，也包括评测本身的工程化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体来说，在人工评测中，我们如何去解决分类的标准问题？什么是“好”，什么是“中”，什么是“差”？如何能够确保，评测对真实业务意图的覆盖度是足够的？如果覆盖度足够好，标准也足够清晰，我们又如何通过工程化的方式，对系统的迭代和变动进行自动化评测？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;由于人工评测和度量，很多时候就像写一篇小作文，它是非标的，是没有标准答案的东西。相反，为什么现在编程发展很快？因为数学和编程都有标准答案，可以被编辑器校验，但是纯文本是没有标准答案的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以，评测这项工作非常耗时，也很容易成为整个项目的瓶颈，是需要极大加强的。如果不去加强，那么整个项目的基石就可能动摇。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在评测的过程中有一个非常重要的点，叫&amp;nbsp;E2E 归因。因为在智能体的过程中会有非常多的环节，在这么多工作流和智能体的编排逻辑中，如果一个意图没有被满足，我们必须要有能力确定这个 Bad case 的问题到底出在哪个环节。当每一个 Badcase 都应该归因到工程里的具体环节，才能对具体的原因进行聚类和改进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b4/b4959fc8d9887488b8ad3f85288eebeb.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果从产品宏观功能体系来看，体系的最底层，必须要有两样东西：第一，是业务评测；第二，是全链路的归因分析能力。我把这两项放在最底层，就是因为它们太重要了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下图这是个大概率的经验总结，也就是说，如果具备度量能力，会发现&amp;nbsp;大部分问题都出现在数据层面，出现在非结构化、结构化数据 API。如果基本能力不具备，这就是智能体失败的主要原因。部分问题可能出现在知识预处理、意图识别、上下文检索，以及后续的意图识别总结等环节。数据极为重要，但没有评测也就谈不上数据。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/1b/1b260a7e00c9eec4a1b1814491691a22.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;引出一个经常被讨论的问题：是否需要引入模型训练？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们的观点非常明确：必须在白盒方式下使用基模 API，注重评测和数据，并进行 E2E 归因迭代。只有当数据质量和评测能力具备时，才能引入训练。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原因很简单，如果数据和评测能力不 Ready，投入在训练上的每一分钱都是浪费。如果数据不够好，那就是“garbage in, garbage out”。这些问题，都不是训练本身能够帮助解决的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而且，训练的周期长、成本高、迭代速度慢，如果没有能力评估训练结果的好坏，也没有足够的数据进行训练，这种投入是不明智的。因此，只有在必须使用训练，且基模无法解决问题时，我们才会引入预训练。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/af/af4dcf4c9bf5a8fb2b7d24b1f94954ce.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;写在最后：AI+云的「大电梯」&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最后，为大家回顾一下。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们在阿里云内部推进 AI 转型，本质上是需要为业务提供 Result as a Service（RaaS）。我们也是当前时点为数不多的，能够真正大规模实现 E2E 落地，给业务交付结果的实践团队。&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而我们实现 Result as a Service 的方法叫&amp;nbsp;RIDE，RIDE 分别代表 Reorganize、Identify、Define 和 Execute。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;需要特别注意的是，在必要条件上再努力，也解决不了充分条件的问题，所以这个 RIDE 方法论的核心是在提醒大家：只有把落地所需要的充分条件补齐，才能真正开展 AI 企业有效落地的工作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a0/a0118e1b86a2b596ba7940d8b986889a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;呼应最开始讲的“电梯”，想表达的是，冰山之上，我带着团队一直在做业务的数字化转型，之所以能够实现，是因为冰山之下，有强大的阿里云作为底座。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;无论是涵盖通义千问在内各种模型服务的 MaaS 百炼，还是 PAI，ODPS，数据库等 PAAS 服务、或是底层 IaaS 比如 ECS、灵骏、存储、网络服务，都是我们依赖的企业应用的有力支撑武器。而且，这些能力的成本在不断下降，功能也在持续拓展。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;所以，当企业选择了一个强大的技术底座，随着技术水平的增长和成本的下降，企业的数字化转型也就能够搭上一部更好的“电梯”。我自己认为，阿里云就是这样一部“大电梯”，企业上云后，这部电梯持续为企业实现数字化转型，提供源源不断的上升动力。&lt;/p&gt;</description><link>https://www.infoq.cn/article/BKMR19Rj75XwLR1ysM4B</link><guid isPermaLink="false">https://www.infoq.cn/article/BKMR19Rj75XwLR1ysM4B</guid><pubDate>Mon, 19 Jan 2026 03:23:05 GMT</pubDate><author>籍云</author><category>云计算</category><category>AI&amp;大模型</category></item><item><title>微软介绍了TypeScript 7的更新</title><description>&lt;p&gt;微软近日分享了&lt;a href=&quot;https://www.typescriptlang.org/&quot;&gt;TypeScript&lt;/a&gt;&quot;&amp;nbsp;7（代号为Corsa项目）的最新进展，披露了对TypeScript编译器的一次根本性重构。该更新&lt;a href=&quot;https://devblogs.microsoft.com/typescript/progress-on-typescript-7-december-2025/&quot;&gt;发布于2025年12月&lt;/a&gt;&quot;，详细介绍了团队将TypeScript编译器用Go语言重写的宏伟计划，他们承诺构建速度最高可提升10倍，并显著降低内存的占用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这款名为tsgo的全新原生编译器充分利用了Go语言的性能优势，带来了大幅度的速度提升。据TypeScript团队表示，与旧版本相比，完整构建速度最高可提升10倍，并具备高效的多项目并行处理能力。为编辑器功能（如代码补全、跳转定义、重构等）提供支持的原生语言服务目前已基本稳定，可供日常使用。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;用户现在就可以试用这一预览版：&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;shell&quot;&gt;npm install -g @typescript/native-preview&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;TypeScript 7最重要的变化之一是默认启用&lt;a href=&quot;https://github.com/microsoft/TypeScript/issues/62333&quot;&gt;严格模式（strict mode）&lt;/a&gt;&quot;，这是一项与以往版本不兼容的破坏性变更。这一转变体现了团队对类型安全的坚定承诺，也符合行业最佳实践，但可能要求从旧版本升级的项目进行相应调整。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;选择Go作为实现语言在开发者社区引发了广泛讨论。团队在一份&lt;a href=&quot;https://github.com/microsoft/typescript-go/discussions/411#discussioncomment-12464988&quot;&gt;详尽的FAQ&lt;/a&gt;&quot;中解释说，Go提供了自动垃圾回收机制，同时又是目前最贴近“原生优先”理念的语言。此外，现有TypeScript代码库采用高度函数式的编程风格，几乎不使用类，因此Go的函数与数据结构范式比面向对象语言更为契合。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在&lt;a href=&quot;https://news.ycombinator.com/item?id=43332830&quot;&gt;Hacker News&lt;/a&gt;&quot;上，开发者们对性能提升表现出了极大的热情。一位用户评论说：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;哇，这太震撼了！10倍的速度提升对我们这类大型TypeScript项目将是颠覆性的。我一直在等待这样的改进，我们团队的项目在CI上的类型检查耗时极长，并严重拖慢了IDE的响应速度。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;不过，也有开发者对依赖TypeScript编译器API的工具迁移路径表示担忧：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;……对于我们这些工具作者来说，这个原生编译器将如何分发？我猜会通过WebAssembly（WASM）？编译器API是否兼容？比如转换器（transforms）、抽象语法树（AST）、LanguageService、Program、SourceFile、Checker等等？&amp;nbsp;我非常担心工具生态的迁移可能会异常困难。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一些开发者已经上手尝试。Reddit上有&lt;a href=&quot;https://www.reddit.com/r/typescript/comments/1pcgmrj/comment/ns0frwz/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button&quot;&gt;用户&lt;/a&gt;&quot;称其类型检查时间减少了75%。&lt;a href=&quot;https://www.reddit.com/r/webdev/comments/1pcqzn3/progress_on_typescript_7_december_2025/&quot;&gt;还有人&lt;/a&gt;&quot;对默认开启严格模式表示欢迎：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;默认启用严格模式真是太棒了。我们以前经常在项目中工作到一半才发现严格模式没启用，结果要修复一大堆问题，非常令人头疼。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于重度依赖编译器的开发工具而言，TypeScript 7的原生实现使其与其它以原生语言编写的高性能JavaScript工具站在了同一赛道。例如，用Go编写的&lt;a href=&quot;https://esbuild.github.io/&quot;&gt;esbuild&lt;/a&gt;&quot;，以及用Rust编写的SWC和oxc，均已证明原生实现能带来显著的性能优势。TypeScript团队此次转型不仅验证了这一架构方向的正确性，同时也确保了与TypeScript语言规范的完全兼容。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;TypeScript是由微软开发和维护的一种强类型编程语言，它在JavaScript基础上增加了静态类型定义。自2012年发布以来，TypeScript可编译为纯JavaScript，运行于任何支持JavaScript的环境，包括浏览器、Node.js及其他JavaScript运行时。通过其类型系统，开发者能在编译阶段而非运行时捕获错误；借助智能代码补全、重构等特性，IDE支持也得到了显著增强，同时，显式的类型契约使大型代码库更易于维护。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/typescript-7-progress/&quot;&gt;Microsoft Share Update on TypeScript 7&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/ev8UP654Oux2DreuC6T0</link><guid isPermaLink="false">https://www.infoq.cn/article/ev8UP654Oux2DreuC6T0</guid><pubDate>Mon, 19 Jan 2026 02:42:41 GMT</pubDate><author>作者：Daniel Curtis</author><category>微软</category><category>编程语言</category></item><item><title>谷歌发布适用于多智能体的八种设计模式</title><description>&lt;p&gt;谷歌近期发布了一份指南，&lt;a href=&quot;https://developers.googleblog.com/developers-guide-to-multi-agent-patterns-in-adk/&quot;&gt;详细介绍了多智能体系统（Multi-Agent Systems, MAS）的八种核心设计模式&lt;/a&gt;&quot;，涵盖从顺序流水线到人工介入（human-in-the-loop）架构等多种范式。该指南不仅对每种模式都提供了清晰的解释，还附带了使用谷歌Agent Development Kit（ADK）实现的示例代码。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌指出，构建复杂且可扩展的智能体应用需要采用与其他软件系统相同的工程化方法，因为依赖单一实体会形成性能瓶颈，并使调试变得非常困难。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;可靠性来源于去中心化与专业化。多智能体系统（Multi-Agent Systems,MAS）相当于AI领域的微服务架构。通过为各个智能体分配特定角色（比如，解析器、评判器、调度器），开发者可以构建出天然更具模块化、可测试性和可靠性的系统。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;基于ADK提供的三种基础执行模式,即顺序（sequential）、循环（loop）和并行（parallel），谷歌归纳出八种基本架构（或称为“模式”），帮助开发者以结构化方式设计多智能体系统。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;顺序流水线（Sequential Pipeline）是最简单的模式，智能体像装配线一样依次处理任务，每个智能体将其输出传递给下一个智能体。谷歌表示，这种模式“线性、确定性强，并且调试起来非常直观，因为你能够始终清楚数据来自何处”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;协调器/分发器（Coordinator/Dispatcher）模式是顺序流水线的一种变体，其中一个智能体作为决策者，接收请求并将其分派给下游的专用智能体。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;并行扇出/聚合（Parallel Fan-out/Gather）模式在多个智能体同时执行各自职责时非常有用。例如，在审查PR代码的场景中，主智能体可并行启动多个子智能体分别处理代码风格检查、安全审计和性能分析。随后，一个合成器（synthesizer）智能体汇总所有输出，决定批准或拒绝该PR。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;层次分解（Hierarchical Decomposition）模式适用于更复杂的场景，高层智能体将复杂的目标拆解为子任务，并委派给其他智能体执行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;生成器与评判器（Generator and Critic）模式在输出可靠性至关重要的情况下使用，其中一个智能体负责生成内容，另一个智能体负责验证，并且可选择性地提供反馈，促使生成器迭代优化其输出。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;迭代精进（Iterative Refinement）模式是“生成器与评判器”模式的泛化形式，生成器的输出被送入评判器（critique）和精进器（refiner）智能体，二者协同工作，多次迭代以持续改进原始输出。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;人工介入（Human-in-the-Loop）适用于具有不可逆后果或高风险的决策场景（比如，金融交易、生产环境部署、敏感数据操作）。此时，一个审批工具（approval tool）智能体会在必要时暂停执行，等待人工审核者批准或否决建议的操作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;复合模式（Composite Pattern）允许组合上述任意多种模式。例如，使用协调器路由请求、并行智能体加速处理，再结合生成器/评判器循环确保输出的质量。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;正如指南所述，&lt;a href=&quot;https://google.github.io/adk-docs/agents/multi-agents/&quot;&gt;谷歌为每种模式都提供了详细的架构图和ADK代码片段&lt;/a&gt;&quot;，请参阅该文档以获取更多细节。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，如果想要了解其他使用ADK构建多智能体系统的思路，请参考&lt;a href=&quot;https://medium.com/@shins777/adk-workflow-the-core-logic-of-ai-agent-8ce4be5c1c40&quot;&gt;Hangsik Shin撰写的指南&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/multi-agent-design-patterns/&quot;&gt;Google’s Eight Essential Multi-Agent Design Patterns&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/pTGMtm4Yxej0pWXJB4BN</link><guid isPermaLink="false">https://www.infoq.cn/article/pTGMtm4Yxej0pWXJB4BN</guid><pubDate>Mon, 19 Jan 2026 02:14:17 GMT</pubDate><author>Sergio De Simone</author><category>Google</category><category>AI&amp;大模型</category></item><item><title>ChatGPT 将测试广告投放，AI 信任危机一触即发</title><description>&lt;p&gt;&lt;/p&gt;&lt;h2&gt;事件背景&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2026年1月16日，OpenAI通过官方X（原Twitter）账号正式宣布，将在未来数周内开始在ChatGPT的免费版和新推出的ChatGPT Go（$8/月）中测试广告投放。与此同时，Plus（$20/月）、Pro（$200/月）及企业版将继续保持无广告体验。这一决策迅速引发了科技圈的广泛关注和激烈讨论。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/52/5234f70811ad7bcdaf7e463ddfda46df.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;OpenAI官方推文宣布广告计划，并发布广告原则说明 | 来源：X @OpenAI&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;值得注意的是，OpenAI同时发布了一份详尽的&quot;广告原则&quot;（Our Ad Principles），试图向用户保证广告不会影响ChatGPT的回答质量和隐私保护。然而，这份承诺并未能平息用户的担忧——社交媒体上的反应呈现出高度两极分化的态势。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;OpenAI的广告原则解读&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/7b/7b43057e190743086666c7694c159ab2.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;OpenAI发布的广告原则框架：强调使命对齐、答案独立、对话隐私、用户控制与长期价值&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;📋 OpenAI 官方承诺清单&lt;/p&gt;&lt;p&gt;✓答案独立性：ChatGPT的回答始终基于客观有用性，广告不会影响答案内容&lt;/p&gt;&lt;p&gt;✓对话隐私：不向广告商出售用户数据，对话内容保持私密&lt;/p&gt;&lt;p&gt;✓用户控制：用户可随时关闭个性化广告，清除广告相关数据&lt;/p&gt;&lt;p&gt;✓付费保护：Plus、Pro、Business、Enterprise等高价层级永不显示广告&lt;/p&gt;&lt;p&gt;✓未成年保护：18岁以下用户不会看到广告&lt;/p&gt;&lt;p&gt;✓敏感话题禁区：政治、健康、心理健康等敏感话题禁止广告投放&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;商业化背后的财务压力&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从华尔街日报、彭博社等主流财经媒体的报道来看，OpenAI此举并非心血来潮，而是面对真实财务压力的&quot;不得已之举&quot;。据公开数据显示：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/87/8774f103fa85bde59577b3b6aa2d7e02.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在如此悬殊的付费转化率面前，广告变现被多家媒体评价为&quot;不可避免&quot;的选择。富国银行预测，ChatGPT在搜索市场的占比将从2025年底的17%增长到2030年的三分之一，这为广告业务提供了巨大的潜在市场空间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;社交媒体的激烈反应&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;公告发布后，X平台上的评论区迅速沦陷。从截图可见，用户反应从嘲讽、愤怒到直接引用Sam Altman此前的反广告言论，形成了鲜明的对比和讽刺效果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/bb/bb77475c3007a83e6b3e36055c4cda50.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;X平台用户对OpenAI广告公告的部分反应 | Grok引用了Altman 2024年称广告是&quot;反乌托邦&quot;的言论&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;Sam Altman在2024年曾称将广告嵌入ChatGPT回复是一种&quot;反乌托邦&quot;的想法：&quot;很容易想象那种未来的反乌托邦场景——你问ChatGPT一个问题，它回答说&#39;你应该考虑买这个产品&#39;或者&#39;你应该去这里度假&#39;之类的。&quot;—— 来源：Grok @grok 引用 Altman 2024年采访&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种前后矛盾的表态成为用户攻击的焦点。有用户直言：&quot;直接说你们需要更多钱不就得了&quot;（Just say you guys need more money），简洁而犀利地戳破了官方话术的包装。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;四大核心担忧&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;1. 答案中立性与商业影响的矛盾&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;用户普遍担忧：一旦AI提供的建议与商业利益相关联，就很难保证答案仍然是纯粹基于&quot;客观有用性&quot;的判断。有用户形象地比喻：&quot;感觉就像在心理咨询师办公室里竖起了广告牌。&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;2. 数据隐私与&quot;监听&quot;恐惧&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;尽管OpenAI承诺&quot;不会出售用户数据给广告商&quot;，但用户对此类承诺持谨慎态度。有Reddit用户反映，在ChatGPT中讨论特定话题后，很快在其他平台看到相关广告，这加深了数据被滥用的担忧。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;3. 前科问题：App Recommendations事件&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2025年12月，ChatGPT Plus付费用户在对话中看到来自Target、Peloton等品牌的&quot;推荐&quot;。OpenAI最初辩称这不是广告，只是应用发现功能，但最终在用户强烈反对下关闭了该功能。首席研究官Mark Chen道歉承认公司&quot;做得不够好&quot;。这一事件严重损害了用户对OpenAI承诺的信任。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;4. Instagram模式类比的逻辑悖论&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;CEO Sam Altman提到欣赏Instagram的广告模式，但用户尖锐地指出：Instagram之所以成功，正是因为Meta大规模收集和出售了用户的个人数据——这与OpenAI声称的&quot;隐私优先&quot;立场本质矛盾，形成了无法调和的逻辑悖论。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;广告形态预览&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;根据OpenAI展示的概念图，广告将以&quot;Sponsored&quot;标签的形式出现在ChatGPT回复的底部，与回答内容明确分离。在下图的示例中，当用户询问墨西哥晚宴菜谱时，系统在给出食谱建议后，底部会显示相关食材的赞助商购买链接。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/71/714ddc9a44c97e5f72129b0e6daee51e.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;ChatGPT广告投放概念设计：广告以&quot;Sponsored&quot;标签形式出现在回复底部，与答案内容分离&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种设计理论上可以降低用户对答案被&quot;污染&quot;的担忧，但批评者指出，长期来看广告逻辑一旦被引入系统，算法污染可能是微妙且难以察觉的——即使不是故意为之。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;前科回顾：信任的裂痕&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2024年 Altman 公开反对广告&lt;/p&gt;&lt;p&gt;Sam Altman在采访中称将广告嵌入ChatGPT回复是&quot;反乌托邦&quot;的想法，表示更倾向于订阅模式以避免用户成为产品。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2025年12月 App Recommendations 争议&lt;/p&gt;&lt;p&gt;ChatGPT Plus付费用户发现对话中出现Target、Peloton等品牌推荐。OpenAI先是否认为广告，后在舆论压力下关闭该功能并道歉。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;2026年1月16日正式宣布广告测试&lt;/p&gt;&lt;p&gt;OpenAI官宣在免费版和Go版本中测试广告，同时发布&quot;广告原则&quot;框架，承诺付费用户永远不会看到广告。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这一系列事件的累积效应是：用户现在不再轻易相信OpenAI关于&quot;高价订阅永远不会有广告&quot;的承诺。Reddit社区中大量评论指出，这正是流媒体巨头采用过的老套路——&quot;先在免费端试水，再慢慢侵入付费端&quot;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;有条件的宽容声音&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;💡部分理性用户的接受条件&lt;/p&gt;&lt;p&gt;并非所有反应都是负面的。部分用户认为，如果OpenAI能够做到以下几点，免费用户看广告是一种合理的交换：&lt;/p&gt;&lt;p&gt;1. 透明性：广告必须明确标注为&quot;Sponsored&quot;，不能伪装成自然回答&lt;/p&gt;&lt;p&gt;2. 相关性：广告应与当前对话相关，而非完全无关的干扰&lt;/p&gt;&lt;p&gt;3. 可控性：用户可以关闭个性化广告设置，或清除用于投放广告的对话记录&lt;/p&gt;&lt;p&gt;4. 底线：高价订阅（Plus/Pro）必须永远保持无广告体验&lt;/p&gt;&lt;p&gt;这类&quot;有条件宽容&quot;的声音提醒我们，用户并非完全不能接受商业化，关键在于执行的边界和信任的维护。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;行业视角：竞争压力与战略转向&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;从更宏观的行业视角来看，OpenAI的这一决策也反映了AI领域日益激烈的商业化竞争。谷歌的Gemini和Meta的AI产品已经内置广告机制，OpenAI不想在市场份额争夺中落于下风。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Marketing AI Institute的分析尤其指出，OpenAI内部正面临巨大的商业化压力。公司聘请前Facebook和Instacart高管Fidji Simo担任应用业务CEO，这一人事任命本身就暗示了公司的战略方向——从技术研究机构向消费级商业平台的全面转型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;OpenAI的创新尝试在于&quot;对话语境驱动的广告&quot;（contextual ads triggered by current conversation），理论上这种做法可以降低隐私风险。但实践中，用户很难确信系统不会进行隐蔽的数据关联。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;结论：信任与商业化的钢丝行走&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;社交媒体反应以担忧和怀疑为主，核心议题围绕信任、隐私和&quot;前科&quot;问题。用户普遍采取了&quot;show me&quot;的态度——可以测试，但任何迹象表明承诺被破坏就会转向竞品。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;主流媒体的评价则务实与批判并存：认可这一决策的商业必然性，但广泛质疑其能否在不伤害信任的前提下成功。最尖锐的评论来自社区用户的讽刺——AGI实际上是&quot;Ads Generating Income&quot;（广告创造收入）。这反映了一个更深层的焦虑：开放人工智能的使命（AGI造福全人类）与商业化压力之间可能存在根本性冲突。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;OpenAI正在走钢丝——既要维持无广告体验的付费用户的付费意愿，又要通过免费/低价层的广告收入覆盖高昂的运营成本。这个平衡能维持多久，将决定ChatGPT是否会重蹈社交媒体平台从纯净到被商业完全入侵的老路。&lt;/p&gt;</description><link>https://www.infoq.cn/article/pt1L2jiAHb7tAcB1lAmz</link><guid isPermaLink="false">https://www.infoq.cn/article/pt1L2jiAHb7tAcB1lAmz</guid><pubDate>Mon, 19 Jan 2026 01:25:13 GMT</pubDate><author>作者：晋梅</author><category>AI&amp;大模型</category></item><item><title>Java 近期资讯：Spring Shell、JReleaser、TornadoInsight和Apache Camel</title><description>&lt;p&gt;&lt;/p&gt;&lt;h4&gt;JDK 26&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;连续第二周，JDK 26的&lt;a href=&quot;https://jdk.java.net/26/&quot;&gt;早期访问版本&lt;/a&gt;&quot;仍为&lt;a href=&quot;https://github.com/openjdk/jdk/releases/tag/jdk-26%2B29&quot;&gt;Build 29&lt;/a&gt;&quot;。更多详情请参阅其&lt;a href=&quot;https://jdk.java.net/26/release-notes&quot;&gt;发布说明&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;JDK 27&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;同样，JDK 27的&lt;a href=&quot;https://jdk.java.net/27/&quot;&gt;早期访问版本&lt;/a&gt;&quot;当前仍为&lt;a href=&quot;https://github.com/openjdk/jdk/releases/tag/jdk-27%2B3&quot;&gt;Build 3&lt;/a&gt;&quot;。详细信息可查阅其&lt;a href=&quot;https://jdk.java.net/27/release-notes&quot;&gt;发布说明&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于&lt;a href=&quot;https://openjdk.org/projects/jdk/26/&quot;&gt;JDK 26&lt;/a&gt;&quot;和&lt;a href=&quot;https://openjdk.org/projects/jdk/27/&quot;&gt;JDK 27&lt;/a&gt;&quot;，鼓励开发者通过&lt;a href=&quot;https://bugreport.java.com/bugreport/&quot;&gt;Java Bug数据库&lt;/a&gt;&quot;报告缺陷。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Spring Framework&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Spring Shell 4.0.0正式发布&lt;a href=&quot;https://spring.io/blog/2025/12/30/spring-shell-4-0-0-ga-released&quot;&gt;GA版本&lt;/a&gt;&quot;，包含缺陷修复、文档改进、依赖项升级以及多项新特性，包括，命令编程模型重构，在使用Spring Boot时，不再需要@EnableCommand或@CommandScan注解，并修复了@Command注解的意外行为；全新升级的DSL，解决了CommandRegistration.Builder实例与Spring Security的SecurityFilterChain接口在新构建器格式下的匹配问题；与Spring Framework 7.0和Spring Boot 4.0对齐；新增对&lt;a href=&quot;https://jspecify.dev/&quot;&gt;JSpecify&lt;/a&gt;&quot;的空安全（null safety）支持。更多细节请参见&lt;a href=&quot;https://github.com/spring-projects/spring-shell/releases/tag/v4.0.0&quot;&gt;发布说明&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;JReleaser&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://jreleaser.org/&quot;&gt;JReleaser&lt;/a&gt;&quot;&amp;nbsp;1.22.0&lt;a href=&quot;https://andresalmiray.com/jreleaser-1-22-0-has-been-released/&quot;&gt;发布&lt;/a&gt;&quot;，这是一个用于简化Java项目发布流程的工具，本次更新包括缺陷修复、文档改进、依赖项升级以及新功能，包括，&lt;a href=&quot;https://jreleaser.org/guide/latest/reference/signing.html&quot;&gt;Signing&lt;/a&gt;&quot;模块全面重构，支持同时使用多种方法对构件（artifacts）进行签名；新增对&lt;a href=&quot;https://jedisct1.github.io/minisign/&quot;&gt;Minisign&lt;/a&gt;&quot;（一个用于文件签名和验证的工具）的支持；支持在部署构件到Maven Central时跳过等待期。更多详细信息请见&lt;a href=&quot;https://github.com/jreleaser/jreleaser/releases/tag/v1.22.0&quot;&gt;发布说明&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;TornadoVM&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.tornadovm.org/&quot;&gt;TornadoVM&lt;/a&gt;&quot;团队&lt;a href=&quot;https://www.tornadovm.org/post/tornadoinsight-compatibility-with-tornadovm-sdk-2-0-configuration-guide&quot;&gt;宣布&lt;/a&gt;&quot;，其开源IntelliJ 插件&lt;a href=&quot;https://github.com/beehive-lab/tornado-insight/blob/main/README.md&quot;&gt;TornadoInsight&lt;/a&gt;&quot;（旨在提升TornadoVM的开发体验）现已兼容&lt;a href=&quot;https://www.infoq.com/news/2025/12/tornadovm-20-gpu-llm&quot;&gt;最新发布的TornadoVM 2.0&lt;/a&gt;&quot;。相关配置指南也已同步更新。关于TornadoInsight的更多信息，可参考InfoQ的&lt;a href=&quot;https://www.infoq.com/news/2024/01/introducing-tornadoinsight/&quot;&gt;新闻报道&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Apache Camel&lt;/h4&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://camel.apache.org/&quot;&gt;Apache Camel&lt;/a&gt;&quot;&amp;nbsp;4.14.3&lt;a href=&quot;https://camel.apache.org/blog/2026/01/RELEASE-4.14.3/&quot;&gt;发布&lt;/a&gt;&quot;，包含缺陷修复、依赖项升级及功能改进，包括，在使用&lt;a href=&quot;https://camel.apache.org/manual/camel-jbang.html&quot;&gt;Camel JBang&lt;/a&gt;&quot;时，可通过--repos命令为&lt;a href=&quot;https://camel.apache.org/camel-k/2.9.x/kamelets/kamelets.html&quot;&gt;Camel Kamelet&lt;/a&gt;&quot;相关操作指定Maven仓库；&lt;a href=&quot;https://camel.apache.org/components/4.14.x/neo4j-component.html&quot;&gt;Camel Neo4j&lt;/a&gt;&quot;组件改进了消息体的检测逻辑，避免内部错误；修复了&lt;a href=&quot;https://camel.apache.org/components/4.14.x/netty-component.html&quot;&gt;Camel Netty&lt;/a&gt;&quot;中SSL客户端证书主题名称（subject name）从可读字符串表述被错误转换为晦涩的&lt;a href=&quot;https://datatracker.ietf.org/doc/html/rfc2253&quot;&gt;LDAP&lt;/a&gt;&quot;格式的问题。更多详情请查阅&lt;a href=&quot;https://camel.apache.org/releases/release-4.14.3/&quot;&gt;发布说明&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/java-news-roundup-dec29-2025/&quot;&gt;Java News Roundup: Spring Shell, JReleaser, TornadoInsight, Apache Camel&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/PRKRY1HB7C2ipJFoJBHy</link><guid isPermaLink="false">https://www.infoq.cn/article/PRKRY1HB7C2ipJFoJBHy</guid><pubDate>Mon, 19 Jan 2026 00:00:00 GMT</pubDate><author>Michael Redlich</author><category>编程语言</category></item><item><title>烧掉数万亿 Token、数百 Agent 连跑一周：Cursor“从零写浏览器”，结果是拼装人类代码？</title><description>&lt;p&gt;现在，大模型可以独立写完整整一个浏览器了？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Cursor CEO Michael Truell 最近分享了一项颇为吸睛的实验：他们用 GPT-5.2 让系统连续不间断运行一周，从零构建出一个“可用”的 Web 浏览器。按他的描述，产出规模达到：超过 300 万行代码、横跨数千个文件，全部通过这套 AI 驱动的编程平台生成。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/09/09a68fe91c9f8b726b597d4a49b03612.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;数百个 Agent “从零”写了一个浏览器？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;按照他的说法，这个项目并没有依赖现成的渲染引擎，而是用 Rust 从零实现了一整套渲染引擎，其中包括 HTML 解析、CSS 级联规则、布局计算、文本排版（text shaping）、绘制（paint）流程，甚至还实现了一个自定义的 JavaScript 虚拟机。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Truell 也坦言，这个浏览器目前只是“勉强能用”，距离 WebKit 或 Chromium 等成熟引擎还有很大差距；但团队依然“感到震惊”，因为简单网站在它上面渲染得很快，而且整体效果在很大程度上是正确的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，Cursor 还发布了一篇博客文章，题为《Scaling long-running autonomous coding》（扩展长时间运行的自主编程）。文章回顾了一系列实验：让“编程 agent 连续自主运行数周”，目标是“理解在那些通常需要人类团队耗费数月完成的项目中，agentic coding 的能力边界究竟可以被推进到什么程度”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这篇文章里，他们重点讲的是多 Agent 如何协同：如何在单个项目上同时运行数百个并发 Agent、如何协调它们的工作，并观察它们写出超过一百万行代码和数万亿个 token 的过程与经验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Cursor 先承认了单个 Agent 的局限：任务规模一大、依赖一复杂，推进速度就会明显变慢。并行化看似顺理成章，但他们很快发现，难点不在并发，而在协同。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;“学习如何协同：我们最初的方法是让所有 agent 具有同等地位，并通过一个共享文件自行协同。每个 agent 会检查其他 agent 在做什么、认领一个任务并更新自己的状态。为防止两个 agent 抢占同一项任务，我们使用了锁机制。&amp;nbsp;这一方案在一些有趣的方面失败了：&amp;nbsp;agent 会持有锁太久，或者干脆忘记释放锁。即使锁机制正常工作，它也会成为瓶颈。二十个 agent 的速度会下降到相当于两三个 agent 的有效吞吐量，大部分时间都花在等待上。&amp;nbsp;系统非常脆弱：agent 可能在持有锁的情况下失败、尝试获取自己已经持有的锁，或者在完全没有获取锁的情况下更新协调文件。&amp;nbsp;我们尝试用乐观并发控制来替代锁。agent 可以自由读取状态，但如果自上次读取后状态已经发生变化，则写入会失败。这种方式更简单、也更健壮，但更深层的问题依然存在。&amp;nbsp;在没有层级结构的情况下，agent 变得非常规避风险。它们会回避困难任务，转而做一些小而安全的修改。没有任何一个 agent 承担起解决难题或端到端实现的责任。结果就是工作长时间在空转，却没有实质性进展。”&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为了解决这一问题，Cursor 最终引入了更明确的角色分工，搭建一条职责清晰的流水线：将 Agent 分为规划者和执行者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;“规划者（Planners） 持续探索代码库并创建任务。他们可以针对特定区域派生子规划者，使规划过程本身也可以并行且递归地展开。&amp;nbsp;执行者（Workers） 领取任务并专注于把任务完成到底。他们不会与其他执行者协调，也不关心整体大局，只是全力处理自己被分配的任务，完成后再提交变更。&amp;nbsp;在每个周期结束时，会有一个评审 Agent 判断是否继续，然后下一轮迭代会从干净的初始状态重新开始。这样基本解决了我们的协同问题，并且让我们可以扩展到非常大的项目，而不会让任何单个 Agent 陷入视野过于狭窄的状态。”&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在此基础上，Cursor 把这套系统指向一个更具挑战性的目标：从零构建一个浏览器。他们表示，Agent 持续运行了将近一周，在 1,000 个文件中写出了超过 100 万行代码（原文如此，跟Michael Truell说的300万行不同），并将源码发布在 GitHub 上供外界浏览。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/fc/fc8f661989eab13452b0fd8157d33f1b.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Cursor 进一步宣称：即便代码库规模已经很大，新启动的 agent 仍然能够理解它并取得实质性进展；同时，成百上千个 worker 并发运行，向同一个分支推送代码，而且几乎没有冲突。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;一场“全民打假”的开始？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这次实验之所以引发强烈反应，很大程度上是因为：Web 浏览器本身就是软件工程里公认的“地狱级”项目。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/de/de92607bb9b36483a2a05e52c367cb12.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;它难的不只是“写代码”，而是工作量的量级、模块之间的高耦合，以及兼容性这条几乎看不到尽头的长尾。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 Hacker News 上，有人顺手抛了一个问题：“开发一个浏览器最难的地方是什么？”很快就有人给出一个类比：“说句真心话，这个问题几乎等同于：开发一个操作系统最难的地方是什么？”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;因为现代浏览器是千万级代码量的系统，能够运行非常复杂的应用。它包含网络栈、多种解析器、frame 构建与回流（reflow）模块、合成（composite）、渲染（render）与绘制（paint）组件、前端 UI 组件、可扩展框架等等。这里面每一个模块，都必须同时做到：既支持 30 年前的旧内容，也支持复杂得离谱的当代 Web 应用。同时，它还得在高性能、高安全前提下尽可能少占用系统资源，并且往往要跨 Mac、Windows、Linux、Android、iOS 等多个平台运行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有人提到，最难的是那张超长的任务清单。浏览器里包含多个高复杂度模块，每一个单拎出来都可能要做很久；更麻烦的是，它们之间还要通过一套相当“啰嗦”的 API 连接起来——很多接口你必须实现，至少也得先把壳子（stub）搭出来，否则系统就会崩。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对这个浏览器项目，Cursor 在博客中写道：“虽然这看起来像是一张简单的屏幕截图，但从头开始构建一个浏览器是非常困难的。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;然而如果外界自己去尝试编译这个项目，会很快意识到：它离“功能齐全的浏览器”还差得很远，甚至看起来在公开代码状态下，连最基本的构建都很难稳定通过。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从仓库公开信息来看，近期 main 分支的多次 GitHub Actions 运行结果显示失败（其中还包括工作流文件本身的错误）；不少开发者的独立构建尝试也报告了数十个编译错误。与此同时，最近的一些 PR 虽然被合并，但 CI 仍处于失败状态。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更有开发者表示自己回溯 Git 历史，往前翻了约 100 个提交后表示，依然没能找到一个可以“干净编译通过”的版本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这也引出了一个问题：这些被 Cursor 描述为在代码库中长期并发运行的“agent”，在工程链路上到底做到哪一步？至少从当前公开状态看，它们似乎并没有把“能编译、能检查”当成最基础的收敛目标——因为无论是 cargo build 还是 cargo check，都会立刻暴露出成片的编译错误和大量警告。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而Cursor 的博客文章除了提供代码仓库链接外，既没有提供可复现的演示，也没有提供任何已知的有效版本（标签/发布/提交）来验证截图。无论如何，这文章本身给人一种原型功能完备的错觉，却忽略了此类声明应有的基本可复现性特征。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/18/18f5eca698dcba5b3804f2d1b922713f.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有人在Michael Truell 的LinkedIn上直接把结果抛了回去：“构建直接失败，报了 32 个错误，代码本身就是坏的；没有任何 release、没有 tag，CI 也在持续失败，我们甚至连这个所谓‘可用的浏览器’都没法编译、没法试跑。这更像是一场营销活动，而不是一次真正的 agentic 实验。”Michael Truell 至今没有回复。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c2/c267ef2f437e4f201c1ec9d34b3fb436.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前唯一一个在社交平台上明确分享“复现成功”的人，是前浏览器开发者 Oliver Medhurst。他表示自己花了大约两个小时修复编译错误和漏洞，才把项目跑起来。至于性能，他的评价也很直接：有些页面加载要整整一分钟，“不算好”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有一个更敏感的追问也随之出现：“所以这真的是从零开始写的吗？”他给出的回应更像一句反转预告：“剧透：不是。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/69/69169227bd6dc8d62e0d4cf0637cbb88.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更多网友通过翻看仓库依赖发现，这个项目直接引入了 Servo （一个最初由 Mozilla 开发的基于 Rust 的浏览器）项目的 HTML 与 CSS 解析器（html parser、css parser），以及 QuickJS 的 Rust 绑定（rquickjs），并非所有关键组件都是自行实现。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;再加上 selectors、resvg、wgpu、tiny-skia 等一系列成熟库，这个“浏览器实验”更像是直接调用了人类编写的代码，而不是“从零开始”的一整套渲染与执行引擎。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/64/64b6b900a7d742bf32dafd9f963fe8a5.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e7/e716eb0006daa5131dc89b27d7892306.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/85/85491f9fdccde9acf59685ff7790b541.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更搞笑的是，Cursor 这里用的还是一个发布于 2023 年 6 月的wgpu 0.17这种非常旧的老版本，而当前最新版本已经是 28（发布于 2025 年 12 月）。大概因为大模型写代码时往往会直接改版本管理文件（如 package.json、Cargo.toml），而不是通过 npm add、cargo add 这类构建工具来引入依赖。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/0c/0c15a8df25de61642d98e04625fc169a.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这也不怪网友骂他们：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“这简直是胡扯。应用根本跑不起来，功能也缺得厉害。LLM 更像是在把它训练过的现成代码拼起来做个浏览器——毕竟 Chromium 本来就是开源的。最后堆出了 300 万行‘看起来很多’但没有价值的代码，结果还不能用，更谈不上什么新产品。折腾到最后，你还是得让开发者花大量时间去调试、排查安全漏洞，才能把它打磨得像一个早就存在的成熟产品。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“两周时间、数百个 agent，V8 和 Blink 又都是开源的。说到底，这就是在浪费 GPU 和电力。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/95/95a7b886c9f136fd2ea711159c08cd8d.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最后值得一提的是，这个实验还暴露出一个不容忽视的问题：成本。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有人翻回 Cursor 的原帖指出，他们还在跑类似实验，比如一个 Excel 克隆项目（&lt;a href=&quot;https://github.com/wilson-anysphere/formula&quot;&gt;https://github.com/wilson-anysphere/formula&lt;/a&gt;&quot;）。GitHub Actions 的概览数据很夸张：累计触发了 16 万多次 workflow 运行，但成功的只有 247 次——失败的主要原因不是代码本身，而是超出了支出上限。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，Agent 并不在乎预算；但在真实的软件工程里，可复现的构建、可持续的成本、可验证的产出，才决定一个系统最终能不能被信任、被维护、被继续推进。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://cursor.com/cn/blog/scaling-agents&quot;&gt;https://cursor.com/cn/blog/scaling-agents&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=46646777&quot;&gt;https://news.ycombinator.com/item?id=46646777&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/singularity/comments/1qd541a/ceo_of_cursor_said_they_coordinated_hundreds_of/&quot;&gt;https://www.reddit.com/r/singularity/comments/1qd541a/ceo_of_cursor_said_they_coordinated_hundreds_of/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.linkedin.com/posts/activity-7417328860045959169-PFuT/&quot;&gt;https://www.linkedin.com/posts/activity-7417328860045959169-PFuT/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://xcancel.com/CanadaHonk&quot;&gt;https://xcancel.com/CanadaHonk&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/t0rpY0X2G9RBmXf9SK6g</link><guid isPermaLink="false">https://www.infoq.cn/article/t0rpY0X2G9RBmXf9SK6g</guid><pubDate>Sat, 17 Jan 2026 12:00:00 GMT</pubDate><author>Tina</author><category>生成式 AI</category></item><item><title>告别“刀片利润”，AI如何帮中国数百万中小工厂构筑新护城河？</title><description>&lt;p&gt;“今年上半年我在山东临沂见了一位满头白发的90后老板，他们公司的年销售额超过3亿元，但利润却不到1000万。”&lt;a href=&quot;https://www.infoq.cn/article/xLUE7sWGby4MF5GKpgas&quot;&gt;1688&lt;/a&gt;&quot;商家发展中心总经理王强在日前接受媒体采访时讲道，“白天睡觉、晚上陪客户，这是他们为此生意的主要方式。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;事实上，这不是个例，而是中国数百万中小工厂主的真实缩影——规模在增长，利润在萎缩；订单在增加，确定性在流失。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种悖论背后，是一场深刻的结构性撕裂，是当前B2B产业面临的系统性挑战：合规成本持续攀升，环保、税务、用工等要求日益刚性；与此同时，供给极端碎片化、需求高度非标化，交易决策链冗长，产业经验变得难以沉淀和复用。这使得过去依靠压价和人情关系维系的生意模式，在今天已经难以为继。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;换言之，中国产业带的底层逻辑正在被彻底重构，“K型复苏”成为新常态，头部企业加速扩张，尾部企业加速出清，一个尖锐的问题摆在所有中小工厂面前——出路究竟在哪？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1688在刚刚发布的《2025中国产业带发展趋势报告》（以下简称“报告”）中给出了他们的答案：2025年，中国产业带开始迈向AI原生时代。这不是又一次简单的工具升级，而是一场历史性跨越：从“数字化”向“智能化”的范式转变。在这场变革中，AI不再是可有可无的“外挂”，而是决定生死存亡的“操作系统”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该报告基于1688平台26年产业带深耕经验，整合覆盖全国70%一级产业带、超百万家源头厂商的真实交易大数据，系统分析了AI在产业带的演进路径。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;从“卷成本”到“拼确定性”，中国产业带的游戏规则正在被重写&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;如果说过去二十年产业带的竞争关键词是“规模”与“成本”，那么今天，“确定性”正迅速取代“低价”，成为新的护城河。所谓确定性，不只是按时交货，更包括产品品质稳定、服务响应及时、需求预测精准、合规风险可控。并且，这些变化的覆盖范围不仅限于国内市场，更是全球性的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;报告指出，产业带“江湖规矩”和“权力地图”正被彻底重写，“外转内”与“内转外”并行，产能外迁与产业内移共振，工厂正从“代工者”蜕变为“品牌主”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而AI，成了构建确定性的核心引擎，基于 AI 原生的下一代供应链呼之欲出。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;据王强分享，深圳一家3C配件厂商深圳众鑫通泰曾深陷“低价、欠款、无客”的死循环，但他们通过AI分析亚马逊上的用户差评发现，一款手机支架的核心痛点是“粘不牢、价格高”，并据此开发出了采用真空磁吸技术的新品，同时，借助AI生成的油管爆款视频进行推广，这家工厂最终实现了跨境业务占比突破70%，毛利率远超同行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另一家位于安徽芜湖的一个6人鞋企也在2024年借助AI工具实现了惊人跃升：上新效率提升4倍，支付转化率提升41%，全年销售额达1.5亿元。他们没有设计师，就用AI完成换色、场景图和视频生成；没有客服团队，就部署7×24小时自动响应系统；甚至通过AI分析TikTok热门搜索词，捕捉全球潮流趋势。“AI已经是趋势了，等别人都试完再上，你就被淘汰了。”芜湖苏禾鞋业张云这样说。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;类似的故事正在更多产业带上演。报告显示，和这些工厂一样，越来越多的中小企业正通过AI将内贸积累的柔性快反、品控能力“翻译”为跨境竞争力。AI不再只是巨头的游戏，它同样成为了小微商家对抗规模劣势的“杠杆”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;具体而言，AI已深度融入商家端的三大核心场景：选品方面，通过全球电商平台评论与社媒热词，反向定义产品；小单快返方面，基于柔性供应链使得响应周期大幅缩短；智能质检方面，用图像识别替代人工目检，使得效率大幅提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1688公共事务部总经理范敏强调，这些变化背后指向了这样一种进化逻辑——AI正在驱动三大“位移”：&lt;/p&gt;&lt;p&gt;第一，决策机制位移，从依赖“老师傅经验”转向依赖“AI产业大脑”；第二，组织形态位移：从“人盯人”管理转向“AI调度+人机协同”；第三，核心竞争力位移，从“模具和产能”转向“数据驱动的快速迭代能力”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;正如报告所示，2026年起，增长将向能稳定交付、直连用户、自主开款的源头工厂集中。未来的赢家，不是规模最大、也不是成本最低的，而是将AI融入血液，构建起“效率×合规×确定性”新护城河的企业” 。在这个新规则下，“确定性”本身就成了最稀缺的资源，能否用好AI，则成了企业穿越周期的关键。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;超越“生意搭子”，AI从来不只是一个工具&lt;/h3&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当然，这场跃迁并非坦途。&lt;a href=&quot;https://www.infoq.cn/article/jNFPJE9aRZi37seSRNwc&quot;&gt;数据孤岛&lt;/a&gt;&quot;、模型泛化能力不足、复合型人才短缺仍是大多数企业在AI应用落地过程中遇到的主要瓶颈。尤其在传统产业带，许多工厂连基础的ERP系统都没能打通，导致AI系统缺乏高质量、结构化的数据输入。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;面对这些现实约束，企业可以选择从最小可行场景切入，以业务价值反推技术建设。以深圳众鑫通泰为例，他们并不是从一开始就试图构建“全厂智能大脑”，而是聚焦一个具体痛点——“用户为什么差评我们的手机支架？” 通过抓取公开电商平台评论这一无需内部系统打通的外部数据源，快速验证了AI选品的价值，再逐步将成功经验延伸至生产排程与质检环节。这种“由外而内、由点及面”的路径，有效绕开了初期数据孤岛的制约。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;针对模型泛化难题，目前市场上已经有平台开始探索基于跨商家、跨品类的聚合数据，提炼具有行业共性的智能能力。比如1688依托其覆盖全国70%一级产业带的交易网络，正尝试把成功案例中从选品洞察、质检规则到履约优化的AI应用逻辑，抽象为可借鉴的方法论甚至工具原型，以降低单个工厂的试错成本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而破解人才困局的关键，在于构建“人机协同”的新工作流，而非追求全能型个体。拿芜湖苏禾鞋业这个6人企业来说，他们并没有AI工程师，也没有技术背景，仅仅通过应用AI工具，就实现了设计、营销与客户服务的全面提效。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;王强表示：“未来的AI的卷应该是，你是不是让AI把你做成一套的体系或系统？而&lt;a href=&quot;https://www.infoq.cn/article/MhBpL7m3y873tY1qmm0I&quot;&gt;不仅仅是一个工具&lt;/a&gt;&quot;。” 换言之，AI的价值不在于炫技，而在于能否系统性解决已知问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;报告中对中国产业带进化进行了三阶段划分，随着AI应用深度的变化，企业将从“AI外挂”进入“AI共生”乃至“AI原生”。而这也恰恰是企业应对以上一系列挑战的底层逻辑，企业不应该把AI当作一个孤立的技术项目，而是将其视为重构业务流程、组织协作与客户价值的契机。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对于身处这一变革浪潮中的企业，报告还给出了三条行动建议：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;第一，要信仰AI，用AI做生意，把工厂变成真正的“硅基工厂”——让每一条产线都听得懂需求、看得见订单、控得住质量；第二，要做足确定性，品控要硬、履约要稳、服务要好；第三，要布局双循环，AI正在模糊内需与跨境的边界，因此企业需要一套AI系统，通做全球生意。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当AI不再是“生意搭子”，而成为产业运行的“智能中枢”，中国制造业的下一轮红利，才真正拉开序幕。这场变革不会一夜完成，但方向已然清晰：谁能把不确定性转化为确定性，谁就能在新秩序中占据主动。而AI，正是那把最关键的钥匙。&lt;/p&gt;</description><link>https://www.infoq.cn/article/uPMimwjtFsRSB8thczFi</link><guid isPermaLink="false">https://www.infoq.cn/article/uPMimwjtFsRSB8thczFi</guid><pubDate>Sat, 17 Jan 2026 11:37:25 GMT</pubDate><author>高玉娴</author><category>阿里巴巴</category><category>工业</category><category>AI&amp;大模型</category><category>数字化转型</category></item><item><title>IDE消亡之年？Steve Yegge 两句狠话：2026 年还用 IDE 就不行，每天烧 500–1000 美元 Token 才合理</title><description>&lt;p&gt;虽然我并不认同“IDE 会在 2026 年消亡”这种绝对说法，但 Steve Yegge 和 Gene Kim 在分享中抛出的判断，依然值得认真对待：在他们的推演里，从 2026 年 1 月 1 日起，继续依赖传统 IDE 的工程师，会被更快拉开差距。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;他们认为这不是“工具升级”，而是“生产方式换代”：工程师的竞争力，越来越取决于你能否用好新一代 AI 开发方式，以及你愿不愿意为它付出真实成本——例如把每天的 token 开销重新定价到“接近日薪”的量级。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更刺耳的是，他们转述了 OpenAI 的 Andrew Glover 的一项观察：是否使用 Codex，可能会让同级别工程师之间的生产力差距被拉到 10 倍，这让管理层“非常惊慌”，“因为他们甚至可能不得不裁掉 50% 的工程师”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;其核心观点如下：&lt;/p&gt;&lt;p&gt;现在的模型本质上是派一个潜水员下去，让它在代码库里四处探索，即使给它更大的氧气瓶，比如一百万 token，它仍会耗尽。正确做法应该是派多个角色，而不是寄希望于一个超大的单一潜水员。如果你在2026年 1 月 1 日后还在使用 IDE，那你就是一个“不好的工程师”。作为工程师，我每天花在 Token 上的费用应该与我的日薪相当，也就是每天 500 到 1000 美元。Claude Code 走错了方向，他们造出一只巨大、耗能、高成本的“肌肉蚂蚁”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Steve Yegge：今天的时间会过得很快，我将讨论明年(2026年）开发工具的样貌。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在所有人都迷恋 Claude Code，市面上大概有四十个竞争者，但 Claude Code 并不是答案，代码补全也不是。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;虽然我每天使用它十四个小时，但开发者并未真正采纳。核心问题是这些工具使用难度过高，认知负担重，而且常常“撒谎、作弊、偷懒”。因此大多数开发者并不喜欢这样的工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我逐渐认识到，Claude Code 很像电钻或电锯。对于没有受过训练的人，它既能帮上忙，也能造成巨大损伤。未受训练的工程师使用 Claude Code，与一个新手拿着电锯差不多：既可能“切到脚”，也可能在熟练后完成极其精细的工作。然而软件世界无限广阔，而我们的野心也同样无限。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;因此我想用一个类比说明：明年将是从“手持电锯、电钻”转向“数控机床（CNC）”的一年。CNC 在给定坐标后能自动执行极其精确的操作，这项技术我们已经使用了数百年，也不会在今年停止。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c9/c95d80dbac1bae36cd549db265cdec73.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;有人说“模型已经触顶了”，你的工程师们可能也这么说。即使如此，我们仍然等同于刚发现蒸汽和电力，还需要时间去驾驭它。现在的问题已经主要是工程问题。一年到一年半内，所有代码都将由大型自动化“磨床”式系统生成，工程师不再直接查看代码。这将是一个全新的世界，而我们正走向那里。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Gene 和我曾与 OpenAI 的 Andrew Glover 交流过，他说公司内部出现了明显的分化：部分工程师使用 Codex，而更多人没有用（拒绝使用工具的人主要是资深与 Staff 级工程师），产能差距巨大，导致绩效评估出现警报。两个同级别的工程师，其生产力可能相差十倍，这让管理层非常惊慌，因为他们甚至可能不得不裁掉 50% 的工程师。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/22/22a874b661acbb71717e4f083fa6ce92.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种情况类似瑞士机械表产业的衰落：经历数百年的辉煌，却被石英表在短短几年内颠覆，当时的工匠与今天坚持传统方式的资深工程师反应如出一辙。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2f/2f1fa5c038fae21cd13a5793d3802507.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;未来需要的是一种全新的 UI，不是传统 IDE，而是新的 IDE。事实上，Replit 已经走得最前，他们的方向非常值得称赞。我们不该再继续追着旧形态、构建各种命令行界面。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/89/8982b2a872bb79323b772dde65419d58.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;更重要的是，Claude Code 及其竞争者都走错了方向——它们像在打造“世界上最大的蚂蚁”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我的朋友、澳大利亚联邦银行的 Brendan Hopper 说得很好：自然界靠蚁群协作，而 Claude Code 却造出一只巨大、耗能、高成本的“肌肉蚂蚁”。无论是要分析整个代码库，还是只是问“我的git ignore 还在吗”，它都调用最昂贵的模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/59/598c2514f47467c5c48c87d0de6b3ed5.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;于是我想到了“潜水员隐喻”：上下文窗口就像氧气瓶。现在的模型本质上是派一个潜水员下去，让它在代码库里四处探索，即使给它更大的氧气瓶，比如一百万 token，它仍会耗尽。正确做法应该是派多个角色：产品经理潜水员、开发潜水员、代码审查潜水员、测试潜水员、合并潜水员等，而不是寄希望于一个超大的单一潜水员。可没人这么做，大家都在造“大潜水员”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/3a/3a1a5c011d89fc53ca8fc584af27b027.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;未来的构建方式将是工程师熟悉的：任务分解、逐步细化、组件化、黑盒化，并依赖大量协作的智能体，而不是单一智能体。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/26/269c82af09b2d0b65f15c65fb57e01aa.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在此之前，我的建议还是：学习 Claude Code来适应新方式，并放弃你的 IDE。如果你在明年 1 月 1 日后还在使用 IDE，那你就是一个“不好的工程师”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/97/97077c1a104c8143ba383e9d41ff0aec.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Gene Kim：我研究高绩效技术组织已有 26 年，这段旅程始于我作为 Tripwire 的技术创始人。我们致力于研究那些表现卓越的技术组织——它们在项目交付、运维稳定性、安全合规方面都处于领先。我们想理解这些组织如何实现“从优秀到卓越”的转变，以及其他组织如何复制这些成果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这 26 年中我经历了许多意外，其中最大的意外之一，是这项研究最终将我带到了 DevOps 运动的中心。DevOps 改变了测试、运维、信息安全等角色的协作方式。我曾以为这会是我职业生涯中最激动人心的经历，直到我在今年 6 月首次与 Steve Yegge 见面。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我和Steve有许多共同点，其中之一就是对人工智能的热爱，以及都认为 AI 将从底层重塑软件开发的方式。我们相信，AI 对技术组织的影响，可能比十年前敏捷、云计算、CI/CD 和移动化所带来的变革大上百倍。而这些技术突破不仅会改变组织，也会重塑整个经济，让经济结构围绕更先进的生产方式重新排列。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;过去一年半，我们观察了许多案例，让我们提前看到未来技术组织的雏形。有人可能熟悉 Adrian Cockcroft，他曾是 Netflix 的云架构师，主导了 2009 年将 Netflix 整个基础设施从自建机房迁移到云端。他在几个月前写道，2011 年有人提出“无运维（NoOps）”时，引发了基础设施和运维团队的强烈反对，但现在类似的事情再次发生，只不过这次可能叫“无开发（NoDev）”。如今看来，这似乎不再好笑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们从 Zapier 的分享中看到，支持团队能发版，设计师能发版，UX 设计也能直接发版。过去被开发者告知“排队、等一个季度、等一年、甚至永远等不到”的人，现在突然能够自己把功能“对话式地”写进生产环境。这不仅改变技术组织，也可能改变整个经济。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Steve 和我很幸运能看到部署方式的改变带来什么影响。十年前，我写了《The Phoenix Project（凤凰项目）》，讲述灾难性的部署流程。当时许多组织一年只发布一次版本，难以想象。后来我参与了 DevOps 状况研究，这项跨行业研究在 2013–2019 年间覆盖了 36,000 名受访者。我们发现，高绩效团队每天能多次部署，并能在一小时内完成一次发布。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 2009 年，多次每日部署被视为鲁莽、不负责任甚至“不道德”，但如今却是常态。若想保持高可靠性、缩短平均修复时间，就必须更频繁地进行更小规模的部署。现在我们看到的案例表明，不再手写代码，而是运用新的方式进行开发，可能是一种价值更优的路径。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们在《Vibe coding》一书中提出的定义是：只要不是靠双手在 IDE 里敲代码的方式，都可以称作“Vibe coding”。有些人还像在暗房里冲洗照片一样，依旧习惯在昏暗环境里手动输入代码。但 Anthropic 联合创始人兼 CEO Dario&amp;nbsp;Amodei 给了我们更好的定义：Vibe coding 是由反复对话推动的、由 AI 生成代码的过程。他说这个词很美，能表达一种全新的开发方式，但也略带戏谑。不过对他们而言，这已经是“唯一的方式”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这是编程语言领域的重要人物 Erik Meijer 博士，他参与过 Visual Basic、C#、Haskell，也在 Meta 推出了 Hack 编程语言，在一年内迁移了数百万行 PHP 代码，引入静态类型检查。他说，我们可能是最后一代手写代码的开发者，所以应该享受这一段最后的旅程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/8d/8dd568affd763d1ec9ca2c3125a1308f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;还有一件事是这样的：去年 11 月开始，我一直在观察Steve，他每天在编码代理上花掉几百美元。这在当时看起来非常奇怪。他不仅把各种月度订阅都用到了上限，实际上还远远超出了这些额度。&lt;/p&gt;&lt;p&gt;但现在我们听到的一种说法是：作为一名工程师，我的工作本身就应该要求我每天在 token 上的花费，和我的日薪大致相当。也就是说，大概每天 500 到 1000 美元。因为这些工具带来的，是一种机械优势和认知优势。作为工程师，我会挑战自己，去榨取这种投入所能带来的最大价值，把成果交付给真正重要的人。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/23/2344e7d9a259a019f8dd14122b7348a4.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在书中，我们把人们为何愿意这样做总结成一个缩写：FAAFO。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/aa/aabd819a0f0cd76ab59fe64dd1e3548a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第一个 F 是Faster（更快），但这是最表层的理由。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更重要的是A-Ambitious（雄心），AI 让我们得以完成过去无法实现的雄心项目，把不可能的事情变得可能。在另一端，琐碎麻烦的小任务也几乎变成了零成本。我非常喜欢 Claude Code 团队中的一段采访，Katherine 说，以前客户问题会被放进 Jira 的待办项，在梳理会议中争论，一拖数周；而现在我们直接在当下修复，并在 30 分钟内发布。记录依然会做，但协调成本几乎完全消失了。也就是说，不可能的事情变得可能，麻烦的小事变得免费。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第二个A 是Able（能力），代表“更独立”，更能单独完成工作。这里有两类协调成本正被 AI 消除。第一类协调成本来自“等待”。如果你需要开发者或一个团队帮你做事，你必须沟通、协调、同步、排优先级、游说、升级……总之必须让他们“和你一样在乎这个问题”。而现在，依靠这些近乎奇迹般的新工具，你可以自己完成许多工作。第二类协调成本来自“理解”。即使别人愿意像你一样重视某件事，他们也无法读你的心。但我们发现，LLM 是惊人的“协作中介”。仅通过一个 LLM，你就能以 Markdown 文档的形式与不同职能顺畅协同。这当然不是最终形态，但它让高带宽的理解成为可能。因为要想实现共同的成果，就必须先有共同的目标与共同的理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;第二个 F，是 Fun（好玩）。正如 Steve 所说，Vibe coding 具有成瘾性。我们见过两个人原本以为“写代码的黄金时代已经过去了”，结果却意外发现现实恰恰相反。我现在常常玩得太投入，不逼自己去睡就会写到凌晨两三点。它不是只有好的一面，但肯定比无聊、枯燥甚至痛苦要好得多。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;O是Optionality（可选项）。我们非常重视“创造期权价值”。模块化之所以强大，也因为它能创造更高的期权价值。Vibe coding 能让你同时进行更多实验、更多尝试，因此它是极具经济价值的工具。Steve Yegge 说，对于已经经历“顿悟时刻”的人来说，本能反应往往是：如何让团队中所有人都获得与你现在同等的生产力？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;下面我分享一些让我们看到未来形态的案例。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;例如，Travelopia 的产品与技术负责人 Sree Balakrishna 的分享。Travelopia 是一家年营收 15 亿美元的旅行企业。他们曾用一个小团队，在 6 周内替换一套传统系统。按过去的方式，需要 8 人（6 个开发、1 个 UX、1 个产品负责人）；而现在，也许只需要一个开发与一个领域专家，正如 Kent Beck 所说，“一个有问题的人加一个能解决问题的人”。这种团队规模的变化会深刻影响组织未来的运作方式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e3/e3aadc82b15766130f889bbc3eccdd58.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我最兴奋的案例来自 Dr. Tapabrata Pal。他在 Capital One 推动过 DevOps，如今在 Fidelity 负责一个关键应用，用来查询公司 2.5 万个应用中哪些受 Log4j 影响。过去他的团队总说重新做这个工具需要 5 个月，并需招聘前端工程师。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最终他自己花 5 天 Vibe coding 出了一个版本，并上线生产。他只是想证明：事情完全能做，而且可以更快完成。后续更戏剧的是：他为应用找维护者，资深工程师们都不愿接手，最后是团队中最年轻的工程师成为维护者，并正在快速成长。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与此同时，这个应用的内部用户数量增长了 10 倍，他也因此获得更多人手。这些变化是任何人都没预料到的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;再分享一个例子，我重返 Google Cloud 团队做的 Dora 研究，其中一项未进入正式报告的发现是关于“AI 信任度”。我们采用的信任定义是：你能多大程度预测对方（AI）的行为？越信任，就能给更大请求，用更少词语，减少反馈需求。结果显示：使用 AI 的时间越长，信任越高。那些说“我试了一下，它写代码很差”的人，多半只用了 1 小时。显然，AI 的掌握是可训练的技能，需要实践，而不是一次性体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/18/180a259b65eb420133f3397dc1ab0a39.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;因此，我们的责任之一，是帮助他人获得“顿悟时刻”，并协助他们不断练习，从而真正掌握这些强大的工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;六周前，Steve 和我为领导者们做了一次 Vibe coding 工作坊。三小时内，完成率 100%，每个人都做出了成果。还有一位，他说自己 15 年没写代码了，却在短时间内做出一个自动帮自己抢 Southwest 登机位的工具（直到被反机器人系统封掉），你从他脸上的表情就能看到那种久违的创造力被重新点燃。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/dc/dcb9564856bcd6cc931edd02150191a7.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以，当支持团队、领导者能编码并上线时，技术组织必然会重塑。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一个技术领导者说，当他告诉团队他写了一个应用，其中 6 万行代码都是 AI 写的，而他自己一行没看时，团队看他的眼神仿佛“希望他不存在”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/7e/7e51f4bb833719de52a99ed553bc6f89.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;另一个例子，一些存在十年的遗留系统问题，团队集合资深工程师，用 AI 生成修复方案并提交 Pull Request。这次被接受了，而不像过去那样被污名为“AI生成的低质量内容（AI slop）”。还有团队说，他们现在的代码提交速度如此之快，以至于每个代码仓库只能容纳一个工程师，否则合并冲突会让协作成本爆炸。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;https://www.youtube.com/watch?v=cMSprbJ95jg&amp;amp;t=4206s&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description><link>https://www.infoq.cn/article/SJNt2c2Sh5AgO4LbiSC8</link><guid isPermaLink="false">https://www.infoq.cn/article/SJNt2c2Sh5AgO4LbiSC8</guid><pubDate>Sat, 17 Jan 2026 05:42:26 GMT</pubDate><author>傅宇琪,Tina</author><category>生成式 AI</category></item><item><title>腾讯云ADP国内首发AI原生Widget：一句话秒级生成交互组件，重塑Agent使用体验</title><description>&lt;p&gt;智能体对话正在告别“纯文本时代”！近日，腾讯云智能体开发平台（ADP）重磅上线国内首个“AI原生Widget”，面向企业客户提供“富交互任务交付”能力，只需自然语言描述，就能实时生成表单、按钮等交互组件。该能力还同步在腾讯元器（一站式AI智能体创作与分发平台）生态侧落地，支持创作者一键生成交互卡片。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;值得一提的是，这一功能还兼容OpenAI 生态的 Widget 接入规范，外部 Widget 可依据标准协议直接导入复用，进一步拓展智能体能力边界与生态扩展空间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“AI原生Widget”是一种面向智能体任务交付的“富交互组件形态”，模型输出结构化描述（JSON Schema)，平台自动渲染为可操作的表单、按钮，并将用户交互结果回传智能体，实现任务闭环执行。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.infoq.cn/resource/image/43/40/4396b1bc36e225b054f57d50fdf6ea40.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;自然语言秒级生成智能体交互组件&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在传统的大模型对话中，文本输出是主要形式。海量的文字堆砌，不仅抬高理解成本，而且完成单一任务需要多轮来回沟通，效率低且体验不佳。Widget作为可嵌入式的自定义展示组件，能在智能体对话流中，灵活融入图表、表单、按钮等“富交互”模块，将对话界面升级为沉浸式任务平台，引导用户按步骤操作，大幅提升信息传递与任务执行效率。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当前国内的智能体平台构建Widget时，普遍采用传统“拖拉拽式低代码+手动配置字段/数据源映射关系”的方式，流程繁琐、耗时久、稳定性一般，难以适配高效开发的需求。针对这一痛点，腾讯云ADP推出的AI原生Widget，提供了模版创建、代码创建、自然语言生成等多种方式，降低开发门槛。即使非专业前端开发者，只需用语言描述需求，或调用现成Widget模板，一分钟内就能够生成对应组件，真正实现“所想即所得”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.infoq.cn/resource/image/32/a2/32fdcca20ce95b897452acb94ee92da2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;支持多种Widget开发模式&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比如用户想要搭建一个“健身小助理”智能体，通过AI原生Widget，输入提示词后，一键就能生成对应卡片。当用户询问“我要跑步”时，系统会弹出预设卡片，引导用户点选运动频率、强度等习惯信息，再根据用户的选择，快速生成“跑步训练周计划”卡片，包含每周运动安排、单次运动内容、时长和强度建议等核心信息。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.infoq.cn/resource/image/9e/8a/9ef0f98b4d200e849bb79d5df795068a.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;从纯文本对话到富交互任务执行&lt;/p&gt;</description><link>https://www.infoq.cn/article/KXHUrhczo8le9KpyyNjr</link><guid isPermaLink="false">https://www.infoq.cn/article/KXHUrhczo8le9KpyyNjr</guid><pubDate>Sat, 17 Jan 2026 05:36:06 GMT</pubDate><author>Tina</author><category>生成式 AI</category></item><item><title>AI 的下一个十年：从技术拐点到工程落地的路线图</title><description>&lt;p&gt;生成式 AI 的投资回报远超预期？Snowflake 调研全球 1900 位企业与 IT 专业人士后发现平均 ROI 高达 41%！&lt;a href=&quot;https://www.infoq.cn/minibook/aja6h8SVCM1Smvggyvvu?utm_source=snowflakecn&amp;amp;utm_medium=snowflakecn&amp;amp;utm_campaign=snowflakecn&amp;amp;utm_content=snowflakecn&quot;&gt;点击下载&lt;/a&gt;&quot;完整报告&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在技术发展史上，总会出现一些被反复回望的“拐点时刻”。在 Snowflake 首席执行官 Sridhar Ramaswamy 看来，我们正身处这样的关键节点之中——多年来机器学习与深度学习的研究积累、Transformer 等关键架构的突破，以及云计算规模能力的成熟，在这一刻汇聚，推动人工智能走向真正的产业化阶段。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2b/2bb51e554cb4794fec827c8518aa96f2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这一背景下，Snowflake 邀请了两位深度参与并塑造这一进程的核心人物，共同展开了一场关于 “未来十年 AI 蓝图” 的对话：堪称全球最具影响力的人工智能教育者和先驱者、LandingAI 执行董事长、DeepLearning.AI 创始人吴恩达（Andrew Ng），以及亚马逊云科技 Agentic AI 副总裁Swami Sivasubramanian，他曾主导 Amazon SageMaker 与 Amazon Bedrock 的构建。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这场对话并未停留在对模型能力的抽象讨论，而是围绕竞争优势、商业模式、工程架构、数据治理以及开发者未来等关键问题，勾勒出一条从战略到落地的清晰脉络。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;竞争焦点正逐渐脱离模型本身&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;围绕“AI 时代的护城河从何而来”这一核心问题，讨论首先打破了一个常见误区：竞争优势并不必然源于模型本身。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在吴恩达看来，ChatGPT 这类产品在消费者层面形成的品牌认知，本身就构成了防御壁垒；但在更多行业场景中，护城河往往取决于行业结构，而非 AI 技术能力。例如，借助 AI 加速构建双边市场的平台，其持久性来自平台机制本身，而不是底层模型。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/30/30596c95056a50fa39ca49c9a7644e72.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;一个重要变化是，软件护城河正在被削弱。过去需要多年、大规模团队才能构建的软件系统，如今在 AI 辅助编程的加持下，其可复制性显著提高。API 调用的灵活性也使开发者能够迅速切换工具，这让“API 即护城河”的逻辑变得愈发脆弱。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Swami 从企业市场的视角补充道：在真实的企业环境中，竞争焦点正从“谁的模型更强”，转向“谁能通过 API 和服务，以更优的性价比，帮助企业真正提升收入或降低成本”。在这个意义上，真正的“最佳模型”，往往是企业自身的商业模式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;从订阅制到按量计费：AI 正在重塑软件商业逻辑&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在商业模式层面，圆桌讨论也触及了一个正在发生的结构性变化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去十余年，SaaS 以订阅制为核心，其背后依赖的是软件接近零边际成本的特性。但在 AI 尤其是智能体场景中，这一前提正在发生变化——推理成本真实存在，且可能随使用规模非线性增长。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Swami 指出，当 AI 系统开始代表用户执行任务，且工作负载与用户数量脱钩时，更接近云服务的按量计费模式将变得合理且必要。吴恩达则从开发者体验出发，分享了一个直观感受：AI 编程工具的效率如此之高，以至于开发者愿意为其消耗更多算力和费用，因为由此带来的生产力提升是实实在在的。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/75/757bce25dccf7a8bd6499ab85e2184a2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这并非简单的定价方式变化，而是意味着 AI 正在重新定义“软件价值如何被衡量和付费”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;成功的 AI 架构：产品先行，为不确定性留出空间&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当讨论从战略转向工程实践，三位嘉宾形成了高度一致的共识：产品市场契合（PMF）始终优先于成本优化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;吴恩达强调，在早期创新阶段，最大的挑战不是控制成本，而是打造用户真正热爱的产品。当 PMF 出现后，工程手段总能在后续阶段将成本曲线重新压低。关键在于，在架构设计之初，就为模型可替换性和技术选择权留出空间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Swami 从大量初创企业的实践中总结出一条清晰路径：&lt;/p&gt;&lt;p&gt;初期采用通用基础模型快速验证产品；随着真实负载显现，通过微调、蒸馏、提示缓存优化等手段应对非线性成本；将模型选型视为可演进的工程问题，而非一次性决策。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这一过程中，掌控自身数据层被反复强调。将数据牢牢掌握在企业自身体系内，而不是被封装进供应商的“云端密匣”（box in a cloud），是确保未来技术与合作可选性的关键。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;非结构化数据的真正解锁：从 PDF 开始&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在谈及 AI 应用的下一个增长点时，吴恩达将注意力投向了一个长期被忽视的领域：非结构化数据。&lt;/p&gt;&lt;p&gt;在他看来，企业中最具价值、却最未被充分利用的隐性数据，正大量存在于 PDF 文档之中。无论是金融领域复杂的报表，还是医疗行业的各类表单，过去人们对 PDF 的主要交互方式，往往只是简单的关键词搜索。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而如今，借助智能体驱动的文档解析能力，AI 已能够理解复杂表格结构、提取语义信息，并将其转化为可分析、可计算的数据资产。这一变化，正在迅速催生大量新的企业级应用场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;给开发者的长期建议：回到基础，拥抱创造&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在圆桌的最后，讨论回到了一个更具情绪张力的话题：年轻开发者在 AI 浪潮下的焦虑。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Swami 指出，行业在某种程度上混淆了“编程”与“计算机科学”。即便 AI 能生成大量代码，对底层原理的理解，编译器、数据库、系统架构、数学与统计基础，依然不可替代。历史经验表明，每次技术变革初期都会经历短暂低谷与普遍焦虑，当前正处在类似阶段，但最终带来的是更大规模的创造者群体。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;吴恩达则将这一判断推向更积极的方向：这是一个前所未有的创造窗口期。构建产品所需的时间和成本正在大幅降低，而 AI 辅助编程让“学习编程”本身变得更具现实意义和乐趣。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;正如 Sridhar Ramaswamy 在圆桌结束时表示，未来无需被动等待，当下的我们比以往任何时候都更有能力去进项创造 。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;原视频地址：&lt;a href=&quot;https://www.snowflake.com/en/build/americas/agenda/?login=ML&quot;&gt;https://www.snowflake.com/en/build/americas/agenda/?login=ML&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/36/3625913187f520bdbc21798ff22d17aa.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;点击链接立即报名注册：&lt;a href=&quot;https://www.snowflake.com/events/ascent-snowflake-platform-training-china-cn/&quot;&gt;Ascent - Snowflake Platform Training - China&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/wLeViF4hSl0WQrw3r2cQ</link><guid isPermaLink="false">https://www.infoq.cn/article/wLeViF4hSl0WQrw3r2cQ</guid><pubDate>Fri, 16 Jan 2026 12:02:04 GMT</pubDate><author>王玮</author><category>Snowflake</category><category>云计算</category><category>AI&amp;大模型</category></item><item><title>受够了Copilot的“霸王条款”？GitHub全球宕机遭怒骂，引爆开发者“大逃离”！</title><description>&lt;p&gt;整理 | 华卫&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;几个小时前，有大批开发者反馈：GitHub大面积宕机了，社交平台上充斥着“粉色独角兽”的截图和相应的控诉。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/19/196132f0521e4f6f1f124188610a35ca.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;对于此次故障的原因，目前GitHub还未给出详细分析报告。然而，不少开发者们的猜测已把矛头指向了Copilot。而在近期，也有企业和许多个人开发者们在“逃离”GitHub并将代码库迁移到了其他平台。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;GitHub宕机遭怒骂：拖垮全世界开发流程&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“所有用户都被强制登出，我自己也登不进去，因为整个服务器都宕机了。”“我以为是自己眼花了，但GitHub真的宕机了。很多团队都在周四收尾迭代冲刺，这次故障怕是要导致大量工作项顺延。”“更新即将发布时，登录网站就崩溃了。”“尴尬的时刻：你意识到自己过去一个小时一直在本地提交代码，却无法推送。”“天哪，我现在该怎么给经理汇报啊。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一次GitHub的宕机，很快就在各大平台引发诸多抱怨。在发布的事件报告中能看到，GitHub承认，在宕机期间，“多项服务性能下降，特别是问题报告、拉取请求和 API。”历经大约两小时的故障排查与修复工作后，GitHub恢复服务和功能运行。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而GitHub也在解决问题后在X上作出回应，“本次故障已完全解决。感谢各位在问题处理期间的耐心与理解。故障根本原因的详细分析报告，将在完成后第一时间对外公布。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d7/d75e6c0f283f5e1b475199d0e19607b2.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对于此事，网友纷纷表示，“GitHub 的风险太大了。一家公司不应该有能力拖垮全世界的整个开发流程。”“为什么这么多项目都只托管在 GitHub 上？没有一个镜像站点，所有功能都依赖于 GitHub，成千上万的人甚至都没有考虑过其他方案…”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有人怀疑，“问题可能出在 Copilot 上。”也有人说道，“我们目前尚不能确定这是 Copilot 的问题。不能仅仅因为微软正愈发强制其开发者使用 GitHub Copilot，还吹嘘有大量内部代码由 GHCP 编写，且在此期间 GitHub 发生了数次严重宕机，就认定这些宕机与 Copilot 有关。我们不妨静观其变，等微软宣称此事与 GHCP 毫无关联时，我们就能确定GitHub 宕机和 Copilot 真的没关系了。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;Gentoo Linux将迁出GitHub，导火索直指Copilot&amp;nbsp;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当前，已有企业在因&amp;nbsp;GitHub 强制推行 Copilot 工具的举措而放弃这一平台。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据悉，Gentoo Linux 当前正计划将其仓库从 GitHub 全面迁移。而迁移的导火索，正是GitHub 试图“强制代码库使用 Copilot”。Gnoppix 是领先的开源 AI Linux 发行和服务提供商，以其通过 Portage 实现高度可定制的基于源码的包管理系统而闻名，他们一直依赖 GitHub 托管其主要的 git 仓库，包括作为数千个 ebuild 上游源代码的关键 gentoo.git 树。这一基础设施支持了一个全球开发者和用户社区，他们欣赏Gentoo在编译针对特定硬件架构和优化标志软件方面的灵活性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Gentoo 社区的讨论中，提及了一个关键事件：GitHub 会在代码仓库页面自动弹出横幅提示，敦促贡献者 “启用 Copilot”，并警告不配合的仓库将面临曝光度降低或功能受限的后果。Gentoo 开发者表示，这类干预行为严重干扰了正常开发流程，在合并请求与代码评审环节强行插入未经请求的 AI 代码建议。Gentoo 理事会一名成员发文称：“GitHub 正公然试图强迫我们的代码仓库启用 Copilot，而这是我们明确反对的。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以 Gentoo 维护者为代表的批评者认为，该工具的运作模式在开源许可证的精神与条文层面均构成侵权。Gentoo 的大量软件包构建脚本（ebuild）及专属代码，均采用 GNU 通用公共许可证（GPL）或知识共享协议的衍生版本授权，这类协议通常要求衍生作品需以兼容的授权条款进行共享。而 Copilot 的 “黑箱” 训练流程，使得外界无法判断其生成代码是否构成衍生作品，这就可能导致专有软件在未经署名或未遵循互惠原则的情况下，挪用开源代码成果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“再见了，Github，欢迎Codeberg。”1月5日，Gentoo Linux在发布的2025 年度项目回顾报告中披露迁移细节：受持续遭遇的 GitHub Copilot 强制启用相关争议影响，Gentoo 目前正评估并计划将代码仓库镜像及合并请求贡献渠道迁移至 Codeberg 平台。Codeberg 是一个基于 Forgejo 搭建的代码托管网站，由非营利组织维护，服务器部署于德国柏林。Gentoo 核心的 Git 代码库、问题工单系统等基础设施仍由官方自行托管，且暂无变更计划。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;之后，有外媒报道称，Gentoo 的迁移计划将分阶段推进。初期工作将聚焦于 gentoo.git 核心代码仓库，目标在数月内完成迁移。Gentoo 基础设施团队已在多款备选代码托管平台完成镜像原型部署，评估维度涵盖 Git 托管可靠性、问题追踪系统集成能力、持续集成 / 持续部署（CI/CD）流水线支持以及网页端代码浏览体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;迁移备选方案还包括GitLab、SourceHut，以及在 Gentoo 内部服务器部署 Gitea 等同类平台。其中，自托管方案可实现对代码资产的完全掌控，但需投入额外的运维成本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h1&gt;个人开发者成批“逃离”，Copilot疑似承认再利用开源代码&lt;/h1&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;个人开发者们对GitHub的类似不满也十分严重。在各大开发者社区及讨论平台上，都有愤怒的GitHub用户表示，他们应该摆脱强制使用的Copilot功能。过去一年来，GitHub 平台上的开发者们最热门的讨论之一也是：是否应该阻止微软的AI服务Copilot自动在代码仓库中生成问题和拉取请求。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;1月6日，有开发者在 GitHub上提交一项讨论，称其发现“Copilot似乎公开承认其对开源代码进行了再利用（或盗用？），且未遵守署名规定”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c8/c83d109dac605fbae649f4f0173c8212.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;然而，微软似乎拒绝禁用这些功能，导致许多开源软件开发者开始质疑是否存在其他替代方案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;开发者Andi McClure，在去年1月向微软Visual Studio Code代码仓库提交请求，抗议自己卸载 Copilot 扩展程序后，VS Code 界面中却再次出现 Copilot 图标。一位名叫 Constantine 的开发者在 McClure 的帖子下写道，“今天我拒绝了 Copilot 为我的 PR 生成的两条代码建议，这非常令人不安，所以我开始搜索，然后找到了这个讨论。拒绝使用AI对我来说是原则问题，所以如果这种情况继续下去，微软又不尽快提供让我选择退出代码库AI的方法，我会把我的代码迁移到自托管的解决方案上，并且永远不会再回到 GitHub。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;去年9月，McClure在一封邮件中表示，“此前每当 Copilot 干扰我的 GitHub 使用体验时，我都会在 GitHub 社区反馈区提交问题工单。我强烈反感的是，Copilot 表面上似乎在未经许可的情况下，利用我发布在 GitHub 上的代码进行训练，违反了我设定的开源许可协议；而 GitHub 还要在我眼前反复推送这款我绝不会使用的工具，简直跟广告没两样。既然这件事已经对我造成困扰，我认为没有理由再保持沉默。我觉得，我们之所以会被迫接受一些大家都不认同的事物，部分原因就是我们选择了忍气吞声。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;McClure还表示，自 GitHub 从微软旗下一家独立子公司，被划归至微软核心AI部门（CoreAI group）后，“开源社区的态度似乎已从抱怨Copilot变为开始主动远离GitHub。”据称，其在开源社区的不少同仁都在讨论从 GitHub 迁移至 Codeberg，或是自建基于 Forgejo 的托管平台（Codeberg 正是基于 Forgejo 搭建）的计划。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“微软对Copilot的推广似乎完全是自上而下的，高层似乎已经彻底忘记了客户留存等传统目标。不管出于什么原因，他们只想提升‘AI’指标，把客户群仅仅当作提升这些指标的工具。”McClure认为，人们已经开始厌倦这种情况，如果持续下去，将会削弱开发者与GitHub之间的网络联系，加速开发者进一步迁移。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.githubstatus.com/incidents/q987xpbqjbpl&quot;&gt;https://www.githubstatus.com/incidents/q987xpbqjbpl&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.gentoo.org/news/2026/01/05/new-year.html&quot;&gt;https://www.gentoo.org/news/2026/01/05/new-year.html&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://forum.gnoppix.org/t/gentoo-linux-plans-migration-from-github-over-attempts-to-force-copilot-usage-for-our-repositories/3934&quot;&gt;https://forum.gnoppix.org/t/gentoo-linux-plans-migration-from-github-over-attempts-to-force-copilot-usage-for-our-repositories/3934&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/H16Z6V1Cz3Sf1qeb4fwr</link><guid isPermaLink="false">https://www.infoq.cn/article/H16Z6V1Cz3Sf1qeb4fwr</guid><pubDate>Fri, 16 Jan 2026 10:00:00 GMT</pubDate><author>华卫</author><category>AI&amp;大模型</category></item><item><title>拒绝传统Router“瞎指挥”，多智能体如何实现智能任务分配？</title><description>&lt;p&gt;企业级多智能体（Multi-Agent）系统最大的瓶颈，往往不是Agent不够强，而是负责分发任务的Router（路由器）太“傻”。传统Router只会做简单的单选分类，面对复杂的企业级故障经常“瞎指挥”，在企业运维的十字路口，我们需要一个更聪明的“交警”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;过去一年里，Multi-Agent架构正在成为企业AI的新基建。我们忙着造更强的SQLAgent、更快的检索Agent，但却发现运维系统的十字路口却越来越拥堵了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;和想象中的Agent们“游刃有余”的自动协同、分工协作不同，因为传统Router的上限太低、智能程度有限，很难跟上Agent们“匆匆忙忙”的脚步。在未来的企业&amp;nbsp;AI&amp;nbsp;系统中，Agent越来越多，能力边界越来越模糊，系统必须具备“承认不确定性并协作解决”的能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;今天，腾讯云正式开源TCAR（Tencent Cloud Andon Router）——一个只有4B参数，但学会了“先想清楚，再选择”的智能路由模型，它专为解决跨域、冲突和模糊问题而生，为企业AI应用提供Reasoning-centric Routing+Multi-Agent Collaboration的基础形态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;为什么传统Router在企业运维场景里“玩不转”了？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这里可以看几个非常常见的场景：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1、不同agent可能能解决一样的问题，传统Router通常为单标签分类，只考虑选择一个agent，导致无法给出最优解决方案。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/59/59f3d3f5d8df472e3793060967380b4a.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;2、新业务、新Agent随时上线，传统Router对这些“新同事”完全不了解，需重新训练，也就无法快速分配给他们最合适的工作。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/89/890d442348431d5d2f3f2804da184552.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;3、用户描述模糊、不完整。例如用户提到“网站访问延时”，传统Router就无法确定不确定是CDN、COS还是网络的问题。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c1/c101e510649ddacd2de749050e74ad2e.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;4、传统Router缺乏可解释性，黑盒决策，一旦路由错了，没法快速修复badcase，后面Agent再强也救不回来。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/19/1972e99ed6a4ef6584029842603b9095.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;总结来说，传统Router面对企业场景有三大硬伤：搞不定跨域、解不了冲突、跟不上变化。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;TCAR的解法：像人类专家一样“先想后做”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;TCAR（TencentCloudAndonRouter）的核心很简单，但在Router中几乎没人认真做过——把路由从直接预测标签，变成先推理再选择Agent集合。这时候，Router不再是一个收发任务的转接系统，而是变成了一个具备推理能力的“决策者”。它把路由过程从单项选择变成了“写分析报告+组建任务组”；它的工作职能从挑选队列最前面的agent完成任务，到在专家梯队中找到最合适的那个人选来完成任务。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;它就像是一个拥有顶尖专家团队的，高度聪明且能够自我决策的“项目经理”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;能力一：Reason-then-Select（拒绝黑盒，把思考过程写出来）&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/c8/c898827dd2a674d104464ca6a3e4c1a2.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;TCAR在输出Agent之前，会先生成一段自然语言推理链，明确说明问题可能涉及哪些技术栈，不同Agent的职责边界，为什么多个Agent执行是合理的，这让路由不再是黑盒，而是可解释、可Debug、可持续优化Agent描述。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;能力二：从单挑到团战&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ac/accbee1a4fa500c49d98485ba40d8f61.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;在TCAR中路由结果不再是one-hot，而是一个Agent子集，这一步直接解决了企业系统中最棘手的Agent冲突问题：不强行压缩决策，而是保留不确定性，交给后续协作解决。当然，这也要建立在对指令聪明且充分的理解力上。&lt;/p&gt;&lt;p&gt;能力三：专家会诊，择优输出&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/79/7944b8f50fc5ca92c5a34c6b8437a3c7.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;当TCAR选出多个候选Agent后，每个Agent独立给出自己的专业答案，而后由一个RefiningAgent负责对比、消歧、融合，最终输出一个完整、无冲突的答案，这套模式在排障类问题上效果尤其明显。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;覆盖全面、命中精准，硬核且强大&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;TCAR不是一个简单的Prompt工程产物，为了让它具备上述能力，我们做了两件比较特别的事情：&lt;/p&gt;&lt;p&gt;一是两阶段训练+特殊融合，兼顾推理能力和选择精度。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;阶段一SFT（监督微调）：教会模型结构化推理，学会输出Agent集合，通过Slerp方法融合模型。阶段二RL（强化学习/DAPO）：重点调教模型“选得对不对”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;二是专门针对多Agent设计奖励函数，把路由当成一个集合预测问题，在模型覆盖率和精确度之间形成稳定平衡。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;R1奖励（类似精确率Precision）：你选出来的Agent里，有多少是真正干活的？（防止选了一堆没用的配角）R2奖励（类似召回率Recall）：关键的那几个Agent，你有没有漏掉？（防止漏掉主角）长度惩罚：防止模型为了求稳把所有Agent全选上。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;最后，经过CLINC150、HWU64、MINDS14、SGD、Qcloud五个数据集的评测，TCAR&amp;nbsp;在企业高冲突数据上全面超过当前主流大模型&amp;nbsp;Router，在高歧义、跨域问题中更稳定，4B&amp;nbsp;参数量推理速度快成本低，更重要的是下游多Agent + Refining Agent的整体成功率显著提升。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;腾讯云还提供了全套的完整开源范式，包括：TCAR&amp;nbsp;路由模型（4B）、Prompt&amp;nbsp;规范（Router / Refining Agent）、训练方法与实验细节、可直接落地的多&amp;nbsp;Agent&amp;nbsp;路由范式。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;相关链接：&lt;/p&gt;&lt;p&gt;HuggingFace：https://huggingface.co/tencent/TCAndon-RouterGitHub：https://github.com/Tencent/TCAndon-RouterPaper：https://arxiv.org/pdf/2601.04544&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description><link>https://www.infoq.cn/article/cYlRMETcNGxhDvBqCDII</link><guid isPermaLink="false">https://www.infoq.cn/article/cYlRMETcNGxhDvBqCDII</guid><pubDate>Fri, 16 Jan 2026 09:20:05 GMT</pubDate><author>腾讯云</author><category>腾讯</category><category>生成式 AI</category></item><item><title>聚焦 AI Agent 系统诊断，智能运维助手 SysOM MCP 正式开源</title><description>&lt;p&gt;&lt;/p&gt;&lt;h2&gt;AIOps 新范式：说句话就能做运维&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当前，操作系统运维面临复杂架构、依赖关系混乱、故障定位难、依赖人工经验、工具碎片化、监控不足及自动化欠缺等挑战。为应对以上难题，阿里云结合大语言模型（LLM）、智能体（Agent）与模型上下文协议（MCP），实现了自然语言驱动的智能运维：LLM 理解指令，Agent 自主执行任务，MCP 连接底层诊断工具。这三者的协同，使 AI 助手能自动诊断系统问题，生成报告与修复建议，显著提升效率，推动运维向主动智能演进。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;阿里云操作系统控制台（以下简称操作系统控制台）是一站式操作系统运维管理平台，提供了内存、I/O、网络、内核崩溃等强大的系统诊断能力，SysOM是操作系统控制台的运维组件。但这些功能通常需要用户登录控制台，并具备一定的运维经验才能有效使用。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着 AI 助手（如 Qwen Code）的普及，用户更希望用自然语言一句话解决问题，比如“为什么 CPU 变高了？”为此，SysOM 将原有诊断能力通过 MCP（Model Context Protocol）进行标准化封装，推出开源项目&amp;nbsp;SysOM MCP。SysOM MCP 脱胎于阿里云操作系统控制台，把复杂的运维操作转化为 AI 可直接调用的标准工具，让 AI Agent 能像专业工程师一样“动手”诊断系统问题——用户无需懂命令，只需用自然语言提问，即可获得精准的系统级分析。如今，SysOM MCP 正在推动自然语言成为操作系统诊断的新入口，让智能运维真正走向普惠与高效。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SysOM MCP 项目开源地址：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/alibaba/sysom_mcp&quot;&gt;https://github.com/alibaba/sysom_mcp&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;SysOM MCP：用自然语言驱动系统诊断&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;传统运维依赖命令行和专家经验，而通用 AI 虽能“说”却不能“做”。SysOM MCP&amp;nbsp;的出现填补了这一鸿沟——通过 MCP 协议，AI 不仅能理解问题，还能自动执行真实诊断，实现从“问答”到“行动”的闭环。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SysOM MCP 项目内置超过 20 个生产级诊断工具，全部通过标准 JSON-RPC over stdio/SSE 暴露，包括：&lt;/p&gt;&lt;p&gt;内存分析：内存全景诊断、Java 内存诊断、OOM 内存诊断；IO 诊断：IO 一键诊断、IO 流量分析诊断；网络排查：网络丢包诊断、网络抖动诊断；调度诊断：系统负载诊断、调度抖动诊断；磁盘诊断：磁盘分析诊断；宕机诊断：宕机诊断（dmesg 分析）、宕机诊断（vmcore 深入分析）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;项目支持&amp;nbsp;--stdio&amp;nbsp;（本地嵌入）和&amp;nbsp;--sse（HTTP 服务）两种模式，轻松集成各类 AI 客户端。&lt;/p&gt;&lt;p&gt;要在支持 MCP 协议的 AI Agent 平台（如 Qwen Code）中使用 SysOM MCP，首先需将项目代码克隆到本地：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;null&quot;&gt;git clone https://github.com/alibaba/sysom_mcp.git
cd sysom_mcp&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;再在配置文件中添加如下配置，就可以让 AI 助手能以自然语言驱动操作系统及运维操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;null&quot;&gt;{
&amp;nbsp;&amp;nbsp;&quot;mcpServers&quot;: {
&amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;sysom_mcp&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;command&quot;:&amp;nbsp;&quot;uv&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;args&quot;: [&quot;run&quot;,&amp;nbsp;&quot;python&quot;,&amp;nbsp;&quot;sysom_main_mcp.py&quot;,&amp;nbsp;&quot;--stdio&quot;],
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;env&quot;: {
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;ACCESS_KEY_ID&quot;:&amp;nbsp;&quot;your_access_key_id&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;ACCESS_KEY_SECRET&quot;:&amp;nbsp;&quot;your_access_key_secret&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;DASHSCOPE_API_KEY&quot;:&amp;nbsp;&quot;your_dashscope_api_key&quot;
&amp;nbsp; &amp;nbsp; &amp;nbsp; },
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;cwd&quot;:&amp;nbsp;&quot;&lt;sysom mcp项目目录=&quot;&quot;&gt;&quot;,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;timeout&quot;:&amp;nbsp;30000,
&amp;nbsp; &amp;nbsp; &amp;nbsp;&amp;nbsp;&quot;trust&quot;: false
&amp;nbsp; &amp;nbsp; }
&amp;nbsp; }
}&lt;/sysom&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;最佳实践：谈话间揭秘隐藏内存泄漏&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzUxNjE3MTcwMg==&amp;amp;mid=2247489171&amp;amp;idx=1&amp;amp;sn=478ea3261ce3d329ed55e05331c080a6&amp;amp;scene=21#wechat_redirect&quot;&gt;OS Copilot&amp;nbsp;&lt;/a&gt;&quot;是阿里云基于大模型构建的操作系统智能助手，支持自然语言问答、辅助命令执行、系统运维调优等功能，帮助您更好地使用 Linux 系统，提高 Linux 的使用效率。目前，操作系统控制台上的 OS copilot 已接入 SysOM MCP，用户只需在操作系统控制台中以自然语言与 OS Copilot 对话，即可自动触发操作系统问题的根因排查。整个诊断过程无需人工干预，结果以结构化形式清晰呈现，大幅降低运维门槛，让复杂问题“一问即解”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;本文以隐蔽的内存泄漏为例，展示 SysOM MCP 的诊断功能。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/5f/5f472f9db24e87b31f8202d62b8823fc.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/93/932801e5554e51e1584245c35663a8f9.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;我们可以看到上图的对话中，OS Copilot 给出了可能的泄漏原因。同时也可以点击图中下方的诊断报告，在操作系统控制台查看更详细的诊断结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/92/9246802fc8116d85f45d2778d5c1b60f.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SysOM MCP 脱胎于阿里云操作系统控制台，诊断工具已在大规模生产环境验证。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;下载地址&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;项目采用现代 Python 工具链（uv + Python 3.11+），安装简单：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;null&quot;&gt;git clone https://github.com/alibaba/sysom_mcp.git
cd sysom_mcp &amp;amp;&amp;amp; uv sync
&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;支持一键启动：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;code lang=&quot;null&quot;&gt;uv run python sysom_main_mcp.py --stdio &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;# 供本地调用 &amp;nbsp;
uv run python sysom_main_mcp.py --sse --port 7140 &amp;nbsp;# 启动 HTTP 服务 &amp;nbsp;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;使用场景&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;SysOM MCP 可接入各种 AI agent，帮助您打造具备系统诊断能力的智能助手。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;开源共建&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;🌟&amp;nbsp;GitHub 地址：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/alibaba/sysom_mcp&quot;&gt;https://github.com/alibaba/sysom_mcp&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;欢迎 Star、Fork、提交 Issue，一起构建 AI 原生运维新生态！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;联系我们&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;若想使用更全面的 SysOM 功能，请登录阿里云操作系统控制台体验，地址：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://alinux.console.aliyun.com/&quot;&gt;https://alinux.console.aliyun.com/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;您在使用操作系统控制台的过程中，有任何疑问和建议，可以扫描下方二维码或搜索群号：94405014449&amp;nbsp;加入钉钉群反馈，欢迎大家扫码加入交流。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b2/b25287aa24b6e95b58056b5056ca0927.webp&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;操作系统控制台钉钉交流群&lt;/p&gt;</description><link>https://www.infoq.cn/article/285HkzS0EM8tpHg9mBgY</link><guid isPermaLink="false">https://www.infoq.cn/article/285HkzS0EM8tpHg9mBgY</guid><pubDate>Fri, 16 Jan 2026 08:46:00 GMT</pubDate><author>万瑞萍</author><category>阿里巴巴</category><category>操作系统</category></item><item><title>亚马逊云科技发布第五代 Graviton 处理器，M9g 实例同步登场</title><description>&lt;p&gt;亚马逊云科技近日宣布了&lt;a href=&quot;https://www.aboutamazon.com/news/aws/aws-graviton-5-cpu-amazon-ec2&quot;&gt;全新的 Graviton5 处理器&lt;/a&gt;&quot;，并预览了首批基于该处理器的 EC2 实例——通用型 M9g 实例。据亚马逊云科技介绍，Graviton5 相比 Graviton4 最高可提升 25% 的性能，并首次引入 Nitro 隔离引擎（Isolation Engine），同时配备更大的 L3 缓存，在延迟、内存带宽和网络吞吐量方面均有所改善。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;根据新闻稿，基于 Arm 架构的 &lt;a href=&quot;https://aws.amazon.com/ec2/instance-types/m9g&quot;&gt;EC2 M9g 实例&lt;/a&gt;&quot;单实例最多支持 192 个 CPU 核心。更高的核心密度使核间延迟最多降低 33%，并提升了带宽表现，从而改善了数据库、分析型负载、应用服务器、游戏以及电子设计自动化（EDA）等工作负载的扩展能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Graviton5 将 Nitro 隔离引擎纳入 Nitro 系统。这是一个全新的引擎，利用形式化验证来证明不同工作负载之间，以及工作负载与亚马逊云科技运维人员之间的隔离性。该引擎拥有规模较小且经过验证的代码库，亚马逊云科技还将向客户开放其实现及相关证明，以供审查。亚马逊云科技内核和虚拟化工程师 Mohamed Mediouni &lt;a href=&quot;https://www.linkedin.com/posts/mohamed-mediouni-kaos_graviton5-introduces-the-nitro-isolation-activity-7402401265080664064-o_cD/&quot;&gt;写道&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;一个厂商自研的 hypervisor（说白了，就是对 KVM 的替代）本身就很有意思。至于这条路最终会走向哪里，还有待观察。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在最近的 re:Invent 大会上，亚马逊云科技还介绍了主题为 《&lt;a href=&quot;https://www.youtube.com/watch?v=hqqKi3E-oG8&quot;&gt;引入 Nitro 隔离引擎：用数学证明实现云端透明安全&lt;/a&gt;&quot;》 的演讲，目前已在油管上线。亚马逊副总裁兼杰出工程师 &lt;a href=&quot;https://www.linkedin.com/posts/a-saidi_aws-reinvent-2025-introducing-nitro-isolation-activity-7403510493107126272-1b-O?utm_source=share&amp;amp;utm_medium=member_desktop&amp;amp;rcm=ACoAABaQ5R4B1z_TPIVzQKBvbJ9SpDn29zaiJcY&quot;&gt;Ali Saidi 表示&lt;/a&gt;&quot;：“Nitro 隔离引擎利用 Rust 和形式化验证，打造了一个经过数学证明的云 hypervisor，为云安全树立了新的标准。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;亚马逊云科技客户对 Graviton 的采用率持续增长。根据官方数据，亚马逊云科技新增 CPU 容量中已有超过 50% 来自 Graviton；在最近一次亚马逊会员日活动中，Amazon.com 使用的 EC2 计算资源中，有超过 40% 由 Graviton 提供。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在硬件层面，Graviton5 的 L3 缓存容量是 Graviton4 的五倍，单核可用 L3 缓存增加至原来的 2.6 倍，降低了内存访问的延迟。其内存速度也高于基于 Graviton4 的 M8g 实例，对大规模、内存密集型工作负载更为有利。官方还指出，网络带宽平均提升可达 15%，EBS 带宽最高提升 20%，整体网络吞吐能力相比上一代实例最高可提升两倍。不过在 Hacker News 上，用户 diath &lt;a href=&quot;https://news.ycombinator.com/item?id=46171008&quot;&gt;评论&lt;/a&gt;&quot;道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;没有基准测试，没有 FLOPs，也没有和通用硬件的对比……“9 比 8 快，8 比 7 快，7 比 6 快，……1 最慢，但具体多快谁也不知道。”&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Reddit 上的讨论则褒贬不一，主要质疑集中在技术细节披露不足，以及 M9g 目前仅在部分区域以预览形式提供。用户 Ill-Side-8092 &lt;a href=&quot;https://www.reddit.com/r/aws/comments/1penqtp/comment/nsfr0v9/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button&quot;&gt;写道&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;作为一次自然的增量更新，这当然是件好事，而且 Annapurna 团队算是当前 AWS 中少数仍在进行真正创新的团队之一。不过现实是，在大厂之间，自研芯片如今已经成了“入场门槛”——谷歌、苹果和微软也都有相当成熟的自有芯片方案。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;也有用户指出，亚马逊云科技在不同区域之间的服务和功能一致性仍然存在明显差距。用户 Rude_Walk &lt;a href=&quot;https://www.reddit.com/r/aws/comments/1penqtp/comment/nsljsh4/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button&quot;&gt;评论&lt;/a&gt;&quot;道：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;要不先把 Graviton4 全面铺开？新加坡这种重要区域现在都还没支持。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;亚马逊云科技表示，Graviton5 的早期采用者包括 Adobe、Epic Games 和 Pinterest 等公司。目前，亚马逊云科技已开放 M9g 实例预览版的申请页面，供用户&lt;a href=&quot;https://pages.awscloud.com/AWSGraviton5-AmazonEC2M9ginstances-Preview.html&quot;&gt;报名体验&lt;/a&gt;&quot;。&lt;/p&gt;</description><link>https://www.infoq.cn/article/xtXzsEPA5rVb6ZGfpUyh</link><guid isPermaLink="false">https://www.infoq.cn/article/xtXzsEPA5rVb6ZGfpUyh</guid><pubDate>Fri, 16 Jan 2026 08:23:00 GMT</pubDate><author>Renato Losio</author><category>亚马逊云科技</category><category>框架</category></item><item><title>OpenAI前团队创业内乱，CTO泄密竞对遭开除！翁荔火速发文</title><description>&lt;p&gt;过去一年里，前 OpenAI 首席技术官 Mira Murati 创办的 Thinking Machines Lab，一度被视为“OpenAI 体系外最值得关注的实验之一”。然而，这家成立时间并不长、却已完成 20 亿美元种子轮融资的明星公司，如今正迎来成立以来最关键的一次人员震荡。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当地时间周三，Murati 在社交媒体上宣布了公司联合创始人兼 CTO Barret Zoph的离职。“我们已与Barret Zoph分道扬镳，”Murati在X平台上发帖称。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;“Soumith Chintala 将出任Thinking Machines的新任 CTO。他是一位才华横溢、经验丰富的领导者，十多年来为人工智能领域做出了重要贡献，也是我们团队的重要成员。我们非常高兴他能承担起这项新的职责。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Murati 声明中的用词较为克制，仅强调“双方已分道扬镳”，并未对离职原因、过程或分歧作出任何解释。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/9a/9a65a758cca557efb2e70169a5d27057.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;根据有人获悉的内部消息，此次是由于 Barret Zoph 个人的不道德行为（向竞争对手公司泄漏了公司机密），Thinking Machines Lab 才解雇了他。Mira Murati 甚至是在全体员工大会上宣布了这一消息。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/83/835dfa3bbd8a99f4a7d779a7c6fff42c.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但不到一小时后，另一则公开信息迅速改变了外界对这一事件的理解。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI 应用部门 CEO Fidji Simo同样在 X 平台发文，宣布欢迎 Barret Zoph、Luke Metz 以及 Sam Schoenholz “回归 OpenAI”，并明确表示这一安排“已筹备数周”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Simo在发文中称，“Barret 将向我汇报工作；Luke 和 Sam 将向 Barret 汇报工作。关于他们未来的工作重点，敬请期待！”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f4/f458d4cd3910684874a5d4c0177cc084.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;短短 58 分钟内，两个高度相关却几乎没有交集的公开声明，构成了一次罕见而耐人寻味的“信息对冲”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从结果看，这不仅是 Thinking Machines Lab 失去了一位联合创始人，更是一次系统性的“回流”：三位核心技术人物，几乎同时从 Murati 的创业公司转向 OpenAI。对于一家尚未正式推出核心产品、却以“重塑通用人工智能研究方式”为愿景的初创公司而言，这一变化的象征意义，远大于人员数量本身。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;随着事情的发酵，Thinking Machines Lab 联合创始人、前 OpenAI 安全研究副总裁翁荔（Lilian Weng）也在X上发声了，她的发文中没有明确就此事展开评论，而是发了一些个人感慨：&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ac/ac30f030960f27c584c284ece3bba8a3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;从 OpenAI 核心到创业阵营&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;要理解这次事件的分量，必须回到几位关键人物的背景。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Mira Murati 曾长期担任 OpenAI 的首席技术官，是 GPT-4 等核心模型研发阶段的重要管理者之一。她在 2024 年 9 月离开 OpenAI，此举一度被外界解读为 OpenAI 高层频繁变动背景下的又一次重要分叉。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;离职后不久，她便与 Barret Zoph、Luke Metz 等人共同创立 Thinking Machines Lab，并亲自出任首席执行官。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a0/a01fd91c64633279d997c7ed5145f7a3.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Thinking Machines Lab CEO、OpenAI 前CTO Mira Murati&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Zoph 的履历在 AI 研究界极具分量。他曾担任 OpenAI 研究副总裁，在此之前，他在谷歌担任研究科学家长达六年，是深度学习与架构搜索方向的重要研究者之一。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 OpenAI 期间，他负责后训练（Post-Training）研究，这包括模型对齐、工具调用、评估体系、ChatGPT 性能提升、搜索功能以及多模态能力开发等关键项目。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其博客个人介绍中也明确指出，他在 OpenAI 工作期间 “他的团队负责对齐、工具使用、评估、ChatGPT、搜索和多模态等功能，并训练用于 ChatGPT 与 API 的模型”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这些职责意味着 Zoph 在当时直接参与了 OpenAI 核心模型（例如 ChatGPT 与大型语言模型系列）从研究阶段到产品化前训练阶段的关键工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/31/310edd24ffe4ad0adff6520b3e035213.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Thinking Machines Lab 前 CTO、 OpenAI 前研究副总裁 Barret Zoph&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Luke Metz 同样曾在 OpenAI 工作多年，曾是 OpenAI 团队的创始成员之一。他与 John Schulman、Barret Zoph、Liam Fedus 以及其他许多人一起，开发了ChatGPT。在此之前，他曾在 Google Brain 担任研究科学家。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在进入行业之前，Metz 就已活跃于机器学习研究领域，其学术作品涉及优化、元学习、生成模型等多个方向。从他在 ResearchGate 和 Semantic Scholar 上的发表记录可以看出，他参与了多篇关于深度学习、学习优化策略和元学习的论文，这些论文的引用量很高，表明其研究在社区内部具有较强影响力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e8/e8598c453903bbdfd6c54c89ff28734b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;OpenAI 前核心成员 Luke Metz&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Sam Schoenholz 也有 OpenAI 工作经历，在 OpenAI 工作期间，他参与了多个生成式模型研发相关的体系贡献，但官方报道并未具体列出他的单项项目头衔或单独负责成果。他的 LinkedIn 页面在事件发生后仍显示其供职于 Thinking Machines Lab。在加入OpenAI之前，他也曾供职于谷歌。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/5d/5da470f9ef0afb80027ba6771f07cde1.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;OpenAI前研究员 Sam Schoenholz&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;虽然 Thinking Machines Lab 的官方公告未单独提到 Schoenholz 的离职，但 OpenAI 的声明中明确包括他，表明他确实从Thinking Machines Lab 转向 OpenAI。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;正因如此，Thinking Machines Lab 从一开始就被视为一次“前 OpenAI 核心技术团队的集体外溢”。这一判断并非空穴来风。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;高调的AI创企，首个产品没砸出任何水花&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;公司自成立之初就定位于 构建通用、更可定制、更易理解的 AI 系统，希望让 AI 能适应人类多种需求，并让研究社区与开发者更容易使用最前沿的模型能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;成立后不到半年，Thinking Machines Lab 在 2025 年 7 月完成了规模高达 20 亿美元 的种子轮融资，由风险投资机构 Andreessen Horowitz（a16z） 领投，多家机构参与，包括 Nvidia、AMD、Accel、Cisco、ServiceNow 和 Jane Street 等。该融资使公司估值达到约 120 亿美元，成为当时成立尚短、尚无收入、尚未明确推出产品的 AI 初创公司中估值最高的一例。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一融资规模之所以备受关注，主要来自两个方面：一是资本对核心人才的押注：资本市场对包括 Murati 在内的“OpenAI 系创业团队”给予了极高的信任，认为该团队能够开拓新一代 AI 研究与产业方向。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;二是对 AI 未来路径的押注：投资者愿意用“种子轮”阶段资金支持一个尚未推出产品的团队，反映出市场对 AI 基础研究与基础设施工具方向的高度预期。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在这个阶段，公司极少透露技术细节、产品计划或战略路线图，外界对其业务进展了解甚少。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;直到 2025 年 10 月，Thinking Machines Lab 才首次对外推出公司开发的 第一个产品——Tinker。这是公司成立之后首次公开可用于外界访问的软件工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Tinker 是一个 面向 AI 开发者和研究者的 fine-tuning（微调）工具 API，旨在让用户无需管理复杂的训练基础设施，就能对大型语言模型进行定制训练。具体来说：它为语言模型提供微调的 API 接口，让开发者可以通过几行代码选择不同模型（如 LLaMA、Qwen 等），进行任务定制。 官方宣传称该产品旨在“将前沿 AI 能力民主化，让更广泛的研究者和开发者有机会实验与定制模型”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;然而，首款产品问世后，市场反馈保持审慎甚至怀疑的态度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一些用户认为，目前许多大模型平台（包括 OpenAI、Anthropic、Meta 等）已有 fine-tuning 工具，因此 Tinker 并不构成明显的“突破性产品”，存在独特性不足的短板。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，根据少量外媒评述，Tinker 的用户基础尚处于探索期，没有展现出“行业级爆款”效果，而只是一个在开发者社区和实验环境中被尝试的工具。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;推出时间距离融资完成有较长滞后，且产品本身尚处于早期阶段，并未显现出对现有大模型平台的明显替代或补充效应，因此外界对Thinking Machines Lab的评价愈发消极。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这种情况下，往往更容易暴露出创始团队的理念分歧。因此也就有了如今创始团队“内讧”的局面。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/56/5632762a27f2a490f96c3193fa6f299b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;截图源自网络&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;资本充足，为什么还会出现人员流失？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Wired 的相关报道指出，Zoph 与 Thinking Machines Lab 的分手“并不友好”。虽然报道并未披露具体冲突细节，但这一描述本身，已经与 Murati 在公开声明中所采用的克制措辞形成了明显对比。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;值得注意的是，Murati 的声明中并未提及 Luke Metz 与 Sam Schoenholz 的去向，也未就公司内部是否发生更广泛的人事变动作出说明。而 OpenAI 方面的表态，则一次性点名三人，并强调这一回归“已筹备数周”。这意味着，至少在时间线上，相关沟通并非临时决定，而更可能是在 Thinking Machines Lab 内部结构尚未对外公开调整之前，就已基本敲定。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这一时间差，为外界留下了足够的解读空间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从 OpenAI 的角度看，这次人员回流同样耐人寻味。近年来，OpenAI 在模型研发、产品化和组织治理层面都经历了快速变化。应用部门的地位不断上升，通用模型之外，如何将能力转化为可持续的产品与平台，成为公司内部的重要议题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Fidji Simo 的表态，释放了一个清晰信号：这些回归并非偶发，而是被视为战略性补强。Zoph 曾负责 OpenAI 的研究工作，Metz 与 Schoenholz 也熟悉公司内部体系。在一个研发复杂度不断提高、组织规模持续扩张的阶段，重新吸纳“熟悉文化、具备研究深度”的技术骨干，本身就是一种降低组织摩擦的选择。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与之形成对照的是，Thinking Machines Lab 仍处于“高度依赖创始人协作”的阶段。当联合创始人之间在研究方向、组织节奏或权责边界上出现分歧时，其冲击往往更直接。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这次事件的特殊性，还在于其发生在一家资金极其充裕的初创公司内部。20 亿美元的种子轮融资，本应为团队提供充足的试错空间。但事实表明，资金并不能消解所有结构性张力，尤其是在高密度智力劳动与强价值主张并存的组织中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这次事件已经为外界提供了一个极为罕见的观察窗口：当顶级 AI 人才、超级资本与宏大愿景同时汇聚时，真正决定组织命运的，往往不是融资规模或履历光环，而是能否在高度不确定的探索中，维持稳定而清晰的共同方向。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前，以TechCrunch 为代表的多家外媒已联系 Thinking Machines Lab 与 OpenAI 寻求进一步置评，但截至报道时，双方尚未提供更多公开说明。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;网友怎么看？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此事发生后迅速在社交媒体引发热议。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在Reddit平台，有用户评论称这次“AI 人才流转实在太正常了”，OpenAI 有能力快速重新吸引之前的员工，因为其资源和品牌影响力强大。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一位用户用半开玩笑的语气说他“想象 Zoph 像是 OpenAI 的间谍，被抓住后跑回去了（笑）”，表明社区对事件背后动机的好奇与揣测。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/54/54427aaae3eb86e16beab8831e071018.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此次 Thinking Machines Lab CEO 与其他成员之间“不体面的分手”也让一些网友嗅到了OpenAI内部层级架构之间的不足之处。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在X平台，有用户表示，“OpenAI 在人工智能领域是开放的，但在组织结构方面则不然。&lt;/p&gt;&lt;p&gt;层级结构依然存在。大型团队就是这样运作的。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e0/e0165efc93224540ee7aed3ccbab2e16.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://dataconomy.com/2026/01/15/openai-rehires-top-talent-as-muratis-12b-startup-loses-co-founders/?utm_source=chatgpt.com&quot;&gt;https://dataconomy.com/2026/01/15/openai-rehires-top-talent-as-muratis-12b-startup-loses-co-founders/?utm_source=chatgpt.com&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://techcrunch.com/2026/01/14/mira-muratis-startup-thinking-machines-lab-is-losing-two-of-its-co-founders-to-openai/&quot;&gt;https://techcrunch.com/2026/01/14/mira-muratis-startup-thinking-machines-lab-is-losing-two-of-its-co-founders-to-openai/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.researchgate.net/profile/Luke-Metz?utm_source=chatgpt.com&quot;&gt;https://www.researchgate.net/profile/Luke-Metz?utm_source=chatgpt.com&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://lukemetz.com/about/&quot;&gt;https://lukemetz.com/about/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/jP3NTaQpjTjP7U7FrSRW</link><guid isPermaLink="false">https://www.infoq.cn/article/jP3NTaQpjTjP7U7FrSRW</guid><pubDate>Fri, 16 Jan 2026 07:13:46 GMT</pubDate><author>李冬梅</author><category>OpenAI</category><category>生成式 AI</category></item><item><title>AWS CloudWatch成为一个统一的可观测性平台，支持Apache Iceberg</title><description>&lt;p&gt;亚马逊云科技宣布，&lt;a href=&quot;https://aws.amazon.com/cloudwatch/&quot;&gt;Amazon CloudWatch&lt;/a&gt;&quot;实现重大增强，从一个基本的监控服务转变为一个统一的可观测性平台，能够整合多账户环境中的操作、安全和合规日志。本次更新解决了企业中一个长期存在的挑战：分散的日志管理需要多个工具和数据副本，每一个都会增加成本和复杂性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;本次更新的关键创新是&lt;a href=&quot;https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/s3-tables-integration.html&quot;&gt;通过Amazon S3表以兼容Apache Iceberg的方式访问日志数据&lt;/a&gt;&quot;，使组织能够在不使用ETL管道的情况下就地查询日志，同时保持与第三方分析工具的兼容性。这种方法，结合对&lt;a href=&quot;https://docs.aws.amazon.com/security-lake/latest/userguide/open-cybersecurity-schema-framework.html&quot;&gt;Open Cybersecurity Schema Framework&lt;/a&gt;&quot;（OCSF）和&lt;a href=&quot;https://opentelemetry.io/&quot;&gt;Open Telemetry&lt;/a&gt;&quot;（OTel）标准的原生支持，使CloudWatch成为像Splunk和Datadog这样的成熟的可观测性平台的潜在替代品（至少对于以亚马逊云科技云为中心的组织来说是这样）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;CloudWatch现已原生支持跨账户和区域聚合预置日志，通过AWS Organizations整合AWS CloudTrail、Amazon VPC Flow Logs和AWS WAF访问日志等。此外，该服务还支持第三方数据源，包括：CrowdStrike、Okta、Wiz、Zscaler、Microsoft Office 365以及ServiceNow CMDB。CloudWatch为各类数据源提供了托管的OCSF转换服务，并&lt;a href=&quot;https://zerogrok.com/grok-patterns/&quot;&gt;通过Grok实现自定义解析与字段级操作&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;CloudWatch将日志管理简化为一个内置治理功能的单一服务，消除了在不同工具中复制多个数据副本的需求。统一数据存储减少了ETL管道的复杂性，降低了运营成本和管理开销。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;用户可以在CloudWatch中使用自然语言或流行的查询语言，如LogSQL、PPL和SQL，通过单个界面运行查询。此外，他们可以通过兼容Apache Iceberg的表，使用自己喜欢的分析工具查询数据。新版&lt;a href=&quot;https://davidmorrill.github.io/facets/facets_ui.html&quot;&gt;Facets界面&lt;/a&gt;&quot;允许通过源、应用程序、账户、区域和日志类型简便地进行筛选，并通过智能参数推断实现跨账户和跨区域查询。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a6/a681e0f444f22651035122687c0d3965.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;图片来源：&lt;a href=&quot;https://aws.amazon.com/blogs/aws/amazon-cloudwatch-introduces-unified-data-management-and-analytics-for-operations-security-and-compliance/&quot;&gt;亚马逊云科技新闻博客&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在LinkedIn上的一篇&lt;a href=&quot;https://www.linkedin.com/posts/suresh-rajashekaraiah_amazon-cloudwatch-just-changed-the-game-activity-7404201064591167490-Owc5&quot;&gt;博文&lt;/a&gt;&quot;中，Mphasis架构师Suresh Rajashekaraiah指出，多年来企业一直苦于运营日志与安全日志存储分散的问题，这使得故障排查和合规流程变得复杂。然而，通过增强Amazon CloudWatch，这个问题得到了解决。该服务提供了一个统一的日志平台，整合并规范了来自其云服务和第三方的数据，支持更高效的查询。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;然而，Corey Quinn通过他的AWS Snarkbot在Bluesky上发了这样一个&lt;a href=&quot;https://bsky.app/profile/aws-snarkbot.lastweekinaws.com/post/3m6zgsivyvx22&quot;&gt;帖子&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;CloudWatch如今做到了Splunk十五年前做的事，但每句话里云服务名称的数量远超实际内容。“统一数据存储”=S3加上额外的步骤和咨询账单。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;虽然Splunk提供了跨Azure、GCP和本地环境等平台的可见性，但亚马逊云科技押注其原生集成和“零ETL”成本，这可以为他们赢得以亚马逊云科技云为中心的组织的青睐。此外，虽然像Datadog和Dynatrace这样的竞争对手提供了深入的应用性能监控和混合云UI，但它们产生的出口和索引费用通常高于亚马逊云科技采用的S3表“就地查询”模型。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;开源替代方案，如ELK技术栈（Elasticsearch、Logstash、Kibana）和Grafana Loki，提供了供应商无关的统一日志管理，并且由社区驱动创新，不过它们需要组织管理自己的基础设施和运营复杂性。CloudWatch的托管服务方法消除了这种运营负担，但会将组织更紧密地绑定到亚马逊云科技的生态系统，对于寻求多云灵活性的团队来说，这会带来供应商锁定的问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;目前，除了AWS GovCloud（美国）区域和中国区域，Amazon CloudWatch的增强功能在所有AWS区域都已提供。要了解Amazon CloudWatch的定价详情，可查看&lt;a href=&quot;https://aws.amazon.com/cloudwatch/pricing&quot;&gt;定价页面&lt;/a&gt;&quot;。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/aws-cloudwatch-unified-logs/&quot;&gt;https://www.infoq.com/news/2026/01/aws-cloudwatch-unified-logs/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/siglzhFYdV4bfKPfplrj</link><guid isPermaLink="false">https://www.infoq.cn/article/siglzhFYdV4bfKPfplrj</guid><pubDate>Fri, 16 Jan 2026 07:03:00 GMT</pubDate><author>Steef-Jan Wiggers</author><category>亚马逊云科技</category><category>框架</category></item><item><title>首个智能体商业信任协议来了！支付宝携手千问App、淘宝闪购等发布AI商业协议ACT</title><description>&lt;p&gt;1月16日，支付宝联合千问App、淘宝闪购、Rokid、大麦、阿里云百炼等伙伴，正式发布ACT协议（Agentic Commerce Trust Protocol，智能体商业信任协议）。这是中国首个面向Agent 商业需求设计的开放技术协议框架，为 AI 与电商、外卖等服务平台的协同打造一套 “通用语言”，让跨终端、跨系统、跨平台的 AI 任务执行，变得更便捷、更高效。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/7e/7e0d550b6327306c0a821430007191f9.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;以千问App为例，依托 ACT协议 ，千问App成功打通淘宝闪购与支付宝 AI 付：用户只需向千问发出指令 “帮我点杯珍珠奶茶”，千问基于用户地理位置，智能推荐附近符合需求的商品，同步完成比价与优惠券自动核销。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;用户仅需点击 “选它”，确认支付宝付款，即可一键完成结账。整个购物流程以对话式、自动化、不跳端的方式推进，千问化身专属 “购物助手”，包办繁琐操作。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;当AI 的能力边界不断拓展，从“聊天对话”延伸至购物付款等“办事时代”，新的问题也随之浮现：AI 操作是否获得用户明确授权？资金交易过程是否足够安全？更换设备或应用后，服务体验能否保持连贯？&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;ACT 协议的诞生正是为破解这些问题而来。支付宝为其搭建了 “委托授权域”“商业交互域”“支付服务域”“信任服务域” 四大核心基础设施标准，实现 AI 操作全流程可追溯、可验证，让人更放心；支持自动化交易流程，减少不必要的人工干预，提升服务效率；统一多平台服务标准，避免体验的割裂。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/f9/f9df1ea4382f50cb3b8946230068cb42.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;与传统付款模式不同，在ACT协议的规则框架下，AI 仅承担下单操作的执行角色，付款环节始终由用户主导或自主授权。在保障资金安全的前提下，为用户大幅节省时间成本。而对商家而言，未来接入 AI 原生应用时，只需按照协议标准配置统一接口，即可对接全渠道入口，无需单独进行复杂的 API 开发，大幅降低对接成本。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;目前，ACT 协议可使用在AI 代买、企业自动化采购等多元场景，并提供两种付款模式：一是即时付款，用户与 AI 实时对话，基于推荐列表自主决策，确认后完成付款授权与身份验证，适用于 AI 点外卖、日常购物等高频场景；二是委托授权，用户可提前设定时间窗口、金额上限、商家范围等条件，即便离线无指令，AI 也能自动监测商品动态并完成下单结算，适用于机票、酒店预订等场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;该协议最大限度遵循兼容性、隐私性、开放性三大原则，全面适配现有商业与支付系统，并将伴随AI 行业技术发展持续优化。支付宝同时表示，正积极推动更多支付服务商、商家与平台、AI 开发者、智能终端生态厂商加入，共同完善协议内容，共建 AI 商业信任新生态。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;随着AI 原生应用能力的持续升级，“AI 代办” 服务日渐普及，支付作为其中特殊且关键的环节，正成为全球科技企业的布局焦点。此前，OpenAI 联合 Stripe 推出协议以支持 ChatGPT 结账功能；近期，谷歌也发布 AI 购物全流程通用商务协议（Universal Commerce Protocol，简称 UCP），将实现用户在 Gemini 内直接下单。&lt;/p&gt;</description><link>https://www.infoq.cn/article/DE0ifdKyd4Oevz5Bgr3X</link><guid isPermaLink="false">https://www.infoq.cn/article/DE0ifdKyd4Oevz5Bgr3X</guid><pubDate>Fri, 16 Jan 2026 03:11:39 GMT</pubDate><author>李冬梅</author><category>阿里巴巴</category><category>生成式 AI</category></item><item><title>谷歌发布 Gemma Scope 2，深化对 LLM 行为的理解</title><description>&lt;p&gt;&lt;a href=&quot;https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/&quot;&gt;Gemma Scope 2 是一套旨在解释 Gemini 3 模型行为的工具&lt;/a&gt;&quot;，使研究人员能够分析模型的突发行为，审核和调试 AI 代理，并针对越狱、幻觉和阿谀奉承等安全问题制定缓解策略。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;可解释性研究旨在理解 AI 模型的内部工作机制和学习算法。随着 AI 变得越来越强大和复杂，可解释性对于构建安全可靠的 AI 至关重要。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌将 Gemma Scope 描述为大型语言模型（LLM）显微镜。它结合了稀疏自编码器（SAEs）和转码器，让研究人员能够检查模型的内部表示，查看它“思考”的内容，并理解这些内部状态如何塑造了其行为。一个关键的应用场景是检查模型输出与其内部状态之间的差异，按照谷歌的说法，这可能有助于发现安全风险。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Gemma Scope 2 针对 Gemma 2 模型家族从多个方面扩展了原先的 Gemma Scope。最值得注意的是，它在 Gemini 3 模型的每一层中重新训练了其 SAEs 和转码器，包括 &lt;a href=&quot;https://arxiv.org/abs/2501.18823&quot;&gt;kip-transcoders&lt;/a&gt;&quot; 和 &lt;a href=&quot;https://transformer-circuits.pub/2025/attribution-graphs/methods.html&quot;&gt;cross-layer transcoders&lt;/a&gt;&quot; 。这些转码器旨在使多步计算和分布式算法更容易解释。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌&lt;a href=&quot;https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/Gemma_Scope_2_Technical_Paper.pdf&quot;&gt;解释说&lt;/a&gt;&quot;，增加层数直接增加了计算和内存需求。为了保持复杂性随层数线性增长，这需要设计专门的稀疏内核。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;此外，谷歌采用了&lt;a href=&quot;https://arxiv.org/abs/2503.17547&quot;&gt;一种更先进的训练技术&lt;/a&gt;&quot;，使 Gemma Scope 2 有更强的能力来识别更有用的概念，同时也解决了初版实现中已知的几个缺陷。最后，Gemma Scope 2 引入了专门针对聊天机器人进行分析的工具，使研究人员能够研究复杂的多步行为，如越狱、拒绝机制和思维链忠实度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;稀疏自编码器使用一对编码器和解码器函数来分解和重建所有 LLM 输入。另一方面，经过训练后，转码器能够稀疏重建多层感知器（MLP）子层的计算过程，即学习如何对给定输入进行输出近似。这使其能够识别各层及子层中哪些部分（更精确地说是哪些激活模式）是由单输入令牌或令牌序列触发的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;除了应用于安全领域外，&lt;a href=&quot;https://www.reddit.com/r/LocalLLaMA/comments/1eh4wja/comment/lfykb9o/&quot;&gt;Reddit 用户 Mescalian 预测&lt;/a&gt;&quot;，这项研究还可以：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;指导其他领域的最佳实践，未来可能会被用来监控智能程度更高的 AI 的内部推理。不过目前，它最适用于通过对权重进行微调及其他修改来调整模型能力。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与谷歌类似，&lt;a href=&quot;https://www.infoq.com/news/2025/04/anthropic-ai-microscope/&quot;&gt;Anthropic&lt;/a&gt;&quot; 和 &lt;a href=&quot;https://www.infoq.com/news/2020/04/open-ai-microscope/&quot;&gt;OpenAI&lt;/a&gt;&quot; 也针对他们的模型发布了自己的“ AI 显微镜”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌已在 Hugging Face 上&lt;a href=&quot;https://huggingface.co/google/gemma-scope-2&quot;&gt;发布&lt;/a&gt;&quot;了 Gemma Scope 2 的权重。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/google-gemma-scope-2/&quot;&gt;https://www.infoq.com/news/2026/01/google-gemma-scope-2/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/QAVo2JuWaAElyqUA6joF</link><guid isPermaLink="false">https://www.infoq.cn/article/QAVo2JuWaAElyqUA6joF</guid><pubDate>Fri, 16 Jan 2026 02:36:30 GMT</pubDate><author>Sergio De Simone</author><category>Google</category><category>AI&amp;大模型</category></item><item><title>FACTS基准测试套件问世，用于评估大型语言模型的事实准确性</title><description>&lt;p&gt;&lt;a href=&quot;https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/?utm_source=ALL&amp;amp;utm_medium=social&amp;amp;utm_campaign=&amp;amp;utm_content=&quot;&gt;FACTS基准测试套件&lt;/a&gt;&quot;发布，这是一个旨在系统性评估大型语言模型事实准确性的全新行业基准。该套件由FACTS团队与Kaggle联合开发，扩展了早期事实基础研究相关的工作，并引入了一个更广泛的多维度框架，用于衡量语言模型在不同使用场景下产生事实正确响应的可靠性。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;FACTS基准测试套件基于原先的FACTS Grounding Benchmark，并增加了三个新基准：参数化（Parametric）、搜索（Search）和多模态（Multimodal）。结合更新后的Grounding Benchmark v2，该套件可以从反映现实世界常见模型使用场景的四个维度评估事实性。该基准测试总共包括3513个精选示例，分为公共和私有评估集两部分。Kaggle负责管理保留的私有数据集，评估参赛模型，并通过公开排行榜发布结果。总体性能以FACTS评分的形式呈现。该分值是通过所有基准测试以及两部分数据集的平均准确率计算得出的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参数化基准测试侧重于模型仅凭内部知识（无需外部工具）回答基于事实的问题的能力。问题形式类似于常见的知识问答题，通常可通过维基百科等来源找到答案。搜索基准测试评估模型能否通过标准的Web搜索工具准确地检索并整合信息，通常需要多步检索才能完成单个查询。多模态基准测试在回答图像相关的问题时检验事实准确性，需要结合背景知识进行正确的视觉解读。更新后的Grounding Benchmark v2评估响应是否基于提供的上下文信息进行了合理推演。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;初步结果既凸显了进展，也揭示了接下来要面对的挑战。在评估的模型中，Gemini 3 Pro以68.8%的总体FACTS评分位居首位，其参数化事实性与搜索事实性较前代模型均有显著提升。然而，评估的所有模型总体准确率均未突破70%，多模态事实性成为各模型普遍面临的难题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/0e/0e7c0336b403b9988fa4cff728f7bc8f.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;图片来源：谷歌DeepMind博客&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;基准测试的结构引起了从业者的关注。资深iOS工程师Alexey Marinin在评论此次发布时&lt;a href=&quot;https://www.linkedin.com/feed/update/urn:li:activity:7404597456069369856?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7404597456069369856%2C7404784965244301312%29&amp;amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287404784965244301312%2Curn%3Ali%3Aactivity%3A7404597456069369856%29&quot;&gt;指出&lt;/a&gt;&quot;：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;这种四维视角（知识、Web、基础、多模态）感觉更接近人们日常实际使用这些模型的方式。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;FACTS团队表示，该基准旨在支持正在进行的研究，而不是作为模型质量的最终衡量标准。通过公开数据集并规范评估标准，该项目旨在为衡量语言模型的事实可靠性提供一个共同的基准，以适应其持续演进的发展需求。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;原文链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.infoq.com/news/2026/01/facts-benchmark-suite/&quot;&gt;https://www.infoq.com/news/2026/01/facts-benchmark-suite/&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/zQZlFUuAIBS7HfoIK2CD</link><guid isPermaLink="false">https://www.infoq.cn/article/zQZlFUuAIBS7HfoIK2CD</guid><pubDate>Fri, 16 Jan 2026 01:53:49 GMT</pubDate><author>作者：Robert Krzaczyński</author><category>AI&amp;大模型</category></item><item><title>全靠Claude Code 10天赶工上线，Cowork 删用户11G文件不含糊！核心研发：长时间打磨再发布很难成功</title><description>&lt;p&gt;&lt;/p&gt;&lt;p&gt;Anthropic 发布 Claude Cowork 研究预览版没多久，就被曝出了删用户文件、窃取文件等问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;近日，博主James McAulay在测试Cowork 功能中，选择“整理文件夹”这一基础且高频的场景，同时还与Claude Code进行对比。当James正在对比两款工具的整理进度时，Claude Cowork 突然触发了致命错误：在整理过程中擅自删除了约11GB文件。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更令人崩溃的是，这些文件并未进入回收站，而是被执行了“rm -rf”不可逆删除命令。James紧急让 Claude Cowork 导出操作日志，确认该命令的执行记录后，咨询 Claude Code 能否恢复，得到的却是“无法恢复，属于致命操作”的回复。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;事后复盘发现，James在 Claude Cowork 询问文件操作权限时，点击了“全部允许”或“始终允许”，但没有预料到它会无视明确的“保留文件”指令，更没想到会执行不可逆删除操作。万幸的是，此次被删除的均为过往上传记录，并非核心重要文件，未造成严重损失，但这一安全隐患足以让用户对其望而却步。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/e1/e1b1ebaee3574961ce9b86f7d2044b21.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;James还指出，Cowork 与Claude Code相比，存在两点不足：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;首先是交互的繁琐性。发出“整理文件夹”的指令后，Claude Cowork 并未直接行动，而是要求先启动新任务并手动选择目标文件夹；Claude Code则直接定位文件夹并开始分析，仅需授予一次权限即可推进。Claude Cowork 通过反复交互确认整理细节，比如询问“文件按什么维度分类”“用户数据文件夹如何处理”，即便明确回复“用户数据文件夹暂不删除、保留”，它仍在待办清单中标记“删除用户数据文件夹：已完成”，虽后续未实际执行该删除操作，但也暴露了指令响应的漏洞。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其次是效率的滞后性。整理过程中，Claude Cowork 运行命令多次停顿，节奏拖沓；而同期用 Claude Code 整理“音乐文件夹”，智能体快速给出“专辑和迷你专辑、单曲、Demo、翻唱”的分类建议，确认后即刻推进整理，全程仅需数十秒。即便两者均搭载 Opus 4.5 模型，Claude Cowork 的响应速度和执行效率仍明显落后，甚至让简单的文件夹整理变成了“持久战”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;除此之外，AI 安全公司PromptArmor还发现，由于 Claude 代码执行环境中存在已知但未解决的隔离缺陷，Claude Cowork 易受通过间接提示注入实施的文件窃取攻击。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;据悉，这是一个最早由 Johann Rehberger 在 Cowork 尚未出现之前、于 Claude.ai 聊天环境中发现的漏洞，已经扩展到 Cowork中。Anthropic 对该漏洞进行了确认，但并未进行修复。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Anthropic 提醒用户：“Cowork 是一个研究预览版，由于其agentic的特性以及可访问互联网，存在独特风险。”官方建议用户警惕“可能表明存在提示注入的可疑行为”。然而，由于该功能面向的是普通大众而非仅限技术用户，PromptArmor表示认同 Simon Willison 的观点：“要求普通、非程序员用户去警惕‘可能表明提示注入的可疑行为’，这是不公平的！”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d2/d221638382f4de83263c0417be5d498b.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此前，Every 团队提前获得权限，Dan Shipper、Kieran Klaassen 直播测试了该产品并分享了使用体验。期间，Anthropic Claude Cowork 项目核心成员 Felix Rieseberg 参与解读了产品设计思路。Felix 介绍，Cowork 是一个快速上线、先交给大家看怎么应用的产品，只用了 1.5 周就完成了开发，Felix 表示未来将以用户反馈为核心快速迭代。此外，工程师 Boris Cherny 还在X 上透露，该产品的全部代码都是由 Claude Code 编写的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在直播中，Felix表示，产品工作流可拆分为 “非确定性（依赖模型智能）” 和 “稳定可重复（编写工具）” 两类，按需取舍。Skills 是平衡 “模型灵活性” 与 “工作流稳定性” 的关键，能沉淀可复用知识，还能催生涌现能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他认为，未来 Agent 类应用界面会趋简，用统一的 “泛化入口” 覆盖更多场景，而非专用化输入框堆砌。下面是三人对话部分内容，我们进行了翻译，并且在不改变原意基础上进行了删减，以飨读者。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;一周半冲刺、先上线再说&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：这是我们团队做的产品。我们在最近大概一周半的时间里全力冲刺，把它做出来了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：一周半？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：对，不过我想澄清一下：其实很多人早就有一个共识：如果能有一个“给非程序员用的 Claude Code”，那一定会非常有帮助、也很有价值。我们真正想做的，是帮助人把事情做完，不管是生活里还是公司工作中。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这之前，我们其实已经做过好几个原型，尤其是在圣诞节前。但假期期间我们观察到一件事，我相信很多人也注意到了：越来越多的人开始用 Claude Code 做几乎所有事情，某种程度上，大家是在用它“自动化自己的人生”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;于是我们就在想：有没有一个足够小、足够早期的形态，可以先做出来给大家用，然后和用户一起快速迭代，真正搞清楚什么样的用户体验才是对的、我们到底应该构建什么。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在你们看到的这个就是答案。它是一个 research preview，非常早期的 alpha 版本，有很多不完善的地方、很多毛糙的边角，你们已经看到不少了，这些我们都会很快改进。但这就是我们的尝试：在开放状态下构建产品，和外部的人一起打磨。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：我太喜欢这种方式了，能不能讲讲你们做的一些设计决策？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：这是个很好的问题。我个人有一个判断：不只是 Anthropic，而是整个 Agent 类应用的用户界面，在接下来一两年里都会发生非常大的变化。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;现在我们看到的，是为不同任务设计的高度专用化输入框，以及围绕特定任务搭出来的一整套脚手架。但随着模型能力不断提升、整个行业对“泛化问题”的理解逐渐加深，我认为未来我们会用更少的界面，覆盖更广的使用场景。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在当下，我们之所以把 Cowork 单独拆出来，是因为我们想非常透明地告诉用户：这是一个“施工中的区域”。某种意义上，我们是在邀请你走进我们的厨房。我们希望能和用户一起工作，几乎每天都上线新功能、修 bug、尝试新想法。所以这个独立的 Tab 本身就是实验性的，可以说是在前沿、甚至是“流血边缘”。它节奏更快、打磨得没那么精致，这也是我们把它单独拎出来的主要原因之一。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，也有一些技术层面的原因。比如现在这个 Cowork 是运行在你本地电脑上的，所以里面的对话是本地的，不会在多设备之间同步。同时，我们给了 Claude 更激进的一些 Agent 能力。综合这些因素，才决定做成现在这个形态。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：同一个应用里，一边是云端的聊天，一边却是在自己电脑上跑的 Agent。怎么让用户真正理解“这两者不一样”？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：是的，我心里有一个梦想，我相信很多人也有同样的想法：最终这些其实都不重要，代码到底跑在什么地方，应该只是一个技术实现细节。对用户来说，它应该就跟你访问纽约时报网站时会不会用 WebSocket 一样，谁会在乎呢？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;对我们来说，现阶段这样做的好处是，可以跑得更快、发布得更快，也能和真正使用这个产品的人更近距离地一起共创。我一直很坚定地认为，一个人关起门来是很难做出好产品的。那种“躲进山洞里干一年，最后拿出来”的方式，其实很难成功。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我也经常提醒大家：就连第一代 iPhone，都缺了很多我们现在觉得是“理所当然”的功能。所以，这确实是一个不小的门槛，但我们暂时可以接受，因为我们希望现在选择用这个产品的人，本身就是带着明确意图来的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：我觉得这是一个非常有意思的模式，先极快地把东西做出来，以一个“新入口”的形式放在应用里，让相对更少的人点进来。这样就能在真实世界里快速迭代，而不是一开始就追求完美。尤其是在你刚才说一周半就能做出一个版本，简直疯狂。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;“现在的状态是，先看看大家怎么用”&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kieran：但在你们脑海里，这个产品“真正的形态”是什么样的？你们接下来想往哪里走？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：我太喜欢这个问题了，因为说实话，我也想反过来问你们两个同样的问题：你们希望它变成什么？你们想用它做什么？我已经听你们提到过，比如想让它能访问整台电脑，还有多选交互是不是可以更灵活一些之类的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但我现在更多的状态是，先看看大家怎么用，然后疯狂尝试各种可能性。里面肯定有很多是错的，也会有一些是对的。对我来说，真正有意思的不是我个人的愿景，而是用户真正想拿它干什么。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我过去做过的产品几乎都是这样：你心里以为用户会这么用，结果他们找到了完全不同的用法，然后你顺着那个方向继续做下去。所以我特别希望我们能搞清楚：人们现在到底想要什么、喜欢什么、不喜欢什么。肯定也会有人明确说不喜欢某些地方，那我们就根据这些反馈不断调整、迭代。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kieran：这又回到一个老问题了。比如 Boris 就非常擅长把 Claude Code 做成一种让用户在使用过程中逐渐发现“自己到底想要什么”的工具。那你们在 Cowork 里有没有类似的策略？比如给我们一些“积木式”的东西？能不能加自己的插件或 Skills？Claude Code 很酷的一个地方在于它特别好 hack、特别可塑，你们面向非程序员的 Cowork 是不是也有类似理念？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：对，非常强调可组合性。你刚才提到 Boris 推动 Claude Code 早发布、快迭代、看用户怎么用，其实特别巧，我们之所以能这么快上线，很大程度上也是 Boris 在推动我说，“你应该早点给大家看看，看他们会怎么用”。（注：Boris Cherny&amp;nbsp;是Claude Code核心创作者）&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;至于可组合这一点，过去几周、甚至最近两个月里，我自己感受最深的，是我越来越依赖 Skills。以前我可能会去写 MCP 工具，或者为 Claude 专门做一套很定制化的东西，现在我更多是直接写 Skills。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有时候我还是会写一个二进制程序，但我随后就会在一个 Skill 文件里用 Markdown 描述：Claude，如果你要做这件事，请遵循这些规则。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;举个例子，我最近在给自己做一个马拉松训练计划。我写了一个小程序，从不同平台抓取我的运动数据；然后在一个 Skill 里写清楚：如果你要帮我做训练计划，请按这些原则来。现在，只要你在 Claude AI 里装过的 Skill，都会自动加载到 Cowork 里。而且我觉得这只会越来越重要，尤其是模型越来越聪明，比如Opus 4.5 版本，对 Skills 的遵循能力真的非常强。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以目前来说，Skills 大概是我们最主要、也最“可 hack”的入口。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;统一的“泛化入口”趋势&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：太棒了。你刚才提到未来会有更少的 UI 形态。这是不是也意味着，围绕“聊天是不是 AI 的最终形态”这个争论，你其实是在押注自然语言会长期存在？也就是说，我们最终不会有越来越多复杂的 UI，而是更少的界面，人只需要和一个 Agent，或者一个能调度其他 Agent 的 Agent 对话？你们现在推动的方向，某种程度上是不是就类似今天 Claude Code 所展现出来的那种形态？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：是的，这个问题现在仍然存在很大的争论空间，而且肯定不存在什么“Anthropic 官方立场”。老实说，就算是在我这个并不算大的团队里，大家也未必能在整体上达成一致。每个人对于未来人类将如何与 AI、与模型交互，都有非常不同的想象。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果只从我个人的角度来说，我大概坚信两件事。第一是：聊天式输入及其各种变体——不仅仅是模型意义上的聊天，而是更广义的那种“我想要点什么”的输入框——会比我们想象中存在得更久。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果你把它抽象开来看，不管是 Google 首页，还是 Chrome 的地址栏，本质上都是一个“我想要某样东西”的输入框，我认为这种形态会长期存在，我们会继续拥有某种看起来很像搜索框的入口。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;问题是，我们到底需要多少个这样的输入框？你会有一个专门写代码的框吗？一个用于个人娱乐的、一个处理医疗相关问题的？我并不确定未来会存在这么多彼此割裂的输入框。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我再拿 Google 做类比。过去你可能记得，Google 会为不同需求提供不同的搜索入口和子产品。但现在，越来越多时候，你只是直接在 Chrome 的地址栏里输入你想要的东西。你不会真的先想清楚“我现在是在购物模式”，然后再专门去打开 Google Shopping。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以，如果我们未来看不到一种更聪明的、能理解你想做什么的“泛化入口”，我会很意外。当然，后端可能仍然会分流，比如它理解你想要做的是 X，于是给你呈现一个适合 X 的界面，但入口本身很可能是统一的。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;产品设计中的取舍&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：我觉得一个很有意思的反例是 Microsoft Excel。某种程度上，它和 AI 的工作方式其实也很像：这是一个通用型产品，上手极其简单，但你可以在里面把事情做到无限复杂。而且，Excel 甚至某种程度上催生了后来的 B2B SaaS 浪潮，很多 SaaS 本质上就是把Excel 里的复杂工作流“产品化”了。所以也有另一种可能：你先有一个极其通用的工具，然后人们在里面发现了高价值、高强度的工作流，最后这些工作流再被拆分成独立产品。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：我觉得 Excel 真的是一个极其漂亮的例子。对很多开发者来说，Excel 其实处在一个有点“边缘化”的位置，但如果你比较一下 Excel 的日活用户数量和全球开发者的数量，那是一个非常惊人的对比。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我在 Excel 身上看到的一个很有意思的点是：它的重度用户，其实并不太在意那种“边际效率提升”，或者 UI 上一点点的小优化。他们更在意的是对这个产品的深度熟悉和肌肉记忆。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这里面是有教训的。我在很多产品表面上都见过这种情况：作为开发者，你会觉得“如果我单独给你做一个更贴合这个场景的小工具，你的工作流会更好”。但结果往往是，用户并不会去用那个新工具，而是继续在他们已经非常熟悉的产品里，把事情做完。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;举个例子，这是我在 Slack 工作多年反复学到的一课：你可以做很多你自认为更适合某个使用场景的独立服务，但用户最后往往还是选择就在聊天里完成这件事。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：说到这里，虽然今天的主题更偏向非开发者，但我感觉现在有不少开发者在看。你正好是那种“真的把这个东西做出来了”的人，对 Agent native 应用的构建理解非常深。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我们一直在思考 Agent-native 应用的核心原则。比如其中一个原则是“对等性（parity）”：用户通过 UI 能做的事情，agent 也应该能做。我在 Cowork 里已经能看到这一点。另一个是“粒度（granularity）”：工具应该尽量处在比功能更底层的层级，而“功能”更多存在于 prompt 或 Skill 中，这样你就能以开发者没预料到的方式去组合工具。这会自然带来第三个原则“可组合性（composability）”，而可组合性最终会产生第四个：涌现能力（emergent capability）。也就是用户开始用它做你完全没想到的事情，你看到了潜在需求，然后再围绕它构建产品。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这在我看来，几乎就是 Claude Code 的工作方式。我很好奇，这一套在你听来是否成立？或者从你们在 Anthropic 大规模落地的经验来看，有没有什么能让大家把 Agent native 应用做得更好的建议？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：这套说法对我来说非常有共鸣。而且我觉得，“涌现能力”里隐藏着一个非常重要的事实：无论是个人还是在孤立的小团队里，我们几乎不可能提前预测一个 Agent 最终会在哪些地方变得极其有用，尤其是当你只给了它一些相对原始的工具时。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;把工具尽可能下沉、做成通用形态，是一件非常强大的事情。工具越可组合、越通用，你就越能从模型智能的持续提升中获益。我和很多开发者聊过一个感受：模型智能提升、以及模型“正确调用工具”的能力，增长速度往往远快于你新增工具、或者教育用户理解这些工具的速度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以如果你退一步思考：“我能不能先做一个高度通用的工具？”那你构建出一个可以适应未来新场景的产品的概率，其实会大得多。这一点，我非常认同。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：那在这些原则之下，你怎么看其中的取舍？比如工具设计本身的权衡问题。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kieran：对，我觉得把东西放进 prompt 里、再配合工具，本身是很棒的。但问题在于，我们现在突然需要去创建一些“能读取 Skills 的工具”，或者类似的东西。于是就出现了一个新的“元层”。Skills 本质上就像是一种即时的 prompt 注入，但你得先把这个体系搭出来。现在所有在做这些东西的人，如果不是直接用 Claude Code 或 Cloud SDK，那基本都得自己从头构建一整套。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;于是就出现了一种拉扯：你到底是把行为直接描述在一个 tool 里？还是再包一层 tool，让它去调用别的东西？这中间是有摩擦成本的。当然，可组合性是很好的。比如一开始你可能会有五个 tool：搜索邮件、读取邮件、做这个、做那个。但你也可以说：不，我只提供一个 execute tool，然后用 Skills、MCP，或者某种抽象层来完成这些事情。现在正处在这样一个转变期，而 Claude Code 和 Claude SDK 显然是在推动这个方向。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但我确实能感受到这种摩擦。我猜你也一定感受到了。所以我很好奇：你有没有什么最佳实践，能给那些还停留在“传统 AI 应用思维”的人一些建议？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：我不确定我能给出什么“来自山顶的智慧”，会比你已经拥有的经验更有价值。但你说的那点，确实非常戳中我。我觉得你必须做一个取舍：哪些输出你愿意让它是非确定性的、哪些地方你愿意依赖模型的智能。而且一旦你依赖模型智能，每当你换一个更便宜、或者“更笨”的模型，那些地方的质量就会下降。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;所以我会把整个工作流拆成两类：一类是非确定性的；一类是可重复、稳定的。如果某个部分非常可重复，而且你可以非常确信它“永远不会变”，而且就算模型变聪明了，你也得不到任何额外收益，那我会觉得，这正是写一个工具的好地方。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其实我们已经在这么做了。你完全可以给 Claude 一个极其通用的“汇编级”工具，比如：“直接调用 GCC，你想怎么编就怎么编。”但我们并没有这么做，因为那样就太疯狂了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Skills 与可组合性实践&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：那已经是粒度的极限了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kieran：不过我也想说一句：当我和很多开发者聊的时候，我发现即便这个“是否要给模型工具”的基本假设，也正在被挑战。我不会把太多赌注压在这个假设上。比如，我们到底是不是还需要给 Claude 工具？还是说，某一天它只需要靠记忆和权重，直接把 0 和 1 写到世界里？这是一个非常有意思、也非常难判断的问题，没人真的知道答案。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但你们已经在实践中学到了一些东西。你们之所以创造了 Skills，就是因为仅靠 Slash command 或子 Agent 已经不够了，对吧？我们需要 Claude.md 更强，但现实是 Skills 正是为了解决这个问题而诞生的，而且显然它们效果很好。我完全认同你说的，Skills 太棒了。我现在几乎每天都在写 Skills，而且真的很爱用。所以这里面一定有些什么。但问题是：什么时候应该用 Skill？什么时候又不该？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：这真的是一场特别有意思的对话。有一个你以后真的应该跟 Barry 聊聊。在公司内部，至少在某种程度上，Skills 这个概念就是他提出来的。从根本上说，Skills 正是你刚才描述的那种张力的自然产物。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;举个例子，我们想让公司内部的人能很容易地拿到各种仪表盘。我们用的是一家主流数据服务商，很多数据都在那儿。一开始我们在想：要不要做一堆非常具体的工具，专门去拉数据、压缩成固定格式。最早那几版仪表盘，其实效果并不理想（那还是 4.5 之前）。大概每三四个里面，就有一个看起来很拉胯。于是，我们开始想：要不要把参数卡死，直接做一个“固定模板”的仪表盘？Claude 只负责往里面填新数据。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;但在这个过程中，我们突然发现了一件事：如果你只是告诉 Claude 如何正确地查询这个数据源、可以使用 SQL、以及生成仪表盘时需要遵循哪些设计原则，突然间，它就能稳定地产出质量很高的结果，而且是“几乎每一次”都很好。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;更重要的是，这就打开了“涌现能力”的大门。因为你还可以对 Claude 说：“我知道你在遵循这些仪表盘原则，但我想换一种图表类型”，或者“我想把它和另一份数据结合起来。”就在这一刻，事情真正开始变得有趣了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：这真的很有意思。我觉得为什么要用 Skill，而不是只给它 GCC、让一切都即兴发生，其中一个关键原因在于：你需要把一些可重复的、可分享的知识，变成一个大家都能讨论、都能复用的东西。并不是所有事情都应该是“即时生成”的。有些事情，你就是希望一个团队能长期、反复地用同一种方式来做。而这，本质上就是 Skill。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：而且这其实也很符合人类本身的工作方式，对吧？比如我刚加入一家公司时，总有人教我怎么订机票、怎么订会议室。从某种意义上说，我们每个人，都是靠着一堆 markdown 文件在工作。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;我觉得差不多该下线了，但在走之前，我想让你们两个各自给我一个建议：你们最希望我们改的一件事是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Dan：那我先来一个最简单的：给我对整台电脑的完全访问权限。还有就是，让我更清楚地知道它现在到底是在我本地电脑上运行，还是在云端以聊天的形式运行；以及，让它在手机上用起来更顺畅。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Kieran：我也支持移动端。但我最想要的是能让我添加自己的插件。我有一个插件市场，我只想把它接进来直接用。现在我得在一个应用里加东西，再拷贝到这里，有点绕。可能也能凑合用，但如果能原生支持插件市场、直接添加插件，那真的会非常棒。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Felix：好，明白了。谢谢你们，这些反馈都非常有价值。我们会把这些带回去，跟团队一起讨论。也欢迎大家把想法发给我们。我们真的很希望听到大家的反馈，并据此调整路线图。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;测试总结：理念可以，做得一般&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最后，我们总结了Every团队的测评结果。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Claude Cowork 的核心定位是为非技术用户提供 Claude Code 级别的 AI 协作能力，其最显著的突破在于重构了 AI 使用逻辑，从传统“发提示词→等回复”的一问一答模式，升级为“异步协作”模式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;与普通 Claude 聊天相比，Claude Cowork 专为“长时间工作”设计，具备持续推进任务直至完成的能力。直播中展示的典型案例包括：审计过去一个月的日历并分析与目标的匹配度、抓取 PostHog 数据统计按钮点击量、分析 Every 咨询业务的竞品、整理下载文件夹、校对 Google Docs 文案等。这些任务均需 AI 持续“浏览”、推理，部分任务耗时可达一小时左右，远超普通 AI 聊天的响应速度。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;产品的场景适配性极强，尤其适合需要深度研究和数据处理的岗位。用户只需连接 Chrome 浏览器，AI 即可直接使用用户已登录的各类服务，无需重复认证，轻松完成 Twitter 时间线热点分析、竞品信息搜集等需多平台联动的任务。同时，它支持生成文档、Excel、PPT、PDF 等多种产出物，可应用于简历优化、会议发言起草等日常工作场景，大幅提升增长团队、咨询人员、写作者等群体的工作效率。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在交互设计上，产品右侧设置了待办任务列表，清晰展示任务进度与当前阶段，用户可直观掌握 AI 工作状态。其“询问用户”功能还配备了可视化交互界面，支持多选项快速响应，进一步降低了操作门槛。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;根据测评，Cowork具备较强的可扩展性，支持加载用户已安装的 Claude Skills，这也是其最具“可玩度”和“可定制性”的核心入口。用户可通过 Skills 封装专业知识与操作逻辑，实现个性化需求。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;测评团队也指出了产品当前存在的争议与不足。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最核心的争议在于“单独设置 Cowork 标签页”的设计：部分用户认为应在同一标签页内根据任务自动切换模式，避免额外的选择成本；但也有观点认为，独立标签页能明确提醒用户切换使用心态：从“实时对话”转向“异步托付”，尤其对非技术用户而言，这种明确的区分有助于适应全新的协作范式。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另外在体验细节上，产品仍有诸多优化空间：一是 UI 打磨不足，任务列表仅按时间排序，缺乏视觉区分度，部分内容存在“懒加载”导致展示不及时；二是权限管理不够直观，普通用户难以清晰判断 AI 是在本地还是云端运行，文件夹访问权限需手动配置易造成困惑；三是“询问用户”功能存在逻辑缺陷，可能在用户未响应时自动跳过问题，且选项数量和字符数存在限制；四是对复杂应用（如 Google Docs）的适配尚不完善，相关操作容易失败。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;针对不同用户，测评团队给出了针对性使用建议：非技术用户可将其视为“升级版聊天功能”，用日常任务直接尝试，逐步适应异步协作模式；重度用户可尝试通过 Skills 定制个性化功能，探索组合使用的可能性。他们表示，所有用户均需保持好奇心，忽略“三个月前 AI 做不到”的固有认知，在每一次产品更新后重新尝试核心需求，毕竟 AI 能力每隔几个月就会发生巨大迭代。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;最终，测评团队给出的评分结论为：“理念绿牌，当前执行黄牌”。理念层面，产品开创性地将 Claude Code 级别的异步协作能力开放给非技术用户，推动了 AI 协作范式的转变，具备极高的探索价值；执行层面，因 UI 粗糙、部分功能逻辑不完善等问题，当前体验仍有较大优化空间。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_6C9nMvQsGU&quot;&gt;https://www.youtube.com/watch?v=_6C9nMvQsGU&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=oPBN-QIfLaY&quot;&gt;https://www.youtube.com/watch?v=oPBN-QIfLaY&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.promptarmor.com/resources/claude-cowork-exfiltrates-files&quot;&gt;https://www.promptarmor.com/resources/claude-cowork-exfiltrates-files&lt;/a&gt;&quot;&lt;/p&gt;</description><link>https://www.infoq.cn/article/WDcTxr8g5TT064NaQyp3</link><guid isPermaLink="false">https://www.infoq.cn/article/WDcTxr8g5TT064NaQyp3</guid><pubDate>Fri, 16 Jan 2026 00:00:00 GMT</pubDate><author>褚杏娟</author><category>AI&amp;大模型</category></item><item><title>刚刚，阿里园区被奶茶包围，都是千问点的！西溪叫不动外卖</title><description>&lt;p&gt;2026 年，AI 真正“下地干活”的第一战，被阿里打响了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;1 月 15 日，在杭州阿里园区举行的千问 App 发布会上，阿里巴巴集团总裁吴嘉做了一次并不复杂、却很直观的演示：他用千问给现场嘉宾点了 40 杯“伯牙绝弦”奶茶。整个过程没有人工介入。千问自行匹配附近奶茶店，下单，并调用支付宝完成支付。没一会儿，淘宝闪购的骑手把奶茶送进会场。发布会的气氛，也在这一刻被彻底点燃。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;事后，有杭州的网友恍然大悟“怪不得刚刚西溪附近叫不动外卖！”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/ba/ba72fd559beaf5ece58490ff5c1ae8b3.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;相比 PPT 上的参数和模型指标，这个场景更容易被理解：AI 第一次在公开场合，完整地替人把一件现实中的事情办成了。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在这次更新中，阿里将千问定位成&amp;nbsp;“每个人的生活助手”。路径也很明确：不从新场景做起，而是直接接入阿里现有的业务体系，让 AI 先把眼前的事干好。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在&amp;nbsp;日常生活&amp;nbsp;层面，千问首批接入了&amp;nbsp;淘宝闪购、支付宝、淘宝、飞猪和高德&amp;nbsp;五大业务，可以一句话&amp;nbsp;点外卖、买东西、订机票、订酒店、查路线，这些原本需要在多个 App 之间来回切换的操作，现在可以交给一句话来完成。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/6c/6c659e25b3b2f5fd57a8386e902d2613.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在&amp;nbsp;“办事”&amp;nbsp;这一层，千问的能力被进一步拉长。它开始尝试处理更复杂的任务，比如打电话订餐厅、整理调研资料、处理财务文件、辅助搭建网站等。这类功能目前仍处于定向邀测阶段，&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;吴嘉在发布会上表示：“AI 在拥有超强大脑之后，正在长出能够触达真实世界的手和脚，在生活中实实在在地替用户‘干活’。&amp;nbsp;千问的优势在于‘最强的 Qwen 模型’与‘阿里最完整的商业生态’的结合。AI 办事的时代才刚刚开始，我们会持续探索，把千问打造成真正有用的个人 AI 助手。”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;自千问上线两个月以来，月度活跃用户已突破 1 亿。&amp;nbsp;吴嘉认为，随着 AI coding、全模态理解以及超长上下文等关键能力逐步成熟，AI 正在走出手机屏幕，进入更复杂、也更真实的生产与生活场景。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;把阿里折叠进千问中，&amp;nbsp;通过统一的 AI 入口，让千问拥有&amp;nbsp;400&amp;nbsp;余项办事能力，在&amp;nbsp;生活、办公、教育&amp;nbsp;等方面全场景覆盖，让千问成为 AI 时代的超级应用入口，这正是阿里的野心。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;办事之上如何理解需求，才能判断是不是一个合格的助手&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;伴随着模型能力的跃迁，思考让 Agent 做事，已经是近几年行业的集体共识。但&amp;nbsp;干的活好不好，这才是能否放心 AI 当助手的关键。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;阿里此次的更新方向，既在意料之中，又有些意料之外的惊喜，这个惊喜的落脚点就在于&amp;nbsp;对需求的理解。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在对千问用户数据观察中，用户主动询问商品推荐的月环比高达 300%，这引起了阿里的注意，利用好千问与淘宝的链接，让千问拥有更可用的商品推荐能力，这确实踩中了不少人的真实需求，也成为千问区别其他通用 Agent 的功能独特切入点。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/d7/d77d96dc23f662ce274acc00f1023a61.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这不仅发挥了阿里在电商上的传统优势，也让庞大的商品供给和相对成熟的推荐体系真正被用起来。用户只需一句话，就能完成从商品推荐到下单的完整流程。其背后，是&amp;nbsp;阿里各业务接口的打通和协同调用，用起来足够顺，也足够省事。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;但更令人惊喜的是&amp;nbsp;对决策层面的关注，这也是&amp;nbsp;模型深入理解真实需求的表现，如何调用工具做更好的决策，体现了阿里强大的整合能力。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;比如，现场展示了要给老人购买一款家庭扫地机，并且家里还养了一只猫，预算在 2000-4000 左右。千问在综合产品的价格与能力之上，还进一步老人的便捷需求与对猫毛的清洁效果，在综合这些复杂的条件后，给出推荐产品与相关理由，这正是大模型方便人类决策的一个虚拟需求感知。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/a1/a141ee5ec5f8bdcb211d4a17eb9197e7.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在另一个徒步推荐的方案中，千问不仅推荐出行路线，结合天气情况给出建议，还将徒步需要的产品直接发送到了千问界面上，确实让人看到 AI 未来融入世界的真实摸样。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/94/94c795db2602bc1789406c2e8d10bbac.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不是只做简单的一件事，而是将好多事做好，形成闭环，阿里已经迈出第一步。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;笔者能想到的弊端，可能就是如何避免大模型被商家刷的假好评和广告垃圾数据污染，根据错误数据给出错误推荐。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在一个全家人考虑去三亚出行的案例中，千问综合了路线、预算、老人与孩子的需求等，给出了路线选择，并给出三套酒店方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/fe/fe5cc6ca26ffb34e7e474aba35271405.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过，酒店的均价都在两三千左右，不少人吐槽这恐怕没人住得起，方案不适用，不接地气，这或许是笔者认为的阿里迈出的是“半步”，还需要进一步的地方。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;现场还有一个小惊喜是，千问演示现场定饭店的时候，有一段与老板确定需求的打电话环节，从包间大小，价格，有小朋友等需求进行多方拉扯沟通，直到最后，电话结尾说，“我是千问 AI 助手在与你沟通”，大家才恍然大悟，原来是千问的语音功能在完成订酒店的“最后一公里”。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这正是各种多模态打通后，AI 能做到的程度，留给人更多想象空间。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;这种好用，同时体现在在对办公需求上，在更专业的场景上，需要更好的交付结果，要求也更难。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;千问可以集成各种复杂工具，完成做表格、整理数据、处理报表、汇报 PPT 等各种具体业务。从如何处理资料到最后成品展现，从效果来看，确实还不错。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/07/07fa85f8f5b6844bf016d30842fb6e9a.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;此次，阿里找来了专业人士来验收干活效果，千万财经博主小 Lin 说，亲自下场演示了用千问生成一份《2026 毕业生就业报告》，从信息汇总，消化资料，角度分析，文章演示到 PPT 的生成，千问干了一个完整的活。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;不过，如果把千问当做个工作三年内的大学生，来干这些活，效果还是不错的，如果要求更高，可能就是把控 PPT 的内容重点质量，PPT 的设计是否美观。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/40/40fb2d9103811e218d0cafb2f183e743.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;而在教育领域，千问也做出一些精心设计，令人印象深刻的是在各种题目中，除了思路的讲解，还会生成一段动态视频进行图示演说，能随时对话沟通，给出思路和解法，并且多模态展示，这让千问更像一个人一样解决问题。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/fe/feaccba85e81a081dd48331badff811f.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;笔者也亲自进行了一个上手测评，一个是用千问点奶茶，还有一个是用千问询问如何落户问题，千问都给出了较为实用的操作结果。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/b1/b1c582f476f9719185aa2a395af5352d.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;总体来看，千问并没有试图一下子把所有事都做好，而是在尝试把复杂的事做得更完整、更贴近人的真实需求。它距离“完全可靠的 AI 助手”还有距离，但已经明显走出了聊天框，开始进入决策和执行的真实环节。而对干活质量的进一步打磨，恐怕正是阿里下一步要发力的方向。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;在几家最受关注的 AI 巨头中，字节跳动&amp;nbsp;选择从系统层切入，通过豆包手机助手借助操作系统能力，去调度第三方应用，与现实世界建立连接；阿里&amp;nbsp;的路线则更为直接，依托自身已高度成熟的电商、支付、物流、出行等业务体系，将这些能力整体接入千问，形成一个以自有生态为核心的闭环。腾讯&amp;nbsp;目前尚未对外展示完整方案，但从近期在 Agent 和多模态方向上的密集招聘来看，其下一步布局大概率仍将围绕微信这一超级入口展开。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/0c/0c08da37ff9047adf91ec2784c9765e8.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;表面上看，Agent 之争比拼的是模型能力，但更深层的竞争，实际上取决于谁能更稳定、更规模化地承接真实世界的复杂需求。&lt;/p&gt;</description><link>https://www.infoq.cn/article/JrwSzMTgarBg4Ims5vmr</link><guid isPermaLink="false">https://www.infoq.cn/article/JrwSzMTgarBg4Ims5vmr</guid><pubDate>Thu, 15 Jan 2026 11:13:35 GMT</pubDate><author>高允毅</author><category>阿里巴巴</category><category>生成式 AI</category></item><item><title>“商业版 HTTP”来了：谷歌 CEO 劈柴官宣 UCP，Agent 直接下单，倒逼淘宝京东“拆家式重构”？</title><description>&lt;p&gt;谷歌把“Agent 购物”这件事，推到了一个更标准化的层面：Universal Commerce Protocol（UCP）正式亮相。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;近日（1月11日），谷歌 CEO Sundar Pichai（绰号“劈柴”） 首次登上 NRF（美国零售联合会年会），在题为“人工智能平台转型及零售业的未来机遇”的主题演讲中宣布了该协议。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;按照谷歌的说法，UCP 是一项新的开放标准，目标是让 Agent 能够在线上直接买东西。在实现机制上，UCP 通过定义一组“代理商务的构建模块”，把端到端的购物流程拆解成可复用的能力组件：既覆盖推动商品发现与购买的关键动作，也延伸到下单后的体验与服务等环节。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌表示，这套设计将让生态系统在同一套标准下实现互操作，使任何 Agent 都能与任意商家进行对话，并自主完成从商品发现到结账的完整购物流程。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;该标准采用 Apache 2.0 开源许可证发布：&lt;a href=&quot;https://github.com/Universal-Commerce-Protocol/ucp&quot;&gt;https://github.com/Universal-Commerce-Protocol/ucp&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/8a/8ac749381cca480abba528ff41699a7b.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;很多人一看到这条消息就意识到：大事可能真要来了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;风险投资人 Linas Beliūnas 在LinkedIn 上评论称：“谷歌刚刚对‘商业’做了一件类似 HTTP 当年对 Web 所做的事情。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在他看来，UCP 的野心，是把电商 20 年来那条固定链路，“搜索—广告—商品页—结账”——压缩成“意图—Agent 推理—购买”：用户不再需要点击跳转，不再被迫参与 SEO博弈，也不再被传统的转化漏斗一层层“导流”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;进一步说，Beliūnas 认为，UCP 试图成为商业领域的“HTTP”——也就是所有由 AI 介导的交易背后，那层看不见、但不可或缺的基础设施，“品牌不再争夺用户注意力，他们将竞相争取被Agent选中。网站变得可有可无。这就是非人类商业的开端。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/2b/2b1750b564c1fe87991e9db7109580b5.jpeg&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;长期关注零售的连续创业者 Scott Wingo 甚至把谷歌这次在 NRF 上的一系列动作形容为一次“震撼与威慑（shock and awe）式”的进攻。他感叹自己在这个行业干了 30 年，“从来没见过现在这样的场面，真的太疯狂了。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在 Wingo 看来，NRF 过去一直带着点“昏昏欲睡”的气质：讨论的多是收银系统、收银机、POS，以及超市自助结账的传送带这些传统议题。而如今，它几乎已经变成了一场围绕 Agent Commerce（智能体商业）展开的大会。“这种变化，是我做梦都想不到的。”他说。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;统一零售界的新标准？&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;那么，UCP 到底是什么？&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;简单说，UCP 的目标是让 Agent 能够贯穿用户购买流程的各个环节：从商品发现、对比，到下单结账，再到购买后的支持服务，都可以在同一套标准下衔接起来。它想解决的核心问题是：用一个统一标准承载这些流程能力，而不是让商家和平台为不同 Agent、不同系统反复做一遍又一遍的对接。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/af/affc2226740f2bd401efbcd843d05752.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从谷歌给出的设计图可以看到整体思路：左侧是各种消费者触点——消费者在这些地方与 Agentic Commerce 交互。在谷歌的世界里，这些包括 Google AI Mode、核心搜索、Gemini 等。右侧是后台系统——零售商后台需要的订单管理、库存管理等能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;中间是六项能力：产品发现、购物车、身份绑定、结账、订单，以及其他垂直能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;中间是六个圆角矩形，其中三个是实线框，三个是虚线框。实线框的，是已经宣布、可用的能力。尚未上线的三项是：产品发现、购物车，以及其他垂直能力。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;围绕这六项能力，Scott Wingo 也给出了更具体的解读：&lt;/p&gt;&lt;p&gt;产品发现（Product Discovery）：目前官方并没有披露太多细节，但他判断，这很可能会与后续对 Google Shopping Feed 规范的扩展绑定在一起。未来 UCP 可能会提供类似“开关”的机制：商家可以决定哪些商品对 Agent 开放，Agent 也可以通过协议以不同方式拉取商品信息——某种程度上，这有点像 Stripe 的 Agentic Commerce 套件思路。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;购物车（Cart）：这是他认为“最值得盯”的部分。谷歌在图里用虚线框把它标出来，像是在释放一个强信号：UCP 可能要去挑战电商的“圣杯”——跨商家、多商品、由商家作为交易主体（merchant-of-record）的统一购物车。一句话：“一个购物车管全网”。他认为 ChatGPT/ACP 可能也有类似目标，但谷歌这次等于把这个方向直接摆到台面上。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;身份绑定（Identity Linking）：他推测这会涉及“识别你的 Agent”（某种 know your agent 的机制）、银行卡 token 化等能力，类似 Link 或 ShopPay 那套：如果系统能把你的身份与支付凭据映射成 token，就有机会实现自动填充信用卡信息等体验。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;结账（Checkout）：谷歌准备把 “Buy for Me” 做一次大升级——新结账入口将同时出现在搜索 AI Mode 和 Gemini 应用的符合条件商品页中，流程被压成三步“商品 → 确认订单 → 下单完成”，并将率先在美国上线。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;订单（Order）：一旦开始“在对话里结账”，就必须有一套双向的订单体验。一边是面向消费者：查看订单、取消、退货等；另一边是面向商家：拉取订单、处理履约、上传物流信息，并完成一整套购买后流程（退货、评价等）。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其他垂直能力（Other Vertical Capabilities）：这部分目前更像一个“兜底项”，官方也没有给出更多细节。他猜测它可能用于未来扩展到更多品类/行业，比如汽配、生鲜、B2B 等。当天新闻里被提到的客户之一是 Papa Johns（达美乐/披萨这种即时零售/本地履约场景），因此也不排除这块会成为一种“插件位”，让类似“ChatGPT App”式的体验从 UCP 的侧边接入。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;在这些能力下方，还有三个模块，代表底层通信方式：API、MCP，以及 A2A。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;谷歌同时强调，UCP 并不是一套孤立协议，它可以与其他 Agent 协议协同使用，例如其在去年发布的 Agent Payments Protocol（AP2）、Agent2Agent（A2A） 以及 Model Context Protocol（MCP）。Agent 与商家可以根据自身需求，灵活选择和组合协议中的不同扩展模块。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;其中，MCP 更像是一个“工具与上下文协议”，用于让 Agent 安全、标准化地访问各类工具；A2A 是谷歌推出的多 Agent 通信协议，用来支持 Agent 之间的协作与任务分工； 而 AP2 是去年底发布的，聚焦在支付层，试图为 Agent 执行交易提供可验证、可授权的支付机制。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而 UCP，看起来就是在这些协议之上的一次延伸，专门聚焦在零售这一层。可以说，谷歌这段时间在 Agent 协议这件事上确实是在“加班加点”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/24/243fc7c4415ac7a479eb2f2b3b8b95ac.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;当然，谷歌并不是第一个做这件事的。OpenAI 的 Agent Commerce Protocol&lt;/p&gt;&lt;p&gt;几个月前，OpenAI 其实也推出过一个 Agent 商业相关的协议，主打“即时结账”，帮助 Agent 发现商品并完成购买。而谷歌的一个巨大优势在于：绝大多数零售商本来就非常熟悉谷歌——比如 AdWords、广告投放，以及一整套谷歌企业服务。谷歌正在尽可能地利用这一点。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;UCP 真正要解决的问题：可发现性&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;UCP 的核心想法，是用一套协议建立“通用兼容性”。商家只需要一次性把“我卖什么、我怎么卖”按标准描述清楚，理论上就能在不同平台、不同 Agent 之间通用。而它真正想啃下的硬骨头，是 “可发现性”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;这对传统零售网站而言，意味着一次不小的变革：页面不再是交易的唯一入口，商品数据本身开始成为入口。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;为此，谷歌也在补“数据底座”。在扩展产品数据源部分，谷歌还在其 Merchant Seller 工具中为用户提供新的“数据属性”，以便品牌可以优化其产品列表，提升 AI 搜索排名。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;要知道，在 AI / LLM 时代，我们过去 20 年一直在为“关键词 + 四五个要点”优化商品页，但这恰恰是 AI 最不需要的东西。这些系统需要的是：内容爆炸 + 上下文，缺一不可。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;举个例子：一个自行车脚踏。几乎所有线上商品都可以有 50–100 个属性：螺纹结构、反光片数量、材质、重量、兼容标准……这叫“内容”。而“上下文”是：它更适合山地还是公路？兼容哪些车型？能不能和某些配件一起用？内容和上下文就像阴与阳，缺了任何一边，Agent 都很难可靠地做判断、更难可靠地下单。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;过去那套 Google 商品数据规范，更像一条长满杂草的碎石路；而 Agentic Commerce 需要的，是一条 30 车道的信息高速公路——是光纤，不是拨号。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;如果谷歌继续用旧的商品 Feed 规范来做 Agentic Commerce，在发现环节一定会失败。Gemini 拿不到足够的信息。这次他们终于开始补这一块：新增描述性文本属性、产品规格、Q&amp;amp;A、评论、特性列表、形态、口味、主题、兼容性信息、推荐配件、替代品等。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;官方说法是“新增数十个字段”。在 Scott Wingo 看来，这个数量大概会在 24–60 个之间；即便今天只先放出 20 个，也一定会很快扩展到 30、40 个——因为所有人都会意识到：这才是决定可发现性的关键。这些数据仍然通过 Merchant Center 上传，本质上可以理解为 Google Shopping Feed 2.0。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;他对所有品牌和零售商的建议只有一句：尽可能“疯狂”地扩展你的商品级内容与上下文。这将直接决定你在 AI 时代能不能被 Agent 选中、能不能“占领 Buy Box”。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;谁站队了&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;UCP 在发布之初，就集结了科技与金融领域的一批重量级玩家，包括 Shopify、Walmart、Target、Etsy、Wayfair、Visa、Stripe、Adyen 等。首日即吸引了 20 多家合作伙伴加入，这正是标准胜出的典型路径。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://static001.geekbang.org/infoq/13/134c45edcab47ba358657acb357548a6.png&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;从已公开的信息来看，这些合作方大致可以分为两类：&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;一类是零售商与电商平台，包括 Etsy、Wayfair、Target、Best Buy、Macy’s、Kroger、Home Depot、Gap Inc.、Sephora、Ulta、Zalando、Chewy、Carrefour、Flipkart、Shopee 等；&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;另一类则是支付与清算体系，如 PayPal、Stripe、Adyen、Visa、Mastercard、American Express、Worldpay。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;有意思的是，有网友注意到，蚂蚁金服（ANT Financial） 也已经出现在 UCP 的合作名单中。有人评论称：“蚂蚁已经接入 UCP，但阿里巴巴推出自己的 Agentic Commerce 平台和 AI 协议，恐怕只是时间问题。”&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而从阿里最近的动作来看，这个判断并不突兀。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;1 月 15 日（今天），阿里千问 App 上线全新 AI Agent 能力“任务助理”，并打通淘宝、闪购、飞猪、高德与支付宝等应用：用户只需一句“我要两杯奶茶”，Agent 就能自动完成选店、选地址、选商品并生成订单，最后一步再由用户确认支付。延伸阅读：《&lt;a href=&quot;https://mp.weixin.qq.com/s/WXM2h4Z9DXrhVaoCjnt-ew&quot;&gt;刚刚，阿里园区被奶茶包围，都是千问点的！西溪叫不动外卖了&lt;/a&gt;&quot;》&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;整体看下来，一个趋势已经很难忽视：走到 2026 年，Agent 不再是大厂用来展示技术实力的“玩具”，而是开始被当成真正的赚钱工具。Agent 正在明显加速进入真实的应用场景，尤其是交易和服务这些最硬的地方。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;说得更激进一点：AI 很可能会把“社交 + 电商 + 服务”这套组合重新洗牌一遍。虽然“重做一遍”这个说法已经被用烂了，但眼下发生的变化，确实不像是在原有体系上打补丁，而更像是在重写入口、链路和分发规则——估计淘宝、京东这种级别的平台，迟早都得跟着重构一遍。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;而且，这种变化最近已经变得非常明显了。&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&lt;p&gt;参考链接：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://blog.google/products/ads-commerce/agentic-commerce-ai-tools-protocol-retailers-platforms/&quot;&gt;https://blog.google/products/ads-commerce/agentic-commerce-ai-tools-protocol-retailers-platforms/&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=OXUn970YHVo&quot;&gt;https://www.youtube.com/watch?v=OXUn970YHVo&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.finextra.com/pressarticle/108486/ant-international-embraces-googles-universal-commerce-protocol&quot;&gt;https://www.finextra.com/pressarticle/108486/ant-international-embraces-googles-universal-commerce-protocol&lt;/a&gt;&quot;&lt;/p&gt;&lt;p&gt;&amp;nbsp;&lt;/p&gt;</description><link>https://www.infoq.cn/article/5uNUBZjeBEhLY24tNdG9</link><guid isPermaLink="false">https://www.infoq.cn/article/5uNUBZjeBEhLY24tNdG9</guid><pubDate>Thu, 15 Jan 2026 11:09:21 GMT</pubDate><author>Tina</author><category>生成式 AI</category></item></channel></rss>